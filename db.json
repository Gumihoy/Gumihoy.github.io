{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/hexo-theme-matery/source/favicon.png","path":"favicon.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/barrager.css","path":"css/barrager.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/bb.css","path":"css/bb.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","path":"css/gitment.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/matery.css","path":"css/matery.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my.css","path":"css/my.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/jquery.barrager.js","path":"js/jquery.barrager.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/matery.js","path":"js/matery.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","path":"medias/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","path":"medias/comment_bg.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","path":"medias/cover.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","path":"medias/icp.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","path":"medias/logo.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","path":"libs/background/canvas-nest.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","path":"libs/background/ribbon-dynamic.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","path":"libs/background/ribbon-refresh.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","path":"libs/background/ribbon.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","path":"libs/instantpage/instantpage.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/minivaline/MiniValine.js","path":"libs/minivaline/MiniValine.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/prism/prism.css","path":"libs/prism/prism.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/twikoo/twikoo.all.min.js","path":"libs/twikoo/twikoo.all.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/twikoo/twikoo.all.min.js.LICENSE.txt","path":"libs/twikoo/twikoo.all.min.js.LICENSE.txt","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/barrager/0.png","path":"medias/barrager/0.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/barrager/1.png","path":"medias/barrager/1.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/barrager/2.png","path":"medias/barrager/2.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/barrager/close.png","path":"medias/barrager/close.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","path":"libs/awesome/css/all.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","path":"libs/awesome/webfonts/fa-brands-400.eot","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","path":"libs/awesome/webfonts/fa-brands-400.svg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","path":"libs/awesome/webfonts/fa-brands-400.ttf","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","path":"libs/awesome/webfonts/fa-brands-400.woff","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","path":"libs/awesome/webfonts/fa-brands-400.woff2","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","path":"libs/awesome/webfonts/fa-regular-400.eot","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","path":"libs/awesome/webfonts/fa-regular-400.svg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","path":"libs/awesome/webfonts/fa-regular-400.ttf","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","path":"libs/awesome/webfonts/fa-regular-400.woff","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","path":"libs/awesome/webfonts/fa-regular-400.woff2","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","path":"libs/awesome/webfonts/fa-solid-900.eot","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","path":"libs/awesome/webfonts/fa-solid-900.svg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","path":"libs/awesome/webfonts/fa-solid-900.ttf","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","path":"libs/awesome/webfonts/fa-solid-900.woff","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","path":"libs/awesome/webfonts/fa-solid-900.woff2","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/gallery.css","path":"css/gallery.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/crypto-js.js","path":"js/crypto-js.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/gallery-encrypt.js","path":"js/gallery-encrypt.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/Meting.min.js","path":"libs/aplayer/Meting.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/fancybox/fancybox.js","path":"libs/fancybox/fancybox.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/fancybox/jquery.fancybox.css","path":"libs/fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery-3.6.0.min.js","path":"libs/jquery/jquery-3.6.0.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/justifiedGallery/justifiedGallery.min.css","path":"libs/justifiedGallery/justifiedGallery.min.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/justifiedGallery/justifiedGallery.min.js","path":"libs/justifiedGallery/justifiedGallery.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.js","path":"libs/mermaid/mermaid.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.min.css","path":"libs/mermaid/mermaid.min.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.min.js","path":"libs/mermaid/mermaid.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/TencentCaptcha.js","path":"libs/others/TencentCaptcha.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-half.js","path":"libs/others/sakura-half.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-reduce.js","path":"libs/others/sakura-reduce.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-small.js","path":"libs/others/sakura-small.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura.js","path":"libs/others/sakura.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/snow.js","path":"libs/others/snow.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/star.js","path":"libs/others/star.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/waline/Waline.min.js","path":"libs/waline/Waline.min.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/images/01.jpg","path":"medias/images/01.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/images/02.jpg","path":"medias/images/02.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/images/03.jpg","path":"medias/images/03.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.min.css","path":"libs/awesome/css/all.min.css","modified":1,"renderable":1}],"Cache":[{"_id":"source/about/index.md","hash":"15813636fc0fa56c43626f223171dd984b7b4157","modified":1625020404809},{"_id":"source/categories/index.md","hash":"152a0c964c8176980d3eea2ed00adfd17d3866ca","modified":1625020404809},{"_id":"source/404/index.md","hash":"eed726178733e2ff858d435d866cf21f7442cb42","modified":1625020404547},{"_id":"source/tags/index.md","hash":"15ea7e881a06ddd9f909e963d15a0b4aafbee6e0","modified":1626320837605},{"_id":"source/.DS_Store","hash":"798bcafcad86f9269fe8d8a40218b9a6a401e85e","modified":1626412177206},{"_id":"source/_posts/01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的.md","hash":"0ca79dd61f3e89323f2cf068c82855a81395e244","modified":1625020404547},{"_id":"source/_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的.md","hash":"ae3e1348382a0d779fd07165d2b1d02ae1e8fe19","modified":1625020404550},{"_id":"source/_posts/03-MySQL实战45讲-事务隔离：为什么你改了我还看不见.md","hash":"ee1c6ea72733d2c90b46a8a4b44785a6583e455a","modified":1625020404558},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）.md","hash":"2e54fb9637c971e79ece664118b5c7cbbb394072","modified":1625020404560},{"_id":"source/_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响.md","hash":"c46670af65bcab21d69f268db129eb5ffc9c36a0","modified":1625020404570},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）.md","hash":"7aa2b6192f391281bc6836482898b765021f88c1","modified":1625020404565},{"_id":"source/_posts/06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍.md","hash":"fedeed70e8a9942c43e834c20840c01e56e998b1","modified":1625020404569},{"_id":"source/_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的.md","hash":"67f368b27706a6b1aecff4cc539d7b9509ec8100","modified":1625020404572},{"_id":"source/_posts/09-MySQL实战45讲-普通索引和唯一索引，应该怎么选择.md","hash":"8964e49a31ed95e1125ac4aa8c1e269fb8561a7b","modified":1625020404576},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引.md","hash":"c5edf8cece048e83ddc996ef528b739f666d2b59","modified":1625020404576},{"_id":"source/_posts/11-怎么给字符串字段加索引.md","hash":"640f5d613f8abdb542bd3cd8e87952e0f5b4f8c6","modified":1625020404589},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题.md","hash":"b29abd29c07026f1743544f2aa572effb43e38d3","modified":1625020404605},{"_id":"source/_posts/14-count-这么慢，我该怎么办.md","hash":"dcb2a66fd8b0dba4599392696e895e196da21b47","modified":1625020404602},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下.md","hash":"10e16000c2d4d0a1dd4105474785b1ba8c3dbdc4","modified":1625020404592},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变.md","hash":"192f4bf3a128d9e52c8439b938933fdc04bc4542","modified":1625020404598},{"_id":"source/_posts/17-如何正确地显示随机消息.md","hash":"4d07ba0528e779b4ec0c428efea39d695e548f4c","modified":1625020404618},{"_id":"source/_posts/16-“order-by”是怎么工作的.md","hash":"43f27e0d6cbabad53f64ac67bb1d5b1d39b8f88b","modified":1625020404610},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大.md","hash":"4ab7abc4e5534e654ea1f37c6f77d0f5dde6ca56","modified":1625020404624},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢.md","hash":"260d06e975e3918ff5e1461a9f33c8588db66f3e","modified":1625020404633},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题.md","hash":"59adbcde520e389219e686ac5479639f1bccccb7","modified":1625020404645},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多.md","hash":"1abf0a28f6553f847c1796eeeeaf2ecd17beca2d","modified":1625020404651},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的.md","hash":"b71758ecd52a078c37a4a523c0700b5f6ca05245","modified":1625020404664},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法.md","hash":"7227a6cdb0f89f0e1d028ed6e894f247e717ba39","modified":1625020404659},{"_id":"source/_posts/27-主库出问题了，从库怎么办？-GTID.md","hash":"5d4b5d50eafeb3ff9293dd057e396764aa8ecf19","modified":1625020404689},{"_id":"source/_posts/25-MySQL是怎么保证高可用的.md","hash":"38ec1d832d9e27162bec32f1a654cd0b3fc8e8e2","modified":1625020404683},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的.md","hash":"9a5eacfad5fd87e8ad8a15c94d0b4dfe78f4226c","modified":1625020404671},{"_id":"source/_posts/26-备库为什么会延迟好几个小时？－并发逻辑.md","hash":"b2684ee91fe6d97850ecc758bf6d8819052b905c","modified":1625020404689},{"_id":"source/_posts/28-读写分离有哪些坑.md","hash":"399dc1a304e87cd63cd00fe74c5f5950d9c3fff3","modified":1625020404689},{"_id":"source/_posts/29-如何判断一个数据库是不是出问题了.md","hash":"c26701976a10c8591f3e0ee623bea60e289e62b8","modified":1625020404689},{"_id":"source/_posts/30-答疑文章（二）：用动态的观点看加锁.md","hash":"ccc3ac9db36782edd6dce60c564ee4bd44c12696","modified":1625020404689},{"_id":"source/_posts/32-为什么还有kill不掉的语句.md","hash":"c3923239da2a8ee4c720b1fc61b44d22fbd88296","modified":1625020404689},{"_id":"source/_posts/31-误删数据后除了跑路，还能怎么办.md","hash":"7ec3534173df7f1526d28373de9ca1bc81440068","modified":1625020404689},{"_id":"source/_posts/33-我查这么多数据，会不会把数据库内存打爆.md","hash":"ab37aa407a4344670170b2e16d9a1064870f6ce6","modified":1625020404690},{"_id":"source/_posts/34-到底可不可以使用join.md","hash":"f82af01ec2e61f02b21cff3e84a518bf47886327","modified":1625020404690},{"_id":"source/_posts/35-join语句怎么优化.md","hash":"bac519dc45bd6b7ea89a7398bf602bacf89f7f0e","modified":1625020404690},{"_id":"source/_posts/36-MySQL的limit用法和分页查询的性能分析及优化.md","hash":"40173eab10593cf5ea871c79fbd5a81529be1dbe","modified":1625020404690},{"_id":"source/_posts/37-MySQL-优化之-index-merge-索引合并.md","hash":"360b5798b7ff1d5b1746d81be29c77de880347c5","modified":1625020404690},{"_id":"source/_posts/46-为什么临时表可以重名.md","hash":"6c7dbc2910bb9b8fa0020aa27da1f71e2051ef9f","modified":1625020404690},{"_id":"source/_posts/47-什么时候会使用内部临时表.md","hash":"cad2e358acafcf83ae8a7113e687d9d0a6e1881b","modified":1625020404691},{"_id":"source/_posts/49-自增主键为什么不是连续的.md","hash":"f0d8142e622336eda33440ddb7442c6a221fcc45","modified":1625020404691},{"_id":"source/_posts/50-insert语句的锁为什么这么多.md","hash":"f9d2277b676de9423eb57703a09030aec27a20ac","modified":1625020404691},{"_id":"source/_posts/48-都说InnoDB好，那还要不要使用Memory引擎.md","hash":"c3e8e73deac7462bb5a78c604e66aced909c1fed","modified":1625020404691},{"_id":"source/_posts/51-怎么最快地复制一张表.md","hash":"efff6f26bc2e2efdded39a85b1ce6378e9e578cd","modified":1625020404691},{"_id":"source/_posts/55-自增id用完怎么办.md","hash":"e74a1f451e43edbaefb5328206ffabe7606c675d","modified":1625020404692},{"_id":"source/_posts/53-要不要使用分区表.md","hash":"47cd25940f63f3fbed796e6c790c68478e5e92ac","modified":1625020404692},{"_id":"source/_posts/56｜InnoDB中的doublewrite-buffer技术原理.md","hash":"94c89d3289a516ea99925248e22102f6aa67311a","modified":1625020404693},{"_id":"source/_posts/54-答疑文章（三）：说一说这些好问题.md","hash":"010f868694336f688a672cd5d3e8b64887dadc77","modified":1625020404692},{"_id":"source/_posts/58-MySQL侧如何分析服务响应速度.md","hash":"f04e68c8db02010edd8b3c9f32167c29e5700888","modified":1625020404693},{"_id":"source/_posts/57-【bug】Mysql5-6-UK索引列过长.md","hash":"40d4449efd4fe2bd5c48952f6c4dfa0bb99d7a8b","modified":1625020404693},{"_id":"source/_posts/52-grant之后要跟着flush-privileges吗.md","hash":"b760b39516a998178706779931991852aa99b06f","modified":1625020404692},{"_id":"source/_posts/59-InnoDB-中buffer-pool（bp）的技术原理.md","hash":"8c0c44fec11f7f14545b38f1276613d682375f22","modified":1625020404693},{"_id":"source/_posts/60-倒排索引原理和实现.md","hash":"3cbe02f90325e267a98535dfad8f6e1b609b7e64","modified":1625020404693},{"_id":"source/_posts/C4.5算法.md","hash":"e4e9675e2cc4e062749d4ce36e337138fbd067d2","modified":1625020404693},{"_id":"source/_posts/EM算法.md","hash":"0e3be9178c8a5c46004c9b0dc2dfb822eb77ef64","modified":1625020404694},{"_id":"source/_posts/Elasticsearch安装.md","hash":"d5da06eccd1fe787bbff45ae4d9e6e75f803d28e","modified":1625020404694},{"_id":"source/_posts/CART算法.md","hash":"6e194acc88d7eb4d5fa3d073eb77f633c0fea7ce","modified":1625020404694},{"_id":"source/_posts/Github搭建Hexo.md","hash":"9fddd9ce7ebb20c1a232b02277a7fc0de60c2423","modified":1625020404694},{"_id":"source/_posts/Homebrew.md","hash":"3e5635baaba55756541102220cd1d91ae0de38cf","modified":1626423683779},{"_id":"source/_posts/ID3算法.md","hash":"3ec2ab79f6b247bce42141a7b96bf8fb06cd35d2","modified":1625020404699},{"_id":"source/_posts/Java-Agent详解.md","hash":"36e7fac410fcf04da90f29c3091d9e48c70d7257","modified":1625020404699},{"_id":"source/_posts/Java使用Redis.md","hash":"8a68400b0e51278f303391368a71e6c39c60d26c","modified":1625020404703},{"_id":"source/_posts/Java常见问题总结.md","hash":"3edae2fb08e67ceba4a748945deba02f3cf0142f","modified":1625020404703},{"_id":"source/_posts/Java环境配置.md","hash":"86a16c5a5def77bb062f442316b4b7800ce7c44a","modified":1626357833394},{"_id":"source/_posts/Joda-Time总结.md","hash":"584548f59083ea66787a00f090f9d424bceb4059","modified":1625020404703},{"_id":"source/_posts/Kafka安装.md","hash":"ba99f7deeb3c2d046cdf1a5be7fa20a82d9dcb44","modified":1625020404703},{"_id":"source/_posts/K近邻算法.md","hash":"5f21ce8f0e761580b7ab2d0ac55db0294ae4e7ad","modified":1625020404704},{"_id":"source/_posts/LaTeX教程.md","hash":"b5e902b5513d20a6a7d50898930a11ed1c233e7d","modified":1625020404704},{"_id":"source/_posts/Mac.md","hash":"7dacf0ffadbb433336123b686e01b9fed86f0674","modified":1626583372679},{"_id":"source/_posts/Linux.md","hash":"725c672a0fffa69b1be4ec8f59851627fa88a777","modified":1626401048380},{"_id":"source/_posts/Mac安装Git.md","hash":"df4ab8d51f42367242cbc84f777f96011219be64","modified":1625020404714},{"_id":"source/_posts/Markdown教程.md","hash":"7ccc6fc1710eed55f1aae769e18eaf632d494064","modified":1625020404715},{"_id":"source/_posts/MongoDB安装.md","hash":"893e4a5df66eb280b3e9b0f33f324acfa06b4426","modified":1625020404715},{"_id":"source/_posts/MySQL汇总.md","hash":"a99f1ed3a30c530da2afc019827f500b36b0ddc5","modified":1625020404717},{"_id":"source/_posts/MongoDB教程.md","hash":"8b74f98dec137ce71e2d4c021d1f69c48d826903","modified":1625020404717},{"_id":"source/_posts/MySQL实战45讲.md","hash":"12faac062b86dffaf177acd6122b83bcd4ff72a1","modified":1625020404717},{"_id":"source/_posts/MongoDB设计与实现.md","hash":"5909a41af11edd4cd5312dad76156fcd717d23a9","modified":1625020404717},{"_id":"source/_posts/MySQL索引.md","hash":"63b63ded716a6b32d07fb04998fc538f874b0c93","modified":1625020404718},{"_id":"source/_posts/MySQL锁.md","hash":"af41826a4a11f687565d18c63ffe431dbc38eee4","modified":1625020404718},{"_id":"source/_posts/PyTorch教程.md","hash":"9f4f2a6fc09c4eb348f0b8223dbe97efed309410","modified":1625020404719},{"_id":"source/_posts/Oracle转EDB总结.md","hash":"e3b6334cea88b6afe62c06f58f8536e02b72b188","modified":1625020404718},{"_id":"source/_posts/Redis安装.md","hash":"2b9769f82b5130749cb1c6b37a4d1919e0566efc","modified":1625020404719},{"_id":"source/_posts/Oracle转Postgresql总结.md","hash":"ebb63a8111f8acc93899c846410c59338bfe02d6","modified":1625020404719},{"_id":"source/_posts/Oracle转MySQL总结.md","hash":"f5e29b89b34b69e324887328148d2b13492ba823","modified":1625020404719},{"_id":"source/_posts/Redis开发规范.md","hash":"1fbeb74ab3db0e77cb344d7a86fcf899ea628750","modified":1625020404720},{"_id":"source/_posts/Redis教程.md","hash":"0fc27adfe430032f530a9522b74cee00aec5ecfb","modified":1625020404720},{"_id":"source/_posts/Redis设计与实现.md","hash":"140f630555c340565a28f9e5c689fac5b2dc7697","modified":1625020404720},{"_id":"source/_posts/SQL运算符优先级.md","hash":"cb06ced00f67a3e718d3c90986e71780f7e0733e","modified":1625020404729},{"_id":"source/_posts/SpringBoot应用启动原理分析.md","hash":"022bd8d9dfd47704aeb58737233e02f4762d8b91","modified":1625020404729},{"_id":"source/_posts/SpringBoot集成Elasticsearch.md","hash":"89bbffe2a6be7e185983042a5325981f717652b8","modified":1625020404729},{"_id":"source/_posts/ZooKeeper安装.md","hash":"a6daca353985f6649e1ebc5ac39dff29893191f4","modified":1625020404729},{"_id":"source/_posts/SQL词法分析器问题总结.md","hash":"2d3cfb7c2837f0aee1f4fae2e71dc8d01d517294","modified":1625020404728},{"_id":"source/_posts/lrzsz.md","hash":"01f82498d2ccae7a6119301ae7b66225eabdda80","modified":1646879442006},{"_id":"source/_posts/iTerm2.md","hash":"9bf537040086a10e8e821243726854ecdadfa691","modified":1626579349985},{"_id":"source/_posts/python教程.md","hash":"21942f98c3fb26920a40432eabe9d5dd2a137aa1","modified":1625020404771},{"_id":"source/_posts/tensorflow教程.md","hash":"2090c9ad20da908da7230c7e86823b24b708f468","modified":1625020404771},{"_id":"source/_posts/thrift教程.md","hash":"7872d491d0cb1b60213de99b05cbb67502ec23b4","modified":1625020404775},{"_id":"source/_posts/中文分词.md","hash":"c5931cc730178997df282e70ab13c32fb9d05c3e","modified":1625020404776},{"_id":"source/_posts/交叉熵.md","hash":"bdea1b1376eadaee7f22922616fe34addbd61c01","modified":1625020404776},{"_id":"source/_posts/人工神经网络.md","hash":"f2bdae9dc528124772b02f6eac08d5b3b2f8a6c7","modified":1625020404777},{"_id":"source/_posts/信息熵.md","hash":"96e0e5033216f1dd893fbe9b012ccc1814522494","modified":1625020404777},{"_id":"source/_posts/前馈神经网络.md","hash":"40704bee80490350647940731aa0fd5a050718d4","modified":1625020404778},{"_id":"source/_posts/半朴素贝叶斯算法.md","hash":"1ffaf798d128513beb3bbe3ab78f2721b91c8d2c","modified":1625020404778},{"_id":"source/_posts/创建SecureRandom过慢问题.md","hash":"971d0938120afe3eb81ae2c2f126fb76f4e7172f","modified":1625020404778},{"_id":"source/_posts/哈希-Hash-函数汇总.md","hash":"0d29c1ec268aee79a65c6215c4317bbf1ed47dd5","modified":1625020404779},{"_id":"source/_posts/卷积神经网络.md","hash":"9b939ca9802bb917b9cd7948abefcdc2646c647a","modified":1625020404778},{"_id":"source/_posts/微积分.md","hash":"4ecb8fc37b652bc75907a815f4789d3fed4cd76f","modified":1625020404779},{"_id":"source/_posts/感知机算法.md","hash":"43b4dce53a14d4e84e98cb7a39e8b7e3dbe138db","modified":1625020404779},{"_id":"source/_posts/排序算法汇总.md","hash":"b5526509fb3b58a03a192c14da8d7864322abcac","modified":1625020404779},{"_id":"source/_posts/协方差.md","hash":"075c96bb6309bf88577d4e55c2b18dacb9aa7ae0","modified":1625020404778},{"_id":"source/_posts/支持向量机.md","hash":"578b0f9d68a12802552d4b616355e2c9734a9ffd","modified":1625020404780},{"_id":"source/_posts/期望值.md","hash":"12e5440608ccde1b600c83fa9e1b328ee9790e74","modified":1625020404780},{"_id":"source/_posts/方差.md","hash":"f1f02aa7a315bf9ecb3d46632595aa9ff6d0154f","modified":1625020404780},{"_id":"source/_posts/机器学习.md","hash":"1d80b885d1db0e2c0bdc46a95037477c9d6ab77e","modified":1625020404780},{"_id":"source/_posts/朴素贝叶斯算法.md","hash":"f8fd73cdd78acfc9415810d7c0ef9a4cd87b6d6c","modified":1625020404780},{"_id":"source/_posts/查看class文件的jdk编译版本.md","hash":"d8e354464b9e8ff46b81a895577d6c4a9340cb13","modified":1625020404781},{"_id":"source/_posts/条件熵.md","hash":"e820e8ae22437c17510c0769c0e0b43b9670aac1","modified":1625020404781},{"_id":"source/_posts/标准差.md","hash":"de104901bfadd73ac4f71a4a4183653905bfa69e","modified":1625020404781},{"_id":"source/_posts/极限.md","hash":"fc0a4d1eb19aebf724a90055316c505ead7364d0","modified":1625020404781},{"_id":"source/_posts/语法分析器的设计和实现.md","hash":"664f0c7104dbf12afbc7be3f6634eedc8485e823","modified":1625020404782},{"_id":"source/_posts/编译器-vs-解释器：编译器和解释器之间的区别.md","hash":"7087cf12ec05e8b28ee000452a148b03c95bb4c7","modified":1625020404782},{"_id":"source/_posts/设计模式总结.md","hash":"08d31bf72ce709a9de23484b0bbf849cbc481a69","modified":1625020404782},{"_id":"source/_posts/编译原理.md","hash":"104f56f4b9cfcb52757c5456f6246335581dba18","modified":1626356468884},{"_id":"source/_posts/递归神经网络.md","hash":"0ff095d524b16da99eaae211ce1b855b46e56355","modified":1625020404808},{"_id":"source/_posts/调用链上下文跨线程传递.md","hash":"65026f5a3365dfc37265bbc03dc75aab31012584","modified":1625020404807},{"_id":"source/_posts/贝叶斯网算法.md","hash":"a8fdb243d95b64748b2c17f4426a85bd66f1785e","modified":1625020404808},{"_id":"source/_posts/面试知识点总结.md","hash":"78769286b0f56dba2ae5cd510d0435fe56ab48ac","modified":1625020404808},{"_id":"source/_posts/负载均衡算法.md","hash":"210842a111cef2790c971afe6b9cdf9bc5034ac5","modified":1625020404808},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg","hash":"9c05ac8bf00fbd4731530de08c220663f26a6996","modified":1625020404579},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg","hash":"0fd9cea75ea2d637acd967609cf3e8fdaf4936f8","modified":1625020404582},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg","hash":"4024e1a6b7b3b6dae44338ca01376ee22029e055","modified":1625020404586},{"_id":"source/_posts/11-怎么给字符串字段加索引/1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg","hash":"4ba3f41a6b2141df49bf7bcce1157ebfecd16ec4","modified":1625020404591},{"_id":"source/_posts/11-怎么给字符串字段加索引/1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg","hash":"f00df976ff1a34bb1db3f93c049cc904077714c4","modified":1625020404590},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg","hash":"973e4ad3035b13b11503898fa36732af6cf4494e","modified":1625020404598},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg","hash":"cd6638158cd4b76dd9fa1fb7d0f1692856292910","modified":1625020404599},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg","hash":"032ad785a430b79eacb0dccfd8b4a982e0986b0a","modified":1625020404603},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg","hash":"b9aceb262e466e38c83f8601b44c17a2312de7e2","modified":1625020404603},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg","hash":"fbf96b93fc7dfb1b1b558a5db1fe0c14c57396c3","modified":1625020404604},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg","hash":"5c174dd31e2fa8bcef9f9760cb8d220b65256b77","modified":1625020404605},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg","hash":"1be27934c1ac7a37e40de395e1bb2e3a418c347c","modified":1625020404604},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg","hash":"e219f4bc52e28c8ab70d35bd7ee9ab2c956ce9da","modified":1625020404606},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg","hash":"542043ac284547a03c69fd9b5196e426d1316890","modified":1625020404606},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg","hash":"270c2ea0e5173d5b80ee5784f97f1bfccfc7cd64","modified":1625020404609},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg","hash":"b2bb32ad6d6204ed0f07c6aa70ccaeb2e000b58c","modified":1625020404608},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg","hash":"81832f1306ddf3e9bd0d5cc445a0d382943f1309","modified":1625020404611},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg","hash":"66293293a51c7df816c5de8238adf8317e2aeee2","modified":1625020404612},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg","hash":"19d69377856bbe9e684c15302a2affbde6441a66","modified":1625020404617},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg","hash":"f6f6807b9aee3f1901a5a084af8ccf6f592f1060","modified":1625020404622},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg","hash":"77987f8178b0d8f3e6e656f4b50e4cd784ae3647","modified":1625020404630},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg","hash":"0417f66c12cf4c94ad840ab85f79550bdfee1668","modified":1625020404632},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg","hash":"cefae60ee8df9bc58e57cb4710c308c81be878f4","modified":1625020404646},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg","hash":"f9f43be2c32586802ece54153ba37efbda2f781f","modified":1625020404646},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg","hash":"8a92e5351e38185ce02d50a237989f87c52ab53a","modified":1625020404647},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg","hash":"3b380fa87e6815954d3ad0bfd638a3db38d283c3","modified":1625020404648},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg","hash":"729f59c0f2e626e71032e4e09313d34f1af5b10e","modified":1625020404650},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg","hash":"77360b2796e2c7aaa9ae441435c978652a43f7a2","modified":1625020404633},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg","hash":"3b065b91b4562b1405e8f4c46975aa5d67af6c88","modified":1625020404635},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg","hash":"b23f7e7c4540d089f3799e3d44be95934858a6d7","modified":1625020404634},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg","hash":"654a1bd74d29430f9f41c2523e505de72823e43a","modified":1625020404636},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg","hash":"142d70c4dd3cd2699f5d23c19783ed08aa137822","modified":1625020404636},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg","hash":"2d7067bc4db84f5d68ee2e57c8ea5fd995ae6e14","modified":1625020404637},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg","hash":"b319610e516d4b1a2fc61fb8ac9eaaae0881e75b","modified":1625020404638},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg","hash":"ab5a98d33111314f6f77bece7de7f32711236295","modified":1625020404638},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg","hash":"9086401053ba3062a7eb1eea6187ab7edc4b3d25","modified":1625020404639},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg","hash":"c934b89e2bf6ce6b59d45185e179dda11ac62c58","modified":1625020404642},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg","hash":"d950c482e2ce326dbed6f7331d8a8165a87d4be4","modified":1625020404645},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg","hash":"d18ddb8a2e07be3454dca5b2662c158731647843","modified":1625020404652},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg","hash":"27ffc4f2dfce0a52e8c524fb6db9b2f50a5af5cb","modified":1625020404655},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg","hash":"eaaf9fc1e85e015ebead5d4401e6cc61a63c4f96","modified":1625020404654},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg","hash":"29f5b4d638f22e8fc29200e6f4a51c4b8d3f673d","modified":1625020404653},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg","hash":"e2357f7a47e88c78d673dda708647f6fd2ee1f96","modified":1625020404654},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg","hash":"fbedd69ae1c0ddb873e771ea5fe7f60f45071205","modified":1625020404656},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg","hash":"7885b779f3c762fe3244c88bbbf8284b8407111f","modified":1625020404658},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg","hash":"902ac2c139be305cd3aea77b47b2a068fef1c184","modified":1625020404659},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg","hash":"16737aac9534c95177369745b3de56e0bc60cfb6","modified":1625020404661},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg","hash":"43776d83d390cac1d0e2a04215df533698598fe0","modified":1625020404660},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg","hash":"5eae7686b0cd9c33f2f6ac9319c3cadcf209d4d6","modified":1625020404658},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpeg","hash":"7ccfca09e1a58bb3d7b3f276c7072e92300c0f26","modified":1625020404684},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg","hash":"fdefd755bd00c669d7745fc08bf045e46964cc61","modified":1625020404667},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpeg","hash":"2a95d21061447428558ba65359a4dbe8e885dd6a","modified":1625020404688},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpeg","hash":"bc721b44d72aeed2a1723d0a9946d1ebf9fd885d","modified":1625020404671},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg","hash":"3863ec6e093bbdf993c6d4de89a4c94e48f17e5b","modified":1625020404675},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg","hash":"9aa25035d0f4760822d63a9fcfa96a50420ec727","modified":1625020404677},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg","hash":"e2215e46472182b35f22c5a75bbd0216944d7f9d","modified":1625020404677},{"_id":"source/_posts/Redis设计与实现/graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png","hash":"9589587ae012ed1578f656ca3d55548f058ca56b","modified":1625020404722},{"_id":"source/_posts/Redis设计与实现/graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png","hash":"8fb35d52fae7bb70ccdea766c8478a73db870ea0","modified":1625020404722},{"_id":"source/_posts/Redis设计与实现/graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png","hash":"8bfd7c4e974653323164bce9b25ceae8eeec2418","modified":1625020404721},{"_id":"source/_posts/Redis设计与实现/graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f.png","hash":"b9289eb1d7550aa01056e1b829ad03df1c1de091","modified":1625020404723},{"_id":"source/_posts/Redis设计与实现/graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png","hash":"a068b49bba0ce76d72f9cb4f0de4a467cd19c2dc","modified":1625020404724},{"_id":"source/_posts/Redis设计与实现/graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png","hash":"4623c92c85483ed8e3d95a4d39365e4a6fcc2ce3","modified":1625020404723},{"_id":"source/_posts/iTerm2/Setting_Default_Term.png","hash":"d40b21b367880a4ef42c11f4eadf02d740a8f463","modified":1626424687641},{"_id":"source/_posts/iTerm2/logo2x.jpg","hash":"aa9f010f51a2051e84c699c46f40bc604b5ef4e2","modified":1625020404771},{"_id":"source/_posts/assets/test.drawio.svg","hash":"8eb271d51d37a40d2ff2da8b7255acd8133118d8","modified":1625020404759},{"_id":"source/_posts/assets/test1.drawio.png","hash":"61507ff23a5a8fde8381241bc4ad02f4e0717d1d","modified":1625020404760},{"_id":"source/_posts/人工神经网络/1543648111947.jpg","hash":"d1ae47e013dc99883394317fef4095a16310caa3","modified":1625020404777},{"_id":"source/_posts/thrift教程/thrift-layers.png","hash":"8950d509517f7128feb0c295cbe29f2fa849e345","modified":1625020404776},{"_id":"source/_posts/语法分析器的设计和实现/test.drawio.svg","hash":"8eb271d51d37a40d2ff2da8b7255acd8133118d8","modified":1625020404804},{"_id":"source/_posts/语法分析器的设计和实现/test1.drawio.png","hash":"61507ff23a5a8fde8381241bc4ad02f4e0717d1d","modified":1625020404804},{"_id":"source/_posts/03-MySQL实战45讲-事务隔离：为什么你改了我还看不见/1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg","hash":"d3fd82dff1a810dce10fcb019973f3a15bee7e3e","modified":1625020404560},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg","hash":"cad313d7963a5b2334cacfac4f1602d64222f85f","modified":1625020404563},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg","hash":"fd2e71097d6368c98ec74f4215096cea2f5f158c","modified":1625020404562},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg","hash":"7867612fe02da163332cd8278a8356e618fbfbae","modified":1625020404564},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","hash":"63d44e9e5ab30a920c4dea005d930b2ac4051ad6","modified":1625020404564},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg","hash":"e27f6851ada21e8ba176fb30a45e2f6d1f9dc7b2","modified":1625020404567},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","hash":"63d44e9e5ab30a920c4dea005d930b2ac4051ad6","modified":1625020404566},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg","hash":"bd18149f40012ef1e22e9209b8c723e44df1f5ea","modified":1625020404569},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg","hash":"c89ee622467e342e527bad2108c7d22043d6bbd5","modified":1625020404567},{"_id":"source/_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响/1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg","hash":"b4a65ce4b8e94e659a3d7b4e970b2f6563c1d5c8","modified":1625020404571},{"_id":"source/_posts/06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍/1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg","hash":"353ed96e240b9d3a3ad6b53302a9760d254b1021","modified":1625020404570},{"_id":"source/_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响/1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg","hash":"10712e12f6491371590f35c722da30766945c9d6","modified":1625020404572},{"_id":"source/_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的/1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg","hash":"bb732386b3bb8fbbef31762f774ad259e94048d3","modified":1625020404575},{"_id":"source/_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的/1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg","hash":"2f8a17d04de6e20dfce370c32fcea096745fed2b","modified":1625020404574},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg","hash":"6720c70668ce98af84c8389c284e4ebb7777e5b2","modified":1625020404578},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg","hash":"c19f4c0772816bd17127fe7a82a7097ba6fe3dc2","modified":1625020404579},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg","hash":"c4154f405ea6c7858b99e660a0a3b29160ed1cad","modified":1625020404585},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg","hash":"7f35feb9efa4ea50f1dbbddcbd67842bb941fa6c","modified":1625020404586},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg","hash":"4c321ba97030e45f32b1439f9ef6f7e92925ee2f","modified":1625020404597},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg","hash":"4120a964c174370ee5839174ceb18e8ae080a058","modified":1625020404602},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg","hash":"308de10672160a4693664566d46c20ed7d6cfaa7","modified":1625020404601},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg","hash":"11fb054ec4b08703ae94d7f494c0b8f84fb2cc70","modified":1625020404607},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg","hash":"de8fd2b3ed418c57eee3a7cb94f78bf5ed63a225","modified":1625020404611},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg","hash":"643bb28166a5f119284a720cde0e71387d682ce3","modified":1625020404609},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg","hash":"08af579d039508fe0c1da1f46095c23f8c77a00e","modified":1625020404613},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg","hash":"f91a872bd50003f917c9773103710fc863a807c6","modified":1625020404614},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg","hash":"c3e0c4520b5f7e7c5585d6d2ba32c7ebd24632b7","modified":1625020404615},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg","hash":"e6138ed0dd8911be92a899f234636ca60457c522","modified":1625020404615},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg","hash":"cf5f8c5193957c0d9256f848a70b303af8ecbf86","modified":1625020404616},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg","hash":"e285b73a4f932e2bc983148c3961f7611fc817f8","modified":1625020404617},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg","hash":"9160f9301cb762803fb0b569f682e52e573a844d","modified":1625020404617},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg","hash":"ca20a11ec6a932e65a4397bd62f08595e6da7491","modified":1625020404620},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg","hash":"f91a872bd50003f917c9773103710fc863a807c6","modified":1625020404618},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg","hash":"caf402e1f2c8c46716fd47a119e7e99be6dce938","modified":1625020404621},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg","hash":"c3e0c4520b5f7e7c5585d6d2ba32c7ebd24632b7","modified":1625020404624},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg","hash":"b0aba4a39d11dd18844f0c4472b76bcc9a60e98a","modified":1625020404623},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg","hash":"a669f0f5b0fd01fe47445dbacf81b90db24cd927","modified":1625020404626},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg","hash":"92e94790e3720e3c4105f8373a66569b67e4a970","modified":1625020404627},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg","hash":"02428f4389d8dea5c5c6c81f9c8be0fa2e328268","modified":1625020404629},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg","hash":"0bfe4610c71c007749076d74fe24fed5c42081b8","modified":1625020404628},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg","hash":"0edf1bcfdb57f22692cc96bf34140237cb1492e8","modified":1625020404631},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg","hash":"a53060eb815c38787b1011bea743c9c710988cb0","modified":1625020404648},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg","hash":"8fbd212a1ba7d5a3b9a954ba0db0eb2f70d9df23","modified":1625020404649},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg","hash":"953ead0ad6fa3642d43976ba5d3cc154f3edd45e","modified":1625020404650},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg","hash":"87ce516d9bce964f4a41d71d032693a91b46319c","modified":1625020404651},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg","hash":"339386f7ae080aa932e05b62dada3649b99704cd","modified":1625020404640},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg","hash":"7827d1caf53180469eddf5d6b94066e339e511a4","modified":1625020404641},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg","hash":"7c3807e0ab877318b203e401026c3f707abfed5a","modified":1625020404642},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg","hash":"361316e689630de320a76590a7bd3b1fcdfb48b8","modified":1625020404643},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg","hash":"04a0260aadd78cf27329bca5c065269285f34ba2","modified":1625020404657},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg","hash":"4919927c99eff0f118c1c078a4cfccc4e90fe003","modified":1625020404655},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg","hash":"7a0c3c413b9b988ca767529264f7116c26401691","modified":1625020404664},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg","hash":"c434335870bc4d33d4c1baad31187fbdb348f0df","modified":1625020404667},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg","hash":"d8d4a09b8acbcccc39d910097cee95de3298f5c8","modified":1625020404668},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpeg","hash":"28c65ba10a6602ee7a557c85ba18fedb07b14044","modified":1625020404685},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpeg","hash":"056e010de5d8acf536f8b91d0de191a27e1836ff","modified":1625020404688},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg","hash":"838ca5f4a85f774e4b18146ce080d0f3c22db79b","modified":1625020404673},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg","hash":"8fa490a8e6f105b67448ea99f2c6e7cb77abea4c","modified":1625020404676},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg","hash":"c2f8bcfc1cff834c60402fdc92272c819ae693da","modified":1625020404678},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg","hash":"0dae5d3fe0ee8733cf029cd3d2d7814ac00f018a","modified":1625020404683},{"_id":"source/_posts/Github搭建Hexo/1542037823098.jpg","hash":"0d8ae68183041f46cab6f094eca36bd07ebc6a33","modified":1625020404695},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg","hash":"72f8cfbe9073024b5271ff2eb3a00800d531beae","modified":1625020404681},{"_id":"source/_posts/iTerm2/Appearance.jpg","hash":"017381bd1ee6b41e96724fde9a4b3d583ecf57f2","modified":1626426409436},{"_id":"source/_posts/lrzsz/122150034707951.png","hash":"0923aa96f15dcefc305cdf3c1ce81effa35438c0","modified":1625020404705},{"_id":"source/_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的/16a7950217b3f0f4ed02db5db59562a7.png","hash":"cb34bc60f583ed3d34b50574782211e0bab66919","modified":1625020404558},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg","hash":"ceba084c6c4b9498b59a4c597130a619d3fab40b","modified":1625020404581},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg","hash":"3db461ee4d0d68bbe81bb595bb37d5742d764d8e","modified":1625020404584},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg","hash":"3d11e58a0ff39eee6c150644891deaf224e72fc3","modified":1625020404589},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg","hash":"59e2484085bf0a8eb3c83c429fb59bd4c5a59493","modified":1625020404588},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg","hash":"41f9d2307738a7fe6eb45722a5f6d6a4deff77c8","modified":1625020404596},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg","hash":"1a3f392f6c1fec10d9430e1bd6da1cdf1d0a503e","modified":1625020404663},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.png","hash":"655d0a4b256c650d1dcab0000aa46f2ff6f7631c","modified":1625020404666},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpeg","hash":"77de4ff91e378e431aae39710830c63c44dcdbdc","modified":1625020404686},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpeg","hash":"ccc7d2e1067f8b33cbfd438ed0b8bc6e82925a00","modified":1625020404687},{"_id":"source/_posts/Github搭建Hexo/1542074055382.jpg","hash":"4e2b693b82c18acc30238548c8734bc6079846f8","modified":1625020404698},{"_id":"source/_posts/Java-Agent详解/1565786297241.jpg","hash":"f4c09845c02065bc284327eea51df400fe071ead","modified":1625020404703},{"_id":"source/_posts/01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的/1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg","hash":"f4fc74db99de3faafdf389876b7de1e6e99f0d74","modified":1625020404550},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png","hash":"beaebc0ac7ce618b22c3dc2f4a805af3a461d144","modified":1625020404594},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg","hash":"46a3c86da86805e056d95f3353d9ce3e72e44619","modified":1625020404645},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg","hash":"39d993d1d47a3cdfbb48d9874031de8920df7721","modified":1625020404670},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg","hash":"3b6ce1bf686bc5ab92ec295469e7dca17d8b7142","modified":1625020404681},{"_id":"source/_posts/Github搭建Hexo/1542073066701.jpg","hash":"cfbdcf85e3d45f5a28bfa2293f773747d0fa9cce","modified":1625020404697},{"_id":"source/_posts/Java-Agent详解/1565784207465.jpg","hash":"1dcd897398954ff6e5bfb16138a41316b1d26194","modified":1625020404700},{"_id":"source/_posts/MongoDB安装/adminMongo_connections.png","hash":"275a4437131ca6c2882a039277412a47c9863c89","modified":1625020404717},{"_id":"source/_posts/iTerm2/Status_bar.jpg","hash":"b08113e6c531c25ab672a31a937fb08ed6a4616d","modified":1626427351814},{"_id":"source/_posts/iTerm2/1543213263217.jpg","hash":"3c1533f93a2fb48141d17180684eca508311bfd5","modified":1625020404770},{"_id":"source/_posts/iTerm2/1543202719106.jpg","hash":"e0cb2a3fa8643c29d72257c469fe06febacbc926","modified":1625020404767},{"_id":"source/_posts/tensorflow教程/tensors_flowing.gif","hash":"868b80c0a655b6c5a8ce07b2fe622c473ef6b96a","modified":1625020404775},{"_id":"source/_posts/Redis设计与实现/lru_comparison.png","hash":"5ce3e2163f4e0de50186576295a08340f25374d3","modified":1625020404728},{"_id":"themes/hexo-theme-matery/.gitignore","hash":"727607929a51db7ea10968f547c26041eee9cfff","modified":1626320097595},{"_id":"themes/hexo-theme-matery/CHANGELOG.md","hash":"084ec8b110a20170d08a0aa5fd8accf601051835","modified":1626320097595},{"_id":"themes/hexo-theme-matery/languages/default.yml","hash":"2ed57824573d7bed71e56023ed92500734a8886d","modified":1640952468900},{"_id":"themes/hexo-theme-matery/_config.yml","hash":"f6a28042a8c6ea23c557b8f0b68a25443205b12e","modified":1640953150054},{"_id":"themes/hexo-theme-matery/languages/zh-CN.yml","hash":"a2695fdb7579a77daec7773a9bb8e71b9edbf16b","modified":1640952468900},{"_id":"themes/hexo-theme-matery/languages/zh-HK.yml","hash":"51c06005927e8bde5b3e23353d2bf2c32ed855f3","modified":1640952468900},{"_id":"themes/hexo-theme-matery/layout/404.ejs","hash":"36f8d3e530e8144bf80d0772284edd9b0da362fe","modified":1640952468900},{"_id":"themes/hexo-theme-matery/layout/about.ejs","hash":"99a74316aed478efb0db823c4460ee2e660f101c","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/bb.ejs","hash":"21959d702f17a3d98b716daf44c8b5eecd59c7c5","modified":1626320097606},{"_id":"themes/hexo-theme-matery/layout/archive.ejs","hash":"cdac701de8370f9f3794a0eed4165983993a1ca7","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/categories.ejs","hash":"8e54665cc25d7c333da7d9f312987190be6215da","modified":1626320097606},{"_id":"themes/hexo-theme-matery/layout/category.ejs","hash":"00019bca11fb46477f22017cb1f5ad8444da0580","modified":1626320097606},{"_id":"themes/hexo-theme-matery/layout/contact.ejs","hash":"851531e78e90a2dc923d6b5d98d3548d37e0cb7a","modified":1640952468910},{"_id":"themes/hexo-theme-matery/README.md","hash":"ddaf6310154e314385d63041da61c418055314f6","modified":1626320097595},{"_id":"themes/hexo-theme-matery/layout/friends.ejs","hash":"534511d9f38f281b531e24c19d9c1526cc7e5e27","modified":1640952468910},{"_id":"themes/hexo-theme-matery/layout/layout.ejs","hash":"13ea3aabb9181f5b765a535e24e7540f1f8f66fd","modified":1640952468911},{"_id":"themes/hexo-theme-matery/layout/post.ejs","hash":"3d4f40121dbb75bcb71837c35ec5ee17cdffae31","modified":1640952468911},{"_id":"themes/hexo-theme-matery/layout/index.ejs","hash":"1656c2db90e24a360282d15c71144b4f14edb43d","modified":1640952468911},{"_id":"themes/hexo-theme-matery/layout/tag.ejs","hash":"85a4b05bd8a6ad0f17ff2e97dae56949b379c204","modified":1626320097607},{"_id":"themes/hexo-theme-matery/layout/tags.ejs","hash":"cf9517aa6a0111355121f44615d6923e312283c7","modified":1626320097607},{"_id":"themes/hexo-theme-matery/source/favicon.png","hash":"774fee8c6d0be9dbb010b20f36c06848d06e3da0","modified":1626320097609},{"_id":"themes/hexo-theme-matery/layout/_partial/back-top.ejs","hash":"47ee36a042bb6d52bbe1d0f329637e8ffcf1d0aa","modified":1626320097597},{"_id":"themes/hexo-theme-matery/LICENSE","hash":"7df059597099bb7dcf25d2a9aedfaf4465f72d8d","modified":1626320097595},{"_id":"themes/hexo-theme-matery/layout/_partial/background.ejs","hash":"acd18121108659b3dd7a94c10943e5f6a4938239","modified":1640952468901},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-analytics.ejs","hash":"3bbcdb474ca1dcad514bdc4b7763e17c55df04fd","modified":1626320097598},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-push.ejs","hash":"2cebcc5ea3614d7f76ec36670e68050cbe611202","modified":1626320097598},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover-content.ejs","hash":"c35e4254ff0738878f65251a657b4fdcafc4b270","modified":1626320097598},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover.ejs","hash":"02191109712f61c0e487b8f0b8466597181a9004","modified":1626320097598},{"_id":"themes/hexo-theme-matery/layout/_partial/changyan.ejs","hash":"cd919d31564e118c2ee8d5cbfb7d51ee6da15d82","modified":1626320097598},{"_id":"themes/hexo-theme-matery/layout/_partial/disqus.ejs","hash":"b2dc2c8b5ed56815e55cc2ea54a6dc4eeba2375d","modified":1626320097598},{"_id":"themes/hexo-theme-matery/README_CN.md","hash":"a2267aed16d52f4adeb13f555d36d076855387af","modified":1626320097596},{"_id":"themes/hexo-theme-matery/layout/_partial/footer.ejs","hash":"7c87e0eb2cf662c2a9b9b0e1e5d228b0fac2622e","modified":1640952468902},{"_id":"themes/hexo-theme-matery/layout/_partial/gitalk.ejs","hash":"2aa8fbb04b046fa7679092a48372d7e036835dff","modified":1626320097599},{"_id":"themes/hexo-theme-matery/layout/_partial/github-link.ejs","hash":"3aeb581bd78ab8e15b858e4c44c03bcf92f20b9e","modified":1626320097599},{"_id":"themes/hexo-theme-matery/layout/_partial/gitment.ejs","hash":"90f6218512ef2eab63ada7ad2fc766ae635a2297","modified":1626320097599},{"_id":"themes/hexo-theme-matery/layout/_partial/google-analytics.ejs","hash":"5f4992205617da5f8cc5863c62b5ec46e414e2fb","modified":1626320097599},{"_id":"themes/hexo-theme-matery/layout/_partial/head.ejs","hash":"60a65b6b181bc77febf71e572e884a61aed91fc8","modified":1640952468903},{"_id":"themes/hexo-theme-matery/layout/_partial/header.ejs","hash":"59e38c70f3d8e7165e686e5e84a627835f4321b0","modified":1626320097599},{"_id":"themes/hexo-theme-matery/layout/_partial/index-cover.ejs","hash":"bf96ff47df2d81bf2edb2a8c6737e36b8b08aca3","modified":1640952468903},{"_id":"themes/hexo-theme-matery/layout/_partial/livere.ejs","hash":"9c3401b42ea7f26410a5593bae93ada7e57b43be","modified":1626320097600},{"_id":"themes/hexo-theme-matery/layout/_partial/mobile-nav.ejs","hash":"52de0cf3ce13a3477b0a1659d2b8aa41db1f622d","modified":1640952468904},{"_id":"themes/hexo-theme-matery/layout/_partial/navigation.ejs","hash":"cda18036a6c782dee122a33f3bba759f3377a68c","modified":1640952468904},{"_id":"themes/hexo-theme-matery/layout/_partial/post-cover.ejs","hash":"d1c873c5de54498c722e155aadb8c0ec39485dfa","modified":1626320097601},{"_id":"themes/hexo-theme-matery/layout/_partial/paging.ejs","hash":"e2df12cf92a82b1a7a7add2eac1db1d954bc5511","modified":1626320097600},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail-toc.ejs","hash":"3ff94aff01936242a9f4e1f31adb9b43bfab8d53","modified":1626320097601},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail.ejs","hash":"a10df7abc9bcac399bcabf727c8491294430dfb0","modified":1640952468905},{"_id":"themes/hexo-theme-matery/layout/_partial/post-statis.ejs","hash":"04889f9031743c6b081d02fa4027b0dbfcc45ecf","modified":1626320097601},{"_id":"themes/hexo-theme-matery/layout/_partial/prev-next.ejs","hash":"c76b78782ea82340104fccc089417572e0adece4","modified":1626320097601},{"_id":"themes/hexo-theme-matery/layout/_partial/reprint-statement.ejs","hash":"0ce3f9361f558b99cc2f059c5e50b0e2a152ae38","modified":1626320097601},{"_id":"themes/hexo-theme-matery/layout/_partial/reward.ejs","hash":"ffc55bc7e73bc698bfc58d8e3780c336b83282cf","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_partial/search.ejs","hash":"150529c9fb9aa8ddb42ec3e02645d301faa2503b","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_partial/share.ejs","hash":"c941730a2471d6aab367cbb6e09ed08b56c83143","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_partial/social-link.ejs","hash":"6f871bd3a70f720e4e451f1f4f625cbc6d8994a4","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_partial/minivaline.ejs","hash":"738b83cd90fe1b26971d803fc89c56193323da1e","modified":1626320097600},{"_id":"themes/hexo-theme-matery/layout/_partial/twikoo.ejs","hash":"f9cb8c82b9d2a7cdb644e10718f1cdeb9400414c","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_partial/valine.ejs","hash":"045f3aaade1dc6749a1f824b0405b5fdb9e041e4","modified":1626320097602},{"_id":"themes/hexo-theme-matery/layout/_widget/artitalk.ejs","hash":"b14e486f12b9ac42a273b80e4d785fcb94cf04b2","modified":1626320097603},{"_id":"themes/hexo-theme-matery/layout/_widget/category-cloud.ejs","hash":"1b3df1009234c0112424b497b18b4ad8240b3bc7","modified":1626320097603},{"_id":"themes/hexo-theme-matery/layout/_widget/category-radar.ejs","hash":"1d8747fda89a0b2ca3c7008867cbfeecad0578a6","modified":1626320097603},{"_id":"themes/hexo-theme-matery/layout/_widget/dream.ejs","hash":"9a472ad5591100cdb65d0df9d01034163bd6dd9d","modified":1626320097603},{"_id":"themes/hexo-theme-matery/layout/_widget/music.ejs","hash":"bb25a6fa51eb5ebfba687b2cbadff6c7a4b4bfef","modified":1640952468907},{"_id":"themes/hexo-theme-matery/layout/_widget/my-gallery.ejs","hash":"65a2d2f9722f84c7fd98f6bdf79087a14848ebd8","modified":1626320097604},{"_id":"themes/hexo-theme-matery/layout/_widget/my-projects.ejs","hash":"ef60b64021fa349b0048425d858dfcf6c906fede","modified":1626320097604},{"_id":"themes/hexo-theme-matery/layout/_widget/post-calendar.ejs","hash":"48821e644bc73553d7c5c56d2e8ee111a70cd776","modified":1626320097604},{"_id":"themes/hexo-theme-matery/layout/_widget/post-charts.ejs","hash":"ab5f986f428215941aeaa0c88aefd440c47d3bcf","modified":1626320097604},{"_id":"themes/hexo-theme-matery/layout/_widget/recommend.ejs","hash":"8551137e94ca4e2e3b8b63d5626255884cb60cb5","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-cloud.ejs","hash":"fc42b72cddc231f7485cdc1fd6852b66be6add26","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-wordcloud.ejs","hash":"487aacb2454d6bf0d21cdb07ddd1fd5ddbca9038","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/_widget/video.ejs","hash":"5e5ec78f8ab229d54786ef2e0ea2864af2dc459f","modified":1626320097605},{"_id":"themes/hexo-theme-matery/layout/_widget/my-skills.ejs","hash":"89a0092df72d23093128f2fbbdc8ca7f83ebcfd9","modified":1626320097604},{"_id":"themes/hexo-theme-matery/source/css/bb.css","hash":"aa15633888c7cf9baea8bb48d796c68b57cf14bf","modified":1626320097608},{"_id":"themes/hexo-theme-matery/source/css/barrager.css","hash":"862879d9313ed8d4c721fa32ef8f94ac2f0a28ae","modified":1626320097607},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","hash":"af18dd29e58642c18bab9b89541767b494c468dd","modified":1626320097608},{"_id":"themes/hexo-theme-matery/source/css/matery.css","hash":"9145d60753fd59278a63fe865047e50aafe66c23","modified":1640952468912},{"_id":"themes/hexo-theme-matery/source/css/my.css","hash":"497e50351f7838f8546cac76850a42e7e380a110","modified":1626320097609},{"_id":"themes/hexo-theme-matery/source/js/matery.js","hash":"b86de5fe3e9766b7ff80df12ea41c3a9e30825f7","modified":1626320097609},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1626320097608},{"_id":"themes/hexo-theme-matery/source/js/jquery.barrager.js","hash":"19c8b2498ca1083e537f7f443172970912107f83","modified":1626320097609},{"_id":"themes/hexo-theme-matery/source/js/search.js","hash":"5caa2d6e3d34c334ac68dfaafc81a583d6123382","modified":1640952468915},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","hash":"2a6287308628881ce27b9a7de53ba15c2be00d02","modified":1626320097666},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","hash":"d9095f5ea8719374d9d1ff020279426f5b2a1396","modified":1626320097691},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","hash":"dfc93d24081884fbc58cab0f8fd19e77d31d6123","modified":1626320097674},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","hash":"27a96f31f7d0413c6ade6f40e06f021f501151c7","modified":1626320097691},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1626320097610},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1626320097610},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1626320097610},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1626320097610},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1626320097611},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1626320097634},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1626320097636},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1626320097635},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1626320097636},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1626320097637},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","hash":"61d71cb30f5f34cbb1f2b5bc469784d6cb908c22","modified":1626320097644},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1626320097650},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1626320097650},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1626320097649},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1626320097650},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","hash":"d20252cf76c3be8af37a8415d13ad368c762b4d8","modified":1640952468972},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1626320097656},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1626320097657},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1626320097657},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1640952469022},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","hash":"39055053a477e7d54b46cfb46591f84cc3818eeb","modified":1640952469023},{"_id":"themes/hexo-theme-matery/source/libs/minivaline/MiniValine.js","hash":"f7f6cdc1b22297e02334e304444e9a8351acb455","modified":1626320097656},{"_id":"themes/hexo-theme-matery/source/libs/prism/prism.css","hash":"f1a273e896538fa4e11cb70acc5ec7e88d8b6c4c","modified":1640952469018},{"_id":"themes/hexo-theme-matery/source/libs/twikoo/twikoo.all.min.js.LICENSE.txt","hash":"1e286a31ef472fb864fe2b9502e87df9242df56b","modified":1626320097663},{"_id":"themes/hexo-theme-matery/source/medias/barrager/0.png","hash":"b30416fd3b3aec5af3fa90823a7e2e9c0af4cda8","modified":1626320097673},{"_id":"themes/hexo-theme-matery/source/medias/barrager/1.png","hash":"b8c211690dba3addedfe7b928e3936cd487df0d6","modified":1626320097673},{"_id":"themes/hexo-theme-matery/source/medias/barrager/close.png","hash":"045346df61ee01abe5018c5d9ba805d2831ce7b1","modified":1626320097674},{"_id":"themes/hexo-theme-matery/source/medias/barrager/2.png","hash":"52b2b13373fe611ad2327b9b40426d6dc05b69cd","modified":1626320097674},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","hash":"da0fbee3b7bde1607eace377ddf834c0be99edfe","modified":1626320097681},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","hash":"98e7f6fd9c97d4de9044b6871ca08ebf14db11b9","modified":1626320097677},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","hash":"35a320174f8e316e3eadaec658024276b651c6e9","modified":1626320097679},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","hash":"97a829c4bc94f9d2929b20a1a9b798c57b9f7205","modified":1626320097681},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","hash":"b26edb128bb0bf58b23fd2f014e9555e89a2ca3b","modified":1626320097685},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","hash":"7d7f37da3fa7128343adac23866449eb2c6a549a","modified":1626320097687},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","hash":"4bba691cf71a517ecaeaf42afd3e8f8b31e346c1","modified":1626320097683},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","hash":"754579747a3e99747d890fca3162f370b96a7941","modified":1626320097686},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","hash":"6ec646c2a70f5f11edacf225c1477f2200a37a96","modified":1626320097687},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","hash":"7975141cd64e875122c0ea33daaca1a06bf00b8e","modified":1626320097690},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","hash":"41ca20129a37fedc573eec28dd7d7b9e5b09228a","modified":1626320097689},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","hash":"8e4b7186352085483ca1174c7c0800114c48df8b","modified":1626320097690},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.jpg","hash":"1abc719b95d1b26f1f898e6b0a9b7609146e332f","modified":1626320097693},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","hash":"fe93385aa92fe328e01c8221a80b039be9e4e140","modified":1626320097693},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","hash":"670fb01e4930ae46fe8d6d2b75ead288f54e8e61","modified":1640952468930},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","hash":"13517529affa39e2585c591acae6dc336b6aa917","modified":1640952468932},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","hash":"c34acd6818df6db6be41a2e331886765d601f2eb","modified":1640952468932},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","hash":"3ad4f4e4b1fb3edee3d4ba25e6cdfed2f0b88a54","modified":1640952468932},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"7873d80020ae04955bb57521bd249a6974d1180f","modified":1640952468968},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1626320097652},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","hash":"509c56c80732a1cd80df8f2b4b0ac1128c31999f","modified":1640952468968},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","hash":"04f09ad797ced119d6608909d06e500f16a03bbb","modified":1640952468969},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1626320097652},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","hash":"49693fa946534a56d7e5d4274e1ce55b05d782c3","modified":1640952468969},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1626320097657},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","hash":"2962e03ddbe04d7e201a5acccac531a2bbccddfc","modified":1626320097653},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","hash":"9b72fc0f86a01467ed0b68c9cc4d604ec316d517","modified":1626320097653},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","hash":"f8d11384d33b7a79ee2ba8d522844f14d5067a80","modified":1626320097653},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"aab2633f69581c2e26e22a23712f1501d7fcec18","modified":1640952468971},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1626320097658},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1626320097660},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1626320097658},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","hash":"1d56c9d5db0273f07c43cc1397e440f98ba7827a","modified":1626320097658},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1626320097658},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1626320097659},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","hash":"490148a22ab2b03a880495cc733ecd1840c02ed6","modified":1640952468949},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1626320097651},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1626320097649},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1626320097664},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","hash":"69ec96cd9b4bc3aa631adc9da61353f50c39f031","modified":1626320097667},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","hash":"39fb2535460ce66cc0b34e07ffb9411db1405f09","modified":1626320097669},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","hash":"4ac047e92d0363b1a61ab756aca6dac13fb77494","modified":1626320097670},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","hash":"f55972ce7175684f2b11c3c9fc2b5b14bccbfae8","modified":1626320097678},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","hash":"1c3300f029fc85d6dda6fa4f1d699551034cdaf7","modified":1626320097676},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","hash":"684ae89de8cb7acefae19f5aee6c612037c46393","modified":1626320097677},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","hash":"8a4b2e7d92ae95c3b0c921db23c35aa9a41a7d58","modified":1626320097679},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","hash":"eb250906fdbc0c408f42ae9933725bc1a05d79fb","modified":1626320097683},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","hash":"38e11221406785bcd93aa9cd23e568e164630ef1","modified":1626320097680},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","hash":"42d47903551ee81885c1386022982cae165841c5","modified":1626320097682},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","hash":"64829272ec85bb819d55ff89e5b5fd6f64aa436b","modified":1626320097682},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","hash":"3b11f9b461168d907073f793190865fe621a8573","modified":1626320097684},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","hash":"e06c47de27619984be9d5d02947f8370a432dfea","modified":1626320097688},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","hash":"c8f2aa4bbb041158b4e73733a341e6a77c8583f7","modified":1626320097689},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","hash":"b956a2291a04b2132366b53666cf34858b8bdb1f","modified":1626320097691},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","hash":"8a4a55db46c5dbfef9c6703fa2d04e89cbfcf633","modified":1640952468918},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","hash":"0613c7ebba55ee47ef302c0f7766324692f899a7","modified":1640952468929},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","hash":"d1ffd6340cdbf72890ccb67f32015eafc5df51a7","modified":1640952468921},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","hash":"8ab907083fecaaa2a9ec93b27f884ad74573705c","modified":1640952468928},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","hash":"1e1f02bfa89e179fe2dd1383273b8812aa873418","modified":1640952468929},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","hash":"0ccb2c814a7e4ca12c4778821633809cb0361eaa","modified":1640952468944},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","hash":"a22acd7697f36e7d4cc31a853c70e776eac54bb1","modified":1640952468944},{"_id":"source/_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的/0d2070e8f84c4801adbfa03bda1f98d9.png","hash":"0399712737ef6427d49e48d5d63dfbd23bf40e4d","modified":1625020404557},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1626320097675},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","hash":"a69d456e3345e7f59cd0d47d1b3e70fd4a496a05","modified":1626320097655},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1626320097656},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1626320097665},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","hash":"ab122a36998a4f62a61e61a4fc5e00248113413b","modified":1626320097668},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","hash":"852418f4f09e796e12bc3bab7a1488d3f37d6486","modified":1626320097672},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","hash":"ed7282cc129c4ff9f322d2f2897fb4aac5c48589","modified":1626320097673},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","hash":"326e1d8f0b23f6df95cd6784fdf330bc6414ecd0","modified":1640952468931},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","hash":"ea845c59bee4a5c6db774b8d8060f5641b789ae9","modified":1640952468935},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","hash":"eb8914f6b1797b45ee0883e6089d92695d9f9441","modified":1640952468943},{"_id":"source/_posts/assets/转换示例.svg","hash":"d32b764972582e55b5e9a6915065322c208cc6ab","modified":1625020404764},{"_id":"source/_posts/语法分析器的设计和实现/转换示例.svg","hash":"d32b764972582e55b5e9a6915065322c208cc6ab","modified":1625020404807},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","hash":"e5ac5033678afa9d69edffe9a61004f836cb5734","modified":1626320097672},{"_id":"themes/hexo-theme-matery/source/libs/twikoo/twikoo.all.min.js","hash":"c3f5f0a69b7864e7ef5bbf99fc774bec37947d7c","modified":1626320097663},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","hash":"907bfbbe295332750575900984a00136de0f0e90","modified":1640952468927},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1626320097643},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","hash":"564fc7c731d05fa70d71ef853a2c8cc7725739e2","modified":1626320097648},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","hash":"d92687d30fa0d43f9ae71009398507bf813a6875","modified":1640952468941},{"_id":"source/_posts/assets/55821626-8701-4F00-879A-93B7D5039B06.png","hash":"da408a98161f0b0e743b16d560c2f78d554f7450","modified":1625020404741},{"_id":"source/_posts/语法分析器的设计和实现/55821626-8701-4F00-879A-93B7D5039B06.png","hash":"da408a98161f0b0e743b16d560c2f78d554f7450","modified":1625020404789},{"_id":"source/_posts/lrzsz/x_engine_paper.pdf","hash":"772606c90a164480ee517b17d1a3cbbb513d048f","modified":1625020404714},{"_id":"source/_posts/assets/carbon.svg","hash":"d54be959122b3ed8d3b70a05edaf56dd53b588f7","modified":1625020404759},{"_id":"source/_posts/语法分析器的设计和实现/carbon.svg","hash":"d54be959122b3ed8d3b70a05edaf56dd53b588f7","modified":1625020404803},{"_id":"source/_posts/assets/55821626-8701-4F00-879A-93B7D5039B06.svg","hash":"e865774e84f445aebc8cfe4cb8ba258a9175c3f3","modified":1625020404753},{"_id":"source/_posts/语法分析器的设计和实现/55821626-8701-4F00-879A-93B7D5039B06.svg","hash":"e865774e84f445aebc8cfe4cb8ba258a9175c3f3","modified":1625020404798},{"_id":"source/_posts/Git.md","hash":"c995ce57b371ce7e7bb3c5643431ad9b069fe07e","modified":1646968733373},{"_id":"source/_posts/Google-Protocol-Buffers.md","hash":"1b5c9ee637d2cac8e4cfe7d256c9d75b759ca2cb","modified":1645586470184},{"_id":"source/_posts/Google分布式系统-BigTable.md","hash":"25fbd2dc231ff529fe16c842c4bdfbd013de681f","modified":1646725051309},{"_id":"source/_posts/Google分布式系统-Dapper.md","hash":"9bc8cc82f0e274254f9e8f05f36ead76f7cfd4c8","modified":1645780854387},{"_id":"source/_posts/Google分布式系统-MapReduce.md","hash":"2c782a562acb41776ef89bd9317cf3093b4b6e8c","modified":1645156421353},{"_id":"source/_posts/Google分布式系统.md","hash":"567c0a244ee4d9828866b6fb7e04d941e80aec31","modified":1645586682545},{"_id":"source/_posts/IntelliJ-IDEA破解.md","hash":"de1065bd967684ab9b8f84ccfe818bf6667e48b1","modified":1645584421534},{"_id":"source/_posts/Google分布式系统-GFS.md","hash":"6af68789cf1a417597c3bf76d792a4b3dbac2cb5","modified":1645157228901},{"_id":"source/_posts/Java17新特性.md","hash":"5bfb9032d6a43ae901536c1bf2f4810d8177873a","modified":1634452922838},{"_id":"source/_posts/Java11新特性.md","hash":"0ee6130e59979e05b781e04f0fcb7e496aa37e60","modified":1634453020294},{"_id":"source/_posts/Java中多态性：重写和重载.md","hash":"81679f74d15999cfef84c8952c4bc78436ee574e","modified":1642934795292},{"_id":"source/_posts/Java中抽象类与接口之间的区别.md","hash":"5c430ee0521003211eda3966b12e863279b35bd1","modified":1642858631092},{"_id":"source/_posts/Java程序设计.md","hash":"c9e4b0faf014f858baa25675c77c5686785322c0","modified":1640954742110},{"_id":"source/_posts/Java中静态绑定与动态绑定区别.md","hash":"ad597a1f42dc39d410c8796128c8bee96de2437c","modified":1643275531624},{"_id":"source/_posts/Maven-Maven安装-配置.md","hash":"ad25dca615505cd7486193321f69be9590faf9bf","modified":1635491166019},{"_id":"source/_posts/MySQL-InnoDB.md","hash":"f0d12cc83ba6bc8fc2a50d8ed2580110db999022","modified":1649594295128},{"_id":"source/_posts/Java源码分析-原子类-AtomicBoolean.md","hash":"cbc15b23d40eb4e8b62fbd87a32a102098662cec","modified":1645683845057},{"_id":"source/_posts/Redis中对象类型.md","hash":"e51e0d8de3be9ec6ba78c41f445e1bf516796185","modified":1646184794953},{"_id":"source/_posts/Redis中数据结构.md","hash":"78c819b38d589654f8c0e89ad9c8c84092c33d7a","modified":1646184863026},{"_id":"source/_posts/分布式系统模式.md","hash":"feb27a9dabedca114aaf982f28bc67098177d6ed","modified":1646722430314},{"_id":"source/_posts/gRPC.md","hash":"3511fb1b454471e170078aba8492cbcf13f33960","modified":1645589243457},{"_id":"source/_posts/计算机科学-字符、字符集、字符编码详解.md","hash":"86768c3613aebe8fed66cc90d7c7f6fca2268dd5","modified":1635164480519},{"_id":"source/_posts/设计模式.md","hash":"e64fab4bf58654a3f7b33ea4842d8ad1458b1524","modified":1642599945267},{"_id":"source/_posts/算法-SHA-1.md","hash":"7e9df759c88b8cdfaff6bfb6edd203aa8343a9d8","modified":1646708314124},{"_id":"source/_posts/Git/areas.png","hash":"a990ceb4480c54a2f1b6fd9c7e2c0669bd59fbf4","modified":1646708550128},{"_id":"source/_posts/Git/basic-merging-2.png","hash":"6b09d910aadc4bd1284f12d3eee4afbfb2b76bb2","modified":1646830662722},{"_id":"source/_posts/Git/basic-rebase-3.png","hash":"b5d030067a66d895121fac2ad6c3e8b4663e17f0","modified":1646831229081},{"_id":"source/_posts/Git/centralized_workflow.png","hash":"6c45409dd6a4ee6f5fb3ffb5c88c42d300867416","modified":1646834868582},{"_id":"source/_posts/Git/benevolent-dictator.png","hash":"b84eaf951473e24576a65d1374c3224b5404f303","modified":1646835229936},{"_id":"source/_posts/Git/commits-and-parents.png","hash":"954aea124f740ea4d0bc286e801a9af1a2de3094","modified":1646819882659},{"_id":"source/_posts/Git/commit-and-tree.png","hash":"b0f161686a82f35832cee400de8f966af9886463","modified":1646819780182},{"_id":"source/_posts/Git/integration-manager.png","hash":"90f5086a66bd9c726288174fe8867c6229b792f2","modified":1646835055205},{"_id":"source/_posts/IntelliJ-IDEA破解/1645497394807.jpg","hash":"fd47a5a142c5c4bffdda7de3e61cf316834a063f","modified":1645497406894},{"_id":"source/_posts/Java程序设计/变量-内存.jpg","hash":"eacd505d864d7a2f4c2afe5fa3a155c1157a0dca","modified":1640954648042},{"_id":"source/_posts/IntelliJ-IDEA破解/1645412947773.jpg","hash":"bb88512fe0f5b4499783c536f803c02a2cf45bf6","modified":1645412978644},{"_id":"source/_posts/IntelliJ-IDEA破解/1645497851808.jpg","hash":"85e257c848421d8866ade3622a1a9c0bfd5cb063","modified":1645497854087},{"_id":"source/_posts/gRPC/landing-2.svg","hash":"0736849feef0a4cda3d3f665ed96548c20dfe1a2","modified":1645586479084},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-video.ejs","hash":"963422029eb5158eb5f5bc97ce19b66e5399db97","modified":1640952468902},{"_id":"themes/hexo-theme-matery/layout/galleries.ejs","hash":"85b8b9e583ffa7a4ee6d0c2be4779cb2f7d91777","modified":1640952468910},{"_id":"themes/hexo-theme-matery/layout/gallery.ejs","hash":"fcc7364b03329148ba4920cddb0d34d5b7410788","modified":1640952468910},{"_id":"themes/hexo-theme-matery/source/css/gallery.css","hash":"015097ca1271dd44e6d663332587dbe58ae2ade8","modified":1640952468912},{"_id":"themes/hexo-theme-matery/source/js/gallery-encrypt.js","hash":"f611a391d62da17b71f75577a72ad246ef6c5a71","modified":1640952468914},{"_id":"themes/hexo-theme-matery/layout/_partial/waline.ejs","hash":"2658cb73ef984a30b248351d7858ee15596a6e7a","modified":1640952468906},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/Meting.min.js","hash":"f2b3d20b8bd64ccd031c64628f2b1323078ae324","modified":1640952468917},{"_id":"themes/hexo-theme-matery/source/libs/fancybox/jquery.fancybox.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1640952468956},{"_id":"themes/hexo-theme-matery/source/libs/justifiedGallery/justifiedGallery.min.css","hash":"b9323091d50785ad6c617d7cae76a41a89eb44b3","modified":1640952468967},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.min.css","hash":"1dbcd9312e57f2a0b569451d0028d88316614481","modified":1640952469005},{"_id":"themes/hexo-theme-matery/source/libs/justifiedGallery/justifiedGallery.min.js","hash":"6f5433cc9f19ce2403e903e5d01a4c7b38f0969b","modified":1640952468967},{"_id":"themes/hexo-theme-matery/source/libs/others/TencentCaptcha.js","hash":"fb4d34c48567b7b992aac1c75f0d24c3eb2cc3fa","modified":1640952469015},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-half.js","hash":"a41b64af88fdd0e2d3502752d059661c1bc743dc","modified":1640952469016},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-reduce.js","hash":"f7527e9fb4e6fe2cc7c8880692d77bcda95900c7","modified":1640952469017},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura.js","hash":"b6ebe8f040c84f067300996a5f377846f01605fa","modified":1640952469017},{"_id":"themes/hexo-theme-matery/source/libs/others/sakura-small.js","hash":"3284a9ab71454e574d80663f3a05735cd12a6a05","modified":1640952469017},{"_id":"themes/hexo-theme-matery/source/libs/others/star.js","hash":"cf32f8ce2a1a51ba65d3b6063fe2ee1482550190","modified":1640952469018},{"_id":"themes/hexo-theme-matery/source/libs/others/snow.js","hash":"02b1eeaca737c47be637b304feb3d36d792ee0c4","modified":1640952469018},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.min.css","hash":"a57ee68d11601b0fd8e5037fc241ff65a754473c","modified":1640952468919},{"_id":"themes/hexo-theme-matery/source/libs/fancybox/fancybox.js","hash":"eef46b6fb2e460838cd7328a6e13ecda0cb1e194","modified":1640952468956},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery-3.6.0.min.js","hash":"b82d238d4e31fdf618bae8ac11a6c812c03dd0d4","modified":1640952468966},{"_id":"themes/hexo-theme-matery/source/libs/waline/Waline.min.js","hash":"94f70e622e2a1ab05adb205033a9ddf371c61534","modified":1640952469031},{"_id":"themes/hexo-theme-matery/source/medias/images/02.jpg","hash":"a5b656606811f4d7e10307f48c0e3c373e0b886d","modified":1640952469065},{"_id":"themes/hexo-theme-matery/source/js/crypto-js.js","hash":"ddacd177f23f65ff97b93b0417048f51928ee17e","modified":1640952468914},{"_id":"themes/hexo-theme-matery/source/medias/images/03.jpg","hash":"2bd3815508a9f5b0ae79aa780bc02ac80b2a354e","modified":1640952469082},{"_id":"themes/hexo-theme-matery/source/medias/images/01.jpg","hash":"6a81f437fb876666bafaa98b2a09bd8bd7f21832","modified":1640952469064},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.min.js","hash":"be7f26d6f063cfec5440517848ae5943adae1f54","modified":1640952469014},{"_id":"themes/hexo-theme-matery/source/libs/mermaid/mermaid.js","hash":"a7933bef8aba190825ba7716497209187ac1de5d","modified":1640952469004}],"Category":[{"name":"MySQL","_id":"ckr8tjsuw0004r5p74d0y8bli"},{"name":"机器学习","_id":"ckr8tjswb004kr5p729fz3ao9"},{"name":"Elasticsearch","_id":"ckr8tjswi0058r5p78pw234ru"},{"name":"Hexo","_id":"ckr8tjswk005hr5p7fno38tp3"},{"name":"Mac","_id":"ckr8tjswm005or5p78ous5s06"},{"name":"Java","_id":"ckr8tjswo005wr5p7663l8xyi"},{"name":"Redis","_id":"ckr8tjswq0065r5p70oupdgqt"},{"name":"Java环境配置","_id":"ckr8tjswu006ir5p7ernm2wp2"},{"name":"Kafka","_id":"ckr8tjsww006qr5p76g6c2j44"},{"name":"LaTeX","_id":"ckr8tjswx006yr5p7dqu692c1"},{"name":"Homebrew","_id":"ckr8tjswz0078r5p74mle2jl2"},{"name":"Linux","_id":"ckr8tjsx1007gr5p7dxavet9n"},{"name":"JavaAgent","parent":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsx3007nr5p77y8x2nrq"},{"name":"Git","_id":"ckr8tjsx5007vr5p7ax493pd2"},{"name":"Markdown","_id":"ckr8tjsx70086r5p71j2gfe73"},{"name":"SQL","_id":"ckr8tjsx9008er5p7dqfk3mbk"},{"name":"SQL转换","_id":"ckr8tjsxb008mr5p717wafpwd"},{"name":"PyTorch","_id":"ckr8tjsxe0090r5p7dlk884vk"},{"name":"SpringBoot","_id":"ckr8tjsxn009nr5p743am74ue"},{"name":"词法分析","_id":"ckr8tjsxq009wr5p78guhdfu1"},{"name":"ZooKeeper","_id":"ckr8tjsxs00a3r5p7b0yz5goj"},{"name":"iTerm2","_id":"ckr8tjsxu00abr5p7dj7l7r8l"},{"name":"MySQL","parent":"ckr8tjsx9008er5p7dqfk3mbk","_id":"ckr8tjsxw00alr5p7528j72f9"},{"name":"Python","_id":"ckr8tjsxy00asr5p7c5ij1pxt"},{"name":"rz","_id":"ckr8tjsxz00b0r5p75h3h0i8k"},{"name":"Tensorflow","_id":"ckr8tjsy100b8r5p7d9cm211c"},{"name":"Thrift","_id":"ckr8tjsy400bjr5p73418bvei"},{"name":"自然语言处理","parent":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsy600bqr5p799lf9o2t"},{"name":"信息论","_id":"ckr8tjsy800bxr5p79kiegev5"},{"name":"神经网络","_id":"ckr8tjsy800c3r5p74sb0922c"},{"name":"Tomcat","_id":"ckr8tjsy900cer5p7awlec400"},{"name":"Algorithm","_id":"ckr8tjsya00cor5p7age53ds8"},{"name":"数学","_id":"ckr8tjsyc00cyr5p7h7b31cc5"},{"name":"概率与统计","_id":"ckr8tjsyd00d4r5p7ckek2xfg"},{"name":"算法","_id":"ckr8tjsyd00dar5p7eoe1aw9o"},{"name":"编译原理","_id":"ckr8tjsyh00e3r5p7541g6d86"},{"name":"设计模式","_id":"ckr8tjsyj00edr5p7axid26wd"},{"name":"sz","_id":"ckr8tjsyk00ejr5p77mgwb3rr"},{"name":"Trace","parent":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsyl00epr5p72ixzdgir"},{"name":"语法分析","parent":"ckr8tjsxq009wr5p78guhdfu1","_id":"ckr8tjsyl00etr5p7agh3dyid"},{"name":"面试","_id":"ckr8tjsyn00f5r5p71nvl2zkb"},{"name":"负载均衡","_id":"ckr8tjsyn00fbr5p79xaacpg8"},{"name":"版本控制系统","_id":"cl1t9uw7s00029op73qm3he2c"},{"name":"Google分布式系统","_id":"cl1t9uw8900079op7gl1g102q"},{"name":"gRPC","_id":"cl1t9uw8p000u9op79i582r2x"},{"name":"IntelliJ IDEA","_id":"cl1t9uw8s00129op71bux99f9"},{"name":"OOP","parent":"ckr8tjswo005wr5p7663l8xyi","_id":"cl1t9uw8v00199op70sdjce73"},{"name":"Java程序设计","_id":"cl1t9uw8z001i9op79aqd6rov"},{"name":"计算机科学","_id":"cl1t9uw96001v9op7ehko42it"}],"Data":[],"Page":[{"title":"about","_content":"\n\n## 个人简介\n一个计算机专业出身的IT男\n我非常喜欢程序员这份工作，\b同时酷爱数学\n对机器学习、模式识别等人工智能方向\b感兴趣\n\n## 本博客的目的\n好记忆不如烂笔头，记录一些自己学的知识、遇到的问题和解决方案的经验；如果对你有些帮助也是我的荣幸。\n\n## 技术方向\n主修java, 分布式、高并发架构，略懂python\nRPC: thrift、dubbo\n数据库方向: mysql、oracle、ppas、pg\n缓存方面: redis、memcached\n消息队列: rabbitmq、kafka\n服务器: nginx、tomcat、jetty\n\n## 个人兴趣\n运动：乒乓球，游泳\n读书：计算机相关、科幻、天文、小说等书籍","source":"about/index.md","raw":"---\ntitle: about\n---\n\n\n## 个人简介\n一个计算机专业出身的IT男\n我非常喜欢程序员这份工作，\b同时酷爱数学\n对机器学习、模式识别等人工智能方向\b感兴趣\n\n## 本博客的目的\n好记忆不如烂笔头，记录一些自己学的知识、遇到的问题和解决方案的经验；如果对你有些帮助也是我的荣幸。\n\n## 技术方向\n主修java, 分布式、高并发架构，略懂python\nRPC: thrift、dubbo\n数据库方向: mysql、oracle、ppas、pg\n缓存方面: redis、memcached\n消息队列: rabbitmq、kafka\n服务器: nginx、tomcat、jetty\n\n## 个人兴趣\n运动：乒乓球，游泳\n读书：计算机相关、科幻、天文、小说等书籍","date":"2021-06-30T02:33:24.809Z","updated":"2021-06-30T02:33:24.809Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckr8tjsuq0000r5p70b8s8vm8","content":"<h2 id=\"个人简介\"><a href=\"#个人简介\" class=\"headerlink\" title=\"个人简介\"></a>个人简介</h2><p>一个计算机专业出身的IT男\n我非常喜欢程序员这份工作，\b同时酷爱数学\n对机器学习、模式识别等人工智能方向\b感兴趣</p>\n<h2 id=\"本博客的目的\"><a href=\"#本博客的目的\" class=\"headerlink\" title=\"本博客的目的\"></a>本博客的目的</h2><p>好记忆不如烂笔头，记录一些自己学的知识、遇到的问题和解决方案的经验；如果对你有些帮助也是我的荣幸。</p>\n<h2 id=\"技术方向\"><a href=\"#技术方向\" class=\"headerlink\" title=\"技术方向\"></a>技术方向</h2><p>主修java, 分布式、高并发架构，略懂python\nRPC: thrift、dubbo\n数据库方向: mysql、oracle、ppas、pg\n缓存方面: redis、memcached\n消息队列: rabbitmq、kafka\n服务器: nginx、tomcat、jetty</p>\n<h2 id=\"个人兴趣\"><a href=\"#个人兴趣\" class=\"headerlink\" title=\"个人兴趣\"></a>个人兴趣</h2><p>运动：乒乓球，游泳\n读书：计算机相关、科幻、天文、小说等书籍</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"个人简介\"><a href=\"#个人简介\" class=\"headerlink\" title=\"个人简介\"></a>个人简介</h2><p>一个计算机专业出身的IT男\n我非常喜欢程序员这份工作，\b同时酷爱数学\n对机器学习、模式识别等人工智能方向\b感兴趣</p>\n<h2 id=\"本博客的目的\"><a href=\"#本博客的目的\" class=\"headerlink\" title=\"本博客的目的\"></a>本博客的目的</h2><p>好记忆不如烂笔头，记录一些自己学的知识、遇到的问题和解决方案的经验；如果对你有些帮助也是我的荣幸。</p>\n<h2 id=\"技术方向\"><a href=\"#技术方向\" class=\"headerlink\" title=\"技术方向\"></a>技术方向</h2><p>主修java, 分布式、高并发架构，略懂python\nRPC: thrift、dubbo\n数据库方向: mysql、oracle、ppas、pg\n缓存方面: redis、memcached\n消息队列: rabbitmq、kafka\n服务器: nginx、tomcat、jetty</p>\n<h2 id=\"个人兴趣\"><a href=\"#个人兴趣\" class=\"headerlink\" title=\"个人兴趣\"></a>个人兴趣</h2><p>运动：乒乓球，游泳\n读书：计算机相关、科幻、天文、小说等书籍</p>\n"},{"title":"404 Not Found：该页无法显示","comments":0,"fancybox":false,"noDate":"true","_content":"\n<style type=\"text/css\">\n\t.article-title {\n\t\tfont-size: 2.1em;\n\t}\n\tstrong a {\n\t\tcolor: #747474;\n\t}\n\t.share {\n\t\tdisplay: none;\n\t}\n\t.player {\n\t\tmargin-left: -10px;\n\t}\n\t.sign {\n\t\ttext-align: right;\n\t\tfont-style: italic;\n\t}\n  \t#page-visit {\n\t\tdisplay: none;\n\t}\n\t.center {\n\t\ttext-align: center;\n\t\theight: 2.5em;\n\t\tfont-weight: bold;\n\t}\n\t.search2 {\n\t\theight: 2.2em;\n\t\tfont-size: 1em;\n\t\twidth: 50%;\n\t\tmargin: auto 24%;\n\t\tcolor: #727272;\n\t\topacity: .6;\n\t\tborder: 2px solid lightgray;\n\t}\n\t.search2:hover {\n\t\topacity: 1;\n\t\tbox-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n\t\t};\n\t.article-entry hr {\n\t\tmargin: 0;\n\t}\n\t.pic {\n\t\ttext-align: center;\n\t\tmargin: 0;\n\t}\n\t.pic br {\n  \t\tdisplay: none;\n  \t}\n</style>\n\n***\n\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"https//music.163.com/outchain/player?type=0&id=993980219&auto=1&height=430\"></iframe>\n</div>","source":"404/index.md","raw":"---\ntitle: 404 Not Found：该页无法显示\ncomments: false\npermalink: /404\nfancybox: false\nnoDate: \"true\"\n---\n\n<style type=\"text/css\">\n\t.article-title {\n\t\tfont-size: 2.1em;\n\t}\n\tstrong a {\n\t\tcolor: #747474;\n\t}\n\t.share {\n\t\tdisplay: none;\n\t}\n\t.player {\n\t\tmargin-left: -10px;\n\t}\n\t.sign {\n\t\ttext-align: right;\n\t\tfont-style: italic;\n\t}\n  \t#page-visit {\n\t\tdisplay: none;\n\t}\n\t.center {\n\t\ttext-align: center;\n\t\theight: 2.5em;\n\t\tfont-weight: bold;\n\t}\n\t.search2 {\n\t\theight: 2.2em;\n\t\tfont-size: 1em;\n\t\twidth: 50%;\n\t\tmargin: auto 24%;\n\t\tcolor: #727272;\n\t\topacity: .6;\n\t\tborder: 2px solid lightgray;\n\t}\n\t.search2:hover {\n\t\topacity: 1;\n\t\tbox-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n\t\t};\n\t.article-entry hr {\n\t\tmargin: 0;\n\t}\n\t.pic {\n\t\ttext-align: center;\n\t\tmargin: 0;\n\t}\n\t.pic br {\n  \t\tdisplay: none;\n  \t}\n</style>\n\n***\n\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"https//music.163.com/outchain/player?type=0&id=993980219&auto=1&height=430\"></iframe>\n</div>","date":"2021-06-30T02:33:24.547Z","updated":"2021-06-30T02:33:24.547Z","path":"/404.html","layout":"page","_id":"ckr8tjsuv0002r5p7dyuwfbfs","content":"<hr>\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=\"330\" height=\"450\" src=\"https//music.163.com/outchain/player?type=0&amp;id=993980219&amp;auto=1&amp;height=430\"></iframe>\n</div>","site":{"data":{}},"excerpt":"","more":"<style type=\"text/css\">\n    .article-title {\n        font-size: 2.1em;\n    }\n    strong a {\n        color: #747474;\n    }\n    .share {\n        display: none;\n    }\n    .player {\n        margin-left: -10px;\n    }\n    .sign {\n        text-align: right;\n        font-style: italic;\n    }\n      #page-visit {\n        display: none;\n    }\n    .center {\n        text-align: center;\n        height: 2.5em;\n        font-weight: bold;\n    }\n    .search2 {\n        height: 2.2em;\n        font-size: 1em;\n        width: 50%;\n        margin: auto 24%;\n        color: #727272;\n        opacity: .6;\n        border: 2px solid lightgray;\n    }\n    .search2:hover {\n        opacity: 1;\n        box-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n        };\n    .article-entry hr {\n        margin: 0;\n    }\n    .pic {\n        text-align: center;\n        margin: 0;\n    }\n    .pic br {\n          display: none;\n      }\n</style>\n\n<hr>\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"https//music.163.com/outchain/player?type=0&id=993980219&auto=1&height=430\"></iframe>\n</div>"},{"title":"文章分类","date":"2018-11-08T16:00:00.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章分类\ndate: 2018-11-09\ntype: categories\nlayout: categories\n---\n","updated":"2021-06-30T02:33:24.809Z","path":"categories/index.html","comments":1,"_id":"ckr8tjsuy0006r5p78ho7d8pw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"文章标签","date":"2018-11-09T01:57:37.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 文章标签\ndate: 2018-11-09 09:57:37\ntype: tags\nlayout: tags\n---\n","updated":"2021-07-15T03:47:17.605Z","path":"tags/index.html","comments":1,"_id":"ckr8tjsuz0008r5p7hmmo2n2n","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"01 | 基础架构：一条SQL查询语句是如何执行的","date":"2019-06-02T16:00:00.000Z","_content":"\n这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：\n\n```\nmysql> select * from T where ID=10；\n```\n\n<!-- more -->\n\n## 简述\n\n我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。\n\n所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些“零件”，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。\n\n下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n\n![MySQL 的逻辑架构图](1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg)\n\n大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。\n\n### 1. Server层\n\n包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n### 2. 存储引擎层\n\n负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n也就是说，你执行 `create table` 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 `create table` 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n连接器\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n```\nmysql -h$ip -P$port -u$user -p\n```\n\n输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n如果用户名或密码不对，你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n\n怎么解决这个问题呢？你可以考虑以下两种方案。\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n## 查询缓存\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\nmysql> select SQL_CACHE * from T where ID=10；\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n分析器\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的\"select\"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\nmysql> elect * from t where ID=1;\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1\n一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。\n\n## 优化器\n\n经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\nmysql> select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;\n既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。\n\n## 执行器\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。\n\n```SQL\nmysql> select * from T where ID=10;\n```\n\n`ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'`\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n- 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n- 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n- 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。\n\n## 小结\n\n今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。\n我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 `select * from T where k=1`, 那肯定是会报“不存在这个列”的错误： `“Unknown column ‘k’ in ‘where clause’”`。\n\n你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n\n答案：分析器。一方面受到Oracle设计思想的影响，另外在《高性能mysql》里提到解析器和预处理器。解析器处理语法和解析查询, 生成一课对应的解析树。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器；","source":"_posts/01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的.md","raw":"---\ntitle: 01 | 基础架构：一条SQL查询语句是如何执行的\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：\n\n```\nmysql> select * from T where ID=10；\n```\n\n<!-- more -->\n\n## 简述\n\n我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。\n\n所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些“零件”，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。\n\n下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n\n![MySQL 的逻辑架构图](1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg)\n\n大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。\n\n### 1. Server层\n\n包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n### 2. 存储引擎层\n\n负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n也就是说，你执行 `create table` 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 `create table` 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n连接器\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n```\nmysql -h$ip -P$port -u$user -p\n```\n\n输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n如果用户名或密码不对，你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n\n怎么解决这个问题呢？你可以考虑以下两种方案。\n1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n2. 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n## 查询缓存\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\nmysql> select SQL_CACHE * from T where ID=10；\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n分析器\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的\"select\"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\nmysql> elect * from t where ID=1;\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1\n一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。\n\n## 优化器\n\n经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\nmysql> select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;\n既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。\n\n## 执行器\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。\n\n```SQL\nmysql> select * from T where ID=10;\n```\n\n`ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'`\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n- 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n- 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n- 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。\n\n## 小结\n\n今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。\n我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 `select * from T where k=1`, 那肯定是会报“不存在这个列”的错误： `“Unknown column ‘k’ in ‘where clause’”`。\n\n你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n\n答案：分析器。一方面受到Oracle设计思想的影响，另外在《高性能mysql》里提到解析器和预处理器。解析器处理语法和解析查询, 生成一课对应的解析树。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器；","slug":"01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的","published":1,"updated":"2021-06-30T02:33:24.547Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsur0001r5p7a2vo974p","content":"<p>这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：</p>\n<pre><code>mysql&gt; select * from T where ID=10；\n</code></pre>\n<span id=\"more\"></span>\n\n<h2 id=\"简述\"><a href=\"#简述\" class=\"headerlink\" title=\"简述\"></a>简述</h2><p>我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。</p>\n<p>所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些“零件”，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。</p>\n<p>下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。</p>\n<p><img src=\"1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg\" alt=\"MySQL 的逻辑架构图\"></p>\n<p>大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。</p>\n<h3 id=\"1-Server层\"><a href=\"#1-Server层\" class=\"headerlink\" title=\"1. Server层\"></a>1. Server层</h3><p>包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p>\n<h3 id=\"2-存储引擎层\"><a href=\"#2-存储引擎层\" class=\"headerlink\" title=\"2. 存储引擎层\"></a>2. 存储引擎层</h3><p>负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n也就是说，你执行 <code>create table</code> 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 <code>create table</code> 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n连接器\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：</p>\n<pre><code>mysql -h$ip -P$port -u$user -p\n</code></pre>\n<p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。</p>\n<p>怎么解决这个问题呢？你可以考虑以下两种方案。</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<h2 id=\"查询缓存\"><a href=\"#查询缓存\" class=\"headerlink\" title=\"查询缓存\"></a>查询缓存</h2><p>连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\nmysql&gt; select SQL_CACHE * from T where ID=10；\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n分析器\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\nmysql&gt; elect * from t where ID=1;\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘elect * from t where ID=1’ at line 1\n一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p>\n<h2 id=\"优化器\"><a href=\"#优化器\" class=\"headerlink\" title=\"优化器\"></a>优化器</h2><p>经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\nmysql&gt; select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;\n既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。</p>\n<h2 id=\"执行器\"><a href=\"#执行器\" class=\"headerlink\" title=\"执行器\"></a>执行器</h2><p>MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from T where ID=10;\n</code></pre>\n<p><code>ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'</code>\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：</p>\n<ul>\n<li>调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；</li>\n<li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li>\n<li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li>\n</ul>\n<p>至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。\n我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 <code>select * from T where k=1</code>, 那肯定是会报“不存在这个列”的错误： <code>“Unknown column ‘k’ in ‘where clause’”</code>。</p>\n<p>你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？</p>\n<p>答案：分析器。一方面受到Oracle设计思想的影响，另外在《高性能mysql》里提到解析器和预处理器。解析器处理语法和解析查询, 生成一课对应的解析树。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器；</p>\n","site":{"data":{}},"excerpt":"<p>这是专栏的第一篇文章，我想来跟你聊聊 MySQL 的基础架构。我们经常说，看一个事儿千万不要直接陷入细节里，你应该先鸟瞰其全貌，这样能够帮助你从高维度理解问题。同样，对于 MySQL 的学习也是这样。平时我们使用数据库，看到的通常都是一个整体。比如，你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：</p>\n<pre><code>mysql&gt; select * from T where ID=10；\n</code></pre>","more":"<h2 id=\"简述\"><a href=\"#简述\" class=\"headerlink\" title=\"简述\"></a>简述</h2><p>我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。</p>\n<p>所以今天我想和你一起把 MySQL 拆解一下，看看里面都有哪些“零件”，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。</p>\n<p>下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。</p>\n<p><img src=\"1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg\" alt=\"MySQL 的逻辑架构图\"></p>\n<p>大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。</p>\n<h3 id=\"1-Server层\"><a href=\"#1-Server层\" class=\"headerlink\" title=\"1. Server层\"></a>1. Server层</h3><p>包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p>\n<h3 id=\"2-存储引擎层\"><a href=\"#2-存储引擎层\" class=\"headerlink\" title=\"2. 存储引擎层\"></a>2. 存储引擎层</h3><p>负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n也就是说，你执行 <code>create table</code> 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 <code>create table</code> 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n连接器\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：</p>\n<pre><code>mysql -h$ip -P$port -u$user -p\n</code></pre>\n<p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。\n如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。</p>\n<p>怎么解决这个问题呢？你可以考虑以下两种方案。</p>\n<ol>\n<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>\n<li>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>\n</ol>\n<h2 id=\"查询缓存\"><a href=\"#查询缓存\" class=\"headerlink\" title=\"查询缓存\"></a>查询缓存</h2><p>连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\nmysql&gt; select SQL_CACHE * from T where ID=10；\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n分析器\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\nmysql&gt; elect * from t where ID=1;\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘elect * from t where ID=1’ at line 1\n一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p>\n<h2 id=\"优化器\"><a href=\"#优化器\" class=\"headerlink\" title=\"优化器\"></a>优化器</h2><p>经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：\nmysql&gt; select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;\n既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。</p>\n<h2 id=\"执行器\"><a href=\"#执行器\" class=\"headerlink\" title=\"执行器\"></a>执行器</h2><p>MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。</p>\n<pre><code class=\"SQL\">mysql&gt; select * from T where ID=10;\n</code></pre>\n<p><code>ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39;</code>\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：</p>\n<ul>\n<li>调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；</li>\n<li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li>\n<li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li>\n</ul>\n<p>至此，这个语句就执行完成了。\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天我给你介绍了 MySQL 的逻辑架构，希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。由于篇幅的限制，我只是用一个查询的例子将各个环节过了一遍。如果你还对每个环节的展开细节存有疑问，也不用担心，后续在实战章节中我还会再提到它们。\n我给你留一个问题吧，如果表 T 中没有字段 k，而你执行了这个语句 <code>select * from T where k=1</code>, 那肯定是会报“不存在这个列”的错误： <code>“Unknown column ‘k’ in ‘where clause’”</code>。</p>\n<p>你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？</p>\n<p>答案：分析器。一方面受到Oracle设计思想的影响，另外在《高性能mysql》里提到解析器和预处理器。解析器处理语法和解析查询, 生成一课对应的解析树。预处理器进一步检查解析树的合法。比如: 数据表和数据列是否存在, 别名是否有歧义等。如果通过则生成新的解析树，再提交给优化器；</p>"},{"title":"02 | 日志系统：一条SQL更新语句是如何执行的","date":"2019-06-02T16:00:00.000Z","_content":"\n\n前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。\n\n那么，一条更新语句的执行流程又是怎样的呢？之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？\n\n我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 `ID` 和一个整型字段 `c`：\n\n```SQL\nmysql> create table T(ID int primary key, c int);\n```\n\n<!-- more -->\n\n如果要将 `ID=2` 这一行的值加 1，SQL 语句就会这么写：\n```\nmysql> update T set c=c+1 where ID=2;\n```\n\n\n\n前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。\n\n![MySQL 的逻辑架构图](0d2070e8f84c4801adbfa03bda1f98d9.png)\n\n你执行语句前要先连接数据库，这是连接器的工作。\n\n\n前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。\n\n\n接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。\n\n\n\n与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。\n\n\n\n## redo log\n\n不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。\n\n\n如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n- 直接把账本翻出来，把这次赊的账加上去或者扣除掉；\n- 先在粉板上记下这次的账，等打烊以后再把账本翻出来核算；\n\n在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。\n\n这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？\n\n同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。\n\n而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 `WAL` 技术，`WAL` 的全称是 `Write-Ahead Logging`，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。\n\n具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 `redo log`（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。\n\n如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。\n\n与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件（innodb_log_files_in_group＝4，innodb_log_file_size＝4294967296），每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\n\n![](16a7950217b3f0f4ed02db5db59562a7.png)\n\n`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n`checkpoint` 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\n\n`write pos` 和 `checkpoint` 之间的是\"粉板\"上还空着的部分，可以用来记录新的操作。如果 `write pos` 追上 `checkpoint`，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 `checkpoint` 推进一下。\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。\n\n要理解 `crash-safe` 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。\n\n## binlog\n\n前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n\n我想你肯定会问，为什么会有两份日志呢？\n\n因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n\n这两种日志有以下三点不同:\n1. `redo log` 是 `InnoDB` 引擎特有的；`binlog` 是 `MySQL Server`层实现的，所有引擎都可以使用\n2. `redo log` 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如\"给 `ID=2` 这一行的 `c` 字段加 1\"\n3. `redo log` 是循环写的，空间固定会用完；`binlog` 是可以追加写入的。“追加写”是指 `binlog` 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。\n\n执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n\n1. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据\n2. 执行器调用引擎接口写入这行新数据\n3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态\n4. 引擎告知执行器执行完成了，随时可以提交事务\n5. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘\n6. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成\n\n这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。\n\nupdate 语句执行流程\n\n你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是\"两阶段提交\"。\n\n## 两阶段提交\n\n为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？\n\n\n前面我们说过了，`binlog` 会记录所有的逻辑操作，并且是采用`追加写`的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。\n\n\n当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：\n\n\n首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；\n\n然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。\n\n这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。\n\n\n\n好了，说完了数据恢复过程，我们回来说说，为什么日志需要`两阶段提交`。这里不妨用反证法来进行解释。\n\n\n由于 `redo log` 和 `binlog` 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。\n\n\n仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n\n1. 先写 `redo log` 后写 `binlog`。假设在 `redo log` 写完，`binlog` 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。\n但是由于 `binlog` 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n\n2. 先写 `binlog` 后写 `redo log`。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n\n\n可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n\n\n\n你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？\n\n\n\n其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\n\n\n\n简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。\n\n\n\n## 小结\n\n今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。\n\n\n\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\n\n\n\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n\n\n\n我还跟你介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。\n\n\n\n文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n\n\n\n备份时间周期的长短，理解需要考虑\n\n业务实际的数据存量，如果大到一天没有办法备份完成，只能一周一次，甚至更长\n\n业务数据的增量，如果增量非常大，如果一周备份一次，增量备份的考验会比较大，极大的概率会出现增量备份失败问题，另外恢复时长和成功率也比较困难\n\n业务比较重要并且对恢复时间的忍受程度低，并且历史上多次出现类似数据回滚的需求，而且增量还不小优先一天一备份，相反业务实际不重要，出问题后可以容忍一定的不可用，而且增量还不多，出于成本考虑可以用一周一备份\n\n备份文件的恢复效率很高的话，大多业务增量一周的恢复时长还是可以保证的，这时候就是提供SLA让业务决策了\n\n综合数据存量、增量、备份成本、恢复效率、业务SLA选择，我理解就有答案了！\n\n\n\n精彩评语：\n\n两阶段提交遇到Mysqld crash\n1. prepare阶段 \n2. 写binlog \n3. commit\n\n当在2之前崩溃时\n重启恢复：后发现没有commit，回滚。\n备份恢复：没有binlog\n当在3之前崩溃\n重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。\n备份：有binlog.\n\n知识点\n\nredo是物理的，binlog是逻辑的；现在由于redo是属于InnoDB引擎，所以必须要有binlog，因为你可以使用别的引擎\n\n保证数据库的一致性，必须要保证2份日志一致，使用的2阶段式提交；其实感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败\n\n如果有一天mysql只有InnoDB引擎了，有redo来实现复制，那么感觉oracle的DG就诞生了，物理的速度也将远超逻辑的，毕竟只记录了改动向量\n\nbinlog几大模式，一般采用row，因为遇到时间，从库可能会出现不一致的情况，但是row更新前后都有，会导致日志变大\n\n最后2个落盘参数，保证事务成功，日志必须落盘，这样，数据库crash后，就不会丢失某个事务的数据了","source":"_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的.md","raw":"---\ntitle: 02 | 日志系统：一条SQL更新语句是如何执行的\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n\n前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。\n\n那么，一条更新语句的执行流程又是怎样的呢？之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？\n\n我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 `ID` 和一个整型字段 `c`：\n\n```SQL\nmysql> create table T(ID int primary key, c int);\n```\n\n<!-- more -->\n\n如果要将 `ID=2` 这一行的值加 1，SQL 语句就会这么写：\n```\nmysql> update T set c=c+1 where ID=2;\n```\n\n\n\n前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。\n\n![MySQL 的逻辑架构图](0d2070e8f84c4801adbfa03bda1f98d9.png)\n\n你执行语句前要先连接数据库，这是连接器的工作。\n\n\n前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。\n\n\n接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。\n\n\n\n与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。\n\n\n\n## redo log\n\n不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。\n\n\n如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n- 直接把账本翻出来，把这次赊的账加上去或者扣除掉；\n- 先在粉板上记下这次的账，等打烊以后再把账本翻出来核算；\n\n在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。\n\n这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？\n\n同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。\n\n而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 `WAL` 技术，`WAL` 的全称是 `Write-Ahead Logging`，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。\n\n具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 `redo log`（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。\n\n如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。\n\n与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件（innodb_log_files_in_group＝4，innodb_log_file_size＝4294967296），每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。\n\n![](16a7950217b3f0f4ed02db5db59562a7.png)\n\n`write pos` 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n`checkpoint` 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\n\n`write pos` 和 `checkpoint` 之间的是\"粉板\"上还空着的部分，可以用来记录新的操作。如果 `write pos` 追上 `checkpoint`，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 `checkpoint` 推进一下。\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为`crash-safe`。\n\n要理解 `crash-safe` 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。\n\n## binlog\n\n前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n\n我想你肯定会问，为什么会有两份日志呢？\n\n因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n\n这两种日志有以下三点不同:\n1. `redo log` 是 `InnoDB` 引擎特有的；`binlog` 是 `MySQL Server`层实现的，所有引擎都可以使用\n2. `redo log` 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如\"给 `ID=2` 这一行的 `c` 字段加 1\"\n3. `redo log` 是循环写的，空间固定会用完；`binlog` 是可以追加写入的。“追加写”是指 `binlog` 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。\n\n执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n\n1. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据\n2. 执行器调用引擎接口写入这行新数据\n3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态\n4. 引擎告知执行器执行完成了，随时可以提交事务\n5. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘\n6. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成\n\n这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。\n\nupdate 语句执行流程\n\n你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是\"两阶段提交\"。\n\n## 两阶段提交\n\n为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？\n\n\n前面我们说过了，`binlog` 会记录所有的逻辑操作，并且是采用`追加写`的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。\n\n\n当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：\n\n\n首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；\n\n然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。\n\n这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。\n\n\n\n好了，说完了数据恢复过程，我们回来说说，为什么日志需要`两阶段提交`。这里不妨用反证法来进行解释。\n\n\n由于 `redo log` 和 `binlog` 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。\n\n\n仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n\n1. 先写 `redo log` 后写 `binlog`。假设在 `redo log` 写完，`binlog` 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。\n但是由于 `binlog` 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n\n2. 先写 `binlog` 后写 `redo log`。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n\n\n可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。\n\n\n\n你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？\n\n\n\n其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\n\n\n\n简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。\n\n\n\n## 小结\n\n今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。\n\n\n\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\n\n\n\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n\n\n\n我还跟你介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。\n\n\n\n文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n\n\n\n备份时间周期的长短，理解需要考虑\n\n业务实际的数据存量，如果大到一天没有办法备份完成，只能一周一次，甚至更长\n\n业务数据的增量，如果增量非常大，如果一周备份一次，增量备份的考验会比较大，极大的概率会出现增量备份失败问题，另外恢复时长和成功率也比较困难\n\n业务比较重要并且对恢复时间的忍受程度低，并且历史上多次出现类似数据回滚的需求，而且增量还不小优先一天一备份，相反业务实际不重要，出问题后可以容忍一定的不可用，而且增量还不多，出于成本考虑可以用一周一备份\n\n备份文件的恢复效率很高的话，大多业务增量一周的恢复时长还是可以保证的，这时候就是提供SLA让业务决策了\n\n综合数据存量、增量、备份成本、恢复效率、业务SLA选择，我理解就有答案了！\n\n\n\n精彩评语：\n\n两阶段提交遇到Mysqld crash\n1. prepare阶段 \n2. 写binlog \n3. commit\n\n当在2之前崩溃时\n重启恢复：后发现没有commit，回滚。\n备份恢复：没有binlog\n当在3之前崩溃\n重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。\n备份：有binlog.\n\n知识点\n\nredo是物理的，binlog是逻辑的；现在由于redo是属于InnoDB引擎，所以必须要有binlog，因为你可以使用别的引擎\n\n保证数据库的一致性，必须要保证2份日志一致，使用的2阶段式提交；其实感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败\n\n如果有一天mysql只有InnoDB引擎了，有redo来实现复制，那么感觉oracle的DG就诞生了，物理的速度也将远超逻辑的，毕竟只记录了改动向量\n\nbinlog几大模式，一般采用row，因为遇到时间，从库可能会出现不一致的情况，但是row更新前后都有，会导致日志变大\n\n最后2个落盘参数，保证事务成功，日志必须落盘，这样，数据库crash后，就不会丢失某个事务的数据了","slug":"02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的","published":1,"updated":"2021-06-30T02:33:24.550Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsuv0003r5p762oi8jkr","content":"<p>前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。</p>\n<p>那么，一条更新语句的执行流程又是怎样的呢？之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？</p>\n<p>我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 <code>ID</code> 和一个整型字段 <code>c</code>：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> create table T(ID int primary key, c int);\n</code></pre>\n<span id=\"more\"></span>\n\n<p>如果要将 <code>ID=2</code> 这一行的值加 1，SQL 语句就会这么写：</p>\n<pre><code>mysql&gt; update T set c=c+1 where ID=2;\n</code></pre>\n<p>前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。</p>\n<p><img src=\"0d2070e8f84c4801adbfa03bda1f98d9.png\" alt=\"MySQL 的逻辑架构图\"></p>\n<p>你执行语句前要先连接数据库，这是连接器的工作。</p>\n<p>前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。</p>\n<p>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。</p>\n<p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。</p>\n<h2 id=\"redo-log\"><a href=\"#redo-log\" class=\"headerlink\" title=\"redo log\"></a>redo log</h2><p>不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。</p>\n<p>如果有人要赊账或者还账的话，掌柜一般有两种做法：</p>\n<ul>\n<li>直接把账本翻出来，把这次赊的账加上去或者扣除掉；</li>\n<li>先在粉板上记下这次的账，等打烊以后再把账本翻出来核算；</li>\n</ul>\n<p>在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。</p>\n<p>这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？</p>\n<p>同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。</p>\n<p>而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 <code>WAL</code> 技术，<code>WAL</code> 的全称是 <code>Write-Ahead Logging</code>，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</p>\n<p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 <code>redo log</code>（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。</p>\n<p>如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。</p>\n<p>与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件（innodb_log_files_in_group＝4，innodb_log_file_size＝4294967296），每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p>\n<p><img src=\"16a7950217b3f0f4ed02db5db59562a7.png\"></p>\n<p><code>write pos</code> 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n<code>checkpoint</code> 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p>\n<p><code>write pos</code> 和 <code>checkpoint</code> 之间的是”粉板”上还空着的部分，可以用来记录新的操作。如果 <code>write pos</code> 追上 <code>checkpoint</code>，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 <code>checkpoint</code> 推进一下。</p>\n<p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<code>crash-safe</code>。</p>\n<p>要理解 <code>crash-safe</code> 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。</p>\n<h2 id=\"binlog\"><a href=\"#binlog\" class=\"headerlink\" title=\"binlog\"></a>binlog</h2><p>前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。</p>\n<p>我想你肯定会问，为什么会有两份日志呢？</p>\n<p>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。</p>\n<p>这两种日志有以下三点不同:</p>\n<ol>\n<li><code>redo log</code> 是 <code>InnoDB</code> 引擎特有的；<code>binlog</code> 是 <code>MySQL Server</code>层实现的，所有引擎都可以使用</li>\n<li><code>redo log</code> 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如”给 <code>ID=2</code> 这一行的 <code>c</code> 字段加 1”</li>\n<li><code>redo log</code> 是循环写的，空间固定会用完；<code>binlog</code> 是可以追加写入的。“追加写”是指 <code>binlog</code> 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>\n</ol>\n<p>有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。</p>\n<p>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p>\n<ol>\n<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据</li>\n<li>执行器调用引擎接口写入这行新数据</li>\n<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态</li>\n<li>引擎告知执行器执行完成了，随时可以提交事务</li>\n<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘</li>\n<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成</li>\n</ol>\n<p>这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。</p>\n<p>update 语句执行流程</p>\n<p>你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。</p>\n<h2 id=\"两阶段提交\"><a href=\"#两阶段提交\" class=\"headerlink\" title=\"两阶段提交\"></a>两阶段提交</h2><p>为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？</p>\n<p>前面我们说过了，<code>binlog</code> 会记录所有的逻辑操作，并且是采用<code>追加写</code>的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p>\n<p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p>\n<p>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</p>\n<p>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</p>\n<p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p>\n<p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要<code>两阶段提交</code>。这里不妨用反证法来进行解释。</p>\n<p>由于 <code>redo log</code> 和 <code>binlog</code> 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p>\n<p>仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？</p>\n<ol>\n<li><p>先写 <code>redo log</code> 后写 <code>binlog</code>。假设在 <code>redo log</code> 写完，<code>binlog</code> 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。\n但是由于 <code>binlog</code> 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</p>\n</li>\n<li><p>先写 <code>binlog</code> 后写 <code>redo log</code>。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。</p>\n</li>\n</ol>\n<p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p>\n<p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？</p>\n<p>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p>\n<p>简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。</p>\n<p>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。</p>\n<p>sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</p>\n<p>我还跟你介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。</p>\n<p>文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？</p>\n<p>备份时间周期的长短，理解需要考虑</p>\n<p>业务实际的数据存量，如果大到一天没有办法备份完成，只能一周一次，甚至更长</p>\n<p>业务数据的增量，如果增量非常大，如果一周备份一次，增量备份的考验会比较大，极大的概率会出现增量备份失败问题，另外恢复时长和成功率也比较困难</p>\n<p>业务比较重要并且对恢复时间的忍受程度低，并且历史上多次出现类似数据回滚的需求，而且增量还不小优先一天一备份，相反业务实际不重要，出问题后可以容忍一定的不可用，而且增量还不多，出于成本考虑可以用一周一备份</p>\n<p>备份文件的恢复效率很高的话，大多业务增量一周的恢复时长还是可以保证的，这时候就是提供SLA让业务决策了</p>\n<p>综合数据存量、增量、备份成本、恢复效率、业务SLA选择，我理解就有答案了！</p>\n<p>精彩评语：</p>\n<p>两阶段提交遇到Mysqld crash</p>\n<ol>\n<li>prepare阶段 </li>\n<li>写binlog </li>\n<li>commit</li>\n</ol>\n<p>当在2之前崩溃时\n重启恢复：后发现没有commit，回滚。\n备份恢复：没有binlog\n当在3之前崩溃\n重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。\n备份：有binlog.</p>\n<p>知识点</p>\n<p>redo是物理的，binlog是逻辑的；现在由于redo是属于InnoDB引擎，所以必须要有binlog，因为你可以使用别的引擎</p>\n<p>保证数据库的一致性，必须要保证2份日志一致，使用的2阶段式提交；其实感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败</p>\n<p>如果有一天mysql只有InnoDB引擎了，有redo来实现复制，那么感觉oracle的DG就诞生了，物理的速度也将远超逻辑的，毕竟只记录了改动向量</p>\n<p>binlog几大模式，一般采用row，因为遇到时间，从库可能会出现不一致的情况，但是row更新前后都有，会导致日志变大</p>\n<p>最后2个落盘参数，保证事务成功，日志必须落盘，这样，数据库crash后，就不会丢失某个事务的数据了</p>\n","site":{"data":{}},"excerpt":"<p>前面我们系统了解了一个查询语句的执行流程，并介绍了执行过程中涉及的处理模块。相信你还记得，一条查询语句的执行过程一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。</p>\n<p>那么，一条更新语句的执行流程又是怎样的呢？之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？</p>\n<p>我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 <code>ID</code> 和一个整型字段 <code>c</code>：</p>\n<pre><code class=\"SQL\">mysql&gt; create table T(ID int primary key, c int);\n</code></pre>","more":"<p>如果要将 <code>ID=2</code> 这一行的值加 1，SQL 语句就会这么写：</p>\n<pre><code>mysql&gt; update T set c=c+1 where ID=2;\n</code></pre>\n<p>前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。</p>\n<p><img src=\"0d2070e8f84c4801adbfa03bda1f98d9.png\" alt=\"MySQL 的逻辑架构图\"></p>\n<p>你执行语句前要先连接数据库，这是连接器的工作。</p>\n<p>前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。</p>\n<p>接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。</p>\n<p>与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。如果接触 MySQL，那这两个词肯定是绕不过的，我后面的内容里也会不断地和你强调。不过话说回来，redo log 和 binlog 在设计上有很多有意思的地方，这些设计思路也可以用到你自己的程序里。</p>\n<h2 id=\"redo-log\"><a href=\"#redo-log\" class=\"headerlink\" title=\"redo log\"></a>redo log</h2><p>不知道你还记不记得《孔乙己》这篇文章，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。</p>\n<p>如果有人要赊账或者还账的话，掌柜一般有两种做法：</p>\n<ul>\n<li>直接把账本翻出来，把这次赊的账加上去或者扣除掉；</li>\n<li>先在粉板上记下这次的账，等打烊以后再把账本翻出来核算；</li>\n</ul>\n<p>在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。你想想，密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后再将结果写回到账本上。</p>\n<p>这整个过程想想都麻烦。相比之下，还是先在粉板上记一下方便。你想想，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？</p>\n<p>同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。</p>\n<p>而粉板和账本配合的整个过程，其实就是 MySQL 里经常说到的 <code>WAL</code> 技术，<code>WAL</code> 的全称是 <code>Write-Ahead Logging</code>，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</p>\n<p>具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 <code>redo log</code>（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。</p>\n<p>如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。</p>\n<p>与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件（innodb_log_files_in_group＝4，innodb_log_file_size＝4294967296），每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p>\n<p><img src=\"16a7950217b3f0f4ed02db5db59562a7.png\"></p>\n<p><code>write pos</code> 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n<code>checkpoint</code> 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p>\n<p><code>write pos</code> 和 <code>checkpoint</code> 之间的是”粉板”上还空着的部分，可以用来记录新的操作。如果 <code>write pos</code> 追上 <code>checkpoint</code>，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 <code>checkpoint</code> 推进一下。</p>\n<p>有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<code>crash-safe</code>。</p>\n<p>要理解 <code>crash-safe</code> 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。</p>\n<h2 id=\"binlog\"><a href=\"#binlog\" class=\"headerlink\" title=\"binlog\"></a>binlog</h2><p>前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。</p>\n<p>我想你肯定会问，为什么会有两份日志呢？</p>\n<p>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。</p>\n<p>这两种日志有以下三点不同:</p>\n<ol>\n<li><code>redo log</code> 是 <code>InnoDB</code> 引擎特有的；<code>binlog</code> 是 <code>MySQL Server</code>层实现的，所有引擎都可以使用</li>\n<li><code>redo log</code> 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如”给 <code>ID=2</code> 这一行的 <code>c</code> 字段加 1”</li>\n<li><code>redo log</code> 是循环写的，空间固定会用完；<code>binlog</code> 是可以追加写入的。“追加写”是指 <code>binlog</code> 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>\n</ol>\n<p>有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。</p>\n<p>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</p>\n<ol>\n<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据</li>\n<li>执行器调用引擎接口写入这行新数据</li>\n<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态</li>\n<li>引擎告知执行器执行完成了，随时可以提交事务</li>\n<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘</li>\n<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成</li>\n</ol>\n<p>这里我给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。</p>\n<p>update 语句执行流程</p>\n<p>你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。</p>\n<h2 id=\"两阶段提交\"><a href=\"#两阶段提交\" class=\"headerlink\" title=\"两阶段提交\"></a>两阶段提交</h2><p>为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？</p>\n<p>前面我们说过了，<code>binlog</code> 会记录所有的逻辑操作，并且是采用<code>追加写</code>的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p>\n<p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p>\n<p>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</p>\n<p>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</p>\n<p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p>\n<p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要<code>两阶段提交</code>。这里不妨用反证法来进行解释。</p>\n<p>由于 <code>redo log</code> 和 <code>binlog</code> 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p>\n<p>仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？</p>\n<ol>\n<li><p>先写 <code>redo log</code> 后写 <code>binlog</code>。假设在 <code>redo log</code> 写完，<code>binlog</code> 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。\n但是由于 <code>binlog</code> 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</p>\n</li>\n<li><p>先写 <code>binlog</code> 后写 <code>redo log</code>。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。</p>\n</li>\n</ol>\n<p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p>\n<p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？</p>\n<p>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p>\n<p>简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天，我介绍了 MySQL 里面最重要的两个日志，即物理日志 redo log 和逻辑日志 binlog。</p>\n<p>redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。</p>\n<p>sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。</p>\n<p>我还跟你介绍了与 MySQL 日志系统密切相关的“两阶段提交”。两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。</p>\n<p>文章的最后，我给你留一个思考题吧。前面我说到定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？</p>\n<p>备份时间周期的长短，理解需要考虑</p>\n<p>业务实际的数据存量，如果大到一天没有办法备份完成，只能一周一次，甚至更长</p>\n<p>业务数据的增量，如果增量非常大，如果一周备份一次，增量备份的考验会比较大，极大的概率会出现增量备份失败问题，另外恢复时长和成功率也比较困难</p>\n<p>业务比较重要并且对恢复时间的忍受程度低，并且历史上多次出现类似数据回滚的需求，而且增量还不小优先一天一备份，相反业务实际不重要，出问题后可以容忍一定的不可用，而且增量还不多，出于成本考虑可以用一周一备份</p>\n<p>备份文件的恢复效率很高的话，大多业务增量一周的恢复时长还是可以保证的，这时候就是提供SLA让业务决策了</p>\n<p>综合数据存量、增量、备份成本、恢复效率、业务SLA选择，我理解就有答案了！</p>\n<p>精彩评语：</p>\n<p>两阶段提交遇到Mysqld crash</p>\n<ol>\n<li>prepare阶段 </li>\n<li>写binlog </li>\n<li>commit</li>\n</ol>\n<p>当在2之前崩溃时\n重启恢复：后发现没有commit，回滚。\n备份恢复：没有binlog\n当在3之前崩溃\n重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。\n备份：有binlog.</p>\n<p>知识点</p>\n<p>redo是物理的，binlog是逻辑的；现在由于redo是属于InnoDB引擎，所以必须要有binlog，因为你可以使用别的引擎</p>\n<p>保证数据库的一致性，必须要保证2份日志一致，使用的2阶段式提交；其实感觉像事务，不是成功就是失败，不能让中间环节出现，也就是一个成功，一个失败</p>\n<p>如果有一天mysql只有InnoDB引擎了，有redo来实现复制，那么感觉oracle的DG就诞生了，物理的速度也将远超逻辑的，毕竟只记录了改动向量</p>\n<p>binlog几大模式，一般采用row，因为遇到时间，从库可能会出现不一致的情况，但是row更新前后都有，会导致日志变大</p>\n<p>最后2个落盘参数，保证事务成功，日志必须落盘，这样，数据库crash后，就不会丢失某个事务的数据了</p>"},{"title":"03 | 事务隔离：为什么你改了我还看不见","date":"2019-06-02T16:00:00.000Z","_content":"\n\n提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。\n\n\n\n最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。\n\n\n\n简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\n\n\n\n今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。\n\n<br/>\n### 隔离性与隔离级别\n\n提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。当数据库上有多个事务同时执行的时候，就可能出现`脏读（dirty read）`、`不可重复读（non-repeatable read）`、`幻读（phantom read）`的问题，为了解决这些问题，就有了“隔离级别”的概念。\n\n\n\n在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：`读未提交（read uncommitted）`、`读提交（read committed）`、`可重复读（repeatable read）`和`串行化（serializable ）`。下面我逐一为你解释：\n\n1. 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。\n\n2. 读提交：一个事务提交之后，它做的变更才会被其他事务看到。\n\n3. 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n\n4. 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n\n其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。\n\n\n```\nmysql> create table T(c int) engine=InnoDB;\ninsert into T(c) values(1);\n```\n\n![](1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg)\n\n我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。\n- `读未提交（read uncommitted）`：则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2\n- `读提交（read committed）`：则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。\n- `可重复读（repeatable read）`：则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。\n- `串行化（serializable ）`：则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。\n\n\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n\n我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。\n\n配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。\n```\nmysql> show variables like 'transaction_isolation'; \n+-----------------------+----------------+\n| Variable_name | Value |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n```\n\n总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。\n\n\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n\n\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n<br/>\n### 事务隔离的实现\n\n理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。\n\n\n当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n\n\n\n同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。\n\n你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。\n\n什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。\n\n基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。\n\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n\n在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。\n\n\n除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。\n\n\n<br/>\n### 事务的启动方式\n\n\n如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：\n\n\n显式启动事务语句， `begin` 或 `start transaction`。配套的提交语句是 `commit`，回滚语句是 `rollback`。\n\n\n`set autocommit=0`，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n\n\n因此，我会建议你总是使用 `set autocommit=1`, 通过显式语句的方式来启动事务。\n\n但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。\n\n\n\n在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n\n\n你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。\n```\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60\n```\n\n\n## 小结\n\n这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。\n\n我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\n\n\n这个问题，我们可以从应用开发端和数据库端来看。\n\n首先，从应用开发端来看：\n\n确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n\n确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中，这种只读事务可以去掉。\n\n业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）\n\n\n其次，从数据库端来看：\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；Percona 的 pt-kill 这个工具不错，推荐使用；\n\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n\n如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。","source":"_posts/03-MySQL实战45讲-事务隔离：为什么你改了我还看不见.md","raw":"---\ntitle: 03 | 事务隔离：为什么你改了我还看不见\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n\n提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。\n\n\n\n最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。\n\n\n\n简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\n\n\n\n今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。\n\n<br/>\n### 隔离性与隔离级别\n\n提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。当数据库上有多个事务同时执行的时候，就可能出现`脏读（dirty read）`、`不可重复读（non-repeatable read）`、`幻读（phantom read）`的问题，为了解决这些问题，就有了“隔离级别”的概念。\n\n\n\n在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：`读未提交（read uncommitted）`、`读提交（read committed）`、`可重复读（repeatable read）`和`串行化（serializable ）`。下面我逐一为你解释：\n\n1. 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。\n\n2. 读提交：一个事务提交之后，它做的变更才会被其他事务看到。\n\n3. 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n\n4. 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n\n其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。\n\n\n```\nmysql> create table T(c int) engine=InnoDB;\ninsert into T(c) values(1);\n```\n\n![](1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg)\n\n我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。\n- `读未提交（read uncommitted）`：则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2\n- `读提交（read committed）`：则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。\n- `可重复读（repeatable read）`：则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。\n- `串行化（serializable ）`：则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。\n\n\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n\n我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。\n\n配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。\n```\nmysql> show variables like 'transaction_isolation'; \n+-----------------------+----------------+\n| Variable_name | Value |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n```\n\n总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。\n\n\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n\n\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n<br/>\n### 事务隔离的实现\n\n理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。\n\n\n当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n\n\n\n同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。\n\n你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。\n\n什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。\n\n基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。\n\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n\n在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。\n\n\n除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。\n\n\n<br/>\n### 事务的启动方式\n\n\n如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：\n\n\n显式启动事务语句， `begin` 或 `start transaction`。配套的提交语句是 `commit`，回滚语句是 `rollback`。\n\n\n`set autocommit=0`，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n\n\n因此，我会建议你总是使用 `set autocommit=1`, 通过显式语句的方式来启动事务。\n\n但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。\n\n\n\n在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n\n\n你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。\n```\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60\n```\n\n\n## 小结\n\n这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。\n\n我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\n\n\n这个问题，我们可以从应用开发端和数据库端来看。\n\n首先，从应用开发端来看：\n\n确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n\n确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中，这种只读事务可以去掉。\n\n业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）\n\n\n其次，从数据库端来看：\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；Percona 的 pt-kill 这个工具不错，推荐使用；\n\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n\n如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。","slug":"03-MySQL实战45讲-事务隔离：为什么你改了我还看不见","published":1,"updated":"2021-06-30T02:33:24.558Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsuy0007r5p7c7s4d9kg","content":"<p>提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。</p>\n<p>最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。</p>\n<p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。</p>\n<p>今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。</p>\n<br>\n### 隔离性与隔离级别\n\n<p>提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。当数据库上有多个事务同时执行的时候，就可能出现<code>脏读（dirty read）</code>、<code>不可重复读（non-repeatable read）</code>、<code>幻读（phantom read）</code>的问题，为了解决这些问题，就有了“隔离级别”的概念。</p>\n<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：<code>读未提交（read uncommitted）</code>、<code>读提交（read committed）</code>、<code>可重复读（repeatable read）</code>和<code>串行化（serializable ）</code>。下面我逐一为你解释：</p>\n<ol>\n<li><p>读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。</p>\n</li>\n<li><p>读提交：一个事务提交之后，它做的变更才会被其他事务看到。</p>\n</li>\n<li><p>可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</p>\n</li>\n<li><p>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p>\n</li>\n</ol>\n<p>其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。</p>\n<pre><code>mysql&gt; create table T(c int) engine=InnoDB;\ninsert into T(c) values(1);\n</code></pre>\n<p><img src=\"1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg\"></p>\n<p>我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。</p>\n<ul>\n<li><code>读未提交（read uncommitted）</code>：则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2</li>\n<li><code>读提交（read committed）</code>：则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。</li>\n<li><code>可重复读（repeatable read）</code>：则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</li>\n<li><code>串行化（serializable ）</code>：则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。</li>\n</ul>\n<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n<p>我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。</p>\n<p>配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。</p>\n<pre><code>mysql&gt; show variables like 'transaction_isolation'; \n+-----------------------+----------------+\n| Variable_name | Value |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n</code></pre>\n<p>总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。</p>\n<p>假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。</p>\n<p>这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p>\n<br>\n### 事务隔离的实现\n\n<p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。</p>\n<p>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。</p>\n<p>当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。</p>\n<p>同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。</p>\n<p>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p>\n<p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。</p>\n<p>基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。</p>\n<p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>\n<p>在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。</p>\n<p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。</p>\n<br>\n### 事务的启动方式\n\n\n<p>如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：</p>\n<p>显式启动事务语句， <code>begin</code> 或 <code>start transaction</code>。配套的提交语句是 <code>commit</code>，回滚语句是 <code>rollback</code>。</p>\n<p><code>set autocommit=0</code>，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。</p>\n<p>有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。</p>\n<p>因此，我会建议你总是使用 <code>set autocommit=1</code>, 通过显式语句的方式来启动事务。</p>\n<p>但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。</p>\n<p>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p>\n<p>你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。</p>\n<pre><code>select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60\n</code></pre>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。</p>\n<p>我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？</p>\n<p>这个问题，我们可以从应用开发端和数据库端来看。</p>\n<p>首先，从应用开发端来看：</p>\n<p>确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。</p>\n<p>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中，这种只读事务可以去掉。</p>\n<p>业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）</p>\n<p>其次，从数据库端来看：</p>\n<p>监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；Percona 的 pt-kill 这个工具不错，推荐使用；</p>\n<p>在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；</p>\n<p>如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>提到事务，你肯定不陌生，和数据库打交道的时候，我们总是会用到事务。</p>\n<p>最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账，如果银行这么整，不就乱了么？这时就要用到“事务”这个概念了。</p>\n<p>简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。</p>\n<p>今天的文章里，我将会以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议，希望这些案例能加深你对 MySQL 事务原理的理解。</p>\n<br/>\n### 隔离性与隔离级别\n\n<p>提到事务，你肯定会想到 ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中 I，也就是“隔离性”。当数据库上有多个事务同时执行的时候，就可能出现<code>脏读（dirty read）</code>、<code>不可重复读（non-repeatable read）</code>、<code>幻读（phantom read）</code>的问题，为了解决这些问题，就有了“隔离级别”的概念。</p>\n<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：<code>读未提交（read uncommitted）</code>、<code>读提交（read committed）</code>、<code>可重复读（repeatable read）</code>和<code>串行化（serializable ）</code>。下面我逐一为你解释：</p>\n<ol>\n<li><p>读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。</p>\n</li>\n<li><p>读提交：一个事务提交之后，它做的变更才会被其他事务看到。</p>\n</li>\n<li><p>可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</p>\n</li>\n<li><p>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</p>\n</li>\n</ol>\n<p>其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。</p>\n<pre><code>mysql&gt; create table T(c int) engine=InnoDB;\ninsert into T(c) values(1);\n</code></pre>\n<p><img src=\"1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg\"></p>\n<p>我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。</p>\n<ul>\n<li><code>读未提交（read uncommitted）</code>：则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2</li>\n<li><code>读提交（read committed）</code>：则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。</li>\n<li><code>可重复读（repeatable read）</code>：则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。</li>\n<li><code>串行化（serializable ）</code>：则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。</li>\n</ul>\n<p>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。</p>\n<p>我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。</p>\n<p>配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。</p>\n<pre><code>mysql&gt; show variables like &#39;transaction_isolation&#39;; \n+-----------------------+----------------+\n| Variable_name | Value |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n</code></pre>\n<p>总结来说，存在即合理，哪个隔离级别都有它自己的使用场景，你要根据自己的业务情况来定。我想你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。</p>\n<p>假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。</p>\n<p>这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。</p>\n<br/>\n### 事务隔离的实现\n\n<p>理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。</p>\n<p>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。</p>\n<p>当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。</p>\n<p>同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。</p>\n<p>你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。</p>\n<p>什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。</p>\n<p>基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。</p>\n<p>长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。</p>\n<p>在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。</p>\n<p>除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。</p>\n<br/>\n### 事务的启动方式\n\n\n<p>如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：</p>\n<p>显式启动事务语句， <code>begin</code> 或 <code>start transaction</code>。配套的提交语句是 <code>commit</code>，回滚语句是 <code>rollback</code>。</p>\n<p><code>set autocommit=0</code>，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。</p>\n<p>有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。</p>\n<p>因此，我会建议你总是使用 <code>set autocommit=1</code>, 通过显式语句的方式来启动事务。</p>\n<p>但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法。</p>\n<p>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</p>\n<p>你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。</p>\n<pre><code>select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60\n</code></pre>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>这篇文章里面，我介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。</p>\n<p>我给你留一个问题吧。你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？</p>\n<p>这个问题，我们可以从应用开发端和数据库端来看。</p>\n<p>首先，从应用开发端来看：</p>\n<p>确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。</p>\n<p>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中，这种只读事务可以去掉。</p>\n<p>业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）</p>\n<p>其次，从数据库端来看：</p>\n<p>监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；Percona 的 pt-kill 这个工具不错，推荐使用；</p>\n<p>在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；</p>\n<p>如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</p>\n"},{"title":"05 | 深入浅出索引（下）","date":"2019-06-02T16:00:00.000Z","_content":"\n在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。\n\n在开始这篇文章之前，我们先来看一下这个问题：\n\n在下面这个表 T 中，如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？\n\n下面是这个表的初始化语句。\n\n```SQL\nmysql> create table T (\n    ID int primary key,\n    k int NOT NULL DEFAULT 0, \n    s varchar(16) NOT NULL DEFAULT '',\n    index k(k)\n) engine=InnoDB;\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n```\n\n<!--more-->\n\n![图 1 InnoDB 的索引组织结构](1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg)\n\n\n\n现在，我们一起来看看这条 SQL 查询语句的执行流程：\n\n1. 在 k 索引树上找到 k=3 的记录，取得 `ID = 300`；\n2. 再到 ID 索引树查到 `ID=300` 对应的 R3；\n3. 在 k 索引树取下一个值 k=5，取得 ID=500；\n4. 再回到 ID 索引树查到 ID=500 对应的 R4；\n5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。\n\n在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。\n\n在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n\n\n## 覆盖索引\n\n如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n\n\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n\n\n需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。\n\n备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。\n\n\n\n基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？\n\n假设这个市民表的定义是这样的：\n\n```SQL\nCREATE TABLE `tuser` (\n  `id` int(11) NOT NULL,\n  `id_card` varchar(32) DEFAULT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `ismale` tinyint(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `id_card` (`id_card`),\n  KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n```\n\n我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？\n\n如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。\n\n当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。\n\n\n\n## 最左前缀原则\n\n看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该这么做呢？\n\n\n\n这里，我先和你说结论吧。B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。\n\n\n![图 2 （name，age）索引示意图](1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg)\n\n\n可以看到，索引项是按照索引定义里面出现的字段顺序排序的。\n\n当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。\n\n\n\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是\"where name like ‘张 %’\"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n\n\n\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n\n\n\n基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。\n\n\n\n这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n\n\n\n所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。\n\n\n\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。\n\n\n\n这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n\n\n## 索引下推\n\n上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？\n\n\n我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：\n\n\n```\nmysql> select * from tuser where name like '张 %' and age=10 and ismale=1;\n```\n\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。\n\n\n\n然后呢？\n\n\n\n当然是判断其他条件是否满足。\n\n在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n\n而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n\n图 3 和图 4，是这两个过程的执行流程图。\n\n![图 3 无索引下推执行流程](1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg)\n\n![图 4 索引下推执行流程](1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg)\n\n\n\n在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。\n\n\n\n图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。\n\n图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。\n\n\n\n### 小结\n\n今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。\n\n接下来我给你留下一个问题吧。\n\n实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：\n\n``` SQL\nCREATE TABLE `geek` (\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  `c` int(11) NOT NULL,\n  `d` int(11) NOT NULL,\n  PRIMARY KEY (`a`,`b`),\n  KEY `ca` (`c`,`a`),\n  KEY `cb` (`c`,`b`)\n) ENGINE=InnoDB;\n```\n\n公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。\n\n但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？\n\n同事告诉他，是因为他们的业务里面有这样的两种语句：\n\n```SQL\nselect ... from geek where c=N order by a;\nselect ... from geek where c=N order by b;\n```\n\n我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？\n\n表记录\n\na | b | c | d\n--|---|---|--\n1 | 2 | 3 | d\n1 | 3 | 2 | d\n1 | 4 | 3 | d\n2 | 1 | 3 | d\n2 | 2 | 2 | d\n2 | 3 | 4 | d\n\n主键 `a`，`b` 的聚簇索引组织顺序相当于 `order by a,b` ，也就是先按 a 排序，再按 b 排序，c 无序。\n\n索引 `ca` 的组织是先按 `c` 排序，再按 `a` 排序，同时记录主键\n\n c | a | 主键部分b（注意，这里不是 ab，而是只有 b）\n---|---|-------------------------\n2 | 1 | 3\n2 | 2 | 2\n3 | 1 | 2\n3 | 1 | 4\n3 | 2 | 1\n4 | 2 | 3\n\n这个跟索引 c 的数据是一模一样的。\n\n索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键\n\n c | b | 主键部分a（同上）\n---|---|----------\n2 | 2 | 2\n2 | 3 | 1\n3 | 1 | 2\n3 | 2 | 1\n3 | 4 | 1\n4 | 3 | 2\n\n所以，结论是 `ca` 可以去掉，`cb` 需要保留","source":"_posts/05-MySQL实战45讲-深入浅出索引（下）.md","raw":"---\ntitle: 05 | 深入浅出索引（下）\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。\n\n在开始这篇文章之前，我们先来看一下这个问题：\n\n在下面这个表 T 中，如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？\n\n下面是这个表的初始化语句。\n\n```SQL\nmysql> create table T (\n    ID int primary key,\n    k int NOT NULL DEFAULT 0, \n    s varchar(16) NOT NULL DEFAULT '',\n    index k(k)\n) engine=InnoDB;\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n```\n\n<!--more-->\n\n![图 1 InnoDB 的索引组织结构](1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg)\n\n\n\n现在，我们一起来看看这条 SQL 查询语句的执行流程：\n\n1. 在 k 索引树上找到 k=3 的记录，取得 `ID = 300`；\n2. 再到 ID 索引树查到 `ID=300` 对应的 R3；\n3. 在 k 索引树取下一个值 k=5，取得 ID=500；\n4. 再回到 ID 索引树查到 ID=500 对应的 R4；\n5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。\n\n在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。\n\n在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n\n\n## 覆盖索引\n\n如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n\n\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n\n\n需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。\n\n备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。\n\n\n\n基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？\n\n假设这个市民表的定义是这样的：\n\n```SQL\nCREATE TABLE `tuser` (\n  `id` int(11) NOT NULL,\n  `id_card` varchar(32) DEFAULT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `ismale` tinyint(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `id_card` (`id_card`),\n  KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n```\n\n我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？\n\n如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。\n\n当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。\n\n\n\n## 最左前缀原则\n\n看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该这么做呢？\n\n\n\n这里，我先和你说结论吧。B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。\n\n\n![图 2 （name，age）索引示意图](1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg)\n\n\n可以看到，索引项是按照索引定义里面出现的字段顺序排序的。\n\n当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。\n\n\n\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是\"where name like ‘张 %’\"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n\n\n\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n\n\n\n基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。\n\n\n\n这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n\n\n\n所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。\n\n\n\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。\n\n\n\n这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n\n\n## 索引下推\n\n上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？\n\n\n我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：\n\n\n```\nmysql> select * from tuser where name like '张 %' and age=10 and ismale=1;\n```\n\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。\n\n\n\n然后呢？\n\n\n\n当然是判断其他条件是否满足。\n\n在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n\n而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n\n图 3 和图 4，是这两个过程的执行流程图。\n\n![图 3 无索引下推执行流程](1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg)\n\n![图 4 索引下推执行流程](1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg)\n\n\n\n在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。\n\n\n\n图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。\n\n图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。\n\n\n\n### 小结\n\n今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。\n\n接下来我给你留下一个问题吧。\n\n实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：\n\n``` SQL\nCREATE TABLE `geek` (\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  `c` int(11) NOT NULL,\n  `d` int(11) NOT NULL,\n  PRIMARY KEY (`a`,`b`),\n  KEY `ca` (`c`,`a`),\n  KEY `cb` (`c`,`b`)\n) ENGINE=InnoDB;\n```\n\n公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。\n\n但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？\n\n同事告诉他，是因为他们的业务里面有这样的两种语句：\n\n```SQL\nselect ... from geek where c=N order by a;\nselect ... from geek where c=N order by b;\n```\n\n我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？\n\n表记录\n\na | b | c | d\n--|---|---|--\n1 | 2 | 3 | d\n1 | 3 | 2 | d\n1 | 4 | 3 | d\n2 | 1 | 3 | d\n2 | 2 | 2 | d\n2 | 3 | 4 | d\n\n主键 `a`，`b` 的聚簇索引组织顺序相当于 `order by a,b` ，也就是先按 a 排序，再按 b 排序，c 无序。\n\n索引 `ca` 的组织是先按 `c` 排序，再按 `a` 排序，同时记录主键\n\n c | a | 主键部分b（注意，这里不是 ab，而是只有 b）\n---|---|-------------------------\n2 | 1 | 3\n2 | 2 | 2\n3 | 1 | 2\n3 | 1 | 4\n3 | 2 | 1\n4 | 2 | 3\n\n这个跟索引 c 的数据是一模一样的。\n\n索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键\n\n c | b | 主键部分a（同上）\n---|---|----------\n2 | 2 | 2\n2 | 3 | 1\n3 | 1 | 2\n3 | 2 | 1\n3 | 4 | 1\n4 | 3 | 2\n\n所以，结论是 `ca` 可以去掉，`cb` 需要保留","slug":"05-MySQL实战45讲-深入浅出索引（下）","published":1,"updated":"2021-06-30T02:33:24.565Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsuz0009r5p7bjyrhve3","content":"<p>在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。</p>\n<p>在开始这篇文章之前，我们先来看一下这个问题：</p>\n<p>在下面这个表 T 中，如果我执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p>\n<p>下面是这个表的初始化语句。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> create table T (\n    ID int primary key,\n    k int NOT NULL DEFAULT 0, \n    s varchar(16) NOT NULL DEFAULT '',\n    index k(k)\n) engine=InnoDB;\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n</code></pre>\n<span id=\"more\"></span>\n\n<p><img src=\"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg\" alt=\"图 1 InnoDB 的索引组织结构\"></p>\n<p>现在，我们一起来看看这条 SQL 查询语句的执行流程：</p>\n<ol>\n<li>在 k 索引树上找到 k=3 的记录，取得 <code>ID = 300</code>；</li>\n<li>再到 ID 索引树查到 <code>ID=300</code> 对应的 R3；</li>\n<li>在 k 索引树取下一个值 k=5，取得 ID=500；</li>\n<li>再回到 ID 索引树查到 ID=500 对应的 R4；</li>\n<li>在 k 索引树取下一个值 k=6，不满足条件，循环结束。</li>\n</ol>\n<p>在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。</p>\n<p>在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？</p>\n<h2 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h2><p>如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p>\n<p>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</p>\n<p>需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。</p>\n<p>备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。</p>\n<p>基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？</p>\n<p>假设这个市民表的定义是这样的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `tuser` (\n  `id` int(11) NOT NULL,\n  `id_card` varchar(32) DEFAULT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `ismale` tinyint(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `id_card` (`id_card`),\n  KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n</code></pre>\n<p>我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？</p>\n<p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。</p>\n<p>当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。</p>\n<h2 id=\"最左前缀原则\"><a href=\"#最左前缀原则\" class=\"headerlink\" title=\"最左前缀原则\"></a>最左前缀原则</h2><p>看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该这么做呢？</p>\n<p>这里，我先和你说结论吧。B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。</p>\n<p><img src=\"1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg\" alt=\"图 2 （name，age）索引示意图\"></p>\n<p>可以看到，索引项是按照索引定义里面出现的字段顺序排序的。</p>\n<p>当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。</p>\n<p>如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。</p>\n<p>可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p>\n<p>基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。</p>\n<p>这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</p>\n<p>所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。</p>\n<p>那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。</p>\n<p>这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。</p>\n<h2 id=\"索引下推\"><a href=\"#索引下推\" class=\"headerlink\" title=\"索引下推\"></a>索引下推</h2><p>上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？</p>\n<p>我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：</p>\n<pre><code>mysql&gt; select * from tuser where name like '张 %' and age=10 and ismale=1;\n</code></pre>\n<p>你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。</p>\n<p>然后呢？</p>\n<p>当然是判断其他条件是否满足。</p>\n<p>在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。</p>\n<p>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p>\n<p>图 3 和图 4，是这两个过程的执行流程图。</p>\n<p><img src=\"1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg\" alt=\"图 3 无索引下推执行流程\"></p>\n<p><img src=\"1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg\" alt=\"图 4 索引下推执行流程\"></p>\n<p>在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。</p>\n<p>图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。</p>\n<p>图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。</p>\n<p>接下来我给你留下一个问题吧。</p>\n<p>实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `geek` (\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  `c` int(11) NOT NULL,\n  `d` int(11) NOT NULL,\n  PRIMARY KEY (`a`,`b`),\n  KEY `ca` (`c`,`a`),\n  KEY `cb` (`c`,`b`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。</p>\n<p>但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？</p>\n<p>同事告诉他，是因为他们的业务里面有这样的两种语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select ... from geek where c=N order by a;\nselect ... from geek where c=N order by b;\n</code></pre>\n<p>我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？</p>\n<p>表记录</p>\n<table>\n<thead>\n<tr>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n<th>d</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>2</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>1</td>\n<td>3</td>\n<td>2</td>\n<td>d</td>\n</tr>\n<tr>\n<td>1</td>\n<td>4</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>1</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n<td>4</td>\n<td>d</td>\n</tr>\n</tbody></table>\n<p>主键 <code>a</code>，<code>b</code> 的聚簇索引组织顺序相当于 <code>order by a,b</code> ，也就是先按 a 排序，再按 b 排序，c 无序。</p>\n<p>索引 <code>ca</code> 的组织是先按 <code>c</code> 排序，再按 <code>a</code> 排序，同时记录主键</p>\n<table>\n<thead>\n<tr>\n<th>c</th>\n<th>a</th>\n<th>主键部分b（注意，这里不是 ab，而是只有 b）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2</td>\n<td>1</td>\n<td>3</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>4</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2</td>\n<td>1</td>\n</tr>\n<tr>\n<td>4</td>\n<td>2</td>\n<td>3</td>\n</tr>\n</tbody></table>\n<p>这个跟索引 c 的数据是一模一样的。</p>\n<p>索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键</p>\n<table>\n<thead>\n<tr>\n<th>c</th>\n<th>b</th>\n<th>主键部分a（同上）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3</td>\n<td>4</td>\n<td>1</td>\n</tr>\n<tr>\n<td>4</td>\n<td>3</td>\n<td>2</td>\n</tr>\n</tbody></table>\n<p>所以，结论是 <code>ca</code> 可以去掉，<code>cb</code> 需要保留</p>\n","site":{"data":{}},"excerpt":"<p>在上一篇文章中，我和你介绍了 InnoDB 索引的数据结构模型，今天我们再继续聊聊跟 MySQL 索引有关的概念。</p>\n<p>在开始这篇文章之前，我们先来看一下这个问题：</p>\n<p>在下面这个表 T 中，如果我执行 <code>select * from T where k between 3 and 5</code>，需要执行几次树的搜索操作，会扫描多少行？</p>\n<p>下面是这个表的初始化语句。</p>\n<pre><code class=\"SQL\">mysql&gt; create table T (\n    ID int primary key,\n    k int NOT NULL DEFAULT 0, \n    s varchar(16) NOT NULL DEFAULT '',\n    index k(k)\n) engine=InnoDB;\ninsert into T values(100,1, 'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n</code></pre>","more":"<p><img src=\"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg\" alt=\"图 1 InnoDB 的索引组织结构\"></p>\n<p>现在，我们一起来看看这条 SQL 查询语句的执行流程：</p>\n<ol>\n<li>在 k 索引树上找到 k=3 的记录，取得 <code>ID = 300</code>；</li>\n<li>再到 ID 索引树查到 <code>ID=300</code> 对应的 R3；</li>\n<li>在 k 索引树取下一个值 k=5，取得 ID=500；</li>\n<li>再回到 ID 索引树查到 ID=500 对应的 R4；</li>\n<li>在 k 索引树取下一个值 k=6，不满足条件，循环结束。</li>\n</ol>\n<p>在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。</p>\n<p>在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？</p>\n<h2 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h2><p>如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p>\n<p>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</p>\n<p>需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。</p>\n<p>备注：关于如何查看扫描行数的问题，我将会在第 16 文章《如何正确地显示随机消息？》中，和你详细讨论。</p>\n<p>基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？</p>\n<p>假设这个市民表的定义是这样的：</p>\n<pre><code class=\"SQL\">CREATE TABLE `tuser` (\n  `id` int(11) NOT NULL,\n  `id_card` varchar(32) DEFAULT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `ismale` tinyint(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `id_card` (`id_card`),\n  KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n</code></pre>\n<p>我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？</p>\n<p>如果现在有一个高频请求，要根据市民的身份证号查询他的姓名和年龄，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。</p>\n<p>当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。</p>\n<h2 id=\"最左前缀原则\"><a href=\"#最左前缀原则\" class=\"headerlink\" title=\"最左前缀原则\"></a>最左前缀原则</h2><p>看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该这么做呢？</p>\n<p>这里，我先和你说结论吧。B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。</p>\n<p><img src=\"1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg\" alt=\"图 2 （name，age）索引示意图\"></p>\n<p>可以看到，索引项是按照索引定义里面出现的字段顺序排序的。</p>\n<p>当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。</p>\n<p>如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。</p>\n<p>可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。</p>\n<p>基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序。</p>\n<p>这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</p>\n<p>所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引支持“根据身份证号查询地址”的需求。</p>\n<p>那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。</p>\n<p>这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。</p>\n<h2 id=\"索引下推\"><a href=\"#索引下推\" class=\"headerlink\" title=\"索引下推\"></a>索引下推</h2><p>上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？</p>\n<p>我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：</p>\n<pre><code>mysql&gt; select * from tuser where name like &#39;张 %&#39; and age=10 and ismale=1;\n</code></pre>\n<p>你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。</p>\n<p>然后呢？</p>\n<p>当然是判断其他条件是否满足。</p>\n<p>在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。</p>\n<p>而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p>\n<p>图 3 和图 4，是这两个过程的执行流程图。</p>\n<p><img src=\"1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg\" alt=\"图 3 无索引下推执行流程\"></p>\n<p><img src=\"1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg\" alt=\"图 4 索引下推执行流程\"></p>\n<p>在图 3 和 4 这两个图里面，每一个虚线箭头表示回表一次。</p>\n<p>图 3 中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。</p>\n<p>图 4 跟图 3 的区别是，InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天这篇文章，我和你继续讨论了数据库索引的概念，包括了覆盖索引、前缀索引、索引下推。你可以看到，在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。</p>\n<p>接下来我给你留下一个问题吧。</p>\n<p>实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：</p>\n<pre><code class=\"SQL\">CREATE TABLE `geek` (\n  `a` int(11) NOT NULL,\n  `b` int(11) NOT NULL,\n  `c` int(11) NOT NULL,\n  `d` int(11) NOT NULL,\n  PRIMARY KEY (`a`,`b`),\n  KEY `ca` (`c`,`a`),\n  KEY `cb` (`c`,`b`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。</p>\n<p>但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？</p>\n<p>同事告诉他，是因为他们的业务里面有这样的两种语句：</p>\n<pre><code class=\"SQL\">select ... from geek where c=N order by a;\nselect ... from geek where c=N order by b;\n</code></pre>\n<p>我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？</p>\n<p>表记录</p>\n<table>\n<thead>\n<tr>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n<th>d</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>2</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>1</td>\n<td>3</td>\n<td>2</td>\n<td>d</td>\n</tr>\n<tr>\n<td>1</td>\n<td>4</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>1</td>\n<td>3</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n<td>d</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n<td>4</td>\n<td>d</td>\n</tr>\n</tbody></table>\n<p>主键 <code>a</code>，<code>b</code> 的聚簇索引组织顺序相当于 <code>order by a,b</code> ，也就是先按 a 排序，再按 b 排序，c 无序。</p>\n<p>索引 <code>ca</code> 的组织是先按 <code>c</code> 排序，再按 <code>a</code> 排序，同时记录主键</p>\n<table>\n<thead>\n<tr>\n<th>c</th>\n<th>a</th>\n<th>主键部分b（注意，这里不是 ab，而是只有 b）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2</td>\n<td>1</td>\n<td>3</td>\n</tr>\n<tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>4</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2</td>\n<td>1</td>\n</tr>\n<tr>\n<td>4</td>\n<td>2</td>\n<td>3</td>\n</tr>\n</tbody></table>\n<p>这个跟索引 c 的数据是一模一样的。</p>\n<p>索引 cb 的组织是先按 c 排序，在按 b 排序，同时记录主键</p>\n<table>\n<thead>\n<tr>\n<th>c</th>\n<th>b</th>\n<th>主键部分a（同上）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>2</td>\n<td>3</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3</td>\n<td>1</td>\n<td>2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>2</td>\n<td>1</td>\n</tr>\n<tr>\n<td>3</td>\n<td>4</td>\n<td>1</td>\n</tr>\n<tr>\n<td>4</td>\n<td>3</td>\n<td>2</td>\n</tr>\n</tbody></table>\n<p>所以，结论是 <code>ca</code> 可以去掉，<code>cb</code> 需要保留</p>"},{"title":"04 | 深入浅出索引（上）","date":"2019-06-02T16:00:00.000Z","_content":"\n提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。\n\n数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。\n\n一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。\n\n\n### 索引的常见模型\n\n索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\n\n下面我主要从使用的角度，为你简单分析一下这三种模型的区别。\n\n哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。\n\n不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。\n\n假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：\n\n\n![图 1 哈希表示意图](1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg)\n\n图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。\n\n\n需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。\n\n你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。\n\n\n而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：\n\n\n![图 2 有序数组示意图](1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg)\n\n这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。\n\n\n同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。\n\n\n\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\n\n\n\n二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：\n\n![图 3 二叉搜索树示意图](1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg)\n\n\n二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -> UserC -> UserF -> User2 这个路径得到。这个时间复杂度是 O(log(N))。\n\n\n\n当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。\n\n\n\n树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n\n\n\n你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。\n\n\n\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n\n\n\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\n\n\n\nN 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\n\n\n\n不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。\n\n\n\n你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。\n\n\n\n截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。\n\n\n\n现在，我们一起进入相对偏实战的内容吧。\n\n\n\n在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。\n\n\n\n## InnoDB 的索引模型\n\n在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。\n\n每一个索引在 InnoDB 里面对应一棵 B+ 树。\n\n假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。\n\n这个表的建表语句是：\n\n```SQL\nmysql> create table T (\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)\n) engine=InnoDB;\n```\n\n表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下:\n\n![图 4 InnoDB 的索引组织结构](1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg)\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n\n如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树\n\n搜索一次。\n\n这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n\n## 索引维护\n\nB+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。\n\n如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。\n\n基于上面的索引维护过程说明，我们来讨论一个案例：\n\n你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。\n\n自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： `NOT NULL PRIMARY KEY AUTO_INCREMENT`。\n\n插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。\n\n也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n\n除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？\n\n由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。\n\n显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。\n\n有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：\n\n只有一个索引；\n\n该索引必须是唯一索引。\n\n你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。\n\n## 小结\n\n今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。\n\n由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。\n\n最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：\n\n```SQL\nalter table T drop index k;\nalter table T add index(k);\n```\n\n如果你要重建主键索引，也可以这么写：\n\n```SQL\nalter table T drop primary key;\nalter table T add primary key(id);\n```\n\n我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？\n\n- 对于非主键索引重建，只需重建对应的非主键索引即可\n- 对于主键索引重建，先重建主键索引，再把所有非主键索引重建一遍","source":"_posts/04-MySQL实战45讲-深入浅出索引（上）.md","raw":"---\ntitle: 04 | 深入浅出索引（上）\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。\n\n数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。\n\n一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。\n\n\n### 索引的常见模型\n\n索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\n\n下面我主要从使用的角度，为你简单分析一下这三种模型的区别。\n\n哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。\n\n不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。\n\n假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：\n\n\n![图 1 哈希表示意图](1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg)\n\n图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。\n\n\n需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。\n\n你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。\n\n\n而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：\n\n\n![图 2 有序数组示意图](1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg)\n\n这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。\n\n\n同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。\n\n\n\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\n\n\n\n二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：\n\n![图 3 二叉搜索树示意图](1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg)\n\n\n二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -> UserC -> UserF -> User2 这个路径得到。这个时间复杂度是 O(log(N))。\n\n\n\n当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。\n\n\n\n树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n\n\n\n你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。\n\n\n\n为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n\n\n\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\n\n\n\nN 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\n\n\n\n不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。\n\n\n\n你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。\n\n\n\n截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。\n\n\n\n现在，我们一起进入相对偏实战的内容吧。\n\n\n\n在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。\n\n\n\n## InnoDB 的索引模型\n\n在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。\n\n每一个索引在 InnoDB 里面对应一棵 B+ 树。\n\n假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。\n\n这个表的建表语句是：\n\n```SQL\nmysql> create table T (\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)\n) engine=InnoDB;\n```\n\n表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下:\n\n![图 4 InnoDB 的索引组织结构](1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg)\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n\n如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树\n\n搜索一次。\n\n这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n\n## 索引维护\n\nB+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。\n\n如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。\n\n基于上面的索引维护过程说明，我们来讨论一个案例：\n\n你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。\n\n自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： `NOT NULL PRIMARY KEY AUTO_INCREMENT`。\n\n插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。\n\n也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n\n除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？\n\n由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。\n\n显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。\n\n有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：\n\n只有一个索引；\n\n该索引必须是唯一索引。\n\n你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。\n\n## 小结\n\n今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。\n\n由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。\n\n最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：\n\n```SQL\nalter table T drop index k;\nalter table T add index(k);\n```\n\n如果你要重建主键索引，也可以这么写：\n\n```SQL\nalter table T drop primary key;\nalter table T add primary key(id);\n```\n\n我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？\n\n- 对于非主键索引重建，只需重建对应的非主键索引即可\n- 对于主键索引重建，先重建主键索引，再把所有非主键索引重建一遍","slug":"04-MySQL实战45讲-深入浅出索引（上）","published":1,"updated":"2021-06-30T02:33:24.560Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv0000ar5p7dqrkbrss","content":"<p>提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。</p>\n<p>数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。</p>\n<p>一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。</p>\n<h3 id=\"索引的常见模型\"><a href=\"#索引的常见模型\" class=\"headerlink\" title=\"索引的常见模型\"></a>索引的常见模型</h3><p>索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。</p>\n<p>下面我主要从使用的角度，为你简单分析一下这三种模型的区别。</p>\n<p>哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。</p>\n<p>不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。</p>\n<p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p>\n<p><img src=\"1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg\" alt=\"图 1 哈希表示意图\"></p>\n<p>图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。</p>\n<p>需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。</p>\n<p>你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p>\n<p>而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p>\n<p><img src=\"1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg\" alt=\"图 2 有序数组示意图\"></p>\n<p>这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。</p>\n<p>同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。</p>\n<p>如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。</p>\n<p>二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：</p>\n<p><img src=\"1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg\" alt=\"图 3 二叉搜索树示意图\"></p>\n<p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。</p>\n<p>当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。</p>\n<p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。</p>\n<p>你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。</p>\n<p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。</p>\n<p>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p>\n<p>N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</p>\n<p>不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。</p>\n<p>你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。</p>\n<p>截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。</p>\n<p>现在，我们一起进入相对偏实战的内容吧。</p>\n<p>在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。</p>\n<h2 id=\"InnoDB-的索引模型\"><a href=\"#InnoDB-的索引模型\" class=\"headerlink\" title=\"InnoDB 的索引模型\"></a>InnoDB 的索引模型</h2><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。</p>\n<p>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p>\n<p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。</p>\n<p>这个表的建表语句是：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> create table T (\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)\n) engine=InnoDB;\n</code></pre>\n<p>表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下:</p>\n<p><img src=\"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg\" alt=\"图 4 InnoDB 的索引组织结构\"></p>\n<p>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p>\n<p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。</p>\n<p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。</p>\n<p>根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？</p>\n<p>如果语句是 <code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；</p>\n<p>如果语句是 <code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树</p>\n<p>搜索一次。</p>\n<p>这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p>\n<h2 id=\"索引维护\"><a href=\"#索引维护\" class=\"headerlink\" title=\"索引维护\"></a>索引维护</h2><p>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。</p>\n<p>如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p>\n<p>基于上面的索引维护过程说明，我们来讨论一个案例：</p>\n<p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。</p>\n<p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： <code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code>。</p>\n<p>插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。</p>\n<p>也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</p>\n<p>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p>\n<p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p>\n<p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</p>\n<p>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</p>\n<p>有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p>\n<p>只有一个索引；</p>\n<p>该索引必须是唯一索引。</p>\n<p>你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。</p>\n<p>由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。</p>\n<p>最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">alter table T drop index k;\nalter table T add index(k);\n</code></pre>\n<p>如果你要重建主键索引，也可以这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">alter table T drop primary key;\nalter table T add primary key(id);\n</code></pre>\n<p>我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？</p>\n<ul>\n<li>对于非主键索引重建，只需重建对应的非主键索引即可</li>\n<li>对于主键索引重建，先重建主键索引，再把所有非主键索引重建一遍</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>提到数据库索引，我想你并不陌生，在日常工作中会经常接触到。比如某一个 SQL 查询比较慢，分析完原因之后，你可能就会说“给某个字段加个索引吧”之类的解决方案。但到底什么是索引，索引又是如何工作的呢？今天就让我们一起来聊聊这个话题吧。</p>\n<p>数据库索引的内容比较多，我分成了上下两篇文章。索引是数据库系统里面最重要的概念之一，所以我希望你能够耐心看完。在后面的实战文章中，我也会经常引用这两篇文章中提到的知识点，加深你对数据库索引的理解。</p>\n<p>一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录”。</p>\n<h3 id=\"索引的常见模型\"><a href=\"#索引的常见模型\" class=\"headerlink\" title=\"索引的常见模型\"></a>索引的常见模型</h3><p>索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先给你介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。</p>\n<p>下面我主要从使用的角度，为你简单分析一下这三种模型的区别。</p>\n<p>哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。</p>\n<p>不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。</p>\n<p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p>\n<p><img src=\"1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg\" alt=\"图 1 哈希表示意图\"></p>\n<p>图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。</p>\n<p>需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。</p>\n<p>你可以设想下，如果你现在要找身份证号在 [ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。</p>\n<p>而有序数组在等值查询和范围查询场景中的性能就都非常优秀。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p>\n<p><img src=\"1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg\" alt=\"图 2 有序数组示意图\"></p>\n<p>这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。</p>\n<p>同时很显然，这个索引结构支持范围查询。你要查身份证号在 [ID_card_X, ID_card_Y] 区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。</p>\n<p>如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。</p>\n<p>二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：</p>\n<p><img src=\"1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg\" alt=\"图 3 二叉搜索树示意图\"></p>\n<p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。</p>\n<p>当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。</p>\n<p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。</p>\n<p>你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。</p>\n<p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。</p>\n<p>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p>\n<p>N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</p>\n<p>不管是哈希还是有序数组，或者 N 叉树，它们都是不断迭代、不断优化的产物或者解决方案。数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。</p>\n<p>你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。</p>\n<p>截止到这里，我用了半篇文章的篇幅和你介绍了不同的数据结构，以及它们的适用场景，你可能会觉得有些枯燥。但是，我建议你还是要多花一些时间来理解这部分内容，毕竟这是数据库处理数据的核心概念之一，在分析问题的时候会经常用到。当你理解了索引的模型后，就会发现在分析问题的时候会有一个更清晰的视角，体会到引擎设计的精妙之处。</p>\n<p>现在，我们一起进入相对偏实战的内容吧。</p>\n<p>在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛，所以下面我就以 InnoDB 为例，和你分析一下其中的索引模型。</p>\n<h2 id=\"InnoDB-的索引模型\"><a href=\"#InnoDB-的索引模型\" class=\"headerlink\" title=\"InnoDB 的索引模型\"></a>InnoDB 的索引模型</h2><p>在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。</p>\n<p>每一个索引在 InnoDB 里面对应一棵 B+ 树。</p>\n<p>假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。</p>\n<p>这个表的建表语句是：</p>\n<pre><code class=\"SQL\">mysql&gt; create table T (\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)\n) engine=InnoDB;\n</code></pre>\n<p>表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下:</p>\n<p><img src=\"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg\" alt=\"图 4 InnoDB 的索引组织结构\"></p>\n<p>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p>\n<p>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。</p>\n<p>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。</p>\n<p>根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？</p>\n<p>如果语句是 <code>select * from T where ID=500</code>，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；</p>\n<p>如果语句是 <code>select * from T where k=5</code>，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树</p>\n<p>搜索一次。</p>\n<p>这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p>\n<h2 id=\"索引维护\"><a href=\"#索引维护\" class=\"headerlink\" title=\"索引维护\"></a>索引维护</h2><p>B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。</p>\n<p>如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。</p>\n<p>基于上面的索引维护过程说明，我们来讨论一个案例：</p>\n<p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。</p>\n<p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： <code>NOT NULL PRIMARY KEY AUTO_INCREMENT</code>。</p>\n<p>插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。</p>\n<p>也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</p>\n<p>而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。</p>\n<p>除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p>\n<p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</p>\n<p>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。</p>\n<p>有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p>\n<p>只有一个索引；</p>\n<p>该索引必须是唯一索引。</p>\n<p>你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天，我跟你分析了数据库引擎可用的数据结构，介绍了 InnoDB 采用的 B+ 树结构，以及为什么 InnoDB 要这么选择。B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。</p>\n<p>由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。</p>\n<p>最后，我给你留下一个问题吧。对于上面例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：</p>\n<pre><code class=\"SQL\">alter table T drop index k;\nalter table T add index(k);\n</code></pre>\n<p>如果你要重建主键索引，也可以这么写：</p>\n<pre><code class=\"SQL\">alter table T drop primary key;\nalter table T add primary key(id);\n</code></pre>\n<p>我的问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？</p>\n<ul>\n<li>对于非主键索引重建，只需重建对应的非主键索引即可</li>\n<li>对于主键索引重建，先重建主键索引，再把所有非主键索引重建一遍</li>\n</ul>\n"},{"title":"06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍","date":"2019-06-02T16:00:00.000Z","_content":"\n今天我要跟你聊聊 MySQL 的锁, `数据库锁设计的初衷是处理并发问题`。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。\n\n根据加锁的范围，MySQL 里面的锁大致可以分成`全局锁`、`表级锁`和`行锁`三类。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。\n\n这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。\n\n<!-- more -->\n\n<br/>\n\n### 全局锁\n\n顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：`数据更新语句（数据的增删改）`、`数据定义语句（包括建表、修改表结构等）`和`更新类事务`的提交语句。\n\n`全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本.`\n\n以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。\n\n但是让整库都只读，听上去就很危险：\n\n- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。\n\n假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。\n\n现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。\n\n如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：\n\n\n可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。\n\n\n\n作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？\n\n\n\n也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。\n\n\n\n说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？\n\n\n\n是的，就是在可重复读隔离级别下开启一个事务。\n\n\n\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。\n\n\n\n你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。\n\n\n\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。\n\n\n\n你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：\n\n- 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用.\n- 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高.\n\n业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。\n\n但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。\n\n<br/>\n### 表级锁\n\nMySQL 里面表级别的锁有两种：一种是`表锁`，一种是`元数据锁（meta data lock，MDL)`。\n\n表锁的语法是 `lock tables … read/write`。与 FTWRL 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n\n举个例子, 如果在某个线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 `unlock tables` 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 `lock tables` 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n\n另一类表级的锁是 `MDL（metadata lock)`。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n\n读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。\n\n你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。\n\n![](1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg)\n\n- session A 先启动，这时候会对表 t 加一个 MDL 读锁。\n- session B 需要的也是 MDL 读锁，因此可以正常执行。\n- session C 会被 blocked，因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。\n- 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。\n\n前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。\n\n\n\n你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。\n\n\n\n基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？\n\n\n\n首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。\n\n\n\n但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？\n\n\n\n这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。\n\n\n\nMariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。\n\n\n```SQL\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n\n<br/>\n\n### 小结\n\n今天，我跟你介绍了 MySQL 的全局锁和表级锁。\n\n全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。\n\n表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：\n\n要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；\n\n要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。\n\n\n`MDL` 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。\n\n最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？\n\n假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：\n\n```\nQ1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nQ2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；\n/* other tables */\nQ3:SAVEPOINT sp;\n/* 时刻 1 */\nQ4:show create table `t1`;\n/* 时刻 2 */\nQ5:SELECT * FROM `t1`;\n/* 时刻 3 */\nQ6:ROLLBACK TO SAVEPOINT sp;\n/* 时刻 4 */\n/* other tables */\n```\n\n- 在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);\n- 启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；\n- 设置一个保存点，这个很重要（Q3）；\n- show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5）;\n- 回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。\n- DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。\n\n\n参考答案如下：\n\n如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。\n\n如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；\n\n如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。\n\n从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 后的表结构。\n\n\n[关于online ddl导致DML写锁降级的问题](https://blog.csdn.net/q2878948/article/details/96430129)\n","source":"_posts/06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍.md","raw":"---\ntitle: 06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n今天我要跟你聊聊 MySQL 的锁, `数据库锁设计的初衷是处理并发问题`。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。\n\n根据加锁的范围，MySQL 里面的锁大致可以分成`全局锁`、`表级锁`和`行锁`三类。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。\n\n这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。\n\n<!-- more -->\n\n<br/>\n\n### 全局锁\n\n顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：`数据更新语句（数据的增删改）`、`数据定义语句（包括建表、修改表结构等）`和`更新类事务`的提交语句。\n\n`全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本.`\n\n以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。\n\n但是让整库都只读，听上去就很危险：\n\n- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。\n\n假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。\n\n现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。\n\n如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：\n\n\n可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。\n\n\n\n作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？\n\n\n\n也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。\n\n\n\n说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？\n\n\n\n是的，就是在可重复读隔离级别下开启一个事务。\n\n\n\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。\n\n\n\n你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。\n\n\n\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。\n\n\n\n你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：\n\n- 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用.\n- 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高.\n\n业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。\n\n但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。\n\n<br/>\n### 表级锁\n\nMySQL 里面表级别的锁有两种：一种是`表锁`，一种是`元数据锁（meta data lock，MDL)`。\n\n表锁的语法是 `lock tables … read/write`。与 FTWRL 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n\n举个例子, 如果在某个线程 A 中执行 `lock tables t1 read, t2 write;` 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 `unlock tables` 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 `lock tables` 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n\n另一类表级的锁是 `MDL（metadata lock)`。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n\n读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。\n\n你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。\n\n![](1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg)\n\n- session A 先启动，这时候会对表 t 加一个 MDL 读锁。\n- session B 需要的也是 MDL 读锁，因此可以正常执行。\n- session C 会被 blocked，因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。\n- 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。\n\n前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。\n\n\n\n你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。\n\n\n\n基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？\n\n\n\n首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。\n\n\n\n但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？\n\n\n\n这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。\n\n\n\nMariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。\n\n\n```SQL\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n```\n\n\n<br/>\n\n### 小结\n\n今天，我跟你介绍了 MySQL 的全局锁和表级锁。\n\n全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。\n\n表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：\n\n要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；\n\n要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。\n\n\n`MDL` 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。\n\n最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？\n\n假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：\n\n```\nQ1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nQ2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；\n/* other tables */\nQ3:SAVEPOINT sp;\n/* 时刻 1 */\nQ4:show create table `t1`;\n/* 时刻 2 */\nQ5:SELECT * FROM `t1`;\n/* 时刻 3 */\nQ6:ROLLBACK TO SAVEPOINT sp;\n/* 时刻 4 */\n/* other tables */\n```\n\n- 在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);\n- 启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；\n- 设置一个保存点，这个很重要（Q3）；\n- show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5）;\n- 回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。\n- DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。\n\n\n参考答案如下：\n\n如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。\n\n如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；\n\n如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。\n\n从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 后的表结构。\n\n\n[关于online ddl导致DML写锁降级的问题](https://blog.csdn.net/q2878948/article/details/96430129)\n","slug":"06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍","published":1,"updated":"2021-06-30T02:33:24.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv2000dr5p73txwd8e9","content":"<p>今天我要跟你聊聊 MySQL 的锁, <code>数据库锁设计的初衷是处理并发问题</code>。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。</p>\n<p>根据加锁的范围，MySQL 里面的锁大致可以分成<code>全局锁</code>、<code>表级锁</code>和<code>行锁</code>三类。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。</p>\n<p>这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。</p>\n<span id=\"more\"></span>\n\n<br>\n\n<h3 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h3><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：<code>数据更新语句（数据的增删改）</code>、<code>数据定义语句（包括建表、修改表结构等）</code>和<code>更新类事务</code>的提交语句。</p>\n<p><code>全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本.</code></p>\n<p>以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。</p>\n<p>但是让整库都只读，听上去就很危险：</p>\n<ul>\n<li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li>\n<li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</li>\n</ul>\n<p>看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。</p>\n<p>假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。</p>\n<p>现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。</p>\n<p>如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：</p>\n<p>可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。</p>\n<p>作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？</p>\n<p>也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。</p>\n<p>说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？</p>\n<p>是的，就是在可重复读隔离级别下开启一个事务。</p>\n<p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。</p>\n<p>你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。</p>\n<p>所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。</p>\n<p>你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：</p>\n<ul>\n<li>在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用.</li>\n<li>在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高.</li>\n</ul>\n<p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。</p>\n<p>但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。</p>\n<br>\n### 表级锁\n\n<p>MySQL 里面表级别的锁有两种：一种是<code>表锁</code>，一种是<code>元数据锁（meta data lock，MDL)</code>。</p>\n<p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，<code>lock tables</code> 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p>\n<p>举个例子, 如果在某个线程 A 中执行 <code>lock tables t1 read, t2 write;</code> 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 <code>unlock tables</code> 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。</p>\n<p>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 <code>lock tables</code> 命令来控制并发，毕竟锁住整个表的影响面还是太大。</p>\n<p>另一类表级的锁是 <code>MDL（metadata lock)</code>。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p>\n<p>因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</p>\n<p>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</p>\n<p>读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</p>\n<p>虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。</p>\n<p>你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。</p>\n<p><img src=\"1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg\"></p>\n<ul>\n<li>session A 先启动，这时候会对表 t 加一个 MDL 读锁。</li>\n<li>session B 需要的也是 MDL 读锁，因此可以正常执行。</li>\n<li>session C 会被 blocked，因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。</li>\n<li>如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。</li>\n</ul>\n<p>前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。</p>\n<p>你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。</p>\n<p>基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？</p>\n<p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。</p>\n<p>但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？</p>\n<p>这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。</p>\n<p>MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n</code></pre>\n<br>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天，我跟你介绍了 MySQL 的全局锁和表级锁。</p>\n<p>全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。</p>\n<p>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：</p>\n<p>要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；</p>\n<p>要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。</p>\n<p><code>MDL</code> 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。</p>\n<p>最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？</p>\n<p>假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：</p>\n<pre><code>Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nQ2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；\n/* other tables */\nQ3:SAVEPOINT sp;\n/* 时刻 1 */\nQ4:show create table `t1`;\n/* 时刻 2 */\nQ5:SELECT * FROM `t1`;\n/* 时刻 3 */\nQ6:ROLLBACK TO SAVEPOINT sp;\n/* 时刻 4 */\n/* other tables */\n</code></pre>\n<ul>\n<li>在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);</li>\n<li>启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；</li>\n<li>设置一个保存点，这个很重要（Q3）；</li>\n<li>show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5）;</li>\n<li>回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。</li>\n<li>DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。</li>\n</ul>\n<p>参考答案如下：</p>\n<p>如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。</p>\n<p>如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；</p>\n<p>如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。</p>\n<p>从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 后的表结构。</p>\n<p><a href=\"https://blog.csdn.net/q2878948/article/details/96430129\">关于online ddl导致DML写锁降级的问题</a></p>\n","site":{"data":{}},"excerpt":"<p>今天我要跟你聊聊 MySQL 的锁, <code>数据库锁设计的初衷是处理并发问题</code>。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。</p>\n<p>根据加锁的范围，MySQL 里面的锁大致可以分成<code>全局锁</code>、<code>表级锁</code>和<code>行锁</code>三类。今天这篇文章，我会和你分享全局锁和表级锁。而关于行锁的内容，我会留着在下一篇文章中再和你详细介绍。</p>\n<p>这里需要说明的是，锁的设计比较复杂，这两篇文章不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。</p>","more":"<br/>\n\n<h3 id=\"全局锁\"><a href=\"#全局锁\" class=\"headerlink\" title=\"全局锁\"></a>全局锁</h3><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 <code>Flush tables with read lock (FTWRL)</code>。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：<code>数据更新语句（数据的增删改）</code>、<code>数据定义语句（包括建表、修改表结构等）</code>和<code>更新类事务</code>的提交语句。</p>\n<p><code>全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本.</code></p>\n<p>以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。</p>\n<p>但是让整库都只读，听上去就很危险：</p>\n<ul>\n<li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li>\n<li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。</li>\n</ul>\n<p>看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。</p>\n<p>假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。</p>\n<p>现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。</p>\n<p>如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：</p>\n<p>可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。</p>\n<p>作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？</p>\n<p>也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。</p>\n<p>说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？</p>\n<p>是的，就是在可重复读隔离级别下开启一个事务。</p>\n<p>官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。</p>\n<p>你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。</p>\n<p>所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。</p>\n<p>你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：</p>\n<ul>\n<li>在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用.</li>\n<li>在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高.</li>\n</ul>\n<p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。</p>\n<p>但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。</p>\n<br/>\n### 表级锁\n\n<p>MySQL 里面表级别的锁有两种：一种是<code>表锁</code>，一种是<code>元数据锁（meta data lock，MDL)</code>。</p>\n<p>表锁的语法是 <code>lock tables … read/write</code>。与 FTWRL 类似，可以用 <code>unlock tables</code> 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，<code>lock tables</code> 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。</p>\n<p>举个例子, 如果在某个线程 A 中执行 <code>lock tables t1 read, t2 write;</code> 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 <code>unlock tables</code> 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。</p>\n<p>在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 <code>lock tables</code> 命令来控制并发，毕竟锁住整个表的影响面还是太大。</p>\n<p>另一类表级的锁是 <code>MDL（metadata lock)</code>。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p>\n<p>因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。</p>\n<p>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</p>\n<p>读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</p>\n<p>虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。</p>\n<p>你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表。</p>\n<p><img src=\"1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg\"></p>\n<ul>\n<li>session A 先启动，这时候会对表 t 加一个 MDL 读锁。</li>\n<li>session B 需要的也是 MDL 读锁，因此可以正常执行。</li>\n<li>session C 会被 blocked，因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。</li>\n<li>如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。</li>\n</ul>\n<p>前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。</p>\n<p>你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。</p>\n<p>基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？</p>\n<p>首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。</p>\n<p>但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？</p>\n<p>这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。</p>\n<p>MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。</p>\n<pre><code class=\"SQL\">ALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n</code></pre>\n<br/>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天，我跟你介绍了 MySQL 的全局锁和表级锁。</p>\n<p>全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。</p>\n<p>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：</p>\n<p>要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；</p>\n<p>要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。</p>\n<p><code>MDL</code> 会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。</p>\n<p>最后，我给你留一个问题吧。备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？</p>\n<p>假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：</p>\n<pre><code>Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nQ2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；\n/* other tables */\nQ3:SAVEPOINT sp;\n/* 时刻 1 */\nQ4:show create table `t1`;\n/* 时刻 2 */\nQ5:SELECT * FROM `t1`;\n/* 时刻 3 */\nQ6:ROLLBACK TO SAVEPOINT sp;\n/* 时刻 4 */\n/* other tables */\n</code></pre>\n<ul>\n<li>在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);</li>\n<li>启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；</li>\n<li>设置一个保存点，这个很重要（Q3）；</li>\n<li>show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5）;</li>\n<li>回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。</li>\n<li>DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。</li>\n</ul>\n<p>参考答案如下：</p>\n<p>如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。</p>\n<p>如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止；</p>\n<p>如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。</p>\n<p>从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 后的表结构。</p>\n<p><a href=\"https://blog.csdn.net/q2878948/article/details/96430129\">关于online ddl导致DML写锁降级的问题</a></p>"},{"title":"07 | 行锁功过：怎么减少行锁对性能的影响","date":"2019-06-02T16:00:00.000Z","_content":"\n在上一篇文章中，我跟你介绍了 MySQL 的全局锁和表级锁，今天我们就来讲讲 MySQL 的行锁。\n\n\nMySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n\n我们今天就主要来聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。\n\n顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。\n\n当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。\n\n<!-- more -->\n\n<br/>\n### 从两阶段锁说起\n\n\n我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。\n\n![](1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg)\n\n这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。\n\n\n知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。\n\n\n也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n\n\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。\n\n\n假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：\n\n- 从顾客 A 账户余额中扣除电影票价；\n- 给影院 B 的账户余额增加这张电影票价；\n- 记录一条交易日志。\n\n\n也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？\n\n\n试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。\n\n\n根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。\n\n\n好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。\n\n\n如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？\n\n这里，我就要说到死锁和死锁检测了。\n\n\n<br/>\n### 死锁和死锁检测\n\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。\n\n![](1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg)\n\n这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n- 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n在 InnoDB 中，`innodb_lock_wait_timeout` 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n\n\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n\n\n你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。\n\n\n那如果是我们上面说到的所有事务都要更新同一行的场景呢？\n\n\n每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。\n\n\n根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。\n\n\n一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。\n\n\n可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？\n\n\n你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n\n\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n\n<br/>\n### 小结\n\n今天，我和你介绍了 MySQL 的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。\n\n\n其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。\n\n\n但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。\n\n\n\n最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：\n\n\n\n第一种，直接执行 delete from T limit 10000;\n\n第二种，在一个连接中循环执行 20 次 delete from T limit 500;\n\n第三种，在 20 个连接中同时执行 delete from T limit 500。\n\n\n\n你会选择哪一种方法呢？为什么呢？\n\n二，减少事务时长的同时，降低的锁竞争","source":"_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响.md","raw":"---\ntitle: 07 | 行锁功过：怎么减少行锁对性能的影响\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n在上一篇文章中，我跟你介绍了 MySQL 的全局锁和表级锁，今天我们就来讲讲 MySQL 的行锁。\n\n\nMySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n\n我们今天就主要来聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。\n\n顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。\n\n当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。\n\n<!-- more -->\n\n<br/>\n### 从两阶段锁说起\n\n\n我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。\n\n![](1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg)\n\n这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。\n\n\n知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。\n\n\n也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n\n\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。\n\n\n假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：\n\n- 从顾客 A 账户余额中扣除电影票价；\n- 给影院 B 的账户余额增加这张电影票价；\n- 记录一条交易日志。\n\n\n也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？\n\n\n试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。\n\n\n根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。\n\n\n好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。\n\n\n如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？\n\n这里，我就要说到死锁和死锁检测了。\n\n\n<br/>\n### 死锁和死锁检测\n\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。\n\n![](1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg)\n\n这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n- 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n在 InnoDB 中，`innodb_lock_wait_timeout` 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n\n\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n\n\n你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。\n\n\n那如果是我们上面说到的所有事务都要更新同一行的场景呢？\n\n\n每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。\n\n\n根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。\n\n\n一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。\n\n\n可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？\n\n\n你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n\n\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n\n<br/>\n### 小结\n\n今天，我和你介绍了 MySQL 的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。\n\n\n其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。\n\n\n但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。\n\n\n\n最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：\n\n\n\n第一种，直接执行 delete from T limit 10000;\n\n第二种，在一个连接中循环执行 20 次 delete from T limit 500;\n\n第三种，在 20 个连接中同时执行 delete from T limit 500。\n\n\n\n你会选择哪一种方法呢？为什么呢？\n\n二，减少事务时长的同时，降低的锁竞争","slug":"07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响","published":1,"updated":"2021-06-30T02:33:24.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv3000er5p7gubh7mbr","content":"<p>在上一篇文章中，我跟你介绍了 MySQL 的全局锁和表级锁，今天我们就来讲讲 MySQL 的行锁。</p>\n<p>MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。</p>\n<p>我们今天就主要来聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。</p>\n<p>顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。</p>\n<p>当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。</p>\n<span id=\"more\"></span>\n\n<br>\n### 从两阶段锁说起\n\n\n<p>我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。</p>\n<p><img src=\"1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg\"></p>\n<p>这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。</p>\n<p>知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。</p>\n<p>也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p>\n<p>知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。</p>\n<p>假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p>\n<ul>\n<li>从顾客 A 账户余额中扣除电影票价；</li>\n<li>给影院 B 的账户余额增加这张电影票价；</li>\n<li>记录一条交易日志。</li>\n</ul>\n<p>也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p>\n<p>试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p>\n<p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。</p>\n<p>好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。</p>\n<p>如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？</p>\n<p>这里，我就要说到死锁和死锁检测了。</p>\n<br>\n### 死锁和死锁检测\n\n<p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。</p>\n<p><img src=\"1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg\"></p>\n<p>这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p>\n<ul>\n<li>直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。</li>\n<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。</li>\n</ul>\n<p>在 InnoDB 中，<code>innodb_lock_wait_timeout</code> 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。</p>\n<p>但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p>\n<p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p>\n<p>你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p>\n<p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？</p>\n<p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p>\n<p>根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。</p>\n<p>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</p>\n<p>另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。</p>\n<p>因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。</p>\n<p>可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？</p>\n<p>你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。</p>\n<p>这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。</p>\n<br>\n### 小结\n\n<p>今天，我和你介绍了 MySQL 的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。</p>\n<p>其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。</p>\n<p>但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。</p>\n<p>最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：</p>\n<p>第一种，直接执行 delete from T limit 10000;</p>\n<p>第二种，在一个连接中循环执行 20 次 delete from T limit 500;</p>\n<p>第三种，在 20 个连接中同时执行 delete from T limit 500。</p>\n<p>你会选择哪一种方法呢？为什么呢？</p>\n<p>二，减少事务时长的同时，降低的锁竞争</p>\n","site":{"data":{}},"excerpt":"<p>在上一篇文章中，我跟你介绍了 MySQL 的全局锁和表级锁，今天我们就来讲讲 MySQL 的行锁。</p>\n<p>MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。</p>\n<p>我们今天就主要来聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。</p>\n<p>顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。</p>\n<p>当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。</p>","more":"<br/>\n### 从两阶段锁说起\n\n\n<p>我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。</p>\n<p><img src=\"1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg\"></p>\n<p>这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。</p>\n<p>知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。</p>\n<p>也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</p>\n<p>知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。</p>\n<p>假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p>\n<ul>\n<li>从顾客 A 账户余额中扣除电影票价；</li>\n<li>给影院 B 的账户余额增加这张电影票价；</li>\n<li>记录一条交易日志。</li>\n</ul>\n<p>也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p>\n<p>试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p>\n<p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。</p>\n<p>好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。</p>\n<p>如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？</p>\n<p>这里，我就要说到死锁和死锁检测了。</p>\n<br/>\n### 死锁和死锁检测\n\n<p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。</p>\n<p><img src=\"1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg\"></p>\n<p>这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p>\n<ul>\n<li>直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。</li>\n<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。</li>\n</ul>\n<p>在 InnoDB 中，<code>innodb_lock_wait_timeout</code> 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。</p>\n<p>但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。</p>\n<p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。</p>\n<p>你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p>\n<p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？</p>\n<p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。</p>\n<p>根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的 CPU 资源。</p>\n<p>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。</p>\n<p>另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。</p>\n<p>因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。</p>\n<p>可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？</p>\n<p>你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。</p>\n<p>这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。</p>\n<br/>\n### 小结\n\n<p>今天，我和你介绍了 MySQL 的行锁，涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。</p>\n<p>其中，我以两阶段协议为起点，和你一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。</p>\n<p>但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。</p>\n<p>最后，我给你留下一个问题吧。如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：</p>\n<p>第一种，直接执行 delete from T limit 10000;</p>\n<p>第二种，在一个连接中循环执行 20 次 delete from T limit 500;</p>\n<p>第三种，在 20 个连接中同时执行 delete from T limit 500。</p>\n<p>你会选择哪一种方法呢？为什么呢？</p>\n<p>二，减少事务时长的同时，降低的锁竞争</p>"},{"title":"08 | 事务到底是隔离的还是不隔离的","date":"2019-06-02T16:00:00.000Z","_content":"\n我在第 3 篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，这个事务看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。\n\n但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务如果要更新一行，而刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？\n\n\n<!-- more -->\n\n我给你举一个例子吧。下面是一个只有两行的表的初始化语句。\n\n\n```SQL\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `k` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, k) values(1,1),(2,2);\n```\n\n![图 1 事务 A、B、C 的执行流程](1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg)\n\n这里需要特别注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认 autocommit=1 的。\n\n\n\n在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。语句 Q1 在事务 B 中，更新了行之后查询 ; Q2 在只读事务 A 中查询，并且时间顺序上是在 Q1 的后面。\n\n\n\n这时，如果我告诉你语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1，你是不是感觉有点晕呢？\n\n\n\n所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对 InnoDB 的事务和锁有更进一步的理解。\n\n\n\n在 MySQL 里，有两个“视图”的概念\n\nview，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view，而它的查询方法与表一样。\n\nInnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复度）隔离级别的实现。\n\n它没有物理结构，用来在事务执行期间定义“我能看到什么数据”。\n\n\n\n在第 3 篇文章《事务隔离：为什么你改了我还看不见？》中，我跟你解释过一遍 MVCC 的实现逻辑。今天为了说明查询和更新的区别，我换一个方式来说明，把 read view 拆开。你可以结合这两篇文章的说明来更深一步地理解 MVCC。\n\n\n\n“快照”在 MVCC 里是怎么工作的？\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\n\n\n\n这时，你会说这看上去不太现实啊。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。\n\n实际上，我们并不需要拷贝出这 100G 的数据，我们先来看看这个快照是怎么实现的。\n\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。\n\n而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n\n也就是说，数据表中的一行记录，其实可能有多个版本 (row), 每个版本有自己的 row trx_id。\n\n\n\n如图 2 所示，就是一个记录被多个事务连续更新后的状态。\n\n![图 2 行状态变更图](1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg)\n\n图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。\n\n\n\n你可能会问，前面的文章不是说，语句更新会生成 undo log（回滚日志）吗？那么，undo log 在哪呢？\n\n\n\n实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 执行 U3、U2 算出来。\n\n\n\n明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个“100G”的快照的。\n\n\n\n按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。\n\n\n\n因此，InnoDB 代码实现上，一个事务只需要在启动的时候，找到所有已经提交的事务 ID 的最大值，记为 up_limit_id；然后声明说，“如果一个数据版本的 row trx_id 大于 up_limit_id，我就不认，我必须要找到它的上一个版本”。当然，如果一个事务自己更新的数据，它自己还是要认的。\n\n\n\n备注：up_limit_id 来源于源码里面的变量名，我没有想到更好的名字来称呼它。\n\n\n\n你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，产生的新的数据版本的 row trx_id 都会大于 up_limit_id，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。\n\n\n\n比如，对于图 2 中的数据来说，如果有一个事务，它的 up_limit_id 是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 算出 V3，在它看来，这一行的值是 11。\n\n\n\n所以你现在知道了，InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\n\n\n\n接下来，我们继续看一下图 1 中的三个事务，分析下 Q2 语句返回的结果，为什么是 k=1。\n\n\n\n这里，我们不妨做如下假设：\n\n\n\n事务 A 开始前，系统里面已经提交的事务最大 ID 是 99；\n\n事务 A、B、C 的版本号分别是 100、101、102，且当前系统里没有别的事务；\n\n三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。\n\n这样，事务 A、B、C 的 up_limit_id 的值就都是 99。\n\n为了简化分析，我先把其他干扰语句去掉，只画出了跟 Q2 查询逻辑有关的操作。\n\n\n\n图 3 Q2 数据逻辑图\n\n\n\n从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。\n\n\n\n第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。\n\n\n\n好，现在事务 A 要来读数据了，它的 up_limit_id 是 99。当然了，读数据都是从当前版本读起的。所以，Q2 的读数据流程是这样的：\n\n\n\n找到 (1,3) 的时候，判断出 row trx_id=101 大于 up_limit_id，要不起；\n\n接着，找到上一个历史版本，一看 row trx_id=102，还是要不起；\n\n再往前找，终于找到了（1,1)，它的 row trx_id=90，是可以承认的数据。\n\n\n\n这样执行下来，事务 A 读到的这个数据，跟它在刚开始启动的时候读到的相同，所以我们称之为一致性读。\n\n\n\n这里你可以顺便再想一个问题。(1,1) 这个历史版本，什么时候可以被删除掉呢？\n\n\n\n答案是，当没有事务再需要它的时候，就可以删掉。\n\n\n\n如果只考虑图 1 中的三个事务的话，事务 B 只需要访问到 (1,3) 就可以，而事务 C 需要访问到的是 (1,2)。也就是说，在事务 A 提交后,（1,1) 这个版本就可以被删掉了。\n\n\n<br/>\n### 更新逻辑\n\n细心的同学可能有疑问了：事务 B 的 update 语句，读的到底是哪个版本？这里，我给你画了一个只看事务 B、C 的状态图。\n\n\n\n图 4 Q1 数据逻辑图\n\n这个状态，就是事务 B 刚要执行更新时的状态。\n\n\n\n事务 B 前面的查询语句，拿到的 k 也是 1。但是，当它要去更新数据的时候，不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。\n\n\n\n所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read）”。\n\n\n\n因此，在更新的时候，当前读取到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。\n\n\n\n所以，在执行事务 B 的 Q1 语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，可以用，所以 Q1 得到的 k 的值是 3。\n\n\n\n这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。\n\n\n\n所以，如果把 Q2 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。\n\n\n\nmysql> select k from t where id=1 lock in share mode;\nmysql> select k from t where id=1 for update;\n\n\n现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？\n\n\n\n可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n\n\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n\n\n在可重复读隔离级别下，只需要在事务开始的时候找到那个 up_limit_id，之后事务里的其他查询都共用这个 up_limit_id；在读提交隔离级别下，每一个语句执行前都会重新算一次 up_limit_id 的值。\n\n\n\n那么，我们再看一下，在读提交隔离级别下，语句 Q1 和 Q2 返回的 k 的值，分别应该是多少呢？\n\n\n\n下面是读提交时的状态图， 可以看到 Q1、Q2 语句的 up_limit_id 发生了变化。\n\n\n\n\n\n图 5 读提交隔离级别下的事务状态图\n\n这时，事务 A 的 Q2 语句开始执行的时候，由于事务 B（101）、C（102）都已经提交了，所以 Q2 的 up_limit_id 的值就应该是事务 C 的 transaction id，即 102。那么，它在读到（1,3) 的时候，就满足了 up_limt_id(102) ≥row trx_id(101) 的条件，所以返回了 k=3。\n\n\n\n显然地，语句 Q1 的查询结果 k=3。\n\n\n<br/>\n### 小结\n\nInnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的 up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。\n\n\n\n对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n\n对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n\n\n\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n\n\n\n当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。\n\n\n\n又到思考题时间了。我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况，如下图所示。请你构造出这种情况，并说明其原理。\n\n\n```\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, c) values(1,1),(2,2),(3,3),(4,4);\n```\n\n\n\n\n\n复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？\n\n\n\n\n\n这样，session A 看到的就是我截图的效果了。\n\n\n\n其实，还有另外一种场景，同学们在留言区都还没有提到。\n\n\n\n这个操作序列跑出来，session A 看的内容也是能够复现我截图的效果的。这个 session B’启动的事务比 A 要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。\n\n\n\n用新的方式来分析 session B’的更新为什么对 session A 不可见就是：在 session A 视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。\n\n\n","source":"_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的.md","raw":"---\ntitle: 08 | 事务到底是隔离的还是不隔离的\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n我在第 3 篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，这个事务看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。\n\n但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务如果要更新一行，而刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？\n\n\n<!-- more -->\n\n我给你举一个例子吧。下面是一个只有两行的表的初始化语句。\n\n\n```SQL\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `k` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, k) values(1,1),(2,2);\n```\n\n![图 1 事务 A、B、C 的执行流程](1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg)\n\n这里需要特别注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认 autocommit=1 的。\n\n\n\n在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。语句 Q1 在事务 B 中，更新了行之后查询 ; Q2 在只读事务 A 中查询，并且时间顺序上是在 Q1 的后面。\n\n\n\n这时，如果我告诉你语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1，你是不是感觉有点晕呢？\n\n\n\n所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对 InnoDB 的事务和锁有更进一步的理解。\n\n\n\n在 MySQL 里，有两个“视图”的概念\n\nview，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view，而它的查询方法与表一样。\n\nInnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复度）隔离级别的实现。\n\n它没有物理结构，用来在事务执行期间定义“我能看到什么数据”。\n\n\n\n在第 3 篇文章《事务隔离：为什么你改了我还看不见？》中，我跟你解释过一遍 MVCC 的实现逻辑。今天为了说明查询和更新的区别，我换一个方式来说明，把 read view 拆开。你可以结合这两篇文章的说明来更深一步地理解 MVCC。\n\n\n\n“快照”在 MVCC 里是怎么工作的？\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\n\n\n\n这时，你会说这看上去不太现实啊。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。\n\n实际上，我们并不需要拷贝出这 100G 的数据，我们先来看看这个快照是怎么实现的。\n\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。\n\n而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n\n也就是说，数据表中的一行记录，其实可能有多个版本 (row), 每个版本有自己的 row trx_id。\n\n\n\n如图 2 所示，就是一个记录被多个事务连续更新后的状态。\n\n![图 2 行状态变更图](1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg)\n\n图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。\n\n\n\n你可能会问，前面的文章不是说，语句更新会生成 undo log（回滚日志）吗？那么，undo log 在哪呢？\n\n\n\n实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 执行 U3、U2 算出来。\n\n\n\n明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个“100G”的快照的。\n\n\n\n按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。\n\n\n\n因此，InnoDB 代码实现上，一个事务只需要在启动的时候，找到所有已经提交的事务 ID 的最大值，记为 up_limit_id；然后声明说，“如果一个数据版本的 row trx_id 大于 up_limit_id，我就不认，我必须要找到它的上一个版本”。当然，如果一个事务自己更新的数据，它自己还是要认的。\n\n\n\n备注：up_limit_id 来源于源码里面的变量名，我没有想到更好的名字来称呼它。\n\n\n\n你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，产生的新的数据版本的 row trx_id 都会大于 up_limit_id，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。\n\n\n\n比如，对于图 2 中的数据来说，如果有一个事务，它的 up_limit_id 是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 算出 V3，在它看来，这一行的值是 11。\n\n\n\n所以你现在知道了，InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\n\n\n\n接下来，我们继续看一下图 1 中的三个事务，分析下 Q2 语句返回的结果，为什么是 k=1。\n\n\n\n这里，我们不妨做如下假设：\n\n\n\n事务 A 开始前，系统里面已经提交的事务最大 ID 是 99；\n\n事务 A、B、C 的版本号分别是 100、101、102，且当前系统里没有别的事务；\n\n三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。\n\n这样，事务 A、B、C 的 up_limit_id 的值就都是 99。\n\n为了简化分析，我先把其他干扰语句去掉，只画出了跟 Q2 查询逻辑有关的操作。\n\n\n\n图 3 Q2 数据逻辑图\n\n\n\n从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。\n\n\n\n第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。\n\n\n\n好，现在事务 A 要来读数据了，它的 up_limit_id 是 99。当然了，读数据都是从当前版本读起的。所以，Q2 的读数据流程是这样的：\n\n\n\n找到 (1,3) 的时候，判断出 row trx_id=101 大于 up_limit_id，要不起；\n\n接着，找到上一个历史版本，一看 row trx_id=102，还是要不起；\n\n再往前找，终于找到了（1,1)，它的 row trx_id=90，是可以承认的数据。\n\n\n\n这样执行下来，事务 A 读到的这个数据，跟它在刚开始启动的时候读到的相同，所以我们称之为一致性读。\n\n\n\n这里你可以顺便再想一个问题。(1,1) 这个历史版本，什么时候可以被删除掉呢？\n\n\n\n答案是，当没有事务再需要它的时候，就可以删掉。\n\n\n\n如果只考虑图 1 中的三个事务的话，事务 B 只需要访问到 (1,3) 就可以，而事务 C 需要访问到的是 (1,2)。也就是说，在事务 A 提交后,（1,1) 这个版本就可以被删掉了。\n\n\n<br/>\n### 更新逻辑\n\n细心的同学可能有疑问了：事务 B 的 update 语句，读的到底是哪个版本？这里，我给你画了一个只看事务 B、C 的状态图。\n\n\n\n图 4 Q1 数据逻辑图\n\n这个状态，就是事务 B 刚要执行更新时的状态。\n\n\n\n事务 B 前面的查询语句，拿到的 k 也是 1。但是，当它要去更新数据的时候，不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。\n\n\n\n所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read）”。\n\n\n\n因此，在更新的时候，当前读取到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。\n\n\n\n所以，在执行事务 B 的 Q1 语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，可以用，所以 Q1 得到的 k 的值是 3。\n\n\n\n这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。\n\n\n\n所以，如果把 Q2 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。\n\n\n\nmysql> select k from t where id=1 lock in share mode;\nmysql> select k from t where id=1 for update;\n\n\n现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？\n\n\n\n可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n\n\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n\n\n在可重复读隔离级别下，只需要在事务开始的时候找到那个 up_limit_id，之后事务里的其他查询都共用这个 up_limit_id；在读提交隔离级别下，每一个语句执行前都会重新算一次 up_limit_id 的值。\n\n\n\n那么，我们再看一下，在读提交隔离级别下，语句 Q1 和 Q2 返回的 k 的值，分别应该是多少呢？\n\n\n\n下面是读提交时的状态图， 可以看到 Q1、Q2 语句的 up_limit_id 发生了变化。\n\n\n\n\n\n图 5 读提交隔离级别下的事务状态图\n\n这时，事务 A 的 Q2 语句开始执行的时候，由于事务 B（101）、C（102）都已经提交了，所以 Q2 的 up_limit_id 的值就应该是事务 C 的 transaction id，即 102。那么，它在读到（1,3) 的时候，就满足了 up_limt_id(102) ≥row trx_id(101) 的条件，所以返回了 k=3。\n\n\n\n显然地，语句 Q1 的查询结果 k=3。\n\n\n<br/>\n### 小结\n\nInnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的 up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。\n\n\n\n对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n\n对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n\n\n\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n\n\n\n当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。\n\n\n\n又到思考题时间了。我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况，如下图所示。请你构造出这种情况，并说明其原理。\n\n\n```\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, c) values(1,1),(2,2),(3,3),(4,4);\n```\n\n\n\n\n\n复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？\n\n\n\n\n\n这样，session A 看到的就是我截图的效果了。\n\n\n\n其实，还有另外一种场景，同学们在留言区都还没有提到。\n\n\n\n这个操作序列跑出来，session A 看的内容也是能够复现我截图的效果的。这个 session B’启动的事务比 A 要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。\n\n\n\n用新的方式来分析 session B’的更新为什么对 session A 不可见就是：在 session A 视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。\n\n\n","slug":"08-MySQL实战45讲-事务到底是隔离的还是不隔离的","published":1,"updated":"2021-06-30T02:33:24.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv4000jr5p7c41e91pu","content":"<p>我在第 3 篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，这个事务看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。</p>\n<p>但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务如果要更新一行，而刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？</p>\n<span id=\"more\"></span>\n\n<p>我给你举一个例子吧。下面是一个只有两行的表的初始化语句。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `k` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, k) values(1,1),(2,2);\n</code></pre>\n<p><img src=\"1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg\" alt=\"图 1 事务 A、B、C 的执行流程\"></p>\n<p>这里需要特别注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认 autocommit=1 的。</p>\n<p>在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。语句 Q1 在事务 B 中，更新了行之后查询 ; Q2 在只读事务 A 中查询，并且时间顺序上是在 Q1 的后面。</p>\n<p>这时，如果我告诉你语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1，你是不是感觉有点晕呢？</p>\n<p>所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对 InnoDB 的事务和锁有更进一步的理解。</p>\n<p>在 MySQL 里，有两个“视图”的概念</p>\n<p>view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view，而它的查询方法与表一样。</p>\n<p>InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复度）隔离级别的实现。</p>\n<p>它没有物理结构，用来在事务执行期间定义“我能看到什么数据”。</p>\n<p>在第 3 篇文章《事务隔离：为什么你改了我还看不见？》中，我跟你解释过一遍 MVCC 的实现逻辑。今天为了说明查询和更新的区别，我换一个方式来说明，把 read view 拆开。你可以结合这两篇文章的说明来更深一步地理解 MVCC。</p>\n<p>“快照”在 MVCC 里是怎么工作的？</p>\n<p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。</p>\n<p>这时，你会说这看上去不太现实啊。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。</p>\n<p>实际上，我们并不需要拷贝出这 100G 的数据，我们先来看看这个快照是怎么实现的。</p>\n<p>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。</p>\n<p>而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。</p>\n<p>也就是说，数据表中的一行记录，其实可能有多个版本 (row), 每个版本有自己的 row trx_id。</p>\n<p>如图 2 所示，就是一个记录被多个事务连续更新后的状态。</p>\n<p><img src=\"1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg\" alt=\"图 2 行状态变更图\"></p>\n<p>图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。</p>\n<p>你可能会问，前面的文章不是说，语句更新会生成 undo log（回滚日志）吗？那么，undo log 在哪呢？</p>\n<p>实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 执行 U3、U2 算出来。</p>\n<p>明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个“100G”的快照的。</p>\n<p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。</p>\n<p>因此，InnoDB 代码实现上，一个事务只需要在启动的时候，找到所有已经提交的事务 ID 的最大值，记为 up_limit_id；然后声明说，“如果一个数据版本的 row trx_id 大于 up_limit_id，我就不认，我必须要找到它的上一个版本”。当然，如果一个事务自己更新的数据，它自己还是要认的。</p>\n<p>备注：up_limit_id 来源于源码里面的变量名，我没有想到更好的名字来称呼它。</p>\n<p>你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，产生的新的数据版本的 row trx_id 都会大于 up_limit_id，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。</p>\n<p>比如，对于图 2 中的数据来说，如果有一个事务，它的 up_limit_id 是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 算出 V3，在它看来，这一行的值是 11。</p>\n<p>所以你现在知道了，InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p>\n<p>接下来，我们继续看一下图 1 中的三个事务，分析下 Q2 语句返回的结果，为什么是 k=1。</p>\n<p>这里，我们不妨做如下假设：</p>\n<p>事务 A 开始前，系统里面已经提交的事务最大 ID 是 99；</p>\n<p>事务 A、B、C 的版本号分别是 100、101、102，且当前系统里没有别的事务；</p>\n<p>三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。</p>\n<p>这样，事务 A、B、C 的 up_limit_id 的值就都是 99。</p>\n<p>为了简化分析，我先把其他干扰语句去掉，只画出了跟 Q2 查询逻辑有关的操作。</p>\n<p>图 3 Q2 数据逻辑图</p>\n<p>从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。</p>\n<p>第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。</p>\n<p>好，现在事务 A 要来读数据了，它的 up_limit_id 是 99。当然了，读数据都是从当前版本读起的。所以，Q2 的读数据流程是这样的：</p>\n<p>找到 (1,3) 的时候，判断出 row trx_id=101 大于 up_limit_id，要不起；</p>\n<p>接着，找到上一个历史版本，一看 row trx_id=102，还是要不起；</p>\n<p>再往前找，终于找到了（1,1)，它的 row trx_id=90，是可以承认的数据。</p>\n<p>这样执行下来，事务 A 读到的这个数据，跟它在刚开始启动的时候读到的相同，所以我们称之为一致性读。</p>\n<p>这里你可以顺便再想一个问题。(1,1) 这个历史版本，什么时候可以被删除掉呢？</p>\n<p>答案是，当没有事务再需要它的时候，就可以删掉。</p>\n<p>如果只考虑图 1 中的三个事务的话，事务 B 只需要访问到 (1,3) 就可以，而事务 C 需要访问到的是 (1,2)。也就是说，在事务 A 提交后,（1,1) 这个版本就可以被删掉了。</p>\n<br>\n### 更新逻辑\n\n<p>细心的同学可能有疑问了：事务 B 的 update 语句，读的到底是哪个版本？这里，我给你画了一个只看事务 B、C 的状态图。</p>\n<p>图 4 Q1 数据逻辑图</p>\n<p>这个状态，就是事务 B 刚要执行更新时的状态。</p>\n<p>事务 B 前面的查询语句，拿到的 k 也是 1。但是，当它要去更新数据的时候，不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。</p>\n<p>所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read）”。</p>\n<p>因此，在更新的时候，当前读取到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。</p>\n<p>所以，在执行事务 B 的 Q1 语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，可以用，所以 Q1 得到的 k 的值是 3。</p>\n<p>这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。</p>\n<p>所以，如果把 Q2 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。</p>\n<p>mysql&gt; select k from t where id=1 lock in share mode;\nmysql&gt; select k from t where id=1 for update;</p>\n<p>现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？</p>\n<p>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p>\n<p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p>\n<p>在可重复读隔离级别下，只需要在事务开始的时候找到那个 up_limit_id，之后事务里的其他查询都共用这个 up_limit_id；在读提交隔离级别下，每一个语句执行前都会重新算一次 up_limit_id 的值。</p>\n<p>那么，我们再看一下，在读提交隔离级别下，语句 Q1 和 Q2 返回的 k 的值，分别应该是多少呢？</p>\n<p>下面是读提交时的状态图， 可以看到 Q1、Q2 语句的 up_limit_id 发生了变化。</p>\n<p>图 5 读提交隔离级别下的事务状态图</p>\n<p>这时，事务 A 的 Q2 语句开始执行的时候，由于事务 B（101）、C（102）都已经提交了，所以 Q2 的 up_limit_id 的值就应该是事务 C 的 transaction id，即 102。那么，它在读到（1,3) 的时候，就满足了 up_limt_id(102) ≥row trx_id(101) 的条件，所以返回了 k=3。</p>\n<p>显然地，语句 Q1 的查询结果 k=3。</p>\n<br>\n### 小结\n\n<p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的 up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。</p>\n<p>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；</p>\n<p>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</p>\n<p>而当前读，总是读取已经提交完成的最新版本。</p>\n<p>你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。</p>\n<p>当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。</p>\n<p>又到思考题时间了。我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况，如下图所示。请你构造出这种情况，并说明其原理。</p>\n<pre><code>mysql&gt; CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, c) values(1,1),(2,2),(3,3),(4,4);\n</code></pre>\n<p>复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？</p>\n<p>这样，session A 看到的就是我截图的效果了。</p>\n<p>其实，还有另外一种场景，同学们在留言区都还没有提到。</p>\n<p>这个操作序列跑出来，session A 看的内容也是能够复现我截图的效果的。这个 session B’启动的事务比 A 要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。</p>\n<p>用新的方式来分析 session B’的更新为什么对 session A 不可见就是：在 session A 视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。</p>\n","site":{"data":{}},"excerpt":"<p>我在第 3 篇文章和你讲事务隔离级别的时候提到过，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，这个事务看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务，好像与世无争，不受外界影响。</p>\n<p>但是，我在上一篇文章中，和你分享行锁的时候又提到，一个事务如果要更新一行，而刚好有另外一个事务拥有这一行的行锁，它又不能这么超然了，会被锁住，进入等待状态。问题是，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？</p>","more":"<p>我给你举一个例子吧。下面是一个只有两行的表的初始化语句。</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `k` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, k) values(1,1),(2,2);\n</code></pre>\n<p><img src=\"1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg\" alt=\"图 1 事务 A、B、C 的执行流程\"></p>\n<p>这里需要特别注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是默认 autocommit=1 的。</p>\n<p>在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。语句 Q1 在事务 B 中，更新了行之后查询 ; Q2 在只读事务 A 中查询，并且时间顺序上是在 Q1 的后面。</p>\n<p>这时，如果我告诉你语句 Q1 返回的 k 的值是 3，而语句 Q2 返回的 k 的值是 1，你是不是感觉有点晕呢？</p>\n<p>所以，今天这篇文章，我其实就是想和你说明白这个问题，希望借由把这个疑惑解开的过程，能够帮助你对 InnoDB 的事务和锁有更进一步的理解。</p>\n<p>在 MySQL 里，有两个“视图”的概念</p>\n<p>view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view，而它的查询方法与表一样。</p>\n<p>InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复度）隔离级别的实现。</p>\n<p>它没有物理结构，用来在事务执行期间定义“我能看到什么数据”。</p>\n<p>在第 3 篇文章《事务隔离：为什么你改了我还看不见？》中，我跟你解释过一遍 MVCC 的实现逻辑。今天为了说明查询和更新的区别，我换一个方式来说明，把 read view 拆开。你可以结合这两篇文章的说明来更深一步地理解 MVCC。</p>\n<p>“快照”在 MVCC 里是怎么工作的？</p>\n<p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。</p>\n<p>这时，你会说这看上去不太现实啊。如果一个库有 100G，那么我启动一个事务，MySQL 就要拷贝 100G 的数据出来，这个过程得多慢啊。可是，我平时的事务执行起来很快啊。</p>\n<p>实际上，我们并不需要拷贝出这 100G 的数据，我们先来看看这个快照是怎么实现的。</p>\n<p>InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。</p>\n<p>而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。</p>\n<p>也就是说，数据表中的一行记录，其实可能有多个版本 (row), 每个版本有自己的 row trx_id。</p>\n<p>如图 2 所示，就是一个记录被多个事务连续更新后的状态。</p>\n<p><img src=\"1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg\" alt=\"图 2 行状态变更图\"></p>\n<p>图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。</p>\n<p>你可能会问，前面的文章不是说，语句更新会生成 undo log（回滚日志）吗？那么，undo log 在哪呢？</p>\n<p>实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 执行 U3、U2 算出来。</p>\n<p>明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个“100G”的快照的。</p>\n<p>按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。</p>\n<p>因此，InnoDB 代码实现上，一个事务只需要在启动的时候，找到所有已经提交的事务 ID 的最大值，记为 up_limit_id；然后声明说，“如果一个数据版本的 row trx_id 大于 up_limit_id，我就不认，我必须要找到它的上一个版本”。当然，如果一个事务自己更新的数据，它自己还是要认的。</p>\n<p>备注：up_limit_id 来源于源码里面的变量名，我没有想到更好的名字来称呼它。</p>\n<p>你看，有了这个声明后，系统里面随后发生的更新，是不是就跟这个事务看到的内容无关了呢？因为之后的更新，产生的新的数据版本的 row trx_id 都会大于 up_limit_id，而对它来说，这些新的数据版本是不存在的，所以这个事务的快照，就是“静态”的了。</p>\n<p>比如，对于图 2 中的数据来说，如果有一个事务，它的 up_limit_id 是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 算出 V3，在它看来，这一行的值是 11。</p>\n<p>所以你现在知道了，InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</p>\n<p>接下来，我们继续看一下图 1 中的三个事务，分析下 Q2 语句返回的结果，为什么是 k=1。</p>\n<p>这里，我们不妨做如下假设：</p>\n<p>事务 A 开始前，系统里面已经提交的事务最大 ID 是 99；</p>\n<p>事务 A、B、C 的版本号分别是 100、101、102，且当前系统里没有别的事务；</p>\n<p>三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。</p>\n<p>这样，事务 A、B、C 的 up_limit_id 的值就都是 99。</p>\n<p>为了简化分析，我先把其他干扰语句去掉，只画出了跟 Q2 查询逻辑有关的操作。</p>\n<p>图 3 Q2 数据逻辑图</p>\n<p>从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。</p>\n<p>第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。</p>\n<p>好，现在事务 A 要来读数据了，它的 up_limit_id 是 99。当然了，读数据都是从当前版本读起的。所以，Q2 的读数据流程是这样的：</p>\n<p>找到 (1,3) 的时候，判断出 row trx_id=101 大于 up_limit_id，要不起；</p>\n<p>接着，找到上一个历史版本，一看 row trx_id=102，还是要不起；</p>\n<p>再往前找，终于找到了（1,1)，它的 row trx_id=90，是可以承认的数据。</p>\n<p>这样执行下来，事务 A 读到的这个数据，跟它在刚开始启动的时候读到的相同，所以我们称之为一致性读。</p>\n<p>这里你可以顺便再想一个问题。(1,1) 这个历史版本，什么时候可以被删除掉呢？</p>\n<p>答案是，当没有事务再需要它的时候，就可以删掉。</p>\n<p>如果只考虑图 1 中的三个事务的话，事务 B 只需要访问到 (1,3) 就可以，而事务 C 需要访问到的是 (1,2)。也就是说，在事务 A 提交后,（1,1) 这个版本就可以被删掉了。</p>\n<br/>\n### 更新逻辑\n\n<p>细心的同学可能有疑问了：事务 B 的 update 语句，读的到底是哪个版本？这里，我给你画了一个只看事务 B、C 的状态图。</p>\n<p>图 4 Q1 数据逻辑图</p>\n<p>这个状态，就是事务 B 刚要执行更新时的状态。</p>\n<p>事务 B 前面的查询语句，拿到的 k 也是 1。但是，当它要去更新数据的时候，不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。</p>\n<p>所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读（current read）”。</p>\n<p>因此，在更新的时候，当前读取到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。</p>\n<p>所以，在执行事务 B 的 Q1 语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，可以用，所以 Q1 得到的 k 的值是 3。</p>\n<p>这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。</p>\n<p>所以，如果把 Q2 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。</p>\n<p>mysql&gt; select k from t where id=1 lock in share mode;\nmysql&gt; select k from t where id=1 for update;</p>\n<p>现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？</p>\n<p>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。</p>\n<p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：</p>\n<p>在可重复读隔离级别下，只需要在事务开始的时候找到那个 up_limit_id，之后事务里的其他查询都共用这个 up_limit_id；在读提交隔离级别下，每一个语句执行前都会重新算一次 up_limit_id 的值。</p>\n<p>那么，我们再看一下，在读提交隔离级别下，语句 Q1 和 Q2 返回的 k 的值，分别应该是多少呢？</p>\n<p>下面是读提交时的状态图， 可以看到 Q1、Q2 语句的 up_limit_id 发生了变化。</p>\n<p>图 5 读提交隔离级别下的事务状态图</p>\n<p>这时，事务 A 的 Q2 语句开始执行的时候，由于事务 B（101）、C（102）都已经提交了，所以 Q2 的 up_limit_id 的值就应该是事务 C 的 transaction id，即 102。那么，它在读到（1,3) 的时候，就满足了 up_limt_id(102) ≥row trx_id(101) 的条件，所以返回了 k=3。</p>\n<p>显然地，语句 Q1 的查询结果 k=3。</p>\n<br/>\n### 小结\n\n<p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的 up_limit_id。普通查询语句是一致性读，一致性读会根据 row trx_id 和 up_limit_id 的大小决定数据版本的可见性。</p>\n<p>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；</p>\n<p>对于读提交，查询只承认在语句启动前就已经提交完成的数据；</p>\n<p>而当前读，总是读取已经提交完成的最新版本。</p>\n<p>你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。</p>\n<p>当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。</p>\n<p>又到思考题时间了。我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况，如下图所示。请你构造出这种情况，并说明其原理。</p>\n<pre><code>mysql&gt; CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\ninsert into t(id, c) values(1,1),(2,2),(3,3),(4,4);\n</code></pre>\n<p>复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？</p>\n<p>这样，session A 看到的就是我截图的效果了。</p>\n<p>其实，还有另外一种场景，同学们在留言区都还没有提到。</p>\n<p>这个操作序列跑出来，session A 看的内容也是能够复现我截图的效果的。这个 session B’启动的事务比 A 要早，其实是上期我们描述事务版本的可见性规则时留的彩蛋，因为规则里还有一个“活跃事务的判断”，我是准备留到这里再补充的。</p>\n<p>用新的方式来分析 session B’的更新为什么对 session A 不可见就是：在 session A 视图数组创建的瞬间，session B’是活跃的，属于“版本未提交，不可见”这种情况。</p>"},{"title":"10 | MySQL为什么有时候会选错索引","date":"2019-06-02T16:00:00.000Z","_content":"\n\n\n前面我们介绍过索引，你已经知道了在 MySQL 中一张表其实是可以支持多个索引的。但是，你写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。\n不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？\n我们一起来看一个例子吧。\n我们先建一个简单的表，表里有 a、b 两个字段，并分别建上索引：\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n```\n<!-- more -->\n\n然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。\n我是用存储过程来插入数据的，这里我贴出来方便你复现：\n\n```SQL\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n```\n\n接下来，我们分析一条 SQL 语句：\n\n```SQL\nmysql> select * from t where a between 10000 and 20000;\n```\n\n你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。\n你说得没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。\n\n![图 1 使用 explain 命令查看语句执行情况](1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg)\n\n从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。\n不过别急，这个案例不会这么简单。在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。\n\n![图 2 session A 和 session B 的执行流程](1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg)\n\n这里，session A 的操作你已经很熟悉了，它就是开启了一个事务。随后，session B 把数据都删除后，又调用了 idata 这个存储过程，插入了 10 万行数据。\n这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。\n为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 force index(a) 来让优化器强制使用索引 a（这部分内容，我还会在这篇文章的后半部分中提到）。\n下面的三条 SQL 语句，就是这个实验过程。\n\n```\nset sql_long_query=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n```\n\n第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1 是 session B 原来的查询；\n第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。\n如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。\n\n![图 3 slow log 结果](1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg)\n\n可以看到，Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引，导致了更长的执行时间。\n这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。\n\n<br/>\n\n### 优化器的逻辑\n\n在第一篇文章中，我们就提到过，选择索引是优化器的工作。\n而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。\n我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。\n那么，问题就是：扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n我们可以使用 show index 方法，看到一个索引的基数。如图 4 所示，就是表 t 的 show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。\n\n\n![图 4 表 t 的 show index 结果](1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg)\n\n\n那么，MySQL 是怎样得到索引的基数的呢？这里，我给你简单介绍一下 MySQL 采样统计的方法。\n为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| innodb_stats_persistent              | ON    |\n| innodb_stats_persistent_sample_pages | 20    |\n+--------------------------------------+-------+\n但，这还不是全部。\n你可以从图 4 中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。\n其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。\n接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。\n\n![图 5 意外的 explain 结果](1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg)\n\nrows 这个字段表示的是预计扫描行数。\n其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116，偏差就大了。而图 1 中我们用 explain 命令看到的 rows 是只有 10001 行，是这个偏差误导了优化器的判断。\n到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？\n这是因为，如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的，而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。\n优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n使用普通索引需要把回表的代价算进去，在图 1 执行 explain 的时候，也考虑了这个策略的代价 ，但图 1 的选择是对的。也就是说，这个策略并没有问题。\n所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。\n既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。\n\n![图 6 执行 analyze table t 命令恢复的 explain 结果](1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg)\n\n这回对了。\n所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。\n其实，如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。\n依然是基于这个表 t，我们看看另外一个语句：\n\n```SQL\nmysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;\n```\n\n从条件上看，这个查询没有符合条件的记录，因此会返回空集合。\n在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？\n为了便于分析，我们先来看一下 a、b 这两个索引的结构图。\n图 7 a、b 索引的结构图\n如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。\n如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。\n所以你一定会想，如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。\n图 8 是执行 explain 的结果。\n\n```SQL\nmysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;\n```\n\n![图 8 使用 explain 方法查看执行计划 2](1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg)\n\n可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。\n从这个结果中，你可以得到两个结论：\n• 扫描行数的估计值依然不准确；\n• 这个例子里 MySQL 又选错了索引;\n\n<br/>\n\n### 索引选择异常和处理\n\n其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？\n一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n我们来看看第二个例子。刚开始分析时，我们认为选择索引 a 会更好。现在，我们就来看看执行效果：\n\n![图 9 使用不同索引的语句执行耗时](1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg)\n\n可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。\n也就是说，优化器没有选择正确的索引，force index 起到了“矫正”的作用。\n不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。\n但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。\n所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？\n既然优化器放弃了使用索引 a，说明 a 还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n我们来看看改之后的效果：\n\n\n![图 10 order by b,a limit 1 执行结果](1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg)\n\n之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。\n现在 order by b,a 这种写法，要求按照 b,a 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。\n当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。\n如果你觉得修改语义这件事儿不太好，这里还有一种改法，图 11 是执行效果。\n\n```SQL\nmysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;\n```\n\n![图 11 改写 SQL 的 explain](1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg)\n\n在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。\n第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。\n如果我说还有一个方法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。\n\n<br/>\n\n### 小结\n\n今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。\n对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。\n而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。\n你可能会说，今天这篇文章后面的几个例子，怎么都没有展开说明其原理。我要告诉你的是，今天的话题，我们面对的是 MySQL 的 bug，每一个展开都必须深入到一行行代码去量化，实在不是我们在这里应该做的事情。\n所以，我把我用过的解决方法跟你分享，希望你在碰到类似情况的时候，能够有一些思路。\n你平时在处理 MySQL 优化器 bug 的时候有什么别的方法，也发到评论区分享一下吧。\n思考题：前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t 、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\ndelete 语句删掉了所有的数据，然后再通过 call idata() 插入了 10 万行数据，看上去是覆盖了原来的 10 万行。\n但是，session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。这样，索引 a 上的数据其实就有两份。\n然后你会说，不对啊，主键上的数据也不能删，那没有使用 force index 的语句，使用 explain 命令看到的扫描行数为什么还是 100000 左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段 a 作为索引更合适）\n是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status 的值。这个值的计算方法，我会在后面有文章为你详细讲解。\n\n![](1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg)","source":"_posts/10-MySQL为什么有时候会选错索引.md","raw":"---\ntitle: 10 | MySQL为什么有时候会选错索引\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n\n\n前面我们介绍过索引，你已经知道了在 MySQL 中一张表其实是可以支持多个索引的。但是，你写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。\n不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？\n我们一起来看一个例子吧。\n我们先建一个简单的表，表里有 a、b 两个字段，并分别建上索引：\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n```\n<!-- more -->\n\n然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。\n我是用存储过程来插入数据的，这里我贴出来方便你复现：\n\n```SQL\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n```\n\n接下来，我们分析一条 SQL 语句：\n\n```SQL\nmysql> select * from t where a between 10000 and 20000;\n```\n\n你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。\n你说得没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。\n\n![图 1 使用 explain 命令查看语句执行情况](1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg)\n\n从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。\n不过别急，这个案例不会这么简单。在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。\n\n![图 2 session A 和 session B 的执行流程](1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg)\n\n这里，session A 的操作你已经很熟悉了，它就是开启了一个事务。随后，session B 把数据都删除后，又调用了 idata 这个存储过程，插入了 10 万行数据。\n这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。\n为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 force index(a) 来让优化器强制使用索引 a（这部分内容，我还会在这篇文章的后半部分中提到）。\n下面的三条 SQL 语句，就是这个实验过程。\n\n```\nset sql_long_query=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n```\n\n第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1 是 session B 原来的查询；\n第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。\n如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。\n\n![图 3 slow log 结果](1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg)\n\n可以看到，Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引，导致了更长的执行时间。\n这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。\n\n<br/>\n\n### 优化器的逻辑\n\n在第一篇文章中，我们就提到过，选择索引是优化器的工作。\n而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。\n我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。\n那么，问题就是：扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n我们可以使用 show index 方法，看到一个索引的基数。如图 4 所示，就是表 t 的 show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。\n\n\n![图 4 表 t 的 show index 结果](1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg)\n\n\n那么，MySQL 是怎样得到索引的基数的呢？这里，我给你简单介绍一下 MySQL 采样统计的方法。\n为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| innodb_stats_persistent              | ON    |\n| innodb_stats_persistent_sample_pages | 20    |\n+--------------------------------------+-------+\n但，这还不是全部。\n你可以从图 4 中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。\n其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。\n接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。\n\n![图 5 意外的 explain 结果](1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg)\n\nrows 这个字段表示的是预计扫描行数。\n其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116，偏差就大了。而图 1 中我们用 explain 命令看到的 rows 是只有 10001 行，是这个偏差误导了优化器的判断。\n到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？\n这是因为，如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的，而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。\n优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n使用普通索引需要把回表的代价算进去，在图 1 执行 explain 的时候，也考虑了这个策略的代价 ，但图 1 的选择是对的。也就是说，这个策略并没有问题。\n所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。\n既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。\n\n![图 6 执行 analyze table t 命令恢复的 explain 结果](1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg)\n\n这回对了。\n所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。\n其实，如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。\n依然是基于这个表 t，我们看看另外一个语句：\n\n```SQL\nmysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;\n```\n\n从条件上看，这个查询没有符合条件的记录，因此会返回空集合。\n在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？\n为了便于分析，我们先来看一下 a、b 这两个索引的结构图。\n图 7 a、b 索引的结构图\n如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。\n如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。\n所以你一定会想，如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。\n图 8 是执行 explain 的结果。\n\n```SQL\nmysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;\n```\n\n![图 8 使用 explain 方法查看执行计划 2](1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg)\n\n可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。\n从这个结果中，你可以得到两个结论：\n• 扫描行数的估计值依然不准确；\n• 这个例子里 MySQL 又选错了索引;\n\n<br/>\n\n### 索引选择异常和处理\n\n其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？\n一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n我们来看看第二个例子。刚开始分析时，我们认为选择索引 a 会更好。现在，我们就来看看执行效果：\n\n![图 9 使用不同索引的语句执行耗时](1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg)\n\n可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。\n也就是说，优化器没有选择正确的索引，force index 起到了“矫正”的作用。\n不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。\n但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。\n所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？\n既然优化器放弃了使用索引 a，说明 a 还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n我们来看看改之后的效果：\n\n\n![图 10 order by b,a limit 1 执行结果](1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg)\n\n之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。\n现在 order by b,a 这种写法，要求按照 b,a 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。\n当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。\n如果你觉得修改语义这件事儿不太好，这里还有一种改法，图 11 是执行效果。\n\n```SQL\nmysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;\n```\n\n![图 11 改写 SQL 的 explain](1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg)\n\n在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。\n第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。\n如果我说还有一个方法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。\n\n<br/>\n\n### 小结\n\n今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。\n对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。\n而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。\n你可能会说，今天这篇文章后面的几个例子，怎么都没有展开说明其原理。我要告诉你的是，今天的话题，我们面对的是 MySQL 的 bug，每一个展开都必须深入到一行行代码去量化，实在不是我们在这里应该做的事情。\n所以，我把我用过的解决方法跟你分享，希望你在碰到类似情况的时候，能够有一些思路。\n你平时在处理 MySQL 优化器 bug 的时候有什么别的方法，也发到评论区分享一下吧。\n思考题：前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t 、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\ndelete 语句删掉了所有的数据，然后再通过 call idata() 插入了 10 万行数据，看上去是覆盖了原来的 10 万行。\n但是，session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。这样，索引 a 上的数据其实就有两份。\n然后你会说，不对啊，主键上的数据也不能删，那没有使用 force index 的语句，使用 explain 命令看到的扫描行数为什么还是 100000 左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段 a 作为索引更合适）\n是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status 的值。这个值的计算方法，我会在后面有文章为你详细讲解。\n\n![](1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg)","slug":"10-MySQL为什么有时候会选错索引","published":1,"updated":"2021-06-30T02:33:24.576Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv5000mr5p7b8icclkm","content":"<p>前面我们介绍过索引，你已经知道了在 MySQL 中一张表其实是可以支持多个索引的。但是，你写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。\n不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？\n我们一起来看一个例子吧。\n我们先建一个简单的表，表里有 a、b 两个字段，并分别建上索引：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n</code></pre>\n<span id=\"more\"></span>\n\n<p>然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。\n我是用存储过程来插入数据的，这里我贴出来方便你复现：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">delimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n</code></pre>\n<p>接下来，我们分析一条 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where a between 10000 and 20000;\n</code></pre>\n<p>你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。\n你说得没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。</p>\n<p><img src=\"1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg\" alt=\"图 1 使用 explain 命令查看语句执行情况\"></p>\n<p>从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。\n不过别急，这个案例不会这么简单。在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。</p>\n<p><img src=\"1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg\" alt=\"图 2 session A 和 session B 的执行流程\"></p>\n<p>这里，session A 的操作你已经很熟悉了，它就是开启了一个事务。随后，session B 把数据都删除后，又调用了 idata 这个存储过程，插入了 10 万行数据。\n这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。\n为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 force index(a) 来让优化器强制使用索引 a（这部分内容，我还会在这篇文章的后半部分中提到）。\n下面的三条 SQL 语句，就是这个实验过程。</p>\n<pre><code>set sql_long_query=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n</code></pre>\n<p>第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1 是 session B 原来的查询；\n第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。\n如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。</p>\n<p><img src=\"1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg\" alt=\"图 3 slow log 结果\"></p>\n<p>可以看到，Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引，导致了更长的执行时间。\n这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。</p>\n<br>\n\n<h3 id=\"优化器的逻辑\"><a href=\"#优化器的逻辑\" class=\"headerlink\" title=\"优化器的逻辑\"></a>优化器的逻辑</h3><p>在第一篇文章中，我们就提到过，选择索引是优化器的工作。\n而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。\n我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。\n那么，问题就是：扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n我们可以使用 show index 方法，看到一个索引的基数。如图 4 所示，就是表 t 的 show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p>\n<p><img src=\"1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg\" alt=\"图 4 表 t 的 show index 结果\"></p>\n<p>那么，MySQL 是怎样得到索引的基数的呢？这里，我给你简单介绍一下 MySQL 采样统计的方法。\n为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。\n+————————————–+——-+\n| Variable_name                        | Value |\n+————————————–+——-+\n| innodb_stats_persistent              | ON    |\n| innodb_stats_persistent_sample_pages | 20    |\n+————————————–+——-+\n但，这还不是全部。\n你可以从图 4 中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。\n其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。\n接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。</p>\n<p><img src=\"1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg\" alt=\"图 5 意外的 explain 结果\"></p>\n<p>rows 这个字段表示的是预计扫描行数。\n其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116，偏差就大了。而图 1 中我们用 explain 命令看到的 rows 是只有 10001 行，是这个偏差误导了优化器的判断。\n到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？\n这是因为，如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的，而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。\n优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n使用普通索引需要把回表的代价算进去，在图 1 执行 explain 的时候，也考虑了这个策略的代价 ，但图 1 的选择是对的。也就是说，这个策略并没有问题。\n所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。\n既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。</p>\n<p><img src=\"1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg\" alt=\"图 6 执行 analyze table t 命令恢复的 explain 结果\"></p>\n<p>这回对了。\n所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。\n其实，如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。\n依然是基于这个表 t，我们看看另外一个语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;\n</code></pre>\n<p>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。\n在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？\n为了便于分析，我们先来看一下 a、b 这两个索引的结构图。\n图 7 a、b 索引的结构图\n如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。\n如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。\n所以你一定会想，如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。\n图 8 是执行 explain 的结果。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;\n</code></pre>\n<p><img src=\"1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg\" alt=\"图 8 使用 explain 方法查看执行计划 2\"></p>\n<p>可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。\n从这个结果中，你可以得到两个结论：\n• 扫描行数的估计值依然不准确；\n• 这个例子里 MySQL 又选错了索引;</p>\n<br>\n\n<h3 id=\"索引选择异常和处理\"><a href=\"#索引选择异常和处理\" class=\"headerlink\" title=\"索引选择异常和处理\"></a>索引选择异常和处理</h3><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？\n一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n我们来看看第二个例子。刚开始分析时，我们认为选择索引 a 会更好。现在，我们就来看看执行效果：</p>\n<p><img src=\"1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg\" alt=\"图 9 使用不同索引的语句执行耗时\"></p>\n<p>可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。\n也就是说，优化器没有选择正确的索引，force index 起到了“矫正”的作用。\n不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。\n但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。\n所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？\n既然优化器放弃了使用索引 a，说明 a 还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n我们来看看改之后的效果：</p>\n<p><img src=\"1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg\" alt=\"图 10 order by b,a limit 1 执行结果\"></p>\n<p>之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。\n现在 order by b,a 这种写法，要求按照 b,a 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。\n当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。\n如果你觉得修改语义这件事儿不太好，这里还有一种改法，图 11 是执行效果。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;\n</code></pre>\n<p><img src=\"1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg\" alt=\"图 11 改写 SQL 的 explain\"></p>\n<p>在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。\n第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。\n如果我说还有一个方法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。</p>\n<br>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。\n对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。\n而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。\n你可能会说，今天这篇文章后面的几个例子，怎么都没有展开说明其原理。我要告诉你的是，今天的话题，我们面对的是 MySQL 的 bug，每一个展开都必须深入到一行行代码去量化，实在不是我们在这里应该做的事情。\n所以，我把我用过的解决方法跟你分享，希望你在碰到类似情况的时候，能够有一些思路。\n你平时在处理 MySQL 优化器 bug 的时候有什么别的方法，也发到评论区分享一下吧。\n思考题：前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t 、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\ndelete 语句删掉了所有的数据，然后再通过 call idata() 插入了 10 万行数据，看上去是覆盖了原来的 10 万行。\n但是，session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。这样，索引 a 上的数据其实就有两份。\n然后你会说，不对啊，主键上的数据也不能删，那没有使用 force index 的语句，使用 explain 命令看到的扫描行数为什么还是 100000 左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段 a 作为索引更合适）\n是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status 的值。这个值的计算方法，我会在后面有文章为你详细讲解。</p>\n<p><img src=\"1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg\"></p>\n","site":{"data":{}},"excerpt":"<p>前面我们介绍过索引，你已经知道了在 MySQL 中一张表其实是可以支持多个索引的。但是，你写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。\n不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢？\n我们一起来看一个例子吧。\n我们先建一个简单的表，表里有 a、b 两个字段，并分别建上索引：</p>\n<pre><code class=\"SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB；\n</code></pre>","more":"<p>然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。\n我是用存储过程来插入数据的，这里我贴出来方便你复现：</p>\n<pre><code class=\"SQL\">delimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i&lt;=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n</code></pre>\n<p>接下来，我们分析一条 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where a between 10000 and 20000;\n</code></pre>\n<p>你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。\n你说得没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。</p>\n<p><img src=\"1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg\" alt=\"图 1 使用 explain 命令查看语句执行情况\"></p>\n<p>从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。\n不过别急，这个案例不会这么简单。在我们已经准备好的包含了 10 万行数据的表上，我们再做如下操作。</p>\n<p><img src=\"1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg\" alt=\"图 2 session A 和 session B 的执行流程\"></p>\n<p>这里，session A 的操作你已经很熟悉了，它就是开启了一个事务。随后，session B 把数据都删除后，又调用了 idata 这个存储过程，插入了 10 万行数据。\n这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。\n为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用 force index(a) 来让优化器强制使用索引 a（这部分内容，我还会在这篇文章的后半部分中提到）。\n下面的三条 SQL 语句，就是这个实验过程。</p>\n<pre><code>set sql_long_query=0;\nselect * from t where a between 10000 and 20000; /*Q1*/\nselect * from t force index(a) where a between 10000 and 20000;/*Q2*/\n</code></pre>\n<p>第一句，是将慢查询日志的阈值设置为 0，表示这个线程接下来的语句都会被记录入慢查询日志中；\n第二句，Q1 是 session B 原来的查询；\n第三句，Q2 是加了 force index(a) 来和 session B 原来的查询语句执行情况对比。\n如图 3 所示是这三条 SQL 语句执行完成后的慢查询日志。</p>\n<p><img src=\"1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg\" alt=\"图 3 slow log 结果\"></p>\n<p>可以看到，Q1 扫描了 10 万行，显然是走了全表扫描，执行时间是 40 毫秒。Q2 扫描了 10001 行，执行了 21 毫秒。也就是说，我们在没有使用 force index 的时候，MySQL 用错了索引，导致了更长的执行时间。\n这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL 竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。</p>\n<br/>\n\n<h3 id=\"优化器的逻辑\"><a href=\"#优化器的逻辑\" class=\"headerlink\" title=\"优化器的逻辑\"></a>优化器的逻辑</h3><p>在第一篇文章中，我们就提到过，选择索引是优化器的工作。\n而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。\n我们这个简单的查询语句并没有涉及到临时表和排序，所以 MySQL 选错索引肯定是在判断扫描行数的时候出问题了。\n那么，问题就是：扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\n我们可以使用 show index 方法，看到一个索引的基数。如图 4 所示，就是表 t 的 show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p>\n<p><img src=\"1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg\" alt=\"图 4 表 t 的 show index 结果\"></p>\n<p>那么，MySQL 是怎样得到索引的基数的呢？这里，我给你简单介绍一下 MySQL 采样统计的方法。\n为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n由于是采样统计，所以不管 N 是 20 还是 8，这个基数都是很容易不准的。\n+————————————–+——-+\n| Variable_name                        | Value |\n+————————————–+——-+\n| innodb_stats_persistent              | ON    |\n| innodb_stats_persistent_sample_pages | 20    |\n+————————————–+——-+\n但，这还不是全部。\n你可以从图 4 中看到，这次的索引统计值（cardinality 列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。\n其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。\n接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。</p>\n<p><img src=\"1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg\" alt=\"图 5 意外的 explain 结果\"></p>\n<p>rows 这个字段表示的是预计扫描行数。\n其中，Q1 的结果还是符合预期的，rows 的值是 104620；但是 Q2 的 rows 值是 37116，偏差就大了。而图 1 中我们用 explain 命令看到的 rows 是只有 10001 行，是这个偏差误导了优化器的判断。\n到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？\n这是因为，如果使用索引 a，每次从索引 a 上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的，而如果选择扫描 10 万行，是直接在主键索引上扫描的，没有额外的代价。\n优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。\n使用普通索引需要把回表的代价算进去，在图 1 执行 explain 的时候，也考虑了这个策略的代价 ，但图 1 的选择是对的。也就是说，这个策略并没有问题。\n所以冤有头债有主，MySQL 选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。至于为什么会得到错误的扫描行数，这个原因就作为课后问题，留给你去分析了。\n既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。</p>\n<p><img src=\"1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg\" alt=\"图 6 执行 analyze table t 命令恢复的 explain 结果\"></p>\n<p>这回对了。\n所以在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。\n其实，如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。\n依然是基于这个表 t，我们看看另外一个语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;\n</code></pre>\n<p>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。\n在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？\n为了便于分析，我们先来看一下 a、b 这两个索引的结构图。\n图 7 a、b 索引的结构图\n如果使用索引 a 进行查询，那么就是扫描索引 a 的前 1000 个值，然后取到对应的 id，再到主键索引上去查出每一行，然后根据字段 b 来过滤。显然这样需要扫描 1000 行。\n如果使用索引 b 进行查询，那么就是扫描索引 b 的最后 50001 个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描 50001 行。\n所以你一定会想，如果使用索引 a 的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。\n图 8 是执行 explain 的结果。</p>\n<pre><code class=\"SQL\">mysql&gt; explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;\n</code></pre>\n<p><img src=\"1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg\" alt=\"图 8 使用 explain 方法查看执行计划 2\"></p>\n<p>可以看到，返回结果中 key 字段显示，这次优化器选择了索引 b，而 rows 字段显示需要扫描的行数是 50198。\n从这个结果中，你可以得到两个结论：\n• 扫描行数的估计值依然不准确；\n• 这个例子里 MySQL 又选错了索引;</p>\n<br/>\n\n<h3 id=\"索引选择异常和处理\"><a href=\"#索引选择异常和处理\" class=\"headerlink\" title=\"索引选择异常和处理\"></a>索引选择异常和处理</h3><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？\n一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果 force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。\n我们来看看第二个例子。刚开始分析时，我们认为选择索引 a 会更好。现在，我们就来看看执行效果：</p>\n<p><img src=\"1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg\" alt=\"图 9 使用不同索引的语句执行耗时\"></p>\n<p>可以看到，原本语句需要执行 2.23 秒，而当你使用 force index(a) 的时候，只用了 0.05 秒，比优化器的选择快了 40 多倍。\n也就是说，优化器没有选择正确的索引，force index 起到了“矫正”的作用。\n不过很多程序员不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。\n但其实使用 force index 最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上 force index。而是等到线上出现问题的时候，你才会再去修改 SQL 语句、加上 force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。\n所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？\n既然优化器放弃了使用索引 a，说明 a 还不够合适，所以第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。\n我们来看看改之后的效果：</p>\n<p><img src=\"1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg\" alt=\"图 10 order by b,a limit 1 执行结果\"></p>\n<p>之前优化器选择使用索引 b，是因为它认为使用索引 b 可以避免排序（b 本身是索引，已经是有序的了，如果选择索引 b 的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。\n现在 order by b,a 这种写法，要求按照 b,a 排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描 1000 行的索引 a。\n当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有 limit 1，因此如果有满足条件的记录， order by b limit 1 和 order by b,a limit 1 都会返回 b 是最小的那一行，逻辑上一致，才可以这么做。\n如果你觉得修改语义这件事儿不太好，这里还有一种改法，图 11 是执行效果。</p>\n<pre><code class=\"SQL\">mysql&gt; select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;\n</code></pre>\n<p><img src=\"1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg\" alt=\"图 11 改写 SQL 的 explain\"></p>\n<p>在这个例子里，我们用 limit 100 让优化器意识到，使用 b 索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。\n第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过 DBA 索引优化过的库，再碰到这个 bug，找到一个更合适的索引一般比较难。\n如果我说还有一个方法是删掉索引 b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是 DBA 跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。</p>\n<br/>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>今天我们一起聊了聊索引统计的更新机制，并提到了优化器存在选错索引的可能性。\n对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决。\n而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。\n你可能会说，今天这篇文章后面的几个例子，怎么都没有展开说明其原理。我要告诉你的是，今天的话题，我们面对的是 MySQL 的 bug，每一个展开都必须深入到一行行代码去量化，实在不是我们在这里应该做的事情。\n所以，我把我用过的解决方法跟你分享，希望你在碰到类似情况的时候，能够有一些思路。\n你平时在处理 MySQL 优化器 bug 的时候有什么别的方法，也发到评论区分享一下吧。\n思考题：前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t 、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\ndelete 语句删掉了所有的数据，然后再通过 call idata() 插入了 10 万行数据，看上去是覆盖了原来的 10 万行。\n但是，session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。这样，索引 a 上的数据其实就有两份。\n然后你会说，不对啊，主键上的数据也不能删，那没有使用 force index 的语句，使用 explain 命令看到的扫描行数为什么还是 100000 左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段 a 作为索引更合适）\n是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status 的值。这个值的计算方法，我会在后面有文章为你详细讲解。</p>\n<p><img src=\"1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg\"></p>"},{"title":"09 | 普通索引和唯一索引，应该怎么选择","date":"2019-06-02T16:00:00.000Z","_content":"\n在前面的基础篇文章中，我给你介绍过索引的基本概念，相信你已经了解了唯一索引和普通索引的区别。今天我们就继续来谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？\n\n\n\n假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：\n```\nselect name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';\n```\n所以，你一定会考虑在 `id_card` 字段上建索引。\n\n由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。\n\n\n现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？\n\n\n\n简单起见，我们还是用第 4 篇文章《深入浅出索引（上）》中的例子来说明，假设字段 k 上的值都不重复。\n\n\n![图 1 InnoDB 的索引组织结构]()\n\n接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。\n\n\n<br/>\n### 查询过程\n假设，执行查询的语句是 `select id from T where k=5`。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。\n- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。\n\n那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。\n\n\n你知道的，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。\n\n\n因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。\n\n\n\n当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。\n\n\n\n但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。\n\n\n<br/>\n### 更新过程\n\n为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer。\n\n\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n\n\n\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n\n\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge。除了访问这个数据页会触发 purge 外，系统有后台线程会定期 purge。在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。\n\n\n显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。\n\n那么，什么条件下可以使用 change buffer 呢？\n\n\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n\n\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\n\n\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n```\n+-------------------------------+-------+\n| Variable_name                 | Value |\n+-------------------------------+-------+\n| innodb_change_buffer_max_size | 25    |\n+-------------------------------+-------+\n```\n\n现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。\n\n\n\n第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：\n\n\n对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；\n\n对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。\n\n\n\n这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。\n\n\n第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：\n\n\n\n对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；\n\n对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。\n\n\n\n将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\n\n\n\n之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。\n\n\n\nchange buffer 的使用场景\n\n\n通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？\n\n\n\n因为 purge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 purge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。\n\n\n\n因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n\n\n\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。\n\n\n\n索引选择和实践\n\n\n回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。\n\n\n\n其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n\n\n\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n\n\n\n特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。\n\n\n\nchange buffer 和 redo log\n\n\n理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。\n\n\n\n在前面文章的评论中，我发现有同学混淆了 redo log 和 change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。\n\n\n\n现在，我们要在表上执行这个插入语句：\n\n\n\nmysql> insert into t(id,k) values(id1,k1),(id2,k2);\n\n\n\n这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。\n\n\n\n图 2 带 change buffer 的更新过程\n\n\n\n分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。\n\n\n\n这条更新语句做了如下的操作（按照图中的数字顺序）：\n\n\n\nPage 1 在内存中，直接更新内存；\n\nPage 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息\n\n将上述两个动作记入 redo log 中（图中 3 和 4）。\n\n\n\n做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。\n\n\n\n同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。\n\n\n\n那在这之后的读请求，要怎么处理呢？\n\n\n\n比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。\n\n\n\n如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。\n\n\n\n图 3 带 change buffer 的读过程\n\n从图中可以看到：\n\n\n\n读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。\n\n要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。\n\n\n\n可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。\n\n\n\n所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。\n\n\n<br/>\n### 小结\n今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。\n\n\n最后，又到了思考题时间。\n\n\n通过图 2 你可以看到，change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 purge 过程，就等于是数据丢失了。会不会出现这种情况呢？\n\n\n这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 \n在评论区有同学问到，merge 的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。\n\nmerge 的执行流程是这样的：\n\n从磁盘读入数据页到内存（老版本的数据页）；\n\n从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；\n\n写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。\n\n到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。","source":"_posts/09-MySQL实战45讲-普通索引和唯一索引，应该怎么选择.md","raw":"---\ntitle: 09 | 普通索引和唯一索引，应该怎么选择\ndate: 2019-06-03\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n在前面的基础篇文章中，我给你介绍过索引的基本概念，相信你已经了解了唯一索引和普通索引的区别。今天我们就继续来谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？\n\n\n\n假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：\n```\nselect name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';\n```\n所以，你一定会考虑在 `id_card` 字段上建索引。\n\n由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。\n\n\n现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？\n\n\n\n简单起见，我们还是用第 4 篇文章《深入浅出索引（上）》中的例子来说明，假设字段 k 上的值都不重复。\n\n\n![图 1 InnoDB 的索引组织结构]()\n\n接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。\n\n\n<br/>\n### 查询过程\n假设，执行查询的语句是 `select id from T where k=5`。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。\n- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。\n\n那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。\n\n\n你知道的，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。\n\n\n因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。\n\n\n\n当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。\n\n\n\n但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。\n\n\n<br/>\n### 更新过程\n\n为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer。\n\n\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n\n\n\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n\n\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge。除了访问这个数据页会触发 purge 外，系统有后台线程会定期 purge。在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。\n\n\n显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。\n\n那么，什么条件下可以使用 change buffer 呢？\n\n\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n\n\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\n\n\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n```\n+-------------------------------+-------+\n| Variable_name                 | Value |\n+-------------------------------+-------+\n| innodb_change_buffer_max_size | 25    |\n+-------------------------------+-------+\n```\n\n现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。\n\n\n\n第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：\n\n\n对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；\n\n对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。\n\n\n\n这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。\n\n\n第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：\n\n\n\n对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；\n\n对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。\n\n\n\n将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\n\n\n\n之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。\n\n\n\nchange buffer 的使用场景\n\n\n通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？\n\n\n\n因为 purge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 purge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。\n\n\n\n因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n\n\n\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。\n\n\n\n索引选择和实践\n\n\n回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。\n\n\n\n其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n\n\n\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n\n\n\n特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。\n\n\n\nchange buffer 和 redo log\n\n\n理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。\n\n\n\n在前面文章的评论中，我发现有同学混淆了 redo log 和 change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。\n\n\n\n现在，我们要在表上执行这个插入语句：\n\n\n\nmysql> insert into t(id,k) values(id1,k1),(id2,k2);\n\n\n\n这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。\n\n\n\n图 2 带 change buffer 的更新过程\n\n\n\n分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。\n\n\n\n这条更新语句做了如下的操作（按照图中的数字顺序）：\n\n\n\nPage 1 在内存中，直接更新内存；\n\nPage 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息\n\n将上述两个动作记入 redo log 中（图中 3 和 4）。\n\n\n\n做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。\n\n\n\n同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。\n\n\n\n那在这之后的读请求，要怎么处理呢？\n\n\n\n比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。\n\n\n\n如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。\n\n\n\n图 3 带 change buffer 的读过程\n\n从图中可以看到：\n\n\n\n读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。\n\n要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。\n\n\n\n可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。\n\n\n\n所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。\n\n\n<br/>\n### 小结\n今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。\n\n\n最后，又到了思考题时间。\n\n\n通过图 2 你可以看到，change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 purge 过程，就等于是数据丢失了。会不会出现这种情况呢？\n\n\n这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 \n在评论区有同学问到，merge 的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。\n\nmerge 的执行流程是这样的：\n\n从磁盘读入数据页到内存（老版本的数据页）；\n\n从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；\n\n写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。\n\n到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。","slug":"09-MySQL实战45讲-普通索引和唯一索引，应该怎么选择","published":1,"updated":"2021-06-30T02:33:24.576Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv7000qr5p709jiah95","content":"<p>在前面的基础篇文章中，我给你介绍过索引的基本概念，相信你已经了解了唯一索引和普通索引的区别。今天我们就继续来谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？</p>\n<p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：</p>\n<pre><code>select name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';\n</code></pre>\n<p>所以，你一定会考虑在 <code>id_card</code> 字段上建索引。</p>\n<p>由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。</p>\n<p>现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？</p>\n<p>简单起见，我们还是用第 4 篇文章《深入浅出索引（上）》中的例子来说明，假设字段 k 上的值都不重复。</p>\n<p><img src=\"\" alt=\"图 1 InnoDB 的索引组织结构\"></p>\n<p>接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。</p>\n<br>\n### 查询过程\n假设，执行查询的语句是 `select id from T where k=5`。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n<ul>\n<li>对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。</li>\n<li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li>\n</ul>\n<p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p>\n<p>你知道的，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。</p>\n<p>因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</p>\n<p>当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。</p>\n<p>但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。</p>\n<br>\n### 更新过程\n\n<p>为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer。</p>\n<p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p>\n<p>需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。</p>\n<p>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge。除了访问这个数据页会触发 purge 外，系统有后台线程会定期 purge。在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。</p>\n<p>显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。</p>\n<p>那么，什么条件下可以使用 change buffer 呢？</p>\n<p>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。</p>\n<p>因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。</p>\n<p>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</p>\n<pre><code>+-------------------------------+-------+\n| Variable_name                 | Value |\n+-------------------------------+-------+\n| innodb_change_buffer_max_size | 25    |\n+-------------------------------+-------+\n</code></pre>\n<p>现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。</p>\n<p>第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：</p>\n<p>对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；</p>\n<p>对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。</p>\n<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。</p>\n<p>第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：</p>\n<p>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</p>\n<p>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</p>\n<p>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p>\n<p>之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。</p>\n<p>change buffer 的使用场景</p>\n<p>通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？</p>\n<p>因为 purge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 purge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p>\n<p>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p>\n<p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</p>\n<p>索引选择和实践</p>\n<p>回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。</p>\n<p>其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。</p>\n<p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。</p>\n<p>在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。</p>\n<p>特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</p>\n<p>change buffer 和 redo log</p>\n<p>理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。</p>\n<p>在前面文章的评论中，我发现有同学混淆了 redo log 和 change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。</p>\n<p>现在，我们要在表上执行这个插入语句：</p>\n<p>mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2);</p>\n<p>这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。</p>\n<p>图 2 带 change buffer 的更新过程</p>\n<p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p>\n<p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p>\n<p>Page 1 在内存中，直接更新内存；</p>\n<p>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息</p>\n<p>将上述两个动作记入 redo log 中（图中 3 和 4）。</p>\n<p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。</p>\n<p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p>\n<p>那在这之后的读请求，要怎么处理呢？</p>\n<p>比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。</p>\n<p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。</p>\n<p>图 3 带 change buffer 的读过程</p>\n<p>从图中可以看到：</p>\n<p>读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</p>\n<p>要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。</p>\n<p>可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。</p>\n<p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。</p>\n<br>\n### 小结\n今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n<p>由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。</p>\n<p>最后，又到了思考题时间。</p>\n<p>通过图 2 你可以看到，change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 purge 过程，就等于是数据丢失了。会不会出现这种情况呢？</p>\n<p>这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 \n在评论区有同学问到，merge 的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。</p>\n<p>merge 的执行流程是这样的：</p>\n<p>从磁盘读入数据页到内存（老版本的数据页）；</p>\n<p>从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；</p>\n<p>写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。</p>\n<p>到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在前面的基础篇文章中，我给你介绍过索引的基本概念，相信你已经了解了唯一索引和普通索引的区别。今天我们就继续来谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？</p>\n<p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：</p>\n<pre><code>select name from CUser where id_card = &#39;xxxxxxxyyyyyyzzzzz&#39;;\n</code></pre>\n<p>所以，你一定会考虑在 <code>id_card</code> 字段上建索引。</p>\n<p>由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。</p>\n<p>现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？</p>\n<p>简单起见，我们还是用第 4 篇文章《深入浅出索引（上）》中的例子来说明，假设字段 k 上的值都不重复。</p>\n<p><img src=\"\" alt=\"图 1 InnoDB 的索引组织结构\"></p>\n<p>接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。</p>\n<br/>\n### 查询过程\n假设，执行查询的语句是 `select id from T where k=5`。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n<ul>\n<li>对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。</li>\n<li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li>\n</ul>\n<p>那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。</p>\n<p>你知道的，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。</p>\n<p>因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。</p>\n<p>当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。</p>\n<p>但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。</p>\n<br/>\n### 更新过程\n\n<p>为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer。</p>\n<p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p>\n<p>需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。</p>\n<p>将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge。除了访问这个数据页会触发 purge 外，系统有后台线程会定期 purge。在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。</p>\n<p>显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。</p>\n<p>那么，什么条件下可以使用 change buffer 呢？</p>\n<p>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。</p>\n<p>因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。</p>\n<p>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</p>\n<pre><code>+-------------------------------+-------+\n| Variable_name                 | Value |\n+-------------------------------+-------+\n| innodb_change_buffer_max_size | 25    |\n+-------------------------------+-------+\n</code></pre>\n<p>现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。</p>\n<p>第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：</p>\n<p>对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；</p>\n<p>对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。</p>\n<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。</p>\n<p>第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：</p>\n<p>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</p>\n<p>对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。</p>\n<p>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p>\n<p>之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。</p>\n<p>change buffer 的使用场景</p>\n<p>通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？</p>\n<p>因为 purge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 purge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。</p>\n<p>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p>\n<p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。</p>\n<p>索引选择和实践</p>\n<p>回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。</p>\n<p>其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。</p>\n<p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。</p>\n<p>在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。</p>\n<p>特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。</p>\n<p>change buffer 和 redo log</p>\n<p>理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。</p>\n<p>在前面文章的评论中，我发现有同学混淆了 redo log 和 change buffer。WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。</p>\n<p>现在，我们要在表上执行这个插入语句：</p>\n<p>mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2);</p>\n<p>这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。</p>\n<p>图 2 带 change buffer 的更新过程</p>\n<p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p>\n<p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p>\n<p>Page 1 在内存中，直接更新内存；</p>\n<p>Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息</p>\n<p>将上述两个动作记入 redo log 中（图中 3 和 4）。</p>\n<p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。</p>\n<p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。</p>\n<p>那在这之后的读请求，要怎么处理呢？</p>\n<p>比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。</p>\n<p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。</p>\n<p>图 3 带 change buffer 的读过程</p>\n<p>从图中可以看到：</p>\n<p>读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</p>\n<p>要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。</p>\n<p>可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。</p>\n<p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。</p>\n<br/>\n### 小结\n今天，我从普通索引和唯一索引的选择开始，和你分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n<p>由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。</p>\n<p>最后，又到了思考题时间。</p>\n<p>通过图 2 你可以看到，change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 purge 过程，就等于是数据丢失了。会不会出现这种情况呢？</p>\n<p>这个问题的答案是不会丢失，留言区的很多同学都回答对了。虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 \n在评论区有同学问到，merge 的过程是否会把数据直接写回磁盘，这是个好问题。这里，我再为你分析一下。</p>\n<p>merge 的执行流程是这样的：</p>\n<p>从磁盘读入数据页到内存（老版本的数据页）；</p>\n<p>从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；</p>\n<p>写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。</p>\n<p>到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。</p>\n"},{"title":"11 | 怎么给字符串字段加索引","date":"2019-06-02T16:00:00.000Z","_content":"现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\n```SQL\nmysql> create table SUser(\nID bigint unsigned primary key,\nemail varchar(64),\n...\n)engine=innodb;\n```\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\n```SQL\nmysql> select f1, f2 from SUser where email='xxx';\n```\n\n从第 4 和第 5 篇讲解索引的文章中，我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n比如，这两个在 email 字段上创建索引的语句：\n\n```SQL\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n```\n\n第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图 2 和 3 所示，就是这两个索引的示意图。\n\n![图 1 email 索引结构](1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg)\n\n![图 2 email(6) 索引结构](1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg)\n\n从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。\n但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。\n\n```SQL\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：\n1. 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值；\n2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；\n3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com’的条件了，循环结束。\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：\n1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；\n2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；\n3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。\n通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：\n\n```\nmysql> select count(distinct email) as L from SUser;\n```\n\n然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：\n\n```SQL\nmysql> select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n```\n\n当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。\n\n\n<br/>\n### 前缀索引对覆盖索引的影响\n\n\n前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n你先来看看这个 SQL 语句：\n\n```SQL\nselect id,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n与前面例子中的 SQL 语句\n\n```SQL\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n相比，这个语句只要求返回 id 和 email 字段。\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。\n即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n其他方式\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。\n按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。\n但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n答案是，有的。\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\n```SQL\nmysql> select field_list from t where id_card = reverse('input_id_card_string');\n```\n\n由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n第二种方式是使用 hash字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\n```SQL\nmysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);\n```\n\n然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。\n\n```SQL\nmysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n```\n\n这样，索引的长度变成了 4 个字节，比原来小了很多。\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n它们的区别，主要体现在以下三个方面：\n1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。\n3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n<br/>\n\n### 小结\n\n在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：\n• 直接创建完整索引，这样可能比较占用空间；\n• 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n• 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n• 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n本期问题：如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com\", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。","source":"_posts/11-怎么给字符串字段加索引.md","raw":"---\ntitle: 11 | 怎么给字符串字段加索引\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\n```SQL\nmysql> create table SUser(\nID bigint unsigned primary key,\nemail varchar(64),\n...\n)engine=innodb;\n```\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\n```SQL\nmysql> select f1, f2 from SUser where email='xxx';\n```\n\n从第 4 和第 5 篇讲解索引的文章中，我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n比如，这两个在 email 字段上创建索引的语句：\n\n```SQL\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n```\n\n第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图 2 和 3 所示，就是这两个索引的示意图。\n\n![图 1 email 索引结构](1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg)\n\n![图 2 email(6) 索引结构](1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg)\n\n从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。\n但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。\n\n```SQL\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：\n1. 从 index1 索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得 ID2 的值；\n2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；\n3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com’的条件了，循环结束。\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：\n1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；\n2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；\n3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。\n通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：\n\n```\nmysql> select count(distinct email) as L from SUser;\n```\n\n然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：\n\n```SQL\nmysql> select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n```\n\n当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。\n\n\n<br/>\n### 前缀索引对覆盖索引的影响\n\n\n前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n你先来看看这个 SQL 语句：\n\n```SQL\nselect id,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n与前面例子中的 SQL 语句\n\n```SQL\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n```\n\n相比，这个语句只要求返回 id 和 email 字段。\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。\n即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n其他方式\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。\n按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。\n但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n答案是，有的。\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\n```SQL\nmysql> select field_list from t where id_card = reverse('input_id_card_string');\n```\n\n由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n第二种方式是使用 hash字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\n```SQL\nmysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);\n```\n\n然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。\n\n```SQL\nmysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n```\n\n这样，索引的长度变成了 4 个字节，比原来小了很多。\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n它们的区别，主要体现在以下三个方面：\n1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。\n3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n<br/>\n\n### 小结\n\n在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：\n• 直接创建完整索引，这样可能比较占用空间；\n• 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n• 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n• 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n本期问题：如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com\", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。","slug":"11-怎么给字符串字段加索引","published":1,"updated":"2021-06-30T02:33:24.589Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsv8000tr5p7ap4l6r2t","content":"<p>现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> create table SUser(\nID bigint unsigned primary key,\nemail varchar(64),\n...\n)engine=innodb;\n</code></pre>\n<p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select f1, f2 from SUser where email='xxx';\n</code></pre>\n<p>从第 4 和第 5 篇讲解索引的文章中，我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n比如，这两个在 email 字段上创建索引的语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n</code></pre>\n<p>第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图 2 和 3 所示，就是这两个索引的示意图。</p>\n<p><img src=\"1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg\" alt=\"图 1 email 索引结构\"></p>\n<p><img src=\"1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg\" alt=\"图 2 email(6) 索引结构\"></p>\n<p>从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。\n但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select id,name,email from SUser where email='zhangssxyz@xxx.com';\n</code></pre>\n<p>如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：</p>\n<ol>\n<li>从 index1 索引树找到满足索引值是’<a href=\"mailto:zhangssxyz@xxx.com\">zhangssxyz@xxx.com</a>’的这条记录，取得 ID2 的值；</li>\n<li>到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；</li>\n<li>取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email=‘<a href=\"mailto:zhangssxyz@xxx.com\">zhangssxyz@xxx.com</a>’的条件了，循环结束。\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：</li>\n<li>从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；</li>\n<li>到主键上查到主键值是 ID1 的行，判断出 email 的值不是’<a href=\"mailto:zhangssxyz@xxx.com\">zhangssxyz@xxx.com</a>’，这行记录丢弃；</li>\n<li>取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；</li>\n<li>重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。\n通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</li>\n</ol>\n<pre><code>mysql&gt; select count(distinct email) as L from SUser;\n</code></pre>\n<p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n</code></pre>\n<p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。</p>\n<br>\n### 前缀索引对覆盖索引的影响\n\n\n<p>前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n你先来看看这个 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select id,email from SUser where email='zhangssxyz@xxx.com';\n</code></pre>\n<p>与前面例子中的 SQL 语句</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select id,name,email from SUser where email='zhangssxyz@xxx.com';\n</code></pre>\n<p>相比，这个语句只要求返回 id 和 email 字段。\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。\n即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n其他方式\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。\n按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。\n但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n答案是，有的。\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select field_list from t where id_card = reverse('input_id_card_string');\n</code></pre>\n<p>由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n第二种方式是使用 hash字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);\n</code></pre>\n<p>然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n</code></pre>\n<p>这样，索引的长度变成了 4 个字节，比原来小了很多。\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n它们的区别，主要体现在以下三个方面：</p>\n<ol>\n<li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</li>\n<li>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。</li>\n<li>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li>\n</ol>\n<br>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：\n• 直接创建完整索引，这样可能比较占用空间；\n• 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n• 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n• 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n本期问题：如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com”, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</p>\n<pre><code class=\"SQL\">mysql&gt; create table SUser(\nID bigint unsigned primary key,\nemail varchar(64),\n...\n)engine=innodb;\n</code></pre>\n<p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select f1, f2 from SUser where email=&#39;xxx&#39;;\n</code></pre>\n<p>从第 4 和第 5 篇讲解索引的文章中，我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n比如，这两个在 email 字段上创建索引的语句：</p>\n<pre><code class=\"SQL\">mysql&gt; alter table SUser add index index1(email);\n或\nmysql&gt; alter table SUser add index index2(email(6));\n</code></pre>\n<p>第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；而第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图 2 和 3 所示，就是这两个索引的示意图。</p>\n<p><img src=\"1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg\" alt=\"图 1 email 索引结构\"></p>\n<p><img src=\"1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg\" alt=\"图 2 email(6) 索引结构\"></p>\n<p>从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以占用的空间会更小，这就是使用前缀索引的优势。\n但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行的。</p>\n<pre><code class=\"SQL\">select id,name,email from SUser where email=&#39;zhangssxyz@xxx.com&#39;;\n</code></pre>\n<p>如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：</p>\n<ol>\n<li>从 index1 索引树找到满足索引值是’<a href=\"mailto:&#x7a;&#x68;&#97;&#110;&#103;&#115;&#x73;&#x78;&#x79;&#122;&#64;&#120;&#120;&#x78;&#46;&#x63;&#111;&#x6d;\">&#x7a;&#x68;&#97;&#110;&#103;&#115;&#x73;&#x78;&#x79;&#122;&#64;&#120;&#120;&#x78;&#46;&#x63;&#111;&#x6d;</a>’的这条记录，取得 ID2 的值；</li>\n<li>到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；</li>\n<li>取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email=‘<a href=\"mailto:&#122;&#x68;&#x61;&#110;&#103;&#115;&#115;&#x78;&#x79;&#122;&#x40;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;\">&#122;&#x68;&#x61;&#110;&#103;&#115;&#115;&#x78;&#x79;&#122;&#x40;&#x78;&#x78;&#120;&#46;&#x63;&#x6f;&#x6d;</a>’的条件了，循环结束。\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：</li>\n<li>从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；</li>\n<li>到主键上查到主键值是 ID1 的行，判断出 email 的值不是’<a href=\"mailto:&#x7a;&#104;&#97;&#110;&#103;&#x73;&#x73;&#x78;&#x79;&#122;&#64;&#120;&#120;&#120;&#46;&#99;&#x6f;&#109;\">&#x7a;&#104;&#97;&#110;&#103;&#x73;&#x73;&#x78;&#x79;&#122;&#64;&#120;&#120;&#120;&#46;&#99;&#x6f;&#109;</a>’，这行记录丢弃；</li>\n<li>取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；</li>\n<li>重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。\n通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7），也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</li>\n</ol>\n<pre><code>mysql&gt; select count(distinct email) as L from SUser;\n</code></pre>\n<p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n</code></pre>\n<p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。</p>\n<br/>\n### 前缀索引对覆盖索引的影响\n\n\n<p>前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n你先来看看这个 SQL 语句：</p>\n<pre><code class=\"SQL\">select id,email from SUser where email=&#39;zhangssxyz@xxx.com&#39;;\n</code></pre>\n<p>与前面例子中的 SQL 语句</p>\n<pre><code class=\"SQL\">select id,name,email from SUser where email=&#39;zhangssxyz@xxx.com&#39;;\n</code></pre>\n<p>相比，这个语句只要求返回 id 和 email 字段。\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。\n即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n其他方式\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。\n按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。\n但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。\n答案是，有的。\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p>\n<pre><code class=\"SQL\">mysql&gt; select field_list from t where id_card = reverse(&#39;input_id_card_string&#39;);\n</code></pre>\n<p>由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n第二种方式是使用 hash字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p>\n<pre><code class=\"SQL\">mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc);\n</code></pre>\n<p>然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。</p>\n<pre><code class=\"SQL\">mysql&gt; select field_list from t where id_card_crc=crc32(&#39;input_id_card_string&#39;) and id_card=&#39;input_id_card_string&#39;\n</code></pre>\n<p>这样，索引的长度变成了 4 个字节，比原来小了很多。\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n它们的区别，主要体现在以下三个方面：</p>\n<ol>\n<li>从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。</li>\n<li>在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。</li>\n<li>从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li>\n</ol>\n<br/>\n\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>在今天这篇文章中，我跟你聊了聊字符串字段创建索引的场景。我们来回顾一下，你可以使用的方式有：\n• 直接创建完整索引，这样可能比较占用空间；\n• 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n• 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n• 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。\n本期问题：如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com”, 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n由于这个学号的规则，无论是正向还是反向的前缀索引，重复度都比较高。因为维护的只是一个学校的，因此前面 6 位（其中，前三位是所在城市编号、第四到第六位是学校编号）其实是固定的，邮箱后缀都是 @gamil.com，因此可以只存入学年份加顺序编号，它们的长度是 9 位。而其实在此基础上，可以用数字类型来存这 9 位数字。比如 201100001，这样只需要占 4 个字节。其实这个就是一种 hash，只是它用了最简单的转换规则：字符串转数字的规则，而刚好我们设定的这个背景，可以保证这个转换后结果的唯一性。</p>\n"},{"title":"13 | 为什么表数据删掉一半，表文件大小不变","date":"2019-06-02T16:00:00.000Z","_content":"\n经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？\n那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。\n这里，我们还是针对 MySQL 中应用最广泛的 InnoDB 引擎展开讨论。一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。\n参数 innodb_file_per_table\n表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n• OFF 表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n• ON  每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中;\n从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。\n我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n所以，将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。\n我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。\n我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。\n\n<br/>\n### 数据删除流程\n\n我们先再来看一下 InnoDB 中一个索引的示意图。在前面第 4和第 5篇文章中，我和你介绍索引时曾经提到过，InnoDB 里的数据都是用 B+ 树的结构组织的。\n\n![图 1 B+ 树索引示意图](1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg)\n\n假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？\n答案是，整个数据页就可以被复用了。但是，数据页的复用跟记录的复用是不同的。\n• 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n• 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。\n如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。\n你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n实际上，不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？\n\n![图 2 插入数据导致页分裂](1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg)s\n\n可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。\n另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n而重建表，就可以达到这样的目的。\n\n\n<br/>\n### 重建表\n\n试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。\n\n![图 3 改锁表 DDL](1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg)\n\n显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n我给你简单描述一下引入了 Online DDL 之后，重建表的流程：\n• 建立一个临时文件，扫描表 A 主键的所有数据页；\n• 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n• 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n• 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n图 4 Online DDL\n可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\n我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？\n确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。\n• 为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。\n• 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。\n而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。\n需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。\n\n\n<br/>\n### Online 和 inplace\n\n说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在图 3 中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘空间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：\n\n```SQL\nalter table t engine=innodb,ALGORITHM=inplace;\n```\n\n跟 inplace 对应的就是拷贝表的方式了，用法是：\nalter table t engine=innodb,ALGORITHM=copy;\n当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程就是图 3 的操作过程。\n但我这样说你可能会觉得，inplace 跟 Online 是不是就是一个意思？\n其实不是的，只是在重建表这个逻辑中刚好是这样而已。\n比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：\n\n```SQL\nalter table t add FULLTEXT(field_name);\n```\n\n这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\nDDL 过程如果是 Online 的，就一定是 inplace 的，反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n最后，我们再延伸一下。\n在第 10 篇文章《MySQL 为什么有时候会选错索引》的评论区中，有同学问到使用 optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。\n• alter table t engine = InnoDB（也就是 recreate）从 MySQL 5.6 版本开始默认的就是上面图 4 的流程了；\n• analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\n• optimize table t 等于 recreate+analyze。\n\n<br/>\n### 小结\n\n今天这篇文章，我和你讨论了数据库中收缩表空间的方法。\n现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过 alter table 命令重建表，才能达到表文件变小的目的。我跟你介绍了重建表的两种实现方式，Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。\n本节文：假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：\n一个表 t 文件大小为 1TB；\n对这个表执行 alter table t engine=InnoDB；\n发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n你觉得可能是什么原因呢 ？\n执行alter table过程中有很多的修改行纪录的操作","source":"_posts/13-为什么表数据删掉一半，表文件大小不变.md","raw":"---\ntitle: 13 | 为什么表数据删掉一半，表文件大小不变\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？\n那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。\n这里，我们还是针对 MySQL 中应用最广泛的 InnoDB 引擎展开讨论。一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。\n参数 innodb_file_per_table\n表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n• OFF 表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n• ON  每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中;\n从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。\n我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n所以，将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。\n我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。\n我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。\n\n<br/>\n### 数据删除流程\n\n我们先再来看一下 InnoDB 中一个索引的示意图。在前面第 4和第 5篇文章中，我和你介绍索引时曾经提到过，InnoDB 里的数据都是用 B+ 树的结构组织的。\n\n![图 1 B+ 树索引示意图](1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg)\n\n假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？\n答案是，整个数据页就可以被复用了。但是，数据页的复用跟记录的复用是不同的。\n• 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n• 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。\n如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。\n你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n实际上，不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？\n\n![图 2 插入数据导致页分裂](1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg)s\n\n可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。\n另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n而重建表，就可以达到这样的目的。\n\n\n<br/>\n### 重建表\n\n试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。\n\n![图 3 改锁表 DDL](1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg)\n\n显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n我给你简单描述一下引入了 Online DDL 之后，重建表的流程：\n• 建立一个临时文件，扫描表 A 主键的所有数据页；\n• 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n• 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n• 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n图 4 Online DDL\n可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\n我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？\n确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。\n• 为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。\n• 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。\n而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。\n需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。\n\n\n<br/>\n### Online 和 inplace\n\n说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在图 3 中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘空间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：\n\n```SQL\nalter table t engine=innodb,ALGORITHM=inplace;\n```\n\n跟 inplace 对应的就是拷贝表的方式了，用法是：\nalter table t engine=innodb,ALGORITHM=copy;\n当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程就是图 3 的操作过程。\n但我这样说你可能会觉得，inplace 跟 Online 是不是就是一个意思？\n其实不是的，只是在重建表这个逻辑中刚好是这样而已。\n比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：\n\n```SQL\nalter table t add FULLTEXT(field_name);\n```\n\n这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\nDDL 过程如果是 Online 的，就一定是 inplace 的，反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n最后，我们再延伸一下。\n在第 10 篇文章《MySQL 为什么有时候会选错索引》的评论区中，有同学问到使用 optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。\n• alter table t engine = InnoDB（也就是 recreate）从 MySQL 5.6 版本开始默认的就是上面图 4 的流程了；\n• analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\n• optimize table t 等于 recreate+analyze。\n\n<br/>\n### 小结\n\n今天这篇文章，我和你讨论了数据库中收缩表空间的方法。\n现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过 alter table 命令重建表，才能达到表文件变小的目的。我跟你介绍了重建表的两种实现方式，Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。\n本节文：假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：\n一个表 t 文件大小为 1TB；\n对这个表执行 alter table t engine=InnoDB；\n发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n你觉得可能是什么原因呢 ？\n执行alter table过程中有很多的修改行纪录的操作","slug":"13-为什么表数据删掉一半，表文件大小不变","published":1,"updated":"2021-06-30T02:33:24.598Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvb000xr5p79rwi2mo6","content":"<p>经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？\n那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。\n这里，我们还是针对 MySQL 中应用最广泛的 InnoDB 引擎展开讨论。一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。\n参数 innodb_file_per_table\n表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n• OFF 表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n• ON  每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中;\n从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。\n我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n所以，将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。\n我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。\n我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。</p>\n<br>\n### 数据删除流程\n\n<p>我们先再来看一下 InnoDB 中一个索引的示意图。在前面第 4和第 5篇文章中，我和你介绍索引时曾经提到过，InnoDB 里的数据都是用 B+ 树的结构组织的。</p>\n<p><img src=\"1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg\" alt=\"图 1 B+ 树索引示意图\"></p>\n<p>假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？\n答案是，整个数据页就可以被复用了。但是，数据页的复用跟记录的复用是不同的。\n• 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n• 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。\n如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。\n你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n实际上，不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？</p>\n<p><img src=\"1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg\" alt=\"图 2 插入数据导致页分裂\">s</p>\n<p>可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。\n另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n而重建表，就可以达到这样的目的。</p>\n<br>\n### 重建表\n\n<p>试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。</p>\n<p><img src=\"1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg\" alt=\"图 3 改锁表 DDL\"></p>\n<p>显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n我给你简单描述一下引入了 Online DDL 之后，重建表的流程：\n• 建立一个临时文件，扫描表 A 主键的所有数据页；\n• 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n• 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n• 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n图 4 Online DDL\n可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\n我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？\n确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。\n• 为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。\n• 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。\n而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。\n需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。</p>\n<br>\n### Online 和 inplace\n\n<p>说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在图 3 中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘空间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">alter table t engine=innodb,ALGORITHM=inplace;\n</code></pre>\n<p>跟 inplace 对应的就是拷贝表的方式了，用法是：\nalter table t engine=innodb,ALGORITHM=copy;\n当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程就是图 3 的操作过程。\n但我这样说你可能会觉得，inplace 跟 Online 是不是就是一个意思？\n其实不是的，只是在重建表这个逻辑中刚好是这样而已。\n比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">alter table t add FULLTEXT(field_name);\n</code></pre>\n<p>这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\nDDL 过程如果是 Online 的，就一定是 inplace 的，反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n最后，我们再延伸一下。\n在第 10 篇文章《MySQL 为什么有时候会选错索引》的评论区中，有同学问到使用 optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。\n• alter table t engine = InnoDB（也就是 recreate）从 MySQL 5.6 版本开始默认的就是上面图 4 的流程了；\n• analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\n• optimize table t 等于 recreate+analyze。</p>\n<br>\n### 小结\n\n<p>今天这篇文章，我和你讨论了数据库中收缩表空间的方法。\n现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过 alter table 命令重建表，才能达到表文件变小的目的。我跟你介绍了重建表的两种实现方式，Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。\n本节文：假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：\n一个表 t 文件大小为 1TB；\n对这个表执行 alter table t engine=InnoDB；\n发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n你觉得可能是什么原因呢 ？\n执行alter table过程中有很多的修改行纪录的操作</p>\n","site":{"data":{}},"excerpt":"","more":"<p>经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？\n那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。\n这里，我们还是针对 MySQL 中应用最广泛的 InnoDB 引擎展开讨论。一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。\n参数 innodb_file_per_table\n表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n• OFF 表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n• ON  每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中;\n从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。\n我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。\n所以，将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。\n我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。\n我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。</p>\n<br/>\n### 数据删除流程\n\n<p>我们先再来看一下 InnoDB 中一个索引的示意图。在前面第 4和第 5篇文章中，我和你介绍索引时曾经提到过，InnoDB 里的数据都是用 B+ 树的结构组织的。</p>\n<p><img src=\"1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg\" alt=\"图 1 B+ 树索引示意图\"></p>\n<p>假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\n现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？\n答案是，整个数据页就可以被复用了。但是，数据页的复用跟记录的复用是不同的。\n• 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n• 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。\n如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。\n你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n实际上，不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？</p>\n<p><img src=\"1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg\" alt=\"图 2 插入数据导致页分裂\">s</p>\n<p>可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。\n另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n而重建表，就可以达到这样的目的。</p>\n<br/>\n### 重建表\n\n<p>试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。</p>\n<p><img src=\"1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg\" alt=\"图 3 改锁表 DDL\"></p>\n<p>显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n我给你简单描述一下引入了 Online DDL 之后，重建表的流程：\n• 建立一个临时文件，扫描表 A 主键的所有数据页；\n• 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n• 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n• 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n图 4 Online DDL\n可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\n我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？\n确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。\n• 为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。\n• 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。\n而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。\n需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。</p>\n<br/>\n### Online 和 inplace\n\n<p>说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在图 3 中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在图 4 中，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘空间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：</p>\n<pre><code class=\"SQL\">alter table t engine=innodb,ALGORITHM=inplace;\n</code></pre>\n<p>跟 inplace 对应的就是拷贝表的方式了，用法是：\nalter table t engine=innodb,ALGORITHM=copy;\n当你使用 ALGORITHM=copy 的时候，表示的是强制拷贝表，对应的流程就是图 3 的操作过程。\n但我这样说你可能会觉得，inplace 跟 Online 是不是就是一个意思？\n其实不是的，只是在重建表这个逻辑中刚好是这样而已。\n比如，如果我要给 InnoDB 表的一个字段加全文索引，写法是：</p>\n<pre><code class=\"SQL\">alter table t add FULLTEXT(field_name);\n</code></pre>\n<p>这个过程是 inplace 的，但会阻塞增删改操作，是非 Online 的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\nDDL 过程如果是 Online 的，就一定是 inplace 的，反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n最后，我们再延伸一下。\n在第 10 篇文章《MySQL 为什么有时候会选错索引》的评论区中，有同学问到使用 optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。\n• alter table t engine = InnoDB（也就是 recreate）从 MySQL 5.6 版本开始默认的就是上面图 4 的流程了；\n• analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\n• optimize table t 等于 recreate+analyze。</p>\n<br/>\n### 小结\n\n<p>今天这篇文章，我和你讨论了数据库中收缩表空间的方法。\n现在你已经知道了，如果要收缩一个表，只是 delete 掉表里面不用的数据的话，表文件的大小是不会变的，你还要通过 alter table 命令重建表，才能达到表文件变小的目的。我跟你介绍了重建表的两种实现方式，Online DDL 的方式是可以考虑在业务低峰期使用的，而 MySQL 5.5 及之前的版本，这个命令是会阻塞 DML 的，这个你需要特别小心。\n本节文：假设现在有人碰到了一个“想要收缩表空间，结果适得其反”的情况，看上去是这样的：\n一个表 t 文件大小为 1TB；\n对这个表执行 alter table t engine=InnoDB；\n发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n你觉得可能是什么原因呢 ？\n执行alter table过程中有很多的修改行纪录的操作</p>\n"},{"title":"14 | count(*)这么慢，我该怎么办","date":"2019-06-02T16:00:00.000Z","_content":"\n在开发系统的时候，你可能经常需要计算一个表的行数，比如一个交易系统的所有变更记录总数。这时候你可能会想，一条 select count(*) from t 语句不就解决了吗？\n但是，你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL 怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。\n那么今天，我们就来聊聊 count(*) 语句到底是怎样实现的，以及 MySQL 为什么会这么实现。然后，我会再和你说说，如果应用中有这种频繁变更并需要统计表行数的需求，业务设计上可以怎么做。\ncount(*) 的实现方式\n你首先要明确的是，在不同的 MySQL 引擎中，count(*) 有不同的实现方式。\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n在前面的文章中，我们一起分析了为什么要使用 InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB 都优于 MyISAM。我猜你的表也一定是用了 InnoDB 引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。\n那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n• 会话 A 先启动事务并查询一次表的总行数；\n• 会话 B 启动事务，插入一行后记录后，查询表的总行数；\n• 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。\n\n![图 1 会话 A、B、C 的执行流程](1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg)\n\n你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n当然，现在这个看上去笨笨的 MySQL，在执行 count(*) 操作的时候还是做了优化的。\n你知道的，InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？\n你可能还记得在第 10 篇文章《 MySQL 为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n到这里我们小结一下：\n• MyISAM 表虽然 count(*) 很快，但是不支持事务；\n• show table status 命令虽然返回很快，但是不准确；\n• InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。\n那么，回到文章开头的问题，如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？答案是，我们只能自己计数。\n接下来，我们讨论一下，看看自己计数有哪些方法，以及每种方法的优缺点有哪些。\n这里，我先和你说一下这些方法的基本思路：你需要自己找一个地方，把操作记录表的行数存起来。\n\n\n<br/>\n### 用缓存系统保存计数\n\n对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持。\n你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的 100 条记录。那么，这个页面的逻辑就需要先到 Redis 里面取出计数，再到数据表里面取数据记录。\n我们是这么定义不精确的：\n1. 查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；\n2. 查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n这两种情况，都是逻辑不一致的。\n我们一起来看看这个时序图。\n\n![图 2 会话 A、B 执行时序图](1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg)\n\n图 2 中，会话 A 是一个插入交易记录的逻辑，往数据表里插入一行 R，然后 Redis 计数加 1；会话 B 就是查询页面显示时需要的数据。\n在图 2 的这个时序里，在 T3 时刻会话 B 来查询的时候，会显示出新插入的 R 这个记录，但是 Redis 的计数还没加 1。这时候，就会出现我们说的数据不一致。\n你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改 Redis 计数。而读的时候是先读 Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话 A 的更新顺序换一下，再看看执行结果。\n\n![图 3 调整顺序后，会话 A、B 的执行时序图](1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg)\n\n你会发现，这时候反过来了，会话 B 在 T3 时刻查询的时候，Redis 计数加了 1 了，但还查不到新插入的 R 这一行，也是数据不一致的情况。\n在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。\n\n<br/>\n### 在数据库保存计数\n\n根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n然后，我们再看看能不能解决计数不精确的问题。\n你会说，这不一样吗？无非就是把图 3 中对 Redis 的操作，改成了对计数表 C 的操作。只要出现图 3 的这种执行序列，这个问题还是无解的吧？\n这个问题还真不是无解的。\n我们这篇文章要解决的问题，都是由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。\n\n![图 4 会话 A、B 的执行时序图](1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg)\n\n我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。\n\n<br/>\n### 不同的 count 用法\n\n在前面文章的评论区，有同学留言问到：在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。今天谈到了 count(*) 的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。\n需要注意的是，下面的讨论还是基于 InnoDB 引擎的。\n这里，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，你可以记住这么几个原则：\n• server 层要什么就给什么；\n• InnoDB 只给必要的值；\n现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n这是什么意思呢？接下来，我们就一个个地来看看。\n• 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n• 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n• 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n• 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n• 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 count(*) 来处理，多么简单的优化啊。\n当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 count(*) 了，你直接使用这种用法就可以了。\n\n> 所以结论是：按照效率排序的话，`count(字段)` < `count(主键 id)` < `count(1)` ≈ `count(*)`，所以我建议你，尽量使用 `count(*)`。\n\n<br/>\n### 小结\n\n今天，我和你聊了聊 MySQL 中获得表行数的两种方法。我们提到了在不同引擎中 count(*) 的实现方式是不一样的，也分析了用缓存系统来存储计数值存在的问题。\n• 其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。\n• InnoDB 引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是 InnoDB 引擎备受青睐的原因之一。\n问题：在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n先插入操作纪录，在更新计数表，因为计数表相当于热点行，加锁时间需要考虑足够短！\n","source":"_posts/14-count-这么慢，我该怎么办.md","raw":"---\ntitle: 14 | count(*)这么慢，我该怎么办\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n在开发系统的时候，你可能经常需要计算一个表的行数，比如一个交易系统的所有变更记录总数。这时候你可能会想，一条 select count(*) from t 语句不就解决了吗？\n但是，你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL 怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。\n那么今天，我们就来聊聊 count(*) 语句到底是怎样实现的，以及 MySQL 为什么会这么实现。然后，我会再和你说说，如果应用中有这种频繁变更并需要统计表行数的需求，业务设计上可以怎么做。\ncount(*) 的实现方式\n你首先要明确的是，在不同的 MySQL 引擎中，count(*) 有不同的实现方式。\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n在前面的文章中，我们一起分析了为什么要使用 InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB 都优于 MyISAM。我猜你的表也一定是用了 InnoDB 引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。\n那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n• 会话 A 先启动事务并查询一次表的总行数；\n• 会话 B 启动事务，插入一行后记录后，查询表的总行数；\n• 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。\n\n![图 1 会话 A、B、C 的执行流程](1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg)\n\n你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n当然，现在这个看上去笨笨的 MySQL，在执行 count(*) 操作的时候还是做了优化的。\n你知道的，InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？\n你可能还记得在第 10 篇文章《 MySQL 为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n到这里我们小结一下：\n• MyISAM 表虽然 count(*) 很快，但是不支持事务；\n• show table status 命令虽然返回很快，但是不准确；\n• InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。\n那么，回到文章开头的问题，如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？答案是，我们只能自己计数。\n接下来，我们讨论一下，看看自己计数有哪些方法，以及每种方法的优缺点有哪些。\n这里，我先和你说一下这些方法的基本思路：你需要自己找一个地方，把操作记录表的行数存起来。\n\n\n<br/>\n### 用缓存系统保存计数\n\n对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持。\n你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的 100 条记录。那么，这个页面的逻辑就需要先到 Redis 里面取出计数，再到数据表里面取数据记录。\n我们是这么定义不精确的：\n1. 查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；\n2. 查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n这两种情况，都是逻辑不一致的。\n我们一起来看看这个时序图。\n\n![图 2 会话 A、B 执行时序图](1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg)\n\n图 2 中，会话 A 是一个插入交易记录的逻辑，往数据表里插入一行 R，然后 Redis 计数加 1；会话 B 就是查询页面显示时需要的数据。\n在图 2 的这个时序里，在 T3 时刻会话 B 来查询的时候，会显示出新插入的 R 这个记录，但是 Redis 的计数还没加 1。这时候，就会出现我们说的数据不一致。\n你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改 Redis 计数。而读的时候是先读 Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话 A 的更新顺序换一下，再看看执行结果。\n\n![图 3 调整顺序后，会话 A、B 的执行时序图](1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg)\n\n你会发现，这时候反过来了，会话 B 在 T3 时刻查询的时候，Redis 计数加了 1 了，但还查不到新插入的 R 这一行，也是数据不一致的情况。\n在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。\n\n<br/>\n### 在数据库保存计数\n\n根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n然后，我们再看看能不能解决计数不精确的问题。\n你会说，这不一样吗？无非就是把图 3 中对 Redis 的操作，改成了对计数表 C 的操作。只要出现图 3 的这种执行序列，这个问题还是无解的吧？\n这个问题还真不是无解的。\n我们这篇文章要解决的问题，都是由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。\n\n![图 4 会话 A、B 的执行时序图](1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg)\n\n我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。\n\n<br/>\n### 不同的 count 用法\n\n在前面文章的评论区，有同学留言问到：在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。今天谈到了 count(*) 的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。\n需要注意的是，下面的讨论还是基于 InnoDB 引擎的。\n这里，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，你可以记住这么几个原则：\n• server 层要什么就给什么；\n• InnoDB 只给必要的值；\n现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n这是什么意思呢？接下来，我们就一个个地来看看。\n• 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n• 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n• 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n• 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n• 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 count(*) 来处理，多么简单的优化啊。\n当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 count(*) 了，你直接使用这种用法就可以了。\n\n> 所以结论是：按照效率排序的话，`count(字段)` < `count(主键 id)` < `count(1)` ≈ `count(*)`，所以我建议你，尽量使用 `count(*)`。\n\n<br/>\n### 小结\n\n今天，我和你聊了聊 MySQL 中获得表行数的两种方法。我们提到了在不同引擎中 count(*) 的实现方式是不一样的，也分析了用缓存系统来存储计数值存在的问题。\n• 其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。\n• InnoDB 引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是 InnoDB 引擎备受青睐的原因之一。\n问题：在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n先插入操作纪录，在更新计数表，因为计数表相当于热点行，加锁时间需要考虑足够短！\n","slug":"14-count-这么慢，我该怎么办","published":1,"updated":"2021-06-30T02:33:24.602Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvc0010r5p76ctfb8o2","content":"<p>在开发系统的时候，你可能经常需要计算一个表的行数，比如一个交易系统的所有变更记录总数。这时候你可能会想，一条 select count(<em>) from t 语句不就解决了吗？\n但是，你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL 怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。\n那么今天，我们就来聊聊 count(</em>) 语句到底是怎样实现的，以及 MySQL 为什么会这么实现。然后，我会再和你说说，如果应用中有这种频繁变更并需要统计表行数的需求，业务设计上可以怎么做。\ncount(<em>) 的实现方式\n你首先要明确的是，在不同的 MySQL 引擎中，count(</em>) 有不同的实现方式。\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(<em>) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(</em>) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(<em>)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n在前面的文章中，我们一起分析了为什么要使用 InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB 都优于 MyISAM。我猜你的表也一定是用了 InnoDB 引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。\n那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(</em>) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n• 会话 A 先启动事务并查询一次表的总行数；\n• 会话 B 启动事务，插入一行后记录后，查询表的总行数；\n• 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。</p>\n<p><img src=\"1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg\" alt=\"图 1 会话 A、B、C 的执行流程\"></p>\n<p>你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(<em>) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n当然，现在这个看上去笨笨的 MySQL，在执行 count(</em>) 操作的时候还是做了优化的。\n你知道的，InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(<em>) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(</em>) 吗？\n你可能还记得在第 10 篇文章《 MySQL 为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n到这里我们小结一下：\n• MyISAM 表虽然 count(<em>) 很快，但是不支持事务；\n• show table status 命令虽然返回很快，但是不准确；\n• InnoDB 表直接 count(</em>) 会遍历全表，虽然结果准确，但会导致性能问题。\n那么，回到文章开头的问题，如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？答案是，我们只能自己计数。\n接下来，我们讨论一下，看看自己计数有哪些方法，以及每种方法的优缺点有哪些。\n这里，我先和你说一下这些方法的基本思路：你需要自己找一个地方，把操作记录表的行数存起来。</p>\n<br>\n### 用缓存系统保存计数\n\n<p>对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持。\n你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的 100 条记录。那么，这个页面的逻辑就需要先到 Redis 里面取出计数，再到数据表里面取数据记录。\n我们是这么定义不精确的：</p>\n<ol>\n<li>查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；</li>\n<li>查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n这两种情况，都是逻辑不一致的。\n我们一起来看看这个时序图。</li>\n</ol>\n<p><img src=\"1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg\" alt=\"图 2 会话 A、B 执行时序图\"></p>\n<p>图 2 中，会话 A 是一个插入交易记录的逻辑，往数据表里插入一行 R，然后 Redis 计数加 1；会话 B 就是查询页面显示时需要的数据。\n在图 2 的这个时序里，在 T3 时刻会话 B 来查询的时候，会显示出新插入的 R 这个记录，但是 Redis 的计数还没加 1。这时候，就会出现我们说的数据不一致。\n你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改 Redis 计数。而读的时候是先读 Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话 A 的更新顺序换一下，再看看执行结果。</p>\n<p><img src=\"1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg\" alt=\"图 3 调整顺序后，会话 A、B 的执行时序图\"></p>\n<p>你会发现，这时候反过来了，会话 B 在 T3 时刻查询的时候，Redis 计数加了 1 了，但还查不到新插入的 R 这一行，也是数据不一致的情况。\n在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。</p>\n<br>\n### 在数据库保存计数\n\n<p>根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n然后，我们再看看能不能解决计数不精确的问题。\n你会说，这不一样吗？无非就是把图 3 中对 Redis 的操作，改成了对计数表 C 的操作。只要出现图 3 的这种执行序列，这个问题还是无解的吧？\n这个问题还真不是无解的。\n我们这篇文章要解决的问题，都是由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。</p>\n<p><img src=\"1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg\" alt=\"图 4 会话 A、B 的执行时序图\"></p>\n<p>我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。</p>\n<br>\n### 不同的 count 用法\n\n<p>在前面文章的评论区，有同学留言问到：在 select count(?) from t 这样的查询语句里面，count(<em>)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。今天谈到了 count(</em>) 的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。\n需要注意的是，下面的讨论还是基于 InnoDB 引擎的。\n这里，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(<em>)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，你可以记住这么几个原则：\n• server 层要什么就给什么；\n• InnoDB 只给必要的值；\n现在的优化器只优化了 count(</em>) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n这是什么意思呢？接下来，我们就一个个地来看看。\n• 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n• 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n• 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n• 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n• 但是 count(<em>) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(</em>) 肯定不是 null，按行累加。\n看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 count(<em>) 来处理，多么简单的优化啊。\n当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 count(</em>) 了，你直接使用这种用法就可以了。</p>\n<blockquote>\n<p>所以结论是：按照效率排序的话，<code>count(字段)</code> &lt; <code>count(主键 id)</code> &lt; <code>count(1)</code> ≈ <code>count(*)</code>，所以我建议你，尽量使用 <code>count(*)</code>。</p>\n</blockquote>\n<br>\n### 小结\n\n<p>今天，我和你聊了聊 MySQL 中获得表行数的两种方法。我们提到了在不同引擎中 count(*) 的实现方式是不一样的，也分析了用缓存系统来存储计数值存在的问题。\n• 其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。\n• InnoDB 引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是 InnoDB 引擎备受青睐的原因之一。\n问题：在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n先插入操作纪录，在更新计数表，因为计数表相当于热点行，加锁时间需要考虑足够短！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在开发系统的时候，你可能经常需要计算一个表的行数，比如一个交易系统的所有变更记录总数。这时候你可能会想，一条 select count(<em>) from t 语句不就解决了吗？\n但是，你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL 怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。\n那么今天，我们就来聊聊 count(</em>) 语句到底是怎样实现的，以及 MySQL 为什么会这么实现。然后，我会再和你说说，如果应用中有这种频繁变更并需要统计表行数的需求，业务设计上可以怎么做。\ncount(<em>) 的实现方式\n你首先要明确的是，在不同的 MySQL 引擎中，count(</em>) 有不同的实现方式。\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(<em>) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(</em>) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的 count(<em>)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n在前面的文章中，我们一起分析了为什么要使用 InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB 都优于 MyISAM。我猜你的表也一定是用了 InnoDB 引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。\n那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(</em>) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n• 会话 A 先启动事务并查询一次表的总行数；\n• 会话 B 启动事务，插入一行后记录后，查询表的总行数；\n• 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。</p>\n<p><img src=\"1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg\" alt=\"图 1 会话 A、B、C 的执行流程\"></p>\n<p>你会看到，在最后一个时刻，三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(<em>) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。\n当然，现在这个看上去笨笨的 MySQL，在执行 count(</em>) 操作的时候还是做了优化的。\n你知道的，InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(<em>) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(</em>) 吗？\n你可能还记得在第 10 篇文章《 MySQL 为什么有时候会选错索引？》中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n到这里我们小结一下：\n• MyISAM 表虽然 count(<em>) 很快，但是不支持事务；\n• show table status 命令虽然返回很快，但是不准确；\n• InnoDB 表直接 count(</em>) 会遍历全表，虽然结果准确，但会导致性能问题。\n那么，回到文章开头的问题，如果你现在有一个页面经常要显示交易系统的操作记录总数，到底应该怎么办呢？答案是，我们只能自己计数。\n接下来，我们讨论一下，看看自己计数有哪些方法，以及每种方法的优缺点有哪些。\n这里，我先和你说一下这些方法的基本思路：你需要自己找一个地方，把操作记录表的行数存起来。</p>\n<br/>\n### 用缓存系统保存计数\n\n<p>对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持。\n你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的 100 条记录。那么，这个页面的逻辑就需要先到 Redis 里面取出计数，再到数据表里面取数据记录。\n我们是这么定义不精确的：</p>\n<ol>\n<li>查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；</li>\n<li>查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n这两种情况，都是逻辑不一致的。\n我们一起来看看这个时序图。</li>\n</ol>\n<p><img src=\"1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg\" alt=\"图 2 会话 A、B 执行时序图\"></p>\n<p>图 2 中，会话 A 是一个插入交易记录的逻辑，往数据表里插入一行 R，然后 Redis 计数加 1；会话 B 就是查询页面显示时需要的数据。\n在图 2 的这个时序里，在 T3 时刻会话 B 来查询的时候，会显示出新插入的 R 这个记录，但是 Redis 的计数还没加 1。这时候，就会出现我们说的数据不一致。\n你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改 Redis 计数。而读的时候是先读 Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话 A 的更新顺序换一下，再看看执行结果。</p>\n<p><img src=\"1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg\" alt=\"图 3 调整顺序后，会话 A、B 的执行时序图\"></p>\n<p>你会发现，这时候反过来了，会话 B 在 T3 时刻查询的时候，Redis 计数加了 1 了，但还查不到新插入的 R 这一行，也是数据不一致的情况。\n在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使 Redis 正常工作，这个计数值还是逻辑上不精确的。</p>\n<br/>\n### 在数据库保存计数\n\n<p>根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n然后，我们再看看能不能解决计数不精确的问题。\n你会说，这不一样吗？无非就是把图 3 中对 Redis 的操作，改成了对计数表 C 的操作。只要出现图 3 的这种执行序列，这个问题还是无解的吧？\n这个问题还真不是无解的。\n我们这篇文章要解决的问题，都是由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。</p>\n<p><img src=\"1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg\" alt=\"图 4 会话 A、B 的执行时序图\"></p>\n<p>我们来看下现在的执行结果。虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。</p>\n<br/>\n### 不同的 count 用法\n\n<p>在前面文章的评论区，有同学留言问到：在 select count(?) from t 这样的查询语句里面，count(<em>)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。今天谈到了 count(</em>) 的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。\n需要注意的是，下面的讨论还是基于 InnoDB 引擎的。\n这里，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(<em>)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，你可以记住这么几个原则：\n• server 层要什么就给什么；\n• InnoDB 只给必要的值；\n现在的优化器只优化了 count(</em>) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n这是什么意思呢？接下来，我们就一个个地来看看。\n• 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n• 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n• 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n• 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n• 但是 count(<em>) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(</em>) 肯定不是 null，按行累加。\n看到这里，你一定会说，优化器就不能自己判断一下吗，主键 id 肯定非空啊，为什么不能按照 count(<em>) 来处理，多么简单的优化啊。\n当然，MySQL 专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且 MySQL 已经优化过 count(</em>) 了，你直接使用这种用法就可以了。</p>\n<blockquote>\n<p>所以结论是：按照效率排序的话，<code>count(字段)</code> &lt; <code>count(主键 id)</code> &lt; <code>count(1)</code> ≈ <code>count(*)</code>，所以我建议你，尽量使用 <code>count(*)</code>。</p>\n</blockquote>\n<br/>\n### 小结\n\n<p>今天，我和你聊了聊 MySQL 中获得表行数的两种方法。我们提到了在不同引擎中 count(*) 的实现方式是不一样的，也分析了用缓存系统来存储计数值存在的问题。\n• 其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。\n• InnoDB 引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是 InnoDB 引擎备受青睐的原因之一。\n问题：在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n先插入操作纪录，在更新计数表，因为计数表相当于热点行，加锁时间需要考虑足够短！</p>\n"},{"title":"12 | 为什么我的MySQL会“抖”一下","date":"2019-06-02T16:00:00.000Z","_content":"\n平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。\n看上去，这就像是数据库“抖”了一下。今天，我们就一起来看一看这是什么原因。\n\n<br/>\n\n### 你的 SQL 语句为什么变“慢”了\n\n在MySQL日志系统：一条SQL更新语句是如何执行的？中，我为你介绍了 WAL 机制。现在你知道了，InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。\n做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。\n掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。在这个 flush 操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。\n接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账 10 文，这次又要赊 9 文。\n\n![图 1 “孔乙己赊账”更新和 flush 过程](1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg)\n\n回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。\n\n<br/>\n### 什么情况会引发数据库的 flush 过程呢？\n\n我们还是继续用咸亨酒店掌柜的这个例子，想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？\n第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。\n这个场景，对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。我在第二讲画了一个 redo log 的示意图，这里我改成环形，便于大家理解。\n\n![图 2 redo log 状态图](1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg)\n\ncheckpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。\n第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。\n这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用不就行了？这里其实是从（读）性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：\n1. 内存里存在，内存里就肯定是正确的结果，直接返回；\n2. 内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。\n这样的效率最高。\n第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。\n这种场景，对应的就是 MySQL 认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。\n第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。\n这种场景，对应的就是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n接下来，你可以分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n1. 还没有使用的；\n2. 使用了并且是干净页；\n3. 使用了并且是脏页；\n\nInnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。\n\n<br/>\n\n### InnoDB 刷脏页的控制策略\n\n接下来，我就来和你说说 InnoDB 脏页的控制策略，以及和这些策略相关的参数。\n首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：\n\n```\nfio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n```\n\n其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就有开发同学找我看一个库的性能问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。\n他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看 InnoDB 怎么控制引擎按照“全力”的百分比来刷脏页。\n根据我前面提到的知识点，试想一下，如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。\n所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。\nInnoDB 会根据这两个因素先单独算出两个数字。\n参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：\n\n```\nF1(M)\n{\n  if M>=innodb_max_dirty_pages_pct then\n      return 100;\n  return 100*M/innodb_max_dirty_pages_pct;\n}\n```\n\nInnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。图中的 F1、F2 就是上面我们通过脏页比例和 redo log 写入速度算出来的两个值。\n\n![图 3 InnoDB 刷脏页速度策略](1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg)\n\n现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。\n要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。\n其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：\n\n```SQL\nmysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';\nselect @a/@b;\n```\n\n接下来，我们再看一个有趣的策略。\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居（线上设置为0），自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。\n\n<br/>\n### 小结\n\n今天这篇文章，延续MySQL日志系统：一条SQL更新语句是如何执行的？中介绍的 WAL 的概念，和你解释了这个机制后续需要的刷脏页操作和执行时机。\n利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。\n思考：当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？\n另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？\n答案：其实由于淘汰的时候，刷脏页过程不用动redo log文件的。这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。\n文章最后，我给你留下一个思考题吧。\n一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n要分业务场景来看\n1. 如果业务以写为主或者读写流量差不多，因为读cache相对较大，我理解会频繁出现因日志写满，更新全部堵住，写性能跌为 0的情况\n2. 如果以读为主，我理解redo_log本身设置小并没有明显的影响\n作者答案：每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。\n\n![](1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png)","source":"_posts/12-为什么我的MySQL会“抖”一下.md","raw":"---\ntitle: 12 | 为什么我的MySQL会“抖”一下\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。\n看上去，这就像是数据库“抖”了一下。今天，我们就一起来看一看这是什么原因。\n\n<br/>\n\n### 你的 SQL 语句为什么变“慢”了\n\n在MySQL日志系统：一条SQL更新语句是如何执行的？中，我为你介绍了 WAL 机制。现在你知道了，InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。\n做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。\n掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。在这个 flush 操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。\n接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账 10 文，这次又要赊 9 文。\n\n![图 1 “孔乙己赊账”更新和 flush 过程](1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg)\n\n回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。\n\n<br/>\n### 什么情况会引发数据库的 flush 过程呢？\n\n我们还是继续用咸亨酒店掌柜的这个例子，想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？\n第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。\n这个场景，对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。我在第二讲画了一个 redo log 的示意图，这里我改成环形，便于大家理解。\n\n![图 2 redo log 状态图](1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg)\n\ncheckpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。\n第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。\n这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用不就行了？这里其实是从（读）性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：\n1. 内存里存在，内存里就肯定是正确的结果，直接返回；\n2. 内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。\n这样的效率最高。\n第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。\n这种场景，对应的就是 MySQL 认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。\n第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。\n这种场景，对应的就是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n接下来，你可以分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n1. 还没有使用的；\n2. 使用了并且是干净页；\n3. 使用了并且是脏页；\n\nInnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。\n\n<br/>\n\n### InnoDB 刷脏页的控制策略\n\n接下来，我就来和你说说 InnoDB 脏页的控制策略，以及和这些策略相关的参数。\n首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：\n\n```\nfio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n```\n\n其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就有开发同学找我看一个库的性能问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。\n他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看 InnoDB 怎么控制引擎按照“全力”的百分比来刷脏页。\n根据我前面提到的知识点，试想一下，如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。\n所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。\nInnoDB 会根据这两个因素先单独算出两个数字。\n参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：\n\n```\nF1(M)\n{\n  if M>=innodb_max_dirty_pages_pct then\n      return 100;\n  return 100*M/innodb_max_dirty_pages_pct;\n}\n```\n\nInnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。图中的 F1、F2 就是上面我们通过脏页比例和 redo log 写入速度算出来的两个值。\n\n![图 3 InnoDB 刷脏页速度策略](1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg)\n\n现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。\n要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。\n其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：\n\n```SQL\nmysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';\nselect @a/@b;\n```\n\n接下来，我们再看一个有趣的策略。\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居（线上设置为0），自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。\n\n<br/>\n### 小结\n\n今天这篇文章，延续MySQL日志系统：一条SQL更新语句是如何执行的？中介绍的 WAL 的概念，和你解释了这个机制后续需要的刷脏页操作和执行时机。\n利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。\n思考：当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？\n另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？\n答案：其实由于淘汰的时候，刷脏页过程不用动redo log文件的。这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。\n文章最后，我给你留下一个思考题吧。\n一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n要分业务场景来看\n1. 如果业务以写为主或者读写流量差不多，因为读cache相对较大，我理解会频繁出现因日志写满，更新全部堵住，写性能跌为 0的情况\n2. 如果以读为主，我理解redo_log本身设置小并没有明显的影响\n作者答案：每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。\n\n![](1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png)","slug":"12-为什么我的MySQL会“抖”一下","published":1,"updated":"2021-06-30T02:33:24.592Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvd0014r5p7fvd92d00","content":"<p>平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。\n看上去，这就像是数据库“抖”了一下。今天，我们就一起来看一看这是什么原因。</p>\n<br>\n\n<h3 id=\"你的-SQL-语句为什么变“慢”了\"><a href=\"#你的-SQL-语句为什么变“慢”了\" class=\"headerlink\" title=\"你的 SQL 语句为什么变“慢”了\"></a>你的 SQL 语句为什么变“慢”了</h3><p>在MySQL日志系统：一条SQL更新语句是如何执行的？中，我为你介绍了 WAL 机制。现在你知道了，InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。\n做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。\n掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。在这个 flush 操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。\n接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账 10 文，这次又要赊 9 文。</p>\n<p><img src=\"1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg\" alt=\"图 1 “孔乙己赊账”更新和 flush 过程\"></p>\n<p>回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>\n<br>\n### 什么情况会引发数据库的 flush 过程呢？\n\n<p>我们还是继续用咸亨酒店掌柜的这个例子，想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？\n第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。\n这个场景，对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。我在第二讲画了一个 redo log 的示意图，这里我改成环形，便于大家理解。</p>\n<p><img src=\"1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg\" alt=\"图 2 redo log 状态图\"></p>\n<p>checkpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。\n第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。\n这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用不就行了？这里其实是从（读）性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p>\n<ol>\n<li>内存里存在，内存里就肯定是正确的结果，直接返回；</li>\n<li>内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。\n这样的效率最高。\n第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。\n这种场景，对应的就是 MySQL 认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。\n第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。\n这种场景，对应的就是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n接下来，你可以分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</li>\n<li>还没有使用的；</li>\n<li>使用了并且是干净页；</li>\n<li>使用了并且是脏页；</li>\n</ol>\n<p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p>\n<ol>\n<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li>\n<li>日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</li>\n</ol>\n<br>\n\n<h3 id=\"InnoDB-刷脏页的控制策略\"><a href=\"#InnoDB-刷脏页的控制策略\" class=\"headerlink\" title=\"InnoDB 刷脏页的控制策略\"></a>InnoDB 刷脏页的控制策略</h3><p>接下来，我就来和你说说 InnoDB 脏页的控制策略，以及和这些策略相关的参数。\n首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：</p>\n<pre><code>fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n</code></pre>\n<p>其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就有开发同学找我看一个库的性能问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。\n他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看 InnoDB 怎么控制引擎按照“全力”的百分比来刷脏页。\n根据我前面提到的知识点，试想一下，如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。\n所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。\nInnoDB 会根据这两个因素先单独算出两个数字。\n参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：</p>\n<pre><code>F1(M)\n{\n  if M&gt;=innodb_max_dirty_pages_pct then\n      return 100;\n  return 100*M/innodb_max_dirty_pages_pct;\n}\n</code></pre>\n<p>InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。图中的 F1、F2 就是上面我们通过脏页比例和 redo log 写入速度算出来的两个值。</p>\n<p><img src=\"1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg\" alt=\"图 3 InnoDB 刷脏页速度策略\"></p>\n<p>现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。\n要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。\n其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';\nselect @a/@b;\n</code></pre>\n<p>接下来，我们再看一个有趣的策略。\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居（线上设置为0），自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。</p>\n<br>\n### 小结\n\n<p>今天这篇文章，延续MySQL日志系统：一条SQL更新语句是如何执行的？中介绍的 WAL 的概念，和你解释了这个机制后续需要的刷脏页操作和执行时机。\n利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。\n思考：当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？\n另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？\n答案：其实由于淘汰的时候，刷脏页过程不用动redo log文件的。这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。\n文章最后，我给你留下一个思考题吧。\n一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n要分业务场景来看</p>\n<ol>\n<li>如果业务以写为主或者读写流量差不多，因为读cache相对较大，我理解会频繁出现因日志写满，更新全部堵住，写性能跌为 0的情况</li>\n<li>如果以读为主，我理解redo_log本身设置小并没有明显的影响\n作者答案：每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。</li>\n</ol>\n<p><img src=\"1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>平时的工作中，不知道你有没有遇到过这样的场景，一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。\n看上去，这就像是数据库“抖”了一下。今天，我们就一起来看一看这是什么原因。</p>\n<br/>\n\n<h3 id=\"你的-SQL-语句为什么变“慢”了\"><a href=\"#你的-SQL-语句为什么变“慢”了\" class=\"headerlink\" title=\"你的 SQL 语句为什么变“慢”了\"></a>你的 SQL 语句为什么变“慢”了</h3><p>在MySQL日志系统：一条SQL更新语句是如何执行的？中，我为你介绍了 WAL 机制。现在你知道了，InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完 redo log 后，就返回给客户端，本次更新成功。\n做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。\n掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。在这个 flush 操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。\n当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。\n接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账 10 文，这次又要赊 9 文。</p>\n<p><img src=\"1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg\" alt=\"图 1 “孔乙己赊账”更新和 flush 过程\"></p>\n<p>回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</p>\n<br/>\n### 什么情况会引发数据库的 flush 过程呢？\n\n<p>我们还是继续用咸亨酒店掌柜的这个例子，想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？\n第一种场景是，粉板满了，记不下了。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。\n这个场景，对应的就是 InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。我在第二讲画了一个 redo log 的示意图，这里我改成环形，便于大家理解。</p>\n<p><img src=\"1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg\" alt=\"图 2 redo log 状态图\"></p>\n<p>checkpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。\n第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。\n这种场景，对应的就是系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\n你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿 redo log 出来应用不就行了？这里其实是从（读）性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p>\n<ol>\n<li>内存里存在，内存里就肯定是正确的结果，直接返回；</li>\n<li>内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。\n这样的效率最高。\n第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。\n这种场景，对应的就是 MySQL 认为系统“空闲”的时候。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。\n第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。\n这种场景，对应的就是 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n接下来，你可以分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</li>\n<li>还没有使用的；</li>\n<li>使用了并且是干净页；</li>\n<li>使用了并且是脏页；</li>\n</ol>\n<p>InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：</p>\n<ol>\n<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；</li>\n<li>日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</li>\n</ol>\n<br/>\n\n<h3 id=\"InnoDB-刷脏页的控制策略\"><a href=\"#InnoDB-刷脏页的控制策略\" class=\"headerlink\" title=\"InnoDB 刷脏页的控制策略\"></a>InnoDB 刷脏页的控制策略</h3><p>接下来，我就来和你说说 InnoDB 脏页的控制策略，以及和这些策略相关的参数。\n首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：</p>\n<pre><code>fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n</code></pre>\n<p>其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。之前，就有开发同学找我看一个库的性能问题，说 MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。\n他的主机磁盘用的是 SSD，但是 innodb_io_capacity 的值设置的是 300。于是，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。\n虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看 InnoDB 怎么控制引擎按照“全力”的百分比来刷脏页。\n根据我前面提到的知识点，试想一下，如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？这个问题可以这么想，如果刷太慢，会出现什么情况？首先是内存脏页太多，其次是 redo log 写满。\n所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。\nInnoDB 会根据这两个因素先单独算出两个数字。\n参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样：</p>\n<pre><code>F1(M)\n&#123;\n  if M&gt;=innodb_max_dirty_pages_pct then\n      return 100;\n  return 100*M/innodb_max_dirty_pages_pct;\n&#125;\n</code></pre>\n<p>InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n上述的计算流程比较抽象，不容易理解，所以我画了一个简单的流程图。图中的 F1、F2 就是上面我们通过脏页比例和 redo log 写入速度算出来的两个值。</p>\n<p><img src=\"1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg\" alt=\"图 3 InnoDB 刷脏页速度策略\"></p>\n<p>现在你知道了，InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。\n要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。\n其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：</p>\n<pre><code class=\"SQL\">mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_dirty&#39;;\nselect VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_total&#39;;\nselect @a/@b;\n</code></pre>\n<p>接下来，我们再看一个有趣的策略。\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居（线上设置为0），自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。</p>\n<br/>\n### 小结\n\n<p>今天这篇文章，延续MySQL日志系统：一条SQL更新语句是如何执行的？中介绍的 WAL 的概念，和你解释了这个机制后续需要的刷脏页操作和执行时机。\n利用 WAL 技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。脏页会被后台线程自动 flush，也会由于数据页淘汰而触发 flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。在文章里，我也给你介绍了控制刷脏页的方法和对应的监控方式。\n思考：当内存不够用了，要将脏页写到磁盘，会有一个数据页淘汰机制（最久不使用），假设淘汰的是脏页，则此时脏页所对应的redo log的位置是随机的，当有多个不同的脏页需要刷，则对应的redo log可能在不同的位置，这样就需要把redo log的多个不同位置刷掉，这样对于redo log的处理不是就会很麻烦吗？\n另外，redo log的优势在于将磁盘随机写转换成了顺序写，如果需要将redo log的不同部分刷掉（刷脏页），不是就在redo log里随机读写了么？\n答案：其实由于淘汰的时候，刷脏页过程不用动redo log文件的。这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。\n文章最后，我给你留下一个思考题吧。\n一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n要分业务场景来看</p>\n<ol>\n<li>如果业务以写为主或者读写流量差不多，因为读cache相对较大，我理解会频繁出现因日志写满，更新全部堵住，写性能跌为 0的情况</li>\n<li>如果以读为主，我理解redo_log本身设置小并没有明显的影响\n作者答案：每次事务提交都要写 redo log，如果设置太小，很快就会被写满，也就是下面这个图的状态，这个“环”将很快被写满，write pos 一直追着 CP。</li>\n</ol>\n<p><img src=\"1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png\"></p>\n"},{"title":"15 | 答疑文章（一）：日志和索引相关问题","date":"2019-06-02T16:00:00.000Z","_content":"在浏览这些留言并回复的过程中，我倍受鼓舞，也尽我所知地帮助你解决问题、和你讨论。可以说，你们的留言活跃了整个专栏的氛围、提升了整个专栏的质量，谢谢你们。评论区的大多数的留言我都直接回复了，对于需要展开说明的问题，我都拿出小本子记了下来。这些被记下来的问题，就是我们今天这篇答疑文章的素材了。\n到目前为止，我已经收集了 47 个问题，很难通过今天这一篇文章全部展开。所以，我就先从中找了几个联系非常紧密的问题，串了起来，希望可以帮你解决关于日志和索引的一些疑惑。而其他问题，我们就留着后面慢慢展开吧。\n\n<br/>\n### 日志相关问题\n\n我在第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中，和你讲到 binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。\n在这篇文章下面，很多同学在问，在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？\n现在，我们就从这个问题开始吧。我再放一次两阶段提交的图，方便你学习下面的内容。\n\n![图 1 两阶段提交示意图](1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg)\n\n这里，我要先和你解释一个误会式的问题。有同学在评论区问到，这个图不是一个 update 语句的执行流程吗，怎么还会调用 commit 语句？\n他产生这个疑问的原因，是把两个“commit”的概念混淆了：他说的“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟 begin/start transaction 配对使用。\n而我们图中用到的这个“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。\n“commit 语句”执行的时候，会包含“commit 步骤”。\n而我们这个例子里面，没有显式地开启事务，因此这个 update 语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit 步骤“。\n接下来，我们就一起分析一下在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\n我们先来看一下崩溃恢复时的判断规则。\n1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；\n2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：\na. 如果是，则提交事务；\nb. 否则，回滚事务。\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n现在，我们继续延展一下这个问题。\n\n<br/>\n\n#### 追问 1：MySQL 怎么知道 binlog 是完整的?\n\n回答：一个事务的 binlog 是有完整格式的：\n• statement 格式的 binlog，最后会有 COMMIT；\n• row 格式的 binlog，最后会有一个 XID event。\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。\n\n#### 追问 2：redo log 和 binlog 是怎么关联起来的?\n\n回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n\n1. 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交\n2. 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n#### 追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\n\n回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n\n\n#### 追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\n\n回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。\n如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。\n两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。\n\n#### 追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\n\n回答：这位同学的意思是，只保留 binlog，然后可以把提交流程改成这样：… -> “数据更新到内存” -> “写 binlog” -> “提交事务”，是不是也可以提供崩溃恢复的能力？\n答案是不可以。\n如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。\n1. InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。\n2. InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。\n而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。\n\n![图 2 只用 binlog 支持崩溃恢复](1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg)\n\n这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。\n如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。\n重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。\n但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。\n也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。\n所以，至少现在的 binlog 能力，还不能支持崩溃恢复。\n\n#### 追问 6：那能不能反过来，只用 redo log，不要 binlog？\n\n回答：如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。\n1. 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。\n2. 一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。\n3. 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。\n\n#### 追问 7：redo log 一般设置多大？\n\n回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。\n所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。\n\n#### 追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？\n\n回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。\n实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。\n在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。\n\n#### 追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\n\n回答：这两个问题可以一起回答。\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：\n\n```SQL\nbegin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n```\n\n这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n以上这些问题，就是把大家提过的关于 redo log 和 binlog 的问题串起来，做的一次集中回答。如果你还有问题，可以在评论区继续留言补充。\n\n### 业务设计问题\n\n接下来，我再和你分享 @ithunter 同学在第 8 篇文章《事务到底是隔离的还是不隔离的？》的评论区提到的跟索引相关的一个问题。我觉得这个问题挺有趣、也挺实用的，其他同学也可能会碰上这样的场景，在这里解答和分享一下。\n问题：业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：\n\n#### 以 A 关注 B 为例：\n\n• 第一步，先查询对方有没有关注自己（B 有没有关注 A）\n\n```SQL\nselect * from like where user_id = B and liker_id = A;\n```\n\n• 如果有，则成为好友\n```SQL\ninsert into friend;\n```\n\n• 没有，则只是单向关注关系\n```SQL\ninsert into like;\n```\n但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n接下来，我把 @ithunter 同学说的表模拟出来，方便我们讨论。\n\n```SQL\nCREATE TABLE `like` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `user_id` int(11) NOT NULL,\n  `liker_id` int(11) NOT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)\n) ENGINE=InnoDB;\n \nCREATE TABLE `friend` (\n  id` int(11) NOT NULL AUTO_INCREMENT,\n  `friend_1_id` int(11) NOT NULL,\n  `firned_2_id` int(11) NOT NULL,\n  UNIQUE KEY `uk_friend` (`friend_1_id`,`firned_2_id`)\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n```\n\n虽然这个题干中，并没有说到 friend 表的索引结构。但我猜测 friend_1_id 和 friend_2_id 也有索引，为便于描述，我给加上唯一索引。\n顺便说明一下，“like”是关键字，我一般不建议使用关键字作为库名、表名、字段名或索引名。\n我把他的疑问翻译一下，在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。\n现在，我用你已经熟悉的时刻顺序表的形式，把这两个事务的执行语句列出来：\n\n![图 3 并发“喜欢”逻辑操作顺序](1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg)\n\n由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。\n因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。如提问里面说的，“第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。不过，我想到了另外一个方法，来解决这个问题。\n首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。\n1. 值是 1 的时候，表示 user_id 关注 liker_id;\n2. 值是 2 的时候，表示 liker_id 关注 user_id;\n3. 值是 3 的时候，表示互相关注。\n然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：\n应用代码里面，比较 A 和 B 的大小\n•  如果 A < B，就执行下面的逻辑\n\n```SQL\nmysql> begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;\nselect relation_ship from `like` where user_id=A and liker_id=B;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n  */\ninsert ignore into friend(friend_1_id, friend_2_id) values(A,B);\ncommit;\n```\n\n• 如果 A>B，则执行下面的逻辑\nmysql> begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;\nselect relation_ship from `like` where user_id=B and liker_id=A;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n*/\ninsert ignore into friend(friend_1_id, friend_2_id) values(B,A);\ncommit;\n这个设计里，让“like”表里的数据保证 user_id < liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。\n然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。\n操作符 “|” 是逻辑或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。\n这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。\n而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。\n\n### 小结\n\n我针对前 14 篇文章，大家在评论区中的留言，从中摘取了关于日志和索引的相关问题，串成了今天这篇文章。这里我也要再和你说一声，有些我答应在答疑文章中进行扩展的话题，今天这篇文章没来得及扩展，后续我会再找机会为你解答的。所以，篇幅所限，评论区见吧。\n最后，虽然这篇是答疑文章，但课后问题还是要有的。\n我们创建了一个简单的表 t，并插入一行，然后对这一行做修改。\n\n```SQL\nmysql> CREATE TABLE `t` (\n`id` int(11) NOT NULL primary key auto_increment,\n`a` int(11) DEFAULT NULL\n) ENGINE=InnoDB;\ninsert into t values(1,2);\n```\n\n这时候，表 t 里有唯一的一行数据 (1,2)。假设，我现在要执行：\n\n```\nmysql> update t set a=2 where id=1;\n```\n\n你会看到这样的结果：\n\n![](1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg)\n\n结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。\n仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：\n1. 更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；\n2. MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；\n3. InnoDB 认真执行了“把这个值修改成 (1,2)\"这个操作，该加锁的加锁，该更新的更新。\n你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步的，可以思考一下，MySQL 为什么要选择这种策略呢？\n第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。\n假设，当前表 t 里的值是 (1,2)。\n\n![图 12 锁验证方式](1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg)\n\nsession B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。\n假设当前表里的值是 (1,2)。\n\n![图 13 可见性验证方式](1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg)\n\nsession A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。（如果你对这个逻辑有疑惑的话，可以回顾下第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）\n所以，我们上期思考题的答案应该是选项 3，即：InnoDB 认真执行了“把这个值修改成 (1,2)\"这个操作，该加锁的加锁，该更新的更新。\n然后你会说，MySQL 怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？\n其实 MySQL 是确认了的。只是在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改”的。\n作为验证，你可以看一下下面这个例子。\n\n![图 14 可见性验证方式 -- 对照](1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg)\n\n评论区留言点赞板：\n@郭江伟 同学提到了两个点，都非常好，有去实际验证。结论是这样的\n第一，hexdump 看出来没改应该是 WAL 机制生效了，要过一会儿，或者把库 shutdown 看看。\n第二，binlog 没写是 MySQL Server 层知道行的值没变，所以故意不写的，这个是在 row 格式下的策略。你可以把 binlog_format 改成 statement 再验证下。\n@mahonebags 同学提到了 timestamp 字段的问题，打中了我的知识盲点。今天现翻代码才补上了，多谢啦。结论是：如果表中有 timestamp 字段而且设置了自动更新，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，发现不需要修改。这个点我会在后面讲更新性能的文章中再展开。\n","source":"_posts/15-答疑文章（一）：日志和索引相关问题.md","raw":"---\ntitle: 15 | 答疑文章（一）：日志和索引相关问题\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在浏览这些留言并回复的过程中，我倍受鼓舞，也尽我所知地帮助你解决问题、和你讨论。可以说，你们的留言活跃了整个专栏的氛围、提升了整个专栏的质量，谢谢你们。评论区的大多数的留言我都直接回复了，对于需要展开说明的问题，我都拿出小本子记了下来。这些被记下来的问题，就是我们今天这篇答疑文章的素材了。\n到目前为止，我已经收集了 47 个问题，很难通过今天这一篇文章全部展开。所以，我就先从中找了几个联系非常紧密的问题，串了起来，希望可以帮你解决关于日志和索引的一些疑惑。而其他问题，我们就留着后面慢慢展开吧。\n\n<br/>\n### 日志相关问题\n\n我在第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中，和你讲到 binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。\n在这篇文章下面，很多同学在问，在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？\n现在，我们就从这个问题开始吧。我再放一次两阶段提交的图，方便你学习下面的内容。\n\n![图 1 两阶段提交示意图](1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg)\n\n这里，我要先和你解释一个误会式的问题。有同学在评论区问到，这个图不是一个 update 语句的执行流程吗，怎么还会调用 commit 语句？\n他产生这个疑问的原因，是把两个“commit”的概念混淆了：他说的“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟 begin/start transaction 配对使用。\n而我们图中用到的这个“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。\n“commit 语句”执行的时候，会包含“commit 步骤”。\n而我们这个例子里面，没有显式地开启事务，因此这个 update 语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit 步骤“。\n接下来，我们就一起分析一下在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\n我们先来看一下崩溃恢复时的判断规则。\n1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；\n2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：\na. 如果是，则提交事务；\nb. 否则，回滚事务。\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n现在，我们继续延展一下这个问题。\n\n<br/>\n\n#### 追问 1：MySQL 怎么知道 binlog 是完整的?\n\n回答：一个事务的 binlog 是有完整格式的：\n• statement 格式的 binlog，最后会有 COMMIT；\n• row 格式的 binlog，最后会有一个 XID event。\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。\n\n#### 追问 2：redo log 和 binlog 是怎么关联起来的?\n\n回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n\n1. 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交\n2. 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n#### 追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\n\n回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n\n\n#### 追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\n\n回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。\n如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。\n两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。\n\n#### 追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\n\n回答：这位同学的意思是，只保留 binlog，然后可以把提交流程改成这样：… -> “数据更新到内存” -> “写 binlog” -> “提交事务”，是不是也可以提供崩溃恢复的能力？\n答案是不可以。\n如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。\n1. InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。\n2. InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。\n而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。\n\n![图 2 只用 binlog 支持崩溃恢复](1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg)\n\n这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。\n如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。\n重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。\n但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。\n也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。\n所以，至少现在的 binlog 能力，还不能支持崩溃恢复。\n\n#### 追问 6：那能不能反过来，只用 redo log，不要 binlog？\n\n回答：如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。\n1. 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。\n2. 一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。\n3. 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。\n\n#### 追问 7：redo log 一般设置多大？\n\n回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。\n所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。\n\n#### 追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？\n\n回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。\n实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。\n在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。\n\n#### 追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\n\n回答：这两个问题可以一起回答。\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：\n\n```SQL\nbegin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n```\n\n这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n以上这些问题，就是把大家提过的关于 redo log 和 binlog 的问题串起来，做的一次集中回答。如果你还有问题，可以在评论区继续留言补充。\n\n### 业务设计问题\n\n接下来，我再和你分享 @ithunter 同学在第 8 篇文章《事务到底是隔离的还是不隔离的？》的评论区提到的跟索引相关的一个问题。我觉得这个问题挺有趣、也挺实用的，其他同学也可能会碰上这样的场景，在这里解答和分享一下。\n问题：业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：\n\n#### 以 A 关注 B 为例：\n\n• 第一步，先查询对方有没有关注自己（B 有没有关注 A）\n\n```SQL\nselect * from like where user_id = B and liker_id = A;\n```\n\n• 如果有，则成为好友\n```SQL\ninsert into friend;\n```\n\n• 没有，则只是单向关注关系\n```SQL\ninsert into like;\n```\n但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n接下来，我把 @ithunter 同学说的表模拟出来，方便我们讨论。\n\n```SQL\nCREATE TABLE `like` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `user_id` int(11) NOT NULL,\n  `liker_id` int(11) NOT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)\n) ENGINE=InnoDB;\n \nCREATE TABLE `friend` (\n  id` int(11) NOT NULL AUTO_INCREMENT,\n  `friend_1_id` int(11) NOT NULL,\n  `firned_2_id` int(11) NOT NULL,\n  UNIQUE KEY `uk_friend` (`friend_1_id`,`firned_2_id`)\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n```\n\n虽然这个题干中，并没有说到 friend 表的索引结构。但我猜测 friend_1_id 和 friend_2_id 也有索引，为便于描述，我给加上唯一索引。\n顺便说明一下，“like”是关键字，我一般不建议使用关键字作为库名、表名、字段名或索引名。\n我把他的疑问翻译一下，在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。\n现在，我用你已经熟悉的时刻顺序表的形式，把这两个事务的执行语句列出来：\n\n![图 3 并发“喜欢”逻辑操作顺序](1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg)\n\n由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。\n因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。如提问里面说的，“第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。不过，我想到了另外一个方法，来解决这个问题。\n首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。\n1. 值是 1 的时候，表示 user_id 关注 liker_id;\n2. 值是 2 的时候，表示 liker_id 关注 user_id;\n3. 值是 3 的时候，表示互相关注。\n然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：\n应用代码里面，比较 A 和 B 的大小\n•  如果 A < B，就执行下面的逻辑\n\n```SQL\nmysql> begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;\nselect relation_ship from `like` where user_id=A and liker_id=B;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n  */\ninsert ignore into friend(friend_1_id, friend_2_id) values(A,B);\ncommit;\n```\n\n• 如果 A>B，则执行下面的逻辑\nmysql> begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;\nselect relation_ship from `like` where user_id=B and liker_id=A;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n*/\ninsert ignore into friend(friend_1_id, friend_2_id) values(B,A);\ncommit;\n这个设计里，让“like”表里的数据保证 user_id < liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。\n然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。\n操作符 “|” 是逻辑或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。\n这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。\n而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。\n\n### 小结\n\n我针对前 14 篇文章，大家在评论区中的留言，从中摘取了关于日志和索引的相关问题，串成了今天这篇文章。这里我也要再和你说一声，有些我答应在答疑文章中进行扩展的话题，今天这篇文章没来得及扩展，后续我会再找机会为你解答的。所以，篇幅所限，评论区见吧。\n最后，虽然这篇是答疑文章，但课后问题还是要有的。\n我们创建了一个简单的表 t，并插入一行，然后对这一行做修改。\n\n```SQL\nmysql> CREATE TABLE `t` (\n`id` int(11) NOT NULL primary key auto_increment,\n`a` int(11) DEFAULT NULL\n) ENGINE=InnoDB;\ninsert into t values(1,2);\n```\n\n这时候，表 t 里有唯一的一行数据 (1,2)。假设，我现在要执行：\n\n```\nmysql> update t set a=2 where id=1;\n```\n\n你会看到这样的结果：\n\n![](1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg)\n\n结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。\n仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：\n1. 更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；\n2. MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；\n3. InnoDB 认真执行了“把这个值修改成 (1,2)\"这个操作，该加锁的加锁，该更新的更新。\n你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步的，可以思考一下，MySQL 为什么要选择这种策略呢？\n第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。\n假设，当前表 t 里的值是 (1,2)。\n\n![图 12 锁验证方式](1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg)\n\nsession B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。\n假设当前表里的值是 (1,2)。\n\n![图 13 可见性验证方式](1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg)\n\nsession A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。（如果你对这个逻辑有疑惑的话，可以回顾下第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）\n所以，我们上期思考题的答案应该是选项 3，即：InnoDB 认真执行了“把这个值修改成 (1,2)\"这个操作，该加锁的加锁，该更新的更新。\n然后你会说，MySQL 怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？\n其实 MySQL 是确认了的。只是在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改”的。\n作为验证，你可以看一下下面这个例子。\n\n![图 14 可见性验证方式 -- 对照](1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg)\n\n评论区留言点赞板：\n@郭江伟 同学提到了两个点，都非常好，有去实际验证。结论是这样的\n第一，hexdump 看出来没改应该是 WAL 机制生效了，要过一会儿，或者把库 shutdown 看看。\n第二，binlog 没写是 MySQL Server 层知道行的值没变，所以故意不写的，这个是在 row 格式下的策略。你可以把 binlog_format 改成 statement 再验证下。\n@mahonebags 同学提到了 timestamp 字段的问题，打中了我的知识盲点。今天现翻代码才补上了，多谢啦。结论是：如果表中有 timestamp 字段而且设置了自动更新，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，发现不需要修改。这个点我会在后面讲更新性能的文章中再展开。\n","slug":"15-答疑文章（一）：日志和索引相关问题","published":1,"updated":"2021-06-30T02:33:24.605Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsve0017r5p7b1fh223f","content":"<p>在浏览这些留言并回复的过程中，我倍受鼓舞，也尽我所知地帮助你解决问题、和你讨论。可以说，你们的留言活跃了整个专栏的氛围、提升了整个专栏的质量，谢谢你们。评论区的大多数的留言我都直接回复了，对于需要展开说明的问题，我都拿出小本子记了下来。这些被记下来的问题，就是我们今天这篇答疑文章的素材了。\n到目前为止，我已经收集了 47 个问题，很难通过今天这一篇文章全部展开。所以，我就先从中找了几个联系非常紧密的问题，串了起来，希望可以帮你解决关于日志和索引的一些疑惑。而其他问题，我们就留着后面慢慢展开吧。</p>\n<br>\n### 日志相关问题\n\n<p>我在第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中，和你讲到 binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。\n在这篇文章下面，很多同学在问，在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？\n现在，我们就从这个问题开始吧。我再放一次两阶段提交的图，方便你学习下面的内容。</p>\n<p><img src=\"1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg\" alt=\"图 1 两阶段提交示意图\"></p>\n<p>这里，我要先和你解释一个误会式的问题。有同学在评论区问到，这个图不是一个 update 语句的执行流程吗，怎么还会调用 commit 语句？\n他产生这个疑问的原因，是把两个“commit”的概念混淆了：他说的“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟 begin/start transaction 配对使用。\n而我们图中用到的这个“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。\n“commit 语句”执行的时候，会包含“commit 步骤”。\n而我们这个例子里面，没有显式地开启事务，因此这个 update 语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit 步骤“。\n接下来，我们就一起分析一下在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\n我们先来看一下崩溃恢复时的判断规则。</p>\n<ol>\n<li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li>\n<li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：\na. 如果是，则提交事务；\nb. 否则，回滚事务。\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n现在，我们继续延展一下这个问题。</li>\n</ol>\n<br>\n\n<h4 id=\"追问-1：MySQL-怎么知道-binlog-是完整的\"><a href=\"#追问-1：MySQL-怎么知道-binlog-是完整的\" class=\"headerlink\" title=\"追问 1：MySQL 怎么知道 binlog 是完整的?\"></a>追问 1：MySQL 怎么知道 binlog 是完整的?</h4><p>回答：一个事务的 binlog 是有完整格式的：\n• statement 格式的 binlog，最后会有 COMMIT；\n• row 格式的 binlog，最后会有一个 XID event。\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。</p>\n<h4 id=\"追问-2：redo-log-和-binlog-是怎么关联起来的\"><a href=\"#追问-2：redo-log-和-binlog-是怎么关联起来的\" class=\"headerlink\" title=\"追问 2：redo log 和 binlog 是怎么关联起来的?\"></a>追问 2：redo log 和 binlog 是怎么关联起来的?</h4><p>回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：</p>\n<ol>\n<li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交</li>\n<li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。</li>\n</ol>\n<h4 id=\"追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计\"><a href=\"#追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计\" class=\"headerlink\" title=\"追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\"></a>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</h4><p>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p>\n<h4 id=\"追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\"><a href=\"#追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\" class=\"headerlink\" title=\"追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\"></a>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</h4><p>回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。\n如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。\n两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。</p>\n<h4 id=\"追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？\"><a href=\"#追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？\" class=\"headerlink\" title=\"追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\"></a>追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？</h4><p>回答：这位同学的意思是，只保留 binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt; “提交事务”，是不是也可以提供崩溃恢复的能力？\n答案是不可以。\n如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。</p>\n<ol>\n<li>InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。</li>\n<li>InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。\n而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。</li>\n</ol>\n<p><img src=\"1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg\" alt=\"图 2 只用 binlog 支持崩溃恢复\"></p>\n<p>这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。\n如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。\n重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。\n但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。\n也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。\n所以，至少现在的 binlog 能力，还不能支持崩溃恢复。</p>\n<h4 id=\"追问-6：那能不能反过来，只用-redo-log，不要-binlog？\"><a href=\"#追问-6：那能不能反过来，只用-redo-log，不要-binlog？\" class=\"headerlink\" title=\"追问 6：那能不能反过来，只用 redo log，不要 binlog？\"></a>追问 6：那能不能反过来，只用 redo log，不要 binlog？</h4><p>回答：如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。</p>\n<ol>\n<li>一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。</li>\n<li>一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。</li>\n<li>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。</li>\n</ol>\n<h4 id=\"追问-7：redo-log-一般设置多大？\"><a href=\"#追问-7：redo-log-一般设置多大？\" class=\"headerlink\" title=\"追问 7：redo log 一般设置多大？\"></a>追问 7：redo log 一般设置多大？</h4><p>回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。\n所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。</p>\n<h4 id=\"追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？\"><a href=\"#追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？\" class=\"headerlink\" title=\"追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？\"></a>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</h4><p>回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。\n实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。\n在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。</p>\n<h4 id=\"追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？\"><a href=\"#追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？\" class=\"headerlink\" title=\"追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\"></a>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？</h4><p>回答：这两个问题可以一起回答。\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">begin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n</code></pre>\n<p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n以上这些问题，就是把大家提过的关于 redo log 和 binlog 的问题串起来，做的一次集中回答。如果你还有问题，可以在评论区继续留言补充。</p>\n<h3 id=\"业务设计问题\"><a href=\"#业务设计问题\" class=\"headerlink\" title=\"业务设计问题\"></a>业务设计问题</h3><p>接下来，我再和你分享 @ithunter 同学在第 8 篇文章《事务到底是隔离的还是不隔离的？》的评论区提到的跟索引相关的一个问题。我觉得这个问题挺有趣、也挺实用的，其他同学也可能会碰上这样的场景，在这里解答和分享一下。\n问题：业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：</p>\n<h4 id=\"以-A-关注-B-为例：\"><a href=\"#以-A-关注-B-为例：\" class=\"headerlink\" title=\"以 A 关注 B 为例：\"></a>以 A 关注 B 为例：</h4><p>• 第一步，先查询对方有没有关注自己（B 有没有关注 A）</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select * from like where user_id = B and liker_id = A;\n</code></pre>\n<p>• 如果有，则成为好友</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">insert into friend;\n</code></pre>\n<p>• 没有，则只是单向关注关系</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">insert into like;\n</code></pre>\n<p>但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n接下来，我把 @ithunter 同学说的表模拟出来，方便我们讨论。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `like` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `user_id` int(11) NOT NULL,\n  `liker_id` int(11) NOT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)\n) ENGINE=InnoDB;\n \nCREATE TABLE `friend` (\n  id` int(11) NOT NULL AUTO_INCREMENT,\n  `friend_1_id` int(11) NOT NULL,\n  `firned_2_id` int(11) NOT NULL,\n  UNIQUE KEY `uk_friend` (`friend_1_id`,`firned_2_id`)\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>虽然这个题干中，并没有说到 friend 表的索引结构。但我猜测 friend_1_id 和 friend_2_id 也有索引，为便于描述，我给加上唯一索引。\n顺便说明一下，“like”是关键字，我一般不建议使用关键字作为库名、表名、字段名或索引名。\n我把他的疑问翻译一下，在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。\n现在，我用你已经熟悉的时刻顺序表的形式，把这两个事务的执行语句列出来：</p>\n<p><img src=\"1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg\" alt=\"图 3 并发“喜欢”逻辑操作顺序\"></p>\n<p>由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。\n因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。如提问里面说的，“第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。不过，我想到了另外一个方法，来解决这个问题。\n首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。</p>\n<ol>\n<li>值是 1 的时候，表示 user_id 关注 liker_id;</li>\n<li>值是 2 的时候，表示 liker_id 关注 user_id;</li>\n<li>值是 3 的时候，表示互相关注。\n然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：\n应用代码里面，比较 A 和 B 的大小\n•  如果 A &lt; B，就执行下面的逻辑</li>\n</ol>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;\nselect relation_ship from `like` where user_id=A and liker_id=B;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n  */\ninsert ignore into friend(friend_1_id, friend_2_id) values(A,B);\ncommit;\n</code></pre>\n<p>• 如果 A&gt;B，则执行下面的逻辑\nmysql&gt; begin; /* 启动事务 <em>/\ninsert into <code>like</code>(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;\nselect relation_ship from <code>like</code> where user_id=B and liker_id=A;\n/</em> 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n*/\ninsert ignore into friend(friend_1_id, friend_2_id) values(B,A);\ncommit;\n这个设计里，让“like”表里的数据保证 user_id &lt; liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。\n然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。\n操作符 “|” 是逻辑或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。\n这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。\n而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>我针对前 14 篇文章，大家在评论区中的留言，从中摘取了关于日志和索引的相关问题，串成了今天这篇文章。这里我也要再和你说一声，有些我答应在答疑文章中进行扩展的话题，今天这篇文章没来得及扩展，后续我会再找机会为你解答的。所以，篇幅所限，评论区见吧。\n最后，虽然这篇是答疑文章，但课后问题还是要有的。\n我们创建了一个简单的表 t，并插入一行，然后对这一行做修改。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `t` (\n`id` int(11) NOT NULL primary key auto_increment,\n`a` int(11) DEFAULT NULL\n) ENGINE=InnoDB;\ninsert into t values(1,2);\n</code></pre>\n<p>这时候，表 t 里有唯一的一行数据 (1,2)。假设，我现在要执行：</p>\n<pre><code>mysql&gt; update t set a=2 where id=1;\n</code></pre>\n<p>你会看到这样的结果：</p>\n<p><img src=\"1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg\"></p>\n<p>结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。\n仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：</p>\n<ol>\n<li>更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；</li>\n<li>MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；</li>\n<li>InnoDB 认真执行了“把这个值修改成 (1,2)”这个操作，该加锁的加锁，该更新的更新。\n你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步的，可以思考一下，MySQL 为什么要选择这种策略呢？\n第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。\n假设，当前表 t 里的值是 (1,2)。</li>\n</ol>\n<p><img src=\"1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg\" alt=\"图 12 锁验证方式\"></p>\n<p>session B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。\n假设当前表里的值是 (1,2)。</p>\n<p><img src=\"1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg\" alt=\"图 13 可见性验证方式\"></p>\n<p>session A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。（如果你对这个逻辑有疑惑的话，可以回顾下第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）\n所以，我们上期思考题的答案应该是选项 3，即：InnoDB 认真执行了“把这个值修改成 (1,2)”这个操作，该加锁的加锁，该更新的更新。\n然后你会说，MySQL 怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？\n其实 MySQL 是确认了的。只是在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改”的。\n作为验证，你可以看一下下面这个例子。</p>\n<p><img src=\"1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg\" alt=\"图 14 可见性验证方式 -- 对照\"></p>\n<p>评论区留言点赞板：\n@郭江伟 同学提到了两个点，都非常好，有去实际验证。结论是这样的\n第一，hexdump 看出来没改应该是 WAL 机制生效了，要过一会儿，或者把库 shutdown 看看。\n第二，binlog 没写是 MySQL Server 层知道行的值没变，所以故意不写的，这个是在 row 格式下的策略。你可以把 binlog_format 改成 statement 再验证下。\n@mahonebags 同学提到了 timestamp 字段的问题，打中了我的知识盲点。今天现翻代码才补上了，多谢啦。结论是：如果表中有 timestamp 字段而且设置了自动更新，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，发现不需要修改。这个点我会在后面讲更新性能的文章中再展开。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在浏览这些留言并回复的过程中，我倍受鼓舞，也尽我所知地帮助你解决问题、和你讨论。可以说，你们的留言活跃了整个专栏的氛围、提升了整个专栏的质量，谢谢你们。评论区的大多数的留言我都直接回复了，对于需要展开说明的问题，我都拿出小本子记了下来。这些被记下来的问题，就是我们今天这篇答疑文章的素材了。\n到目前为止，我已经收集了 47 个问题，很难通过今天这一篇文章全部展开。所以，我就先从中找了几个联系非常紧密的问题，串了起来，希望可以帮你解决关于日志和索引的一些疑惑。而其他问题，我们就留着后面慢慢展开吧。</p>\n<br/>\n### 日志相关问题\n\n<p>我在第 2 篇文章《日志系统：一条 SQL 更新语句是如何执行的？》中，和你讲到 binlog（归档日志）和 redo log（重做日志）配合崩溃恢复的时候，用的是反证法，说明了如果没有两阶段提交，会导致 MySQL 出现主备数据不一致等问题。\n在这篇文章下面，很多同学在问，在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？\n现在，我们就从这个问题开始吧。我再放一次两阶段提交的图，方便你学习下面的内容。</p>\n<p><img src=\"1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg\" alt=\"图 1 两阶段提交示意图\"></p>\n<p>这里，我要先和你解释一个误会式的问题。有同学在评论区问到，这个图不是一个 update 语句的执行流程吗，怎么还会调用 commit 语句？\n他产生这个疑问的原因，是把两个“commit”的概念混淆了：他说的“commit 语句”，是指 MySQL 语法中，用于提交一个事务的命令。一般跟 begin/start transaction 配对使用。\n而我们图中用到的这个“commit 步骤”，指的是事务提交过程中的一个小步骤，也是最后一步。当这个步骤执行完成后，这个事务就提交完成了。\n“commit 语句”执行的时候，会包含“commit 步骤”。\n而我们这个例子里面，没有显式地开启事务，因此这个 update 语句自己就是一个事务，在执行完成后提交事务时，就会用到这个“commit 步骤“。\n接下来，我们就一起分析一下在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\n我们先来看一下崩溃恢复时的判断规则。</p>\n<ol>\n<li>如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；</li>\n<li>如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：\na. 如果是，则提交事务；\nb. 否则，回滚事务。\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n现在，我们继续延展一下这个问题。</li>\n</ol>\n<br/>\n\n<h4 id=\"追问-1：MySQL-怎么知道-binlog-是完整的\"><a href=\"#追问-1：MySQL-怎么知道-binlog-是完整的\" class=\"headerlink\" title=\"追问 1：MySQL 怎么知道 binlog 是完整的?\"></a>追问 1：MySQL 怎么知道 binlog 是完整的?</h4><p>回答：一个事务的 binlog 是有完整格式的：\n• statement 格式的 binlog，最后会有 COMMIT；\n• row 格式的 binlog，最后会有一个 XID event。\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。</p>\n<h4 id=\"追问-2：redo-log-和-binlog-是怎么关联起来的\"><a href=\"#追问-2：redo-log-和-binlog-是怎么关联起来的\" class=\"headerlink\" title=\"追问 2：redo log 和 binlog 是怎么关联起来的?\"></a>追问 2：redo log 和 binlog 是怎么关联起来的?</h4><p>回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：</p>\n<ol>\n<li>如果碰到既有 prepare、又有 commit 的 redo log，就直接提交</li>\n<li>如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。</li>\n</ol>\n<h4 id=\"追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计\"><a href=\"#追问-3：处于-prepare-阶段的-redo-log-加上完整-binlog，重启就能恢复，MySQL-为什么要这么设计\" class=\"headerlink\" title=\"追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\"></a>追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?</h4><p>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p>\n<h4 id=\"追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\"><a href=\"#追问-4：如果这样的话，为什么还要两阶段提交呢？干脆先-redo-log-写完，再写-binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\" class=\"headerlink\" title=\"追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\"></a>追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</h4><p>回答：其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。\n如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。\n两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。</p>\n<h4 id=\"追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？\"><a href=\"#追问-5：不引入两个日志，也就没有两阶段提交的必要了。只用-binlog-来支持崩溃恢复，又能支持归档，不就可以了？\" class=\"headerlink\" title=\"追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\"></a>追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？</h4><p>回答：这位同学的意思是，只保留 binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt; “提交事务”，是不是也可以提供崩溃恢复的能力？\n答案是不可以。\n如果说历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。</p>\n<ol>\n<li>InnoDB 在作为 MySQL 的插件加入 MySQL 引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。</li>\n<li>InnoDB 接入了 MySQL 后，发现既然 binlog 没有崩溃恢复的能力，那就用 InnoDB 原有的 redo log 好了。\n而如果说实现上的原因的话，就有很多了。就按照问题中说的，只用 binlog 来实现崩溃恢复的流程，我画了一张示意图，这里就没有 redo log 了。</li>\n</ol>\n<p><img src=\"1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg\" alt=\"图 2 只用 binlog 支持崩溃恢复\"></p>\n<p>这样的流程下，binlog 还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog 没有能力恢复“数据页”。\n如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。\n重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。\n但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。\n也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n你如果要说，那我优化一下 binlog 的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个 redo log 出来。\n所以，至少现在的 binlog 能力，还不能支持崩溃恢复。</p>\n<h4 id=\"追问-6：那能不能反过来，只用-redo-log，不要-binlog？\"><a href=\"#追问-6：那能不能反过来，只用-redo-log，不要-binlog？\" class=\"headerlink\" title=\"追问 6：那能不能反过来，只用 redo log，不要 binlog？\"></a>追问 6：那能不能反过来，只用 redo log，不要 binlog？</h4><p>回答：如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。</p>\n<ol>\n<li>一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。</li>\n<li>一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。</li>\n<li>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。</li>\n</ol>\n<h4 id=\"追问-7：redo-log-一般设置多大？\"><a href=\"#追问-7：redo-log-一般设置多大？\" class=\"headerlink\" title=\"追问 7：redo log 一般设置多大？\"></a>追问 7：redo log 一般设置多大？</h4><p>回答：redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。\n所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。</p>\n<h4 id=\"追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？\"><a href=\"#追问-8：正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的呢？\" class=\"headerlink\" title=\"追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？\"></a>追问 8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？</h4><p>回答：这个问题其实问得非常好。这里涉及到了，“redo log 里面到底是什么“的问题。\n实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。\n在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。</p>\n<h4 id=\"追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？\"><a href=\"#追问-9：redo-log-buffer-是什么？是先修改内存，还是先写-redo-log-文件？\" class=\"headerlink\" title=\"追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\"></a>追问 9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？</h4><p>回答：这两个问题可以一起回答。\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：</p>\n<pre><code class=\"SQL\">begin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n</code></pre>\n<p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n以上这些问题，就是把大家提过的关于 redo log 和 binlog 的问题串起来，做的一次集中回答。如果你还有问题，可以在评论区继续留言补充。</p>\n<h3 id=\"业务设计问题\"><a href=\"#业务设计问题\" class=\"headerlink\" title=\"业务设计问题\"></a>业务设计问题</h3><p>接下来，我再和你分享 @ithunter 同学在第 8 篇文章《事务到底是隔离的还是不隔离的？》的评论区提到的跟索引相关的一个问题。我觉得这个问题挺有趣、也挺实用的，其他同学也可能会碰上这样的场景，在这里解答和分享一下。\n问题：业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：</p>\n<h4 id=\"以-A-关注-B-为例：\"><a href=\"#以-A-关注-B-为例：\" class=\"headerlink\" title=\"以 A 关注 B 为例：\"></a>以 A 关注 B 为例：</h4><p>• 第一步，先查询对方有没有关注自己（B 有没有关注 A）</p>\n<pre><code class=\"SQL\">select * from like where user_id = B and liker_id = A;\n</code></pre>\n<p>• 如果有，则成为好友</p>\n<pre><code class=\"SQL\">insert into friend;\n</code></pre>\n<p>• 没有，则只是单向关注关系</p>\n<pre><code class=\"SQL\">insert into like;\n</code></pre>\n<p>但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n接下来，我把 @ithunter 同学说的表模拟出来，方便我们讨论。</p>\n<pre><code class=\"SQL\">CREATE TABLE `like` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `user_id` int(11) NOT NULL,\n  `liker_id` int(11) NOT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)\n) ENGINE=InnoDB;\n \nCREATE TABLE `friend` (\n  id` int(11) NOT NULL AUTO_INCREMENT,\n  `friend_1_id` int(11) NOT NULL,\n  `firned_2_id` int(11) NOT NULL,\n  UNIQUE KEY `uk_friend` (`friend_1_id`,`firned_2_id`)\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>虽然这个题干中，并没有说到 friend 表的索引结构。但我猜测 friend_1_id 和 friend_2_id 也有索引，为便于描述，我给加上唯一索引。\n顺便说明一下，“like”是关键字，我一般不建议使用关键字作为库名、表名、字段名或索引名。\n我把他的疑问翻译一下，在并发场景下，同时有两个人，设置为关注对方，就可能导致无法成功加为朋友关系。\n现在，我用你已经熟悉的时刻顺序表的形式，把这两个事务的执行语句列出来：</p>\n<p><img src=\"1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg\" alt=\"图 3 并发“喜欢”逻辑操作顺序\"></p>\n<p>由于一开始 A 和 B 之间没有关注关系，所以两个事务里面的 select 语句查出来的结果都是空。\n因此，session 1 的逻辑就是“既然 B 没有关注 A，那就只插入一个单向关注关系”。session 2 也同样是这个逻辑。这个结果对业务来说就是 bug 了。因为在业务设定里面，这两个逻辑都执行完成以后，是应该在 friend 表里面插入一行记录的。如提问里面说的，“第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效”。不过，我想到了另外一个方法，来解决这个问题。\n首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。</p>\n<ol>\n<li>值是 1 的时候，表示 user_id 关注 liker_id;</li>\n<li>值是 2 的时候，表示 liker_id 关注 user_id;</li>\n<li>值是 3 的时候，表示互相关注。\n然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：\n应用代码里面，比较 A 和 B 的大小\n•  如果 A &lt; B，就执行下面的逻辑</li>\n</ol>\n<pre><code class=\"SQL\">mysql&gt; begin; /* 启动事务 */\ninsert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;\nselect relation_ship from `like` where user_id=A and liker_id=B;\n/* 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n  */\ninsert ignore into friend(friend_1_id, friend_2_id) values(A,B);\ncommit;\n</code></pre>\n<p>• 如果 A&gt;B，则执行下面的逻辑\nmysql&gt; begin; /* 启动事务 <em>/\ninsert into <code>like</code>(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;\nselect relation_ship from <code>like</code> where user_id=B and liker_id=A;\n/</em> 代码中判断返回的 relation_ship，\n  如果是 1，事务结束，执行 commit\n  如果是 3，则执行下面这两个语句：\n*/\ninsert ignore into friend(friend_1_id, friend_2_id) values(B,A);\ncommit;\n这个设计里，让“like”表里的数据保证 user_id &lt; liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。\n然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。\n操作符 “|” 是逻辑或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。\n这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n不知道你会不会吐槽：之前明明还说尽量不要使用唯一索引，结果这个例子一上来我就创建了两个。这里我要再和你说明一下，之前文章我们讨论的，是在“业务开发保证不会插入重复记录”的情况下，着重要解决性能问题的时候，才建议尽量使用普通索引。\n而像这个例子里，按照这个设计，业务根本就是保证“我一定会插入重复数据，数据库一定要要有唯一性约束”，这时就没啥好说的了，唯一索引建起来吧。</p>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>我针对前 14 篇文章，大家在评论区中的留言，从中摘取了关于日志和索引的相关问题，串成了今天这篇文章。这里我也要再和你说一声，有些我答应在答疑文章中进行扩展的话题，今天这篇文章没来得及扩展，后续我会再找机会为你解答的。所以，篇幅所限，评论区见吧。\n最后，虽然这篇是答疑文章，但课后问题还是要有的。\n我们创建了一个简单的表 t，并插入一行，然后对这一行做修改。</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `t` (\n`id` int(11) NOT NULL primary key auto_increment,\n`a` int(11) DEFAULT NULL\n) ENGINE=InnoDB;\ninsert into t values(1,2);\n</code></pre>\n<p>这时候，表 t 里有唯一的一行数据 (1,2)。假设，我现在要执行：</p>\n<pre><code>mysql&gt; update t set a=2 where id=1;\n</code></pre>\n<p>你会看到这样的结果：</p>\n<p><img src=\"1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg\"></p>\n<p>结果显示，匹配 (rows matched) 了一行，修改 (Changed) 了 0 行。\n仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：</p>\n<ol>\n<li>更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；</li>\n<li>MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；</li>\n<li>InnoDB 认真执行了“把这个值修改成 (1,2)”这个操作，该加锁的加锁，该更新的更新。\n你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步的，可以思考一下，MySQL 为什么要选择这种策略呢？\n第一个选项是，MySQL 读出数据，发现值与原来相同，不更新，直接返回，执行结束。这里我们可以用一个锁实验来确认。\n假设，当前表 t 里的值是 (1,2)。</li>\n</ol>\n<p><img src=\"1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg\" alt=\"图 12 锁验证方式\"></p>\n<p>session B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n第二个选项是，MySQL 调用了 InnoDB 引擎提供的接口，但是引擎发现值与原来相同，不更新，直接返回。有没有这种可能呢？这里我用一个可见性实验来确认。\n假设当前表里的值是 (1,2)。</p>\n<p><img src=\"1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg\" alt=\"图 13 可见性验证方式\"></p>\n<p>session A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。（如果你对这个逻辑有疑惑的话，可以回顾下第 8 篇文章《事务到底是隔离的还是不隔离的？》中的相关内容）\n所以，我们上期思考题的答案应该是选项 3，即：InnoDB 认真执行了“把这个值修改成 (1,2)”这个操作，该加锁的加锁，该更新的更新。\n然后你会说，MySQL 怎么这么笨，就不会更新前判断一下值是不是相同吗？如果判断一下，不就不用浪费 InnoDB 操作，多去更新一次了？\n其实 MySQL 是确认了的。只是在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改”的。\n作为验证，你可以看一下下面这个例子。</p>\n<p><img src=\"1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg\" alt=\"图 14 可见性验证方式 -- 对照\"></p>\n<p>评论区留言点赞板：\n@郭江伟 同学提到了两个点，都非常好，有去实际验证。结论是这样的\n第一，hexdump 看出来没改应该是 WAL 机制生效了，要过一会儿，或者把库 shutdown 看看。\n第二，binlog 没写是 MySQL Server 层知道行的值没变，所以故意不写的，这个是在 row 格式下的策略。你可以把 binlog_format 改成 statement 再验证下。\n@mahonebags 同学提到了 timestamp 字段的问题，打中了我的知识盲点。今天现翻代码才补上了，多谢啦。结论是：如果表中有 timestamp 字段而且设置了自动更新，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，发现不需要修改。这个点我会在后面讲更新性能的文章中再展开。</p>\n"},{"title":"16 | “order by”是怎么工作的","date":"2019-06-02T16:00:00.000Z","_content":"在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。\n假设这个表的部分定义是这样的：\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB;\n```\n\n这时，你的 SQL 语句可以这么写：\n```SQL\nselect city,name,age from t where city='杭州' order by name limit 1000  ;\n```\n\n这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。\n\n<br/>\n### 全字段排序\n\n前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。\n在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。\n\n![图 1 使用 explain 命令查看语句的执行情况](1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg)\n\nExtra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。\n为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。\n\n![图 2 city 字段的索引示意图](1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg)\n\n从图中可以看到，满足 `city='杭州’`条件的行，是从 `ID_X` 到 `ID_(X+N)` 的这些记录。\n通常情况下，这个语句执行流程如下所示 ：\n\n- 初始化 `sort_buffer`，确定放入 `name`、`city`、`age` 这三个字段；\n- 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；\n- 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n- 从索引 city 取下一个记录的主键 id；\n- 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；\n- 对 sort_buffer 中的数据按照字段 name 做快速排序；\n- 按照排序结果取前 1000 行返回给客户端。\n\n我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。\n\n![图 3 全字段排序](1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg)\n\n图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\nsort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。\n```SQL\n/* 打开 optimizer_trace，只对本线程有效 */\nSET optimizer_trace='enabled=on'; \n \n/* @a 保存 Innodb_rows_read 的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 执行语句 */\nselect city, name,age from t where city='杭州' order by name limit 1000; \n \n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n \n/* @b 保存 Innodb_rows_read 的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 计算 Innodb_rows_read 差值 */\nselect @b-@a;\n```\n\n这个方法是通过查看 `OPTIMIZER_TRACE` 的结果来确认的，你可以从 `number_of_tmp_files` 中看到是否使用了临时文件。\n\n![图 4 全排序的 OPTIMIZER_TRACE 部分结果](1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg)\n\nnumber_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。\n如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。\n否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。\n接下来，我再和你解释一下图 4 中其他两个值的意思。\n我们的示例表中有 4000 条满足 city='杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。\nsort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。\n这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。\n这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。\n\n<br/>\n### rowid 排序\n\n在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n所以如果单行很大，这个方法效率不够好。\n那么，如果 MySQL 认为排序的单行长度太大会怎么做呢？\n接下来，我来修改一个参数，让 MySQL 采用另外一种算法。\n\n```SQL\nSET max_length_for_sort_data = 16;\n```\n\nmax_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：\n• 初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n• 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；\n• 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n• 从索引 city 取下一个记录的主键 id；\n• 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；\n• 对 sort_buffer 中的数据按照字段 name 进行排序；\n• 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n这个执行流程的示意图如下，我把它称为 rowid 排序。\n\n![图 5 rowid 排序](1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg)\n\n对比图 3 的全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。\n需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。\n根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？\n现在，我们就来看看结果有什么不同。\n首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。\n因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。\n\n![图 6 rowid 排序的 OPTIMIZER_TRACE 部分输出](1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg)\n\n从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。\nsort_mode 变成了 `<sort_key, rowid>`，表示参与排序的只有 name 和 id 这两个字段。\nnumber_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。\n\n<br/>\n### 全字段排序 VS rowid 排序\n\n我们来分析一下，从这两个执行流程里，还能得出什么结论。\n• 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n• 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。\n看到这里，你就了解了，MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。\n其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n你可以设想下，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？\n确实是这样的。\n所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n作为与 city 索引的对比，我们来看看这个索引的示意图。\n\n![图 7 city 和 name 联合索引示意图](1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg)\n\n在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city='杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n• 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；\n• 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n• 从索引 city 取下一个记录主键 id；\n• 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。\n\n![图 8 引入 (city,name) 联合索引后，查询语句的执行计划](1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg)\n\n可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。\n\n![图 9 引入 (city,name) 联合索引后，查询语句的执行计划](1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg)\n\n从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。\n既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。\n这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n• 从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n• 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n• 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。\n\n![图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程](1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg)\n\n然后，我们再来看看 explain 的结果。\n\n![图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划](1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg)\n\n可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。\n当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。\n\n<br/>\n### 小结\n\n今天这篇文章，我和你介绍了 MySQL 里面 order by 语句的几种算法流程。\n在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。\n问题：假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：\n\n```SQL\nmysql> select * from t where city in ('杭州',\" 苏州 \") order by name limit 100;\n```\n\n那么，这个语句执行的时候会有排序过程吗，为什么？\n• 如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n• 进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：\n1. 执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。\n2. 执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。\n3. 现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。\n如果把这条 SQL 语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写：\n\n```SQL\nselect * from t where city=\" 杭州 \" order by name limit 10100;\n```\n\n和\n\n```SQL\nselect * from t where city=\" 苏州 \" order by name limit 10100。\n```\n\n这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第 10001~10100 的 name 值，就是需要的结果了。\n当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。\n所以，如果数据的单行比较大的话，可以考虑把这两条 SQL 语句改成下面这种写法：\n\n```SQL\nselect id,name from t where city=\" 杭州 \" order by name limit 10100;\n```\n\n和\n\n```SQL\nselect id,name from t where city=\" 苏州 \" order by name limit 10100。\n```\n\n然后，再用归并排序的方法取得按 name 顺序第 10001~10100 的 name、id 的值，然后拿着这 100 个 id 到数据库中去查出所有记录。\n\n\n\n通过索引优化来实现MySQL的ORDER BY语句优化：\n1. ORDER BY的索引优化。如果一个SQL语句形如：\nSELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];\n在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。\n2. WHERE + ORDER BY的索引优化，形如：\nSELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];\n建立一个联合索引(columnX,sort)来实现order by 优化。\na. 注意：如果columnX对应多个值，如下面语句就无法利用索引来实现order by的优化\nb. SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…)     ORDER BY[sort];\n3. WHERE+ 多个字段ORDER BY\nSELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;\n建立索引(uid,x,y)实现order by的优化,比建立(x,y,uid)索引效果要好得多。\nMySQL Order By不能使用索引来优化排序的情况\n• 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)\nSELECT * FROM t1 ORDER BY key1, key2;\n• 在非连续的索引键部分上做 ORDER BY：(key_part1,key_part2建立联合索引;key2建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;\n• 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)\nSELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;\n• 用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key1;\n• 如果在WHERE和ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化\nSELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;\n特别提示:\n1. mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。\n2. 在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。","source":"_posts/16-“order-by”是怎么工作的.md","raw":"---\ntitle: 16 | “order by”是怎么工作的\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。\n假设这个表的部分定义是这样的：\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB;\n```\n\n这时，你的 SQL 语句可以这么写：\n```SQL\nselect city,name,age from t where city='杭州' order by name limit 1000  ;\n```\n\n这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。\n\n<br/>\n### 全字段排序\n\n前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。\n在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。\n\n![图 1 使用 explain 命令查看语句的执行情况](1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg)\n\nExtra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。\n为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。\n\n![图 2 city 字段的索引示意图](1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg)\n\n从图中可以看到，满足 `city='杭州’`条件的行，是从 `ID_X` 到 `ID_(X+N)` 的这些记录。\n通常情况下，这个语句执行流程如下所示 ：\n\n- 初始化 `sort_buffer`，确定放入 `name`、`city`、`age` 这三个字段；\n- 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；\n- 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n- 从索引 city 取下一个记录的主键 id；\n- 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；\n- 对 sort_buffer 中的数据按照字段 name 做快速排序；\n- 按照排序结果取前 1000 行返回给客户端。\n\n我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。\n\n![图 3 全字段排序](1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg)\n\n图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\nsort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。\n```SQL\n/* 打开 optimizer_trace，只对本线程有效 */\nSET optimizer_trace='enabled=on'; \n \n/* @a 保存 Innodb_rows_read 的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 执行语句 */\nselect city, name,age from t where city='杭州' order by name limit 1000; \n \n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n \n/* @b 保存 Innodb_rows_read 的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 计算 Innodb_rows_read 差值 */\nselect @b-@a;\n```\n\n这个方法是通过查看 `OPTIMIZER_TRACE` 的结果来确认的，你可以从 `number_of_tmp_files` 中看到是否使用了临时文件。\n\n![图 4 全排序的 OPTIMIZER_TRACE 部分结果](1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg)\n\nnumber_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。\n如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。\n否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。\n接下来，我再和你解释一下图 4 中其他两个值的意思。\n我们的示例表中有 4000 条满足 city='杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。\nsort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。\n这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。\n这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。\n\n<br/>\n### rowid 排序\n\n在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n所以如果单行很大，这个方法效率不够好。\n那么，如果 MySQL 认为排序的单行长度太大会怎么做呢？\n接下来，我来修改一个参数，让 MySQL 采用另外一种算法。\n\n```SQL\nSET max_length_for_sort_data = 16;\n```\n\nmax_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：\n• 初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n• 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；\n• 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n• 从索引 city 取下一个记录的主键 id；\n• 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；\n• 对 sort_buffer 中的数据按照字段 name 进行排序；\n• 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n这个执行流程的示意图如下，我把它称为 rowid 排序。\n\n![图 5 rowid 排序](1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg)\n\n对比图 3 的全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。\n需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。\n根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？\n现在，我们就来看看结果有什么不同。\n首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。\n因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。\n\n![图 6 rowid 排序的 OPTIMIZER_TRACE 部分输出](1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg)\n\n从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。\nsort_mode 变成了 `<sort_key, rowid>`，表示参与排序的只有 name 和 id 这两个字段。\nnumber_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。\n\n<br/>\n### 全字段排序 VS rowid 排序\n\n我们来分析一下，从这两个执行流程里，还能得出什么结论。\n• 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n• 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。\n看到这里，你就了解了，MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。\n其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n你可以设想下，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？\n确实是这样的。\n所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n作为与 city 索引的对比，我们来看看这个索引的示意图。\n\n![图 7 city 和 name 联合索引示意图](1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg)\n\n在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city='杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n• 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；\n• 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n• 从索引 city 取下一个记录主键 id；\n• 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。\n\n![图 8 引入 (city,name) 联合索引后，查询语句的执行计划](1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg)\n\n可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。\n\n![图 9 引入 (city,name) 联合索引后，查询语句的执行计划](1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg)\n\n从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。\n既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。\n这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n• 从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n• 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n• 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。\n\n![图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程](1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg)\n\n然后，我们再来看看 explain 的结果。\n\n![图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划](1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg)\n\n可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。\n当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。\n\n<br/>\n### 小结\n\n今天这篇文章，我和你介绍了 MySQL 里面 order by 语句的几种算法流程。\n在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。\n问题：假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：\n\n```SQL\nmysql> select * from t where city in ('杭州',\" 苏州 \") order by name limit 100;\n```\n\n那么，这个语句执行的时候会有排序过程吗，为什么？\n• 如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n• 进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：\n1. 执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。\n2. 执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。\n3. 现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。\n如果把这条 SQL 语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写：\n\n```SQL\nselect * from t where city=\" 杭州 \" order by name limit 10100;\n```\n\n和\n\n```SQL\nselect * from t where city=\" 苏州 \" order by name limit 10100。\n```\n\n这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第 10001~10100 的 name 值，就是需要的结果了。\n当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。\n所以，如果数据的单行比较大的话，可以考虑把这两条 SQL 语句改成下面这种写法：\n\n```SQL\nselect id,name from t where city=\" 杭州 \" order by name limit 10100;\n```\n\n和\n\n```SQL\nselect id,name from t where city=\" 苏州 \" order by name limit 10100。\n```\n\n然后，再用归并排序的方法取得按 name 顺序第 10001~10100 的 name、id 的值，然后拿着这 100 个 id 到数据库中去查出所有记录。\n\n\n\n通过索引优化来实现MySQL的ORDER BY语句优化：\n1. ORDER BY的索引优化。如果一个SQL语句形如：\nSELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];\n在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。\n2. WHERE + ORDER BY的索引优化，形如：\nSELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];\n建立一个联合索引(columnX,sort)来实现order by 优化。\na. 注意：如果columnX对应多个值，如下面语句就无法利用索引来实现order by的优化\nb. SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…)     ORDER BY[sort];\n3. WHERE+ 多个字段ORDER BY\nSELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;\n建立索引(uid,x,y)实现order by的优化,比建立(x,y,uid)索引效果要好得多。\nMySQL Order By不能使用索引来优化排序的情况\n• 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)\nSELECT * FROM t1 ORDER BY key1, key2;\n• 在非连续的索引键部分上做 ORDER BY：(key_part1,key_part2建立联合索引;key2建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;\n• 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)\nSELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;\n• 用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key1;\n• 如果在WHERE和ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化\nSELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;\n特别提示:\n1. mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。\n2. 在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。","slug":"16-“order-by”是怎么工作的","published":1,"updated":"2021-06-30T02:33:24.610Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvf001br5p753ap9jig","content":"<p>在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。\n假设这个表的部分定义是这样的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>这时，你的 SQL 语句可以这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select city,name,age from t where city='杭州' order by name limit 1000  ;\n</code></pre>\n<p>这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。</p>\n<br>\n### 全字段排序\n\n<p>前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。\n在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。</p>\n<p><img src=\"1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg\" alt=\"图 1 使用 explain 命令查看语句的执行情况\"></p>\n<p>Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。\n为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。</p>\n<p><img src=\"1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg\" alt=\"图 2 city 字段的索引示意图\"></p>\n<p>从图中可以看到，满足 <code>city='杭州’</code>条件的行，是从 <code>ID_X</code> 到 <code>ID_(X+N)</code> 的这些记录。\n通常情况下，这个语句执行流程如下所示 ：</p>\n<ul>\n<li>初始化 <code>sort_buffer</code>，确定放入 <code>name</code>、<code>city</code>、<code>age</code> 这三个字段；</li>\n<li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</li>\n<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>\n<li>从索引 city 取下一个记录的主键 id；</li>\n<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>\n<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>\n<li>按照排序结果取前 1000 行返回给客户端。</li>\n</ul>\n<p>我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。</p>\n<p><img src=\"1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg\" alt=\"图 3 全字段排序\"></p>\n<p>图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\nsort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">/* 打开 optimizer_trace，只对本线程有效 */\nSET optimizer_trace='enabled=on'; \n \n/* @a 保存 Innodb_rows_read 的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 执行语句 */\nselect city, name,age from t where city='杭州' order by name limit 1000; \n \n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n \n/* @b 保存 Innodb_rows_read 的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';\n \n/* 计算 Innodb_rows_read 差值 */\nselect @b-@a;\n</code></pre>\n<p>这个方法是通过查看 <code>OPTIMIZER_TRACE</code> 的结果来确认的，你可以从 <code>number_of_tmp_files</code> 中看到是否使用了临时文件。</p>\n<p><img src=\"1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg\" alt=\"图 4 全排序的 OPTIMIZER_TRACE 部分结果\"></p>\n<p>number_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。\n如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。\n否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。\n接下来，我再和你解释一下图 4 中其他两个值的意思。\n我们的示例表中有 4000 条满足 city=’杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。\nsort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。\n这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。\n这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。</p>\n<br>\n### rowid 排序\n\n<p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n所以如果单行很大，这个方法效率不够好。\n那么，如果 MySQL 认为排序的单行长度太大会怎么做呢？\n接下来，我来修改一个参数，让 MySQL 采用另外一种算法。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">SET max_length_for_sort_data = 16;\n</code></pre>\n<p>max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：\n• 初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n• 从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；\n• 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n• 从索引 city 取下一个记录的主键 id；\n• 重复步骤 3、4 直到不满足 city=’杭州’条件为止，也就是图中的 ID_Y；\n• 对 sort_buffer 中的数据按照字段 name 进行排序；\n• 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n这个执行流程的示意图如下，我把它称为 rowid 排序。</p>\n<p><img src=\"1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg\" alt=\"图 5 rowid 排序\"></p>\n<p>对比图 3 的全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。\n需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。\n根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？\n现在，我们就来看看结果有什么不同。\n首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。\n因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。</p>\n<p><img src=\"1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg\" alt=\"图 6 rowid 排序的 OPTIMIZER_TRACE 部分输出\"></p>\n<p>从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。\nsort_mode 变成了 <code>&lt;sort_key, rowid&gt;</code>，表示参与排序的只有 name 和 id 这两个字段。\nnumber_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</p>\n<br>\n### 全字段排序 VS rowid 排序\n\n<p>我们来分析一下，从这两个执行流程里，还能得出什么结论。\n• 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n• 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。\n看到这里，你就了解了，MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。\n其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n你可以设想下，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？\n确实是这样的。\n所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n作为与 city 索引的对比，我们来看看这个索引的示意图。</p>\n<p><img src=\"1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg\" alt=\"图 7 city 和 name 联合索引示意图\"></p>\n<p>在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city=’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n• 从索引 (city,name) 找到第一个满足 city=’杭州’条件的主键 id；\n• 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n• 从索引 city 取下一个记录主键 id；\n• 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。</p>\n<p><img src=\"1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg\" alt=\"图 8 引入 (city,name) 联合索引后，查询语句的执行计划\"></p>\n<p>可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。</p>\n<p><img src=\"1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg\" alt=\"图 9 引入 (city,name) 联合索引后，查询语句的执行计划\"></p>\n<p>从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。\n既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。\n这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n• 从索引 (city,name,age) 找到第一个满足 city=’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n• 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n• 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。</p>\n<p><img src=\"1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg\" alt=\"图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程\"></p>\n<p>然后，我们再来看看 explain 的结果。</p>\n<p><img src=\"1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg\" alt=\"图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划\"></p>\n<p>可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。\n当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。</p>\n<br>\n### 小结\n\n<p>今天这篇文章，我和你介绍了 MySQL 里面 order by 语句的几种算法流程。\n在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。\n问题：假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where city in ('杭州',\" 苏州 \") order by name limit 100;\n</code></pre>\n<p>那么，这个语句执行的时候会有排序过程吗，为什么？\n• 如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n• 进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：</p>\n<ol>\n<li>执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。</li>\n<li>执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。</li>\n<li>现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。\n如果把这条 SQL 语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写：</li>\n</ol>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select * from t where city=\" 杭州 \" order by name limit 10100;\n</code></pre>\n<p>和</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select * from t where city=\" 苏州 \" order by name limit 10100。\n</code></pre>\n<p>这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第 10001~10100 的 name 值，就是需要的结果了。\n当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。\n所以，如果数据的单行比较大的话，可以考虑把这两条 SQL 语句改成下面这种写法：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select id,name from t where city=\" 杭州 \" order by name limit 10100;\n</code></pre>\n<p>和</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select id,name from t where city=\" 苏州 \" order by name limit 10100。\n</code></pre>\n<p>然后，再用归并排序的方法取得按 name 顺序第 10001~10100 的 name、id 的值，然后拿着这 100 个 id 到数据库中去查出所有记录。</p>\n<p>通过索引优化来实现MySQL的ORDER BY语句优化：</p>\n<ol>\n<li>ORDER BY的索引优化。如果一个SQL语句形如：\nSELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];\n在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。</li>\n<li>WHERE + ORDER BY的索引优化，形如：\nSELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];\n建立一个联合索引(columnX,sort)来实现order by 优化。\na. 注意：如果columnX对应多个值，如下面语句就无法利用索引来实现order by的优化\nb. SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…)     ORDER BY[sort];</li>\n<li>WHERE+ 多个字段ORDER BY\nSELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;\n建立索引(uid,x,y)实现order by的优化,比建立(x,y,uid)索引效果要好得多。\nMySQL Order By不能使用索引来优化排序的情况\n• 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)\nSELECT * FROM t1 ORDER BY key1, key2;\n• 在非连续的索引键部分上做 ORDER BY：(key_part1,key_part2建立联合索引;key2建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;\n• 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)\nSELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;\n• 用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key1;\n• 如果在WHERE和ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化\nSELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;\n特别提示:</li>\n<li>mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。</li>\n<li>在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。\n假设这个表的部分定义是这样的：</p>\n<pre><code class=\"SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `city` varchar(16) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  `age` int(11) NOT NULL,\n  `addr` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>这时，你的 SQL 语句可以这么写：</p>\n<pre><code class=\"SQL\">select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000  ;\n</code></pre>\n<p>这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。</p>\n<br/>\n### 全字段排序\n\n<p>前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。\n在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。</p>\n<p><img src=\"1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg\" alt=\"图 1 使用 explain 命令查看语句的执行情况\"></p>\n<p>Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。\n为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。</p>\n<p><img src=\"1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg\" alt=\"图 2 city 字段的索引示意图\"></p>\n<p>从图中可以看到，满足 <code>city=&#39;杭州’</code>条件的行，是从 <code>ID_X</code> 到 <code>ID_(X+N)</code> 的这些记录。\n通常情况下，这个语句执行流程如下所示 ：</p>\n<ul>\n<li>初始化 <code>sort_buffer</code>，确定放入 <code>name</code>、<code>city</code>、<code>age</code> 这三个字段；</li>\n<li>从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；</li>\n<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>\n<li>从索引 city 取下一个记录的主键 id；</li>\n<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>\n<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>\n<li>按照排序结果取前 1000 行返回给客户端。</li>\n</ul>\n<p>我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。</p>\n<p><img src=\"1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg\" alt=\"图 3 全字段排序\"></p>\n<p>图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\nsort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。</p>\n<pre><code class=\"SQL\">/* 打开 optimizer_trace，只对本线程有效 */\nSET optimizer_trace=&#39;enabled=on&#39;; \n \n/* @a 保存 Innodb_rows_read 的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = &#39;Innodb_rows_read&#39;;\n \n/* 执行语句 */\nselect city, name,age from t where city=&#39;杭州&#39; order by name limit 1000; \n \n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n \n/* @b 保存 Innodb_rows_read 的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &#39;Innodb_rows_read&#39;;\n \n/* 计算 Innodb_rows_read 差值 */\nselect @b-@a;\n</code></pre>\n<p>这个方法是通过查看 <code>OPTIMIZER_TRACE</code> 的结果来确认的，你可以从 <code>number_of_tmp_files</code> 中看到是否使用了临时文件。</p>\n<p><img src=\"1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg\" alt=\"图 4 全排序的 OPTIMIZER_TRACE 部分结果\"></p>\n<p>number_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。\n如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。\n否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。\n接下来，我再和你解释一下图 4 中其他两个值的意思。\n我们的示例表中有 4000 条满足 city=’杭州’的记录，所以你可以看到 examined_rows=4000，表示参与排序的行数是 4000 行。\nsort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。\n同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。\n这里需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。\n这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。</p>\n<br/>\n### rowid 排序\n\n<p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n所以如果单行很大，这个方法效率不够好。\n那么，如果 MySQL 认为排序的单行长度太大会怎么做呢？\n接下来，我来修改一个参数，让 MySQL 采用另外一种算法。</p>\n<pre><code class=\"SQL\">SET max_length_for_sort_data = 16;\n</code></pre>\n<p>max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：\n• 初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n• 从索引 city 找到第一个满足 city=’杭州’条件的主键 id，也就是图中的 ID_X；\n• 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n• 从索引 city 取下一个记录的主键 id；\n• 重复步骤 3、4 直到不满足 city=’杭州’条件为止，也就是图中的 ID_Y；\n• 对 sort_buffer 中的数据按照字段 name 进行排序；\n• 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n这个执行流程的示意图如下，我把它称为 rowid 排序。</p>\n<p><img src=\"1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg\" alt=\"图 5 rowid 排序\"></p>\n<p>对比图 3 的全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。\n需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。\n根据这个说明过程和图示，你可以想一下，这个时候执行 select @b-@a，结果会是多少呢？\n现在，我们就来看看结果有什么不同。\n首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b-@a 这个语句的值变成 5000 了。\n因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。</p>\n<p><img src=\"1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg\" alt=\"图 6 rowid 排序的 OPTIMIZER_TRACE 部分输出\"></p>\n<p>从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了。\nsort_mode 变成了 <code>&lt;sort_key, rowid&gt;</code>，表示参与排序的只有 name 和 id 这两个字段。\nnumber_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</p>\n<br/>\n### 全字段排序 VS rowid 排序\n\n<p>我们来分析一下，从这两个执行流程里，还能得出什么结论。\n• 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n• 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n这个结论看上去有点废话的感觉，但是你要记住它，下一篇文章我们就会用到。\n看到这里，你就了解了，MySQL 做排序是一个成本比较高的操作。那么你会问，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短。\n其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n你可以设想下，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？\n确实是这样的。\n所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n作为与 city 索引的对比，我们来看看这个索引的示意图。</p>\n<p><img src=\"1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg\" alt=\"图 7 city 和 name 联合索引示意图\"></p>\n<p>在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city=’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n• 从索引 (city,name) 找到第一个满足 city=’杭州’条件的主键 id；\n• 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n• 从索引 city 取下一个记录主键 id；\n• 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。</p>\n<p><img src=\"1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg\" alt=\"图 8 引入 (city,name) 联合索引后，查询语句的执行计划\"></p>\n<p>可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。</p>\n<p><img src=\"1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg\" alt=\"图 9 引入 (city,name) 联合索引后，查询语句的执行计划\"></p>\n<p>从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。\n既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。\n这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n• 从索引 (city,name,age) 找到第一个满足 city=’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n• 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n• 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。</p>\n<p><img src=\"1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg\" alt=\"图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程\"></p>\n<p>然后，我们再来看看 explain 的结果。</p>\n<p><img src=\"1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg\" alt=\"图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划\"></p>\n<p>可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。\n当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。</p>\n<br/>\n### 小结\n\n<p>今天这篇文章，我和你介绍了 MySQL 里面 order by 语句的几种算法流程。\n在开发系统的时候，你总是不可避免地会使用到 order by 语句。你心里要清楚每个语句的排序逻辑是怎么实现的，还要能够分析出在最坏情况下，每个语句的执行对系统资源的消耗，这样才能做到下笔如有神，不犯低级错误。\n问题：假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where city in (&#39;杭州&#39;,&quot; 苏州 &quot;) order by name limit 100;\n</code></pre>\n<p>那么，这个语句执行的时候会有排序过程吗，为什么？\n• 如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n• 进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n这里，我们要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句，执行流程如下：</p>\n<ol>\n<li>执行 select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为 100 的内存数组 A 保存结果。</li>\n<li>执行 select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组 B。</li>\n<li>现在 A 和 B 是两个有序数组，然后你可以用归并排序的思想，得到 name 最小的前 100 值，就是我们需要的结果了。\n如果把这条 SQL 语句里“limit 100”改成“limit 10000,100”的话，处理方式其实也差不多，即：要把上面的两条语句改成写：</li>\n</ol>\n<pre><code class=\"SQL\">select * from t where city=&quot; 杭州 &quot; order by name limit 10100;\n</code></pre>\n<p>和</p>\n<pre><code class=\"SQL\">select * from t where city=&quot; 苏州 &quot; order by name limit 10100。\n</code></pre>\n<p>这时候数据量较大，可以同时起两个连接一行行读结果，用归并排序算法拿到这两个结果集里，按顺序取第 10001~10100 的 name 值，就是需要的结果了。\n当然这个方案有一个明显的损失，就是从数据库返回给客户端的数据量变大了。\n所以，如果数据的单行比较大的话，可以考虑把这两条 SQL 语句改成下面这种写法：</p>\n<pre><code class=\"SQL\">select id,name from t where city=&quot; 杭州 &quot; order by name limit 10100;\n</code></pre>\n<p>和</p>\n<pre><code class=\"SQL\">select id,name from t where city=&quot; 苏州 &quot; order by name limit 10100。\n</code></pre>\n<p>然后，再用归并排序的方法取得按 name 顺序第 10001~10100 的 name、id 的值，然后拿着这 100 个 id 到数据库中去查出所有记录。</p>\n<p>通过索引优化来实现MySQL的ORDER BY语句优化：</p>\n<ol>\n<li>ORDER BY的索引优化。如果一个SQL语句形如：\nSELECT [column1],[column2],…. FROM [TABLE] ORDER BY [sort];\n在[sort]这个栏位上建立索引就可以实现利用索引进行order by 优化。</li>\n<li>WHERE + ORDER BY的索引优化，形如：\nSELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] = [value] ORDER BY [sort];\n建立一个联合索引(columnX,sort)来实现order by 优化。\na. 注意：如果columnX对应多个值，如下面语句就无法利用索引来实现order by的优化\nb. SELECT [column1],[column2],…. FROM [TABLE] WHERE [columnX] IN ([value1],[value2],…)     ORDER BY[sort];</li>\n<li>WHERE+ 多个字段ORDER BY\nSELECT * FROM [table] WHERE uid=1 ORDER x,y LIMIT 0,10;\n建立索引(uid,x,y)实现order by的优化,比建立(x,y,uid)索引效果要好得多。\nMySQL Order By不能使用索引来优化排序的情况\n• 对不同的索引键做 ORDER BY ：(key1,key2分别建立索引)\nSELECT * FROM t1 ORDER BY key1, key2;\n• 在非连续的索引键部分上做 ORDER BY：(key_part1,key_part2建立联合索引;key2建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key_part2;\n• 同时使用了 ASC 和 DESC：(key_part1,key_part2建立联合索引)\nSELECT * FROM t1 ORDER BY key_part1 DESC, key_part2 ASC;\n• 用于搜索记录的索引键和做 ORDER BY 的不是同一个：(key1,key2分别建立索引)\nSELECT * FROM t1 WHERE key2=constant ORDER BY key1;\n• 如果在WHERE和ORDER BY的栏位上应用表达式(函数)时，则无法利用索引来实现order by的优化\nSELECT * FROM t1 ORDER BY YEAR(logindate) LIMIT 0,10;\n特别提示:</li>\n<li>mysql一次查询只能使用一个索引。如果要对多个字段使用索引，建立复合索引。</li>\n<li>在ORDER BY操作中，MySQL只有在排序条件不是一个查询条件表达式的情况下才使用索引。</li>\n</ol>\n"},{"title":"17 | 如何正确地显示随机消息","date":"2019-06-02T16:00:00.000Z","_content":"我在上一篇文章，为你讲解完 order by 语句的几种执行模式后，就想到了之前一个做英语学习 App 的朋友碰到过的一个性能问题。今天这篇文章，我就从这个性能问题说起，和你说说 MySQL 中的另外一种排序需求，希望能够加深你对 MySQL 排序逻辑的理解。\n这个英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。\n现在，如果让你来设计这个 SQL 语句，你会怎么写呢？\n为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：\n\n```SQL\nmysql> CREATE TABLE words (\nid int(11) NOT NULL AUTO_INCREMENT,\nword varchar(64) DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ndelimiter ;;\ncreate procedure idata()\nbegin\ndeclare i int;\nset i=0;\nwhile i<10000 do\ninsert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\nset i=i+1;\nend while;\nend;;\ndelimiter ;\ncall idata();\n```\n\n为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，我们就一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。\n\n<!-- more -->\n\n<br/>\n### 内存临时表\n\n首先，你会想到用 order by rand() 来实现这个逻辑。\n\n```SQL\nmysql> select word from words order by rand() limit 3;\n```\n\n这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。\n我们先用 explain 命令来看看这个语句的执行情况。\n\n![图 1 使用 explain 命令查看语句的执行情况](1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg)\n\nExtra 字段显示 `Using temporary`:表示的是需要使用临时表；`Using filesort`:表示的是需要执行排序操作。\n因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序。\n\n![图 2 全字段排序](1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg)\n\n![图 3 rowid 排序](1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg)\n\n然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？\n回顾一下上一篇文章的一个结论：对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。我强调了“InnoDB 表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL 这时就会选择 rowid 排序。\n理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。\n\n这条语句的执行流程是这样的：\n\n1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。\n2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。\n3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。\n4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。\n5. 从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。\n6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。\n7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n接下来，我们通过慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。\n\n```\nQuery_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003\nSET timestamp=1541402277;\nselect word from words order by rand() limit 3;\n```\n\n其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。\n这里插一句题外话，在平时学习概念的过程中，你可以经常这样做，先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论。我自己就是经常这么做，这个过程很有趣，分析对了开心，分析错了但是弄清楚了也很开心。\n现在，我来把完整的排序执行流程图画出来。\n\n![图 4 随机排序完整流程图 1](1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg)\n\n图中的 pos 就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对 InnoDB 表排序的时候，明明用的还是 ID 字段。\n这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。\n在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？\n其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。\n这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。\n• 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；\n• 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；\n• MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n到这里，我来稍微小结一下：order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。\n\n<br/>\n### 磁盘临时表\n\n那么，是不是所有的临时表都是内存表呢？\n其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。\n\n```SQL\nset tmp_table_size=1024;\nset sort_buffer_size=32768;\nset max_length_for_sort_data=16;\n/ 打开 optimizer_trace，只对本线程有效 /\nSET optimizer_trace='enabled=on';\n/ 执行语句 /\nselect word from words order by rand() limit 3;\n/ 查看 OPTIMIZER_TRACE 输出 /\n SELECT * FROM information_schema.OPTIMIZER_TRACE\\G\n ```\n\n![图 5 OPTIMIZER_TRACE 部分结果](1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg)\n\n然后，我们来看一下这次 OPTIMIZER_TRACE 的结果。\n因为将 max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。\n这时候你可能心算了一下，发现不对。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（至于为什么是 6 字节，就留给你课后思考吧），数据总行数是 10000，这样算出来就有 140000 字节，超过了 sort_buffer_size 定义的 32768 字节了。但是，number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？\n这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n这里我简单画了一个优先队列排序过程的示意图。\n\n![图 6 优先队列排序算法示例](1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg)\n\n图 6 是模拟 6 个 (R,rowid) 行，通过优先队列排序找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。\n图 5 的 OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。\n这个流程结束后，我们构造的堆里面，就是这个 10000 行里面 R 值最小的三行。然后，依次把它们的 rowid 取出来，去临时表里面拿到 word 字段，这个过程就跟上一篇文章的 rowid 排序的过程一样了。\n我们再看一下上面一篇文章的 SQL 查询语句：\n\n```SQL\nselect city,name,age from t where city='杭州' order by name limit 1000  ;\n```\n\n你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。\n总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。\n再回到我们文章开头的问题，怎么正确地随机排序呢？\n\n<br/>\n### 随机排序方法\n\n我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：\n\n1. 取得这个表的主键 id 的最大值 M 和最小值 N;\n2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;\n3. 取不小于 X 的第一个 ID 的行。\n我们把这个算法，暂时称作随机算法 1。这里，我直接给你贴一下执行语句的序列:\n\n```SQL\nmysql> select max(id),min(id) into @M,@N from t ;\nset @X= floor((@M-@N+1)*rand() + @N);\nselect * from t where id >= @X limit 1;\n```\n\n这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。\n如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。\n\n所以，为了得到严格随机的结果，你可以用下面这个流程:\n\n1. 取得整个表的行数，并记为 C。\n2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n3. 再用 limit Y,1 取得一行。\n   \n我们把这个算法，称为随机算法 2。下面这段代码，就是上面流程的执行语句的序列。\n\n```SQL\nmysql> select count(*) into @C from t;\nset @Y = floor(@C * rand());\nset @sql = concat(\"select * from t limit \", @Y, \",1\");\nprepare stmt from @sql;\nexecute stmt;\nDEALLOCATE prepare stmt;\n```\n\n由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。\n这个随机算法 2，解决了算法 1 里面明显的概率不均匀问题。\nMySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。\n当然，随机算法 2 跟直接 order by rand() 比起来，执行代价还是小很多的。\n你可能问了，如果按照这个表有 10000 行来计算的话，C=10000，要是随机到比较大的 Y 值，那扫描行数也跟 20000 差不多了，接近 order by rand() 的扫描行数，为什么说随机算法 2 的代价要小很多呢？我就把这个问题留给你去课后思考吧。\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：\n\n1. 取得整个表的行数，记为 C；\n2. 根据相同的随机方法得到 Y1、Y2、Y3；\n3. 再执行三个 limit Y, 1 语句得到三行数据。\n我们把这个算法，称作随机算法 3。下面这段代码，就是上面流程的执行语句的序列。\n\n```SQL\nmysql> select count(*) into @C from t;\nset @Y1 = floor(@C * rand());\nset @Y2 = floor(@C * rand());\nset @Y3 = floor(@C * rand());\nselect * from t limit @Y1，1； // 在应用代码里面取 Y1、Y2、Y3 值，拼出 SQL 后执行\nselect * from t limit @Y2，1；\nselect * from t limit @Y3，1；\n```\n\n<br/>\n### 小结\n\n今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n最后，我给你留下一个思考题吧。\n上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。\n我的问题是，如果你是这个需求的开发人员，你会怎么做，来减少扫描行数呢？说说你的方案，并说明你的方案需要的扫描行数。\n这里我给出一种方法，取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：\n\n```SQL\nmysql> select * from t limit N, M-N+1;\n```\n\n再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n当然也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句也是可以的。","source":"_posts/17-如何正确地显示随机消息.md","raw":"---\ntitle: 17 | 如何正确地显示随机消息\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n我在上一篇文章，为你讲解完 order by 语句的几种执行模式后，就想到了之前一个做英语学习 App 的朋友碰到过的一个性能问题。今天这篇文章，我就从这个性能问题说起，和你说说 MySQL 中的另外一种排序需求，希望能够加深你对 MySQL 排序逻辑的理解。\n这个英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。\n现在，如果让你来设计这个 SQL 语句，你会怎么写呢？\n为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：\n\n```SQL\nmysql> CREATE TABLE words (\nid int(11) NOT NULL AUTO_INCREMENT,\nword varchar(64) DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ndelimiter ;;\ncreate procedure idata()\nbegin\ndeclare i int;\nset i=0;\nwhile i<10000 do\ninsert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\nset i=i+1;\nend while;\nend;;\ndelimiter ;\ncall idata();\n```\n\n为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，我们就一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。\n\n<!-- more -->\n\n<br/>\n### 内存临时表\n\n首先，你会想到用 order by rand() 来实现这个逻辑。\n\n```SQL\nmysql> select word from words order by rand() limit 3;\n```\n\n这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。\n我们先用 explain 命令来看看这个语句的执行情况。\n\n![图 1 使用 explain 命令查看语句的执行情况](1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg)\n\nExtra 字段显示 `Using temporary`:表示的是需要使用临时表；`Using filesort`:表示的是需要执行排序操作。\n因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序。\n\n![图 2 全字段排序](1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg)\n\n![图 3 rowid 排序](1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg)\n\n然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？\n回顾一下上一篇文章的一个结论：对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。我强调了“InnoDB 表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL 这时就会选择 rowid 排序。\n理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。\n\n这条语句的执行流程是这样的：\n\n1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。\n2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。\n3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。\n4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。\n5. 从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。\n6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。\n7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n接下来，我们通过慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。\n\n```\nQuery_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003\nSET timestamp=1541402277;\nselect word from words order by rand() limit 3;\n```\n\n其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。\n这里插一句题外话，在平时学习概念的过程中，你可以经常这样做，先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论。我自己就是经常这么做，这个过程很有趣，分析对了开心，分析错了但是弄清楚了也很开心。\n现在，我来把完整的排序执行流程图画出来。\n\n![图 4 随机排序完整流程图 1](1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg)\n\n图中的 pos 就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对 InnoDB 表排序的时候，明明用的还是 ID 字段。\n这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。\n在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？\n其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。\n这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。\n• 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；\n• 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；\n• MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n到这里，我来稍微小结一下：order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。\n\n<br/>\n### 磁盘临时表\n\n那么，是不是所有的临时表都是内存表呢？\n其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。\n\n```SQL\nset tmp_table_size=1024;\nset sort_buffer_size=32768;\nset max_length_for_sort_data=16;\n/ 打开 optimizer_trace，只对本线程有效 /\nSET optimizer_trace='enabled=on';\n/ 执行语句 /\nselect word from words order by rand() limit 3;\n/ 查看 OPTIMIZER_TRACE 输出 /\n SELECT * FROM information_schema.OPTIMIZER_TRACE\\G\n ```\n\n![图 5 OPTIMIZER_TRACE 部分结果](1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg)\n\n然后，我们来看一下这次 OPTIMIZER_TRACE 的结果。\n因为将 max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。\n这时候你可能心算了一下，发现不对。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（至于为什么是 6 字节，就留给你课后思考吧），数据总行数是 10000，这样算出来就有 140000 字节，超过了 sort_buffer_size 定义的 32768 字节了。但是，number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？\n这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n这里我简单画了一个优先队列排序过程的示意图。\n\n![图 6 优先队列排序算法示例](1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg)\n\n图 6 是模拟 6 个 (R,rowid) 行，通过优先队列排序找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。\n图 5 的 OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。\n这个流程结束后，我们构造的堆里面，就是这个 10000 行里面 R 值最小的三行。然后，依次把它们的 rowid 取出来，去临时表里面拿到 word 字段，这个过程就跟上一篇文章的 rowid 排序的过程一样了。\n我们再看一下上面一篇文章的 SQL 查询语句：\n\n```SQL\nselect city,name,age from t where city='杭州' order by name limit 1000  ;\n```\n\n你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。\n总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。\n再回到我们文章开头的问题，怎么正确地随机排序呢？\n\n<br/>\n### 随机排序方法\n\n我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：\n\n1. 取得这个表的主键 id 的最大值 M 和最小值 N;\n2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;\n3. 取不小于 X 的第一个 ID 的行。\n我们把这个算法，暂时称作随机算法 1。这里，我直接给你贴一下执行语句的序列:\n\n```SQL\nmysql> select max(id),min(id) into @M,@N from t ;\nset @X= floor((@M-@N+1)*rand() + @N);\nselect * from t where id >= @X limit 1;\n```\n\n这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。\n如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。\n\n所以，为了得到严格随机的结果，你可以用下面这个流程:\n\n1. 取得整个表的行数，并记为 C。\n2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n3. 再用 limit Y,1 取得一行。\n   \n我们把这个算法，称为随机算法 2。下面这段代码，就是上面流程的执行语句的序列。\n\n```SQL\nmysql> select count(*) into @C from t;\nset @Y = floor(@C * rand());\nset @sql = concat(\"select * from t limit \", @Y, \",1\");\nprepare stmt from @sql;\nexecute stmt;\nDEALLOCATE prepare stmt;\n```\n\n由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。\n这个随机算法 2，解决了算法 1 里面明显的概率不均匀问题。\nMySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。\n当然，随机算法 2 跟直接 order by rand() 比起来，执行代价还是小很多的。\n你可能问了，如果按照这个表有 10000 行来计算的话，C=10000，要是随机到比较大的 Y 值，那扫描行数也跟 20000 差不多了，接近 order by rand() 的扫描行数，为什么说随机算法 2 的代价要小很多呢？我就把这个问题留给你去课后思考吧。\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：\n\n1. 取得整个表的行数，记为 C；\n2. 根据相同的随机方法得到 Y1、Y2、Y3；\n3. 再执行三个 limit Y, 1 语句得到三行数据。\n我们把这个算法，称作随机算法 3。下面这段代码，就是上面流程的执行语句的序列。\n\n```SQL\nmysql> select count(*) into @C from t;\nset @Y1 = floor(@C * rand());\nset @Y2 = floor(@C * rand());\nset @Y3 = floor(@C * rand());\nselect * from t limit @Y1，1； // 在应用代码里面取 Y1、Y2、Y3 值，拼出 SQL 后执行\nselect * from t limit @Y2，1；\nselect * from t limit @Y3，1；\n```\n\n<br/>\n### 小结\n\n今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n最后，我给你留下一个思考题吧。\n上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。\n我的问题是，如果你是这个需求的开发人员，你会怎么做，来减少扫描行数呢？说说你的方案，并说明你的方案需要的扫描行数。\n这里我给出一种方法，取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：\n\n```SQL\nmysql> select * from t limit N, M-N+1;\n```\n\n再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n当然也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句也是可以的。","slug":"17-如何正确地显示随机消息","published":1,"updated":"2021-06-30T02:33:24.618Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvg001er5p7h0t74j4e","content":"<p>我在上一篇文章，为你讲解完 order by 语句的几种执行模式后，就想到了之前一个做英语学习 App 的朋友碰到过的一个性能问题。今天这篇文章，我就从这个性能问题说起，和你说说 MySQL 中的另外一种排序需求，希望能够加深你对 MySQL 排序逻辑的理解。\n这个英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。\n现在，如果让你来设计这个 SQL 语句，你会怎么写呢？\n为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE words (\nid int(11) NOT NULL AUTO_INCREMENT,\nword varchar(64) DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ndelimiter ;;\ncreate procedure idata()\nbegin\ndeclare i int;\nset i=0;\nwhile i<10000 do\ninsert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\nset i=i+1;\nend while;\nend;;\ndelimiter ;\ncall idata();\n</code></pre>\n<p>为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，我们就一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。</p>\n<span id=\"more\"></span>\n\n<br>\n### 内存临时表\n\n<p>首先，你会想到用 order by rand() 来实现这个逻辑。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select word from words order by rand() limit 3;\n</code></pre>\n<p>这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。\n我们先用 explain 命令来看看这个语句的执行情况。</p>\n<p><img src=\"1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg\" alt=\"图 1 使用 explain 命令查看语句的执行情况\"></p>\n<p>Extra 字段显示 <code>Using temporary</code>:表示的是需要使用临时表；<code>Using filesort</code>:表示的是需要执行排序操作。\n因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序。</p>\n<p><img src=\"1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg\" alt=\"图 2 全字段排序\"></p>\n<p><img src=\"1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg\" alt=\"图 3 rowid 排序\"></p>\n<p>然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？\n回顾一下上一篇文章的一个结论：对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。我强调了“InnoDB 表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL 这时就会选择 rowid 排序。\n理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。</p>\n<p>这条语句的执行流程是这样的：</p>\n<ol>\n<li>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</li>\n<li>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。</li>\n<li>现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。</li>\n<li>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</li>\n<li>从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</li>\n<li>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li>\n<li>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n接下来，我们通过慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。</li>\n</ol>\n<pre><code>Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003\nSET timestamp=1541402277;\nselect word from words order by rand() limit 3;\n</code></pre>\n<p>其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。\n这里插一句题外话，在平时学习概念的过程中，你可以经常这样做，先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论。我自己就是经常这么做，这个过程很有趣，分析对了开心，分析错了但是弄清楚了也很开心。\n现在，我来把完整的排序执行流程图画出来。</p>\n<p><img src=\"1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg\" alt=\"图 4 随机排序完整流程图 1\"></p>\n<p>图中的 pos 就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对 InnoDB 表排序的时候，明明用的还是 ID 字段。\n这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。\n在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？\n其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。\n这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。\n• 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；\n• 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；\n• MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n到这里，我来稍微小结一下：order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</p>\n<br>\n### 磁盘临时表\n\n<p>那么，是不是所有的临时表都是内存表呢？\n其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">set tmp_table_size=1024;\nset sort_buffer_size=32768;\nset max_length_for_sort_data=16;\n/ 打开 optimizer_trace，只对本线程有效 /\nSET optimizer_trace='enabled=on';\n/ 执行语句 /\nselect word from words order by rand() limit 3;\n/ 查看 OPTIMIZER_TRACE 输出 /\n SELECT * FROM information_schema.OPTIMIZER_TRACE\\G\n</code></pre>\n<p><img src=\"1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg\" alt=\"图 5 OPTIMIZER_TRACE 部分结果\"></p>\n<p>然后，我们来看一下这次 OPTIMIZER_TRACE 的结果。\n因为将 max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。\n这时候你可能心算了一下，发现不对。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（至于为什么是 6 字节，就留给你课后思考吧），数据总行数是 10000，这样算出来就有 140000 字节，超过了 sort_buffer_size 定义的 32768 字节了。但是，number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？\n这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n这里我简单画了一个优先队列排序过程的示意图。</p>\n<p><img src=\"1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg\" alt=\"图 6 优先队列排序算法示例\"></p>\n<p>图 6 是模拟 6 个 (R,rowid) 行，通过优先队列排序找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。\n图 5 的 OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。\n这个流程结束后，我们构造的堆里面，就是这个 10000 行里面 R 值最小的三行。然后，依次把它们的 rowid 取出来，去临时表里面拿到 word 字段，这个过程就跟上一篇文章的 rowid 排序的过程一样了。\n我们再看一下上面一篇文章的 SQL 查询语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select city,name,age from t where city='杭州' order by name limit 1000  ;\n</code></pre>\n<p>你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。\n总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。\n再回到我们文章开头的问题，怎么正确地随机排序呢？</p>\n<br>\n### 随机排序方法\n\n<p>我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：</p>\n<ol>\n<li>取得这个表的主键 id 的最大值 M 和最小值 N;</li>\n<li>用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;</li>\n<li>取不小于 X 的第一个 ID 的行。\n我们把这个算法，暂时称作随机算法 1。这里，我直接给你贴一下执行语句的序列:</li>\n</ol>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select max(id),min(id) into @M,@N from t ;\nset @X= floor((@M-@N+1)*rand() + @N);\nselect * from t where id >= @X limit 1;\n</code></pre>\n<p>这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。\n如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。</p>\n<p>所以，为了得到严格随机的结果，你可以用下面这个流程:</p>\n<ol>\n<li>取得整个表的行数，并记为 C。</li>\n<li>取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。</li>\n<li>再用 limit Y,1 取得一行。</li>\n</ol>\n<p>我们把这个算法，称为随机算法 2。下面这段代码，就是上面流程的执行语句的序列。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select count(*) into @C from t;\nset @Y = floor(@C * rand());\nset @sql = concat(\"select * from t limit \", @Y, \",1\");\nprepare stmt from @sql;\nexecute stmt;\nDEALLOCATE prepare stmt;\n</code></pre>\n<p>由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。\n这个随机算法 2，解决了算法 1 里面明显的概率不均匀问题。\nMySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。\n当然，随机算法 2 跟直接 order by rand() 比起来，执行代价还是小很多的。\n你可能问了，如果按照这个表有 10000 行来计算的话，C=10000，要是随机到比较大的 Y 值，那扫描行数也跟 20000 差不多了，接近 order by rand() 的扫描行数，为什么说随机算法 2 的代价要小很多呢？我就把这个问题留给你去课后思考吧。\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：</p>\n<ol>\n<li>取得整个表的行数，记为 C；</li>\n<li>根据相同的随机方法得到 Y1、Y2、Y3；</li>\n<li>再执行三个 limit Y, 1 语句得到三行数据。\n我们把这个算法，称作随机算法 3。下面这段代码，就是上面流程的执行语句的序列。</li>\n</ol>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select count(*) into @C from t;\nset @Y1 = floor(@C * rand());\nset @Y2 = floor(@C * rand());\nset @Y3 = floor(@C * rand());\nselect * from t limit @Y1，1； // 在应用代码里面取 Y1、Y2、Y3 值，拼出 SQL 后执行\nselect * from t limit @Y2，1；\nselect * from t limit @Y3，1；\n</code></pre>\n<br>\n### 小结\n\n<p>今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n最后，我给你留下一个思考题吧。\n上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。\n我的问题是，如果你是这个需求的开发人员，你会怎么做，来减少扫描行数呢？说说你的方案，并说明你的方案需要的扫描行数。\n这里我给出一种方法，取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t limit N, M-N+1;\n</code></pre>\n<p>再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n当然也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句也是可以的。</p>\n","site":{"data":{}},"excerpt":"<p>我在上一篇文章，为你讲解完 order by 语句的几种执行模式后，就想到了之前一个做英语学习 App 的朋友碰到过的一个性能问题。今天这篇文章，我就从这个性能问题说起，和你说说 MySQL 中的另外一种排序需求，希望能够加深你对 MySQL 排序逻辑的理解。\n这个英语学习 App 首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。\n现在，如果让你来设计这个 SQL 语句，你会怎么写呢？\n为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE words (\nid int(11) NOT NULL AUTO_INCREMENT,\nword varchar(64) DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ndelimiter ;;\ncreate procedure idata()\nbegin\ndeclare i int;\nset i=0;\nwhile i&lt;10000 do\ninsert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10))));\nset i=i+1;\nend while;\nend;;\ndelimiter ;\ncall idata();\n</code></pre>\n<p>为了便于量化说明，我在这个表里面插入了 10000 行记录。接下来，我们就一起看看要随机选择 3 个单词，有什么方法实现，存在什么问题以及如何改进。</p>","more":"<br/>\n### 内存临时表\n\n<p>首先，你会想到用 order by rand() 来实现这个逻辑。</p>\n<pre><code class=\"SQL\">mysql&gt; select word from words order by rand() limit 3;\n</code></pre>\n<p>这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。\n我们先用 explain 命令来看看这个语句的执行情况。</p>\n<p><img src=\"1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg\" alt=\"图 1 使用 explain 命令查看语句的执行情况\"></p>\n<p>Extra 字段显示 <code>Using temporary</code>:表示的是需要使用临时表；<code>Using filesort</code>:表示的是需要执行排序操作。\n因此这个 Extra 的意思就是，需要临时表，并且需要在临时表上排序。</p>\n<p><img src=\"1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg\" alt=\"图 2 全字段排序\"></p>\n<p><img src=\"1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg\" alt=\"图 3 rowid 排序\"></p>\n<p>然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？\n回顾一下上一篇文章的一个结论：对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。我强调了“InnoDB 表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL 这时就会选择 rowid 排序。\n理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。</p>\n<p>这条语句的执行流程是这样的：</p>\n<ol>\n<li>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</li>\n<li>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。</li>\n<li>现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。</li>\n<li>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</li>\n<li>从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</li>\n<li>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li>\n<li>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n接下来，我们通过慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。</li>\n</ol>\n<pre><code>Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003\nSET timestamp=1541402277;\nselect word from words order by rand() limit 3;\n</code></pre>\n<p>其中，Rows_examined：20003 就表示这个语句执行过程中扫描了 20003 行，也就验证了我们分析得出的结论。\n这里插一句题外话，在平时学习概念的过程中，你可以经常这样做，先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论。我自己就是经常这么做，这个过程很有趣，分析对了开心，分析错了但是弄清楚了也很开心。\n现在，我来把完整的排序执行流程图画出来。</p>\n<p><img src=\"1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg\" alt=\"图 4 随机排序完整流程图 1\"></p>\n<p>图中的 pos 就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对 InnoDB 表排序的时候，明明用的还是 ID 字段。\n这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。\n在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？\n其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。\n这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。\n• 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；\n• 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；\n• MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n到这里，我来稍微小结一下：order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。</p>\n<br/>\n### 磁盘临时表\n\n<p>那么，是不是所有的临时表都是内存表呢？\n其实不是的。tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n为了复现这个过程，我把 tmp_table_size 设置成 1024，把 sort_buffer_size 设置成 32768, 把 max_length_for_sort_data 设置成 16。</p>\n<pre><code class=\"SQL\">set tmp_table_size=1024;\nset sort_buffer_size=32768;\nset max_length_for_sort_data=16;\n/ 打开 optimizer_trace，只对本线程有效 /\nSET optimizer_trace=&#39;enabled=on&#39;;\n/ 执行语句 /\nselect word from words order by rand() limit 3;\n/ 查看 OPTIMIZER_TRACE 输出 /\n SELECT * FROM information_schema.OPTIMIZER_TRACE\\G\n</code></pre>\n<p><img src=\"1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg\" alt=\"图 5 OPTIMIZER_TRACE 部分结果\"></p>\n<p>然后，我们来看一下这次 OPTIMIZER_TRACE 的结果。\n因为将 max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序，这个是符合预期的，参与排序的是随机值 R 字段和 rowid 字段组成的行。\n这时候你可能心算了一下，发现不对。R 字段存放的随机值就 8 个字节，rowid 是 6 个字节（至于为什么是 6 字节，就留给你课后思考吧），数据总行数是 10000，这样算出来就有 140000 字节，超过了 sort_buffer_size 定义的 32768 字节了。但是，number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？\n这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n这里我简单画了一个优先队列排序过程的示意图。</p>\n<p><img src=\"1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg\" alt=\"图 6 优先队列排序算法示例\"></p>\n<p>图 6 是模拟 6 个 (R,rowid) 行，通过优先队列排序找到最小的三个 R 值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个最大堆。\n图 5 的 OPTIMIZER_TRACE 结果中，filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。\n这个流程结束后，我们构造的堆里面，就是这个 10000 行里面 R 值最小的三行。然后，依次把它们的 rowid 取出来，去临时表里面拿到 word 字段，这个过程就跟上一篇文章的 rowid 排序的过程一样了。\n我们再看一下上面一篇文章的 SQL 查询语句：</p>\n<pre><code class=\"SQL\">select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000  ;\n</code></pre>\n<p>你可能会问，这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。\n总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。\n再回到我们文章开头的问题，怎么正确地随机排序呢？</p>\n<br/>\n### 随机排序方法\n\n<p>我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：</p>\n<ol>\n<li>取得这个表的主键 id 的最大值 M 和最小值 N;</li>\n<li>用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;</li>\n<li>取不小于 X 的第一个 ID 的行。\n我们把这个算法，暂时称作随机算法 1。这里，我直接给你贴一下执行语句的序列:</li>\n</ol>\n<pre><code class=\"SQL\">mysql&gt; select max(id),min(id) into @M,@N from t ;\nset @X= floor((@M-@N+1)*rand() + @N);\nselect * from t where id &gt;= @X limit 1;\n</code></pre>\n<p>这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。\n如果这四行的 id 分别是 1、2、40000、40001 呢？这个算法基本就能当 bug 来看待了。</p>\n<p>所以，为了得到严格随机的结果，你可以用下面这个流程:</p>\n<ol>\n<li>取得整个表的行数，并记为 C。</li>\n<li>取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。</li>\n<li>再用 limit Y,1 取得一行。</li>\n</ol>\n<p>我们把这个算法，称为随机算法 2。下面这段代码，就是上面流程的执行语句的序列。</p>\n<pre><code class=\"SQL\">mysql&gt; select count(*) into @C from t;\nset @Y = floor(@C * rand());\nset @sql = concat(&quot;select * from t limit &quot;, @Y, &quot;,1&quot;);\nprepare stmt from @sql;\nexecute stmt;\nDEALLOCATE prepare stmt;\n</code></pre>\n<p>由于 limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了 prepare+execute 的方法。你也可以把拼接 SQL 语句的方法写在应用程序中，会更简单些。\n这个随机算法 2，解决了算法 1 里面明显的概率不均匀问题。\nMySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。\n当然，随机算法 2 跟直接 order by rand() 比起来，执行代价还是小很多的。\n你可能问了，如果按照这个表有 10000 行来计算的话，C=10000，要是随机到比较大的 Y 值，那扫描行数也跟 20000 差不多了，接近 order by rand() 的扫描行数，为什么说随机算法 2 的代价要小很多呢？我就把这个问题留给你去课后思考吧。\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：</p>\n<ol>\n<li>取得整个表的行数，记为 C；</li>\n<li>根据相同的随机方法得到 Y1、Y2、Y3；</li>\n<li>再执行三个 limit Y, 1 语句得到三行数据。\n我们把这个算法，称作随机算法 3。下面这段代码，就是上面流程的执行语句的序列。</li>\n</ol>\n<pre><code class=\"SQL\">mysql&gt; select count(*) into @C from t;\nset @Y1 = floor(@C * rand());\nset @Y2 = floor(@C * rand());\nset @Y3 = floor(@C * rand());\nselect * from t limit @Y1，1； // 在应用代码里面取 Y1、Y2、Y3 值，拼出 SQL 后执行\nselect * from t limit @Y2，1；\nselect * from t limit @Y3，1；\n</code></pre>\n<br/>\n### 小结\n\n<p>今天这篇文章，我是借着随机排序的需求，跟你介绍了 MySQL 对临时表排序的执行过程。\n如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要量避开这种写法。\n今天的例子里面，我们不是仅仅在数据库内部解决问题，还会让应用代码配合拼接 SQL 语句。在实际应用的过程中，比较规范的用法就是：尽量将业务逻辑写在业务代码中，让数据库只做“读写数据”的事情。因此，这类方法的应用还是比较广泛的。\n最后，我给你留下一个思考题吧。\n上面的随机算法 3 的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。\n我的问题是，如果你是这个需求的开发人员，你会怎么做，来减少扫描行数呢？说说你的方案，并说明你的方案需要的扫描行数。\n这里我给出一种方法，取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t limit N, M-N+1;\n</code></pre>\n<p>再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n当然也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句也是可以的。</p>"},{"title":"18 | 为什么这些SQL语句逻辑相同，性能却差异巨大","date":"2019-06-02T16:00:00.000Z","_content":"在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。\n我今天挑选了三个这样的案例和你分享。希望再遇到相似的问题时，你可以做到举一反三、快速解决问题。\n\n<br/>\n### 案例一：条件字段函数操作\n\n假设你现在维护了一个交易系统，其中交易记录表 `tradelog` 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：\n\n```SQL\nmysql> CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n```\n\n假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：\n\n```SQL\nmysql> select count(*) from tradelog where month(t_modified)=7;\n```\n\n由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。\n如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。\n现在你已经学过了 InnoDB 的索引结构了，可以再追问一句为什么？为什么条件是 where t_modified='2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？\n下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值。\n\n![图 1 t_modified 索引示意图](1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg)\n\n如果你的 SQL 语句条件用的是 `where t_modified='2018-7-1’`的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified='2018-7-1’需要的结果。\n实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。\n但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。\n也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。需要注意的是，优化器并不是要放弃使用这个索引。\n在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。\n接下来，我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。\n\n![图 2 explain 结果](1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg)\n\nkey=\"t_modified\"表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引。\n也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。\n\n```SQL\nmysql> select count(*) from tradelog where\n    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or\n    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or \n    -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');\n```\n\n当然，如果你的系统上线时间更早，或者后面又插入了之后年份的数据的话，你就需要再把其他年份补齐。\n到这里我给你说明了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。\n不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。\n\n<br/>\n### 案例二：隐式类型转换\n\n接下来我再跟你说一说，另一个经常让程序员掉坑里的例子。\n我们一起看一下这条 SQL 语句：\n\n```SQL\nmysql> select * from tradelog where tradeid=110717;\n```\n\n交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。\n\n那么，现在这里就有两个问题：\n\n1. 数据类型转换的规则是什么？\n2. 为什么有数据类型转换，就需要走全索引扫描？\n先来看第一个问题，你可能会说，数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？\n\n这里有一个简单的方法，看 `select “10” > 9` 的结果：\n\n1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；\n2. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。\n验证结果如图 3 所示。\n\n![图 3 MySQL 中字符串和数字转换的效果示意图](1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg)\n\n从图中可知，select “10” > 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。\n这时，你再看这个全表扫描的语句：\n\n```SQL\nmysql> select * from tradelog where tradeid=110717;\n```\n\n就知道对于优化器来说，这个语句相当于：\n\n```SQL\nmysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;\n```\n\n也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？\n\n```SQL\nselect * from tradelog where id=\"83126\";\n```\n\n你可以先自己分析一下，再到数据库里面去验证确认。\n接下来，我们再来看一个稍微复杂点的例子。\n\n<br/>\n### 案例三：隐式字符编码转换\n\n假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。\n\n```SQL\nmysql> CREATE TABLE `trade_detail` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `trade_step` int(11) DEFAULT NULL, /* 操作步骤 */\n  `step_info` varchar(32) DEFAULT NULL, /* 步骤信息 */\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n \ninsert into tradelog values(1, 'aaaaaaaa', 1000, now());\ninsert into tradelog values(2, 'aaaaaaab', 1000, now());\ninsert into tradelog values(3, 'aaaaaaac', 1000, now());\n \ninsert into trade_detail values(1, 'aaaaaaaa', 1, 'add');\ninsert into trade_detail values(2, 'aaaaaaaa', 2, 'update');\ninsert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');\ninsert into trade_detail values(4, 'aaaaaaab', 1, 'add');\ninsert into trade_detail values(5, 'aaaaaaab', 2, 'update');\ninsert into trade_detail values(6, 'aaaaaaab', 3, 'update again');\ninsert into trade_detail values(7, 'aaaaaaab', 4, 'commit');\ninsert into trade_detail values(8, 'aaaaaaac', 1, 'add');\ninsert into trade_detail values(9, 'aaaaaaac', 2, 'update');\ninsert into trade_detail values(10, 'aaaaaaac', 3, 'update again');\ninsert into trade_detail values(11, 'aaaaaaac', 4, 'commit');\n```\n\n这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：\n\n```SQL\n/* 语句 Q1*/\nmysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; \n```\n\n![图 4 语句 Q1 的 explain 结果](1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg)\n\n我们一起来看下这个结果：\n\n1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；\n2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。\n在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 称为关联字段。\n接下来，我们看下这个 explain 结果表示的执行流程：\n\n![图 5 语句 Q1 的执行过程](1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg)\n\n图中：\n\n1. 是根据 id 在 tradelog 表里找到 L2 这一行；\n2. 是从 L2 中取出 tradeid 字段的值；\n3. 是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配。\n进行到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过使用 tradeid 索引能够快速定位到等值的行。但，这里并没有。\n如果你去问 DBA 同学，他们可能会告诉你，因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。\n但是你应该再追问一下，为什么字符集不同就用不上索引呢？\n我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：\n\n```SQL\nmysql> select * from trade_detail where tradeid=$L2.tradeid.value;\n```\n\n其中，$L2.tradeid.value 的字符集是 utf8mb4。\n参照前面的两个例子，你肯定就想到了，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。\n这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。\n也就是说，实际上这个语句等同于下面这个写法：\n\n```SQL\nselect * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; \n```\n\nCONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。\n这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n到这里，你终于明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。\n作为对比验证，我给你提另外一个需求，“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。\nmysql>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;\n\n![图 6 explain 结果](1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg)\n\n这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1。\n这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？我们来分析一下。\n假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接的时候（图 5 的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：\n\n```SQL\nselect operator from tradelog  where traideid =$R4.tradeid.value; \n```\n\n这时候 $R4.tradeid.value 的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：\n\n```SQL\nselect operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); \n```\n\n你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。\n理解了原理以后，就可以用来指导操作了。如果要优化语句\n\n```SQL\nselect d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;\n```\n\n的执行过程，有两种做法：\n比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。\n\n```SQL\nalter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;\n```\n\n如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。\n\n```SQL\nmysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; \n```\n\n![图 7 SQL 语句优化后的 explain 结果](1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg)\n\n这里，我主动把 l.tradeid 转成 `utf8`，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。\n\n<br/>\n### 小结\n\n今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n今天我留给你的课后问题是，你遇到过别的、类似今天我们提到的性能问题吗？你认为原因是什么，又是怎么解决的呢？\n@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：\n\n```SQL\nmysql> CREATE TABLE `table_a` (\n  `id` int(11) NOT NULL,\n  `b` varchar(10) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB;\n```\n\n假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:\n\n```SQL\nmysql> select * from table_a where b='1234567890abcd';\n```\n\n这时候，MySQL 会怎么执行呢？\n最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。\n但实际上，MySQL 也不是这么做的。\n\n这条 SQL 语句的执行很慢，流程是这样的：\n\n1. 在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；这样满足条件的数据有 10 万行；\n2. 因为是 select *， 所以要做 10 万次回表；\n3. 但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;\n4. 返回结果是空。\n这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。\n","source":"_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大.md","raw":"---\ntitle: 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。\n我今天挑选了三个这样的案例和你分享。希望再遇到相似的问题时，你可以做到举一反三、快速解决问题。\n\n<br/>\n### 案例一：条件字段函数操作\n\n假设你现在维护了一个交易系统，其中交易记录表 `tradelog` 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：\n\n```SQL\nmysql> CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n```\n\n假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：\n\n```SQL\nmysql> select count(*) from tradelog where month(t_modified)=7;\n```\n\n由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。\n如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。\n现在你已经学过了 InnoDB 的索引结构了，可以再追问一句为什么？为什么条件是 where t_modified='2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？\n下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值。\n\n![图 1 t_modified 索引示意图](1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg)\n\n如果你的 SQL 语句条件用的是 `where t_modified='2018-7-1’`的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified='2018-7-1’需要的结果。\n实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。\n但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。\n也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。需要注意的是，优化器并不是要放弃使用这个索引。\n在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。\n接下来，我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。\n\n![图 2 explain 结果](1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg)\n\nkey=\"t_modified\"表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引。\n也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。\n\n```SQL\nmysql> select count(*) from tradelog where\n    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or\n    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or \n    -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');\n```\n\n当然，如果你的系统上线时间更早，或者后面又插入了之后年份的数据的话，你就需要再把其他年份补齐。\n到这里我给你说明了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。\n不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。\n\n<br/>\n### 案例二：隐式类型转换\n\n接下来我再跟你说一说，另一个经常让程序员掉坑里的例子。\n我们一起看一下这条 SQL 语句：\n\n```SQL\nmysql> select * from tradelog where tradeid=110717;\n```\n\n交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。\n\n那么，现在这里就有两个问题：\n\n1. 数据类型转换的规则是什么？\n2. 为什么有数据类型转换，就需要走全索引扫描？\n先来看第一个问题，你可能会说，数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？\n\n这里有一个简单的方法，看 `select “10” > 9` 的结果：\n\n1. 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；\n2. 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。\n验证结果如图 3 所示。\n\n![图 3 MySQL 中字符串和数字转换的效果示意图](1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg)\n\n从图中可知，select “10” > 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。\n这时，你再看这个全表扫描的语句：\n\n```SQL\nmysql> select * from tradelog where tradeid=110717;\n```\n\n就知道对于优化器来说，这个语句相当于：\n\n```SQL\nmysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;\n```\n\n也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？\n\n```SQL\nselect * from tradelog where id=\"83126\";\n```\n\n你可以先自己分析一下，再到数据库里面去验证确认。\n接下来，我们再来看一个稍微复杂点的例子。\n\n<br/>\n### 案例三：隐式字符编码转换\n\n假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。\n\n```SQL\nmysql> CREATE TABLE `trade_detail` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `trade_step` int(11) DEFAULT NULL, /* 操作步骤 */\n  `step_info` varchar(32) DEFAULT NULL, /* 步骤信息 */\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n \ninsert into tradelog values(1, 'aaaaaaaa', 1000, now());\ninsert into tradelog values(2, 'aaaaaaab', 1000, now());\ninsert into tradelog values(3, 'aaaaaaac', 1000, now());\n \ninsert into trade_detail values(1, 'aaaaaaaa', 1, 'add');\ninsert into trade_detail values(2, 'aaaaaaaa', 2, 'update');\ninsert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');\ninsert into trade_detail values(4, 'aaaaaaab', 1, 'add');\ninsert into trade_detail values(5, 'aaaaaaab', 2, 'update');\ninsert into trade_detail values(6, 'aaaaaaab', 3, 'update again');\ninsert into trade_detail values(7, 'aaaaaaab', 4, 'commit');\ninsert into trade_detail values(8, 'aaaaaaac', 1, 'add');\ninsert into trade_detail values(9, 'aaaaaaac', 2, 'update');\ninsert into trade_detail values(10, 'aaaaaaac', 3, 'update again');\ninsert into trade_detail values(11, 'aaaaaaac', 4, 'commit');\n```\n\n这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：\n\n```SQL\n/* 语句 Q1*/\nmysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; \n```\n\n![图 4 语句 Q1 的 explain 结果](1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg)\n\n我们一起来看下这个结果：\n\n1. 第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；\n2. 第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。\n在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 称为关联字段。\n接下来，我们看下这个 explain 结果表示的执行流程：\n\n![图 5 语句 Q1 的执行过程](1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg)\n\n图中：\n\n1. 是根据 id 在 tradelog 表里找到 L2 这一行；\n2. 是从 L2 中取出 tradeid 字段的值；\n3. 是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配。\n进行到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过使用 tradeid 索引能够快速定位到等值的行。但，这里并没有。\n如果你去问 DBA 同学，他们可能会告诉你，因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。\n但是你应该再追问一下，为什么字符集不同就用不上索引呢？\n我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：\n\n```SQL\nmysql> select * from trade_detail where tradeid=$L2.tradeid.value;\n```\n\n其中，$L2.tradeid.value 的字符集是 utf8mb4。\n参照前面的两个例子，你肯定就想到了，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。\n这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。\n也就是说，实际上这个语句等同于下面这个写法：\n\n```SQL\nselect * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; \n```\n\nCONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。\n这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n到这里，你终于明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。\n作为对比验证，我给你提另外一个需求，“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。\nmysql>select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;\n\n![图 6 explain 结果](1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg)\n\n这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1。\n这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？我们来分析一下。\n假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接的时候（图 5 的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：\n\n```SQL\nselect operator from tradelog  where traideid =$R4.tradeid.value; \n```\n\n这时候 $R4.tradeid.value 的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：\n\n```SQL\nselect operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); \n```\n\n你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。\n理解了原理以后，就可以用来指导操作了。如果要优化语句\n\n```SQL\nselect d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;\n```\n\n的执行过程，有两种做法：\n比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。\n\n```SQL\nalter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;\n```\n\n如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。\n\n```SQL\nmysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; \n```\n\n![图 7 SQL 语句优化后的 explain 结果](1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg)\n\n这里，我主动把 l.tradeid 转成 `utf8`，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。\n\n<br/>\n### 小结\n\n今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n今天我留给你的课后问题是，你遇到过别的、类似今天我们提到的性能问题吗？你认为原因是什么，又是怎么解决的呢？\n@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：\n\n```SQL\nmysql> CREATE TABLE `table_a` (\n  `id` int(11) NOT NULL,\n  `b` varchar(10) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB;\n```\n\n假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:\n\n```SQL\nmysql> select * from table_a where b='1234567890abcd';\n```\n\n这时候，MySQL 会怎么执行呢？\n最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。\n但实际上，MySQL 也不是这么做的。\n\n这条 SQL 语句的执行很慢，流程是这样的：\n\n1. 在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；这样满足条件的数据有 10 万行；\n2. 因为是 select *， 所以要做 10 万次回表；\n3. 但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;\n4. 返回结果是空。\n这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。\n","slug":"18-为什么这些SQL语句逻辑相同，性能却差异巨大","published":1,"updated":"2021-06-30T02:33:24.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvh001ir5p772qt3n1o","content":"<p>在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。\n我今天挑选了三个这样的案例和你分享。希望再遇到相似的问题时，你可以做到举一反三、快速解决问题。</p>\n<br>\n### 案例一：条件字段函数操作\n\n<p>假设你现在维护了一个交易系统，其中交易记录表 <code>tradelog</code> 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n</code></pre>\n<p>假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select count(*) from tradelog where month(t_modified)=7;\n</code></pre>\n<p>由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。\n如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。\n现在你已经学过了 InnoDB 的索引结构了，可以再追问一句为什么？为什么条件是 where t_modified=’2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？\n下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值。</p>\n<p><img src=\"1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg\" alt=\"图 1 t_modified 索引示意图\"></p>\n<p>如果你的 SQL 语句条件用的是 <code>where t_modified='2018-7-1’</code>的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified=’2018-7-1’需要的结果。\n实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。\n但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。\n也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。需要注意的是，优化器并不是要放弃使用这个索引。\n在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。\n接下来，我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。</p>\n<p><img src=\"1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg\" alt=\"图 2 explain 结果\"></p>\n<p>key=”t_modified”表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引。\n也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select count(*) from tradelog where\n    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or\n    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or \n    -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');\n</code></pre>\n<p>当然，如果你的系统上线时间更早，或者后面又插入了之后年份的数据的话，你就需要再把其他年份补齐。\n到这里我给你说明了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。\n不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。</p>\n<br>\n### 案例二：隐式类型转换\n\n<p>接下来我再跟你说一说，另一个经常让程序员掉坑里的例子。\n我们一起看一下这条 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from tradelog where tradeid=110717;\n</code></pre>\n<p>交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。</p>\n<p>那么，现在这里就有两个问题：</p>\n<ol>\n<li>数据类型转换的规则是什么？</li>\n<li>为什么有数据类型转换，就需要走全索引扫描？\n先来看第一个问题，你可能会说，数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？</li>\n</ol>\n<p>这里有一个简单的方法，看 <code>select “10” &gt; 9</code> 的结果：</p>\n<ol>\n<li>如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；</li>\n<li>如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。\n验证结果如图 3 所示。</li>\n</ol>\n<p><img src=\"1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg\" alt=\"图 3 MySQL 中字符串和数字转换的效果示意图\"></p>\n<p>从图中可知，select “10” &gt; 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。\n这时，你再看这个全表扫描的语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from tradelog where tradeid=110717;\n</code></pre>\n<p>就知道对于优化器来说，这个语句相当于：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;\n</code></pre>\n<p>也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select * from tradelog where id=\"83126\";\n</code></pre>\n<p>你可以先自己分析一下，再到数据库里面去验证确认。\n接下来，我们再来看一个稍微复杂点的例子。</p>\n<br>\n### 案例三：隐式字符编码转换\n\n<p>假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `trade_detail` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `trade_step` int(11) DEFAULT NULL, /* 操作步骤 */\n  `step_info` varchar(32) DEFAULT NULL, /* 步骤信息 */\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n \ninsert into tradelog values(1, 'aaaaaaaa', 1000, now());\ninsert into tradelog values(2, 'aaaaaaab', 1000, now());\ninsert into tradelog values(3, 'aaaaaaac', 1000, now());\n \ninsert into trade_detail values(1, 'aaaaaaaa', 1, 'add');\ninsert into trade_detail values(2, 'aaaaaaaa', 2, 'update');\ninsert into trade_detail values(3, 'aaaaaaaa', 3, 'commit');\ninsert into trade_detail values(4, 'aaaaaaab', 1, 'add');\ninsert into trade_detail values(5, 'aaaaaaab', 2, 'update');\ninsert into trade_detail values(6, 'aaaaaaab', 3, 'update again');\ninsert into trade_detail values(7, 'aaaaaaab', 4, 'commit');\ninsert into trade_detail values(8, 'aaaaaaac', 1, 'add');\ninsert into trade_detail values(9, 'aaaaaaac', 2, 'update');\ninsert into trade_detail values(10, 'aaaaaaac', 3, 'update again');\ninsert into trade_detail values(11, 'aaaaaaac', 4, 'commit');\n</code></pre>\n<p>这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">/* 语句 Q1*/\nmysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; \n</code></pre>\n<p><img src=\"1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg\" alt=\"图 4 语句 Q1 的 explain 结果\"></p>\n<p>我们一起来看下这个结果：</p>\n<ol>\n<li>第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；</li>\n<li>第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。\n在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 称为关联字段。\n接下来，我们看下这个 explain 结果表示的执行流程：</li>\n</ol>\n<p><img src=\"1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg\" alt=\"图 5 语句 Q1 的执行过程\"></p>\n<p>图中：</p>\n<ol>\n<li>是根据 id 在 tradelog 表里找到 L2 这一行；</li>\n<li>是从 L2 中取出 tradeid 字段的值；</li>\n<li>是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配。\n进行到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过使用 tradeid 索引能够快速定位到等值的行。但，这里并没有。\n如果你去问 DBA 同学，他们可能会告诉你，因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。\n但是你应该再追问一下，为什么字符集不同就用不上索引呢？\n我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：</li>\n</ol>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from trade_detail where tradeid=$L2.tradeid.value;\n</code></pre>\n<p>其中，$L2.tradeid.value 的字符集是 utf8mb4。\n参照前面的两个例子，你肯定就想到了，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。\n这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。\n也就是说，实际上这个语句等同于下面这个写法：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; \n</code></pre>\n<p>CONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。\n这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n到这里，你终于明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。\n作为对比验证，我给你提另外一个需求，“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。\nmysql&gt;select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;</p>\n<p><img src=\"1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg\" alt=\"图 6 explain 结果\"></p>\n<p>这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1。\n这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？我们来分析一下。\n假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接的时候（图 5 的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select operator from tradelog  where traideid =$R4.tradeid.value; \n</code></pre>\n<p>这时候 $R4.tradeid.value 的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); \n</code></pre>\n<p>你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。\n理解了原理以后，就可以用来指导操作了。如果要优化语句</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;\n</code></pre>\n<p>的执行过程，有两种做法：\n比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;\n</code></pre>\n<p>如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; \n</code></pre>\n<p><img src=\"1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg\" alt=\"图 7 SQL 语句优化后的 explain 结果\"></p>\n<p>这里，我主动把 l.tradeid 转成 <code>utf8</code>，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。</p>\n<br>\n### 小结\n\n<p>今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n今天我留给你的课后问题是，你遇到过别的、类似今天我们提到的性能问题吗？你认为原因是什么，又是怎么解决的呢？\n@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `table_a` (\n  `id` int(11) NOT NULL,\n  `b` varchar(10) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from table_a where b='1234567890abcd';\n</code></pre>\n<p>这时候，MySQL 会怎么执行呢？\n最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。\n但实际上，MySQL 也不是这么做的。</p>\n<p>这条 SQL 语句的执行很慢，流程是这样的：</p>\n<ol>\n<li>在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；这样满足条件的数据有 10 万行；</li>\n<li>因为是 select *， 所以要做 10 万次回表；</li>\n<li>但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;</li>\n<li>返回结果是空。\n这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>在 MySQL 中，有很多看上去逻辑相同，但性能却差异巨大的 SQL 语句。对这些语句使用不当的话，就会不经意间导致整个数据库的压力变大。\n我今天挑选了三个这样的案例和你分享。希望再遇到相似的问题时，你可以做到举一反三、快速解决问题。</p>\n<br/>\n### 案例一：条件字段函数操作\n\n<p>假设你现在维护了一个交易系统，其中交易记录表 <code>tradelog</code> 包含交易流水号（tradeid）、交易员 id（operator）、交易时间（t_modified）等字段。为了便于描述，我们先忽略其他字段。这个表的建表语句如下：</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `tradelog` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `operator` int(11) DEFAULT NULL,\n  `t_modified` datetime DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`),\n  KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n</code></pre>\n<p>假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，运营部门有一个需求是，要统计发生在所有年份中 7 月份的交易记录总数。这个逻辑看上去并不复杂，你的 SQL 语句可能会这么写：</p>\n<pre><code class=\"SQL\">mysql&gt; select count(*) from tradelog where month(t_modified)=7;\n</code></pre>\n<p>由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现执行了特别久，才返回了结果。\n如果你问 DBA 同事为什么会出现这样的情况，他大概会告诉你：如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。\n现在你已经学过了 InnoDB 的索引结构了，可以再追问一句为什么？为什么条件是 where t_modified=’2018-7-1’的时候可以用上索引，而改成 where month(t_modified)=7 的时候就不行了？\n下面是这个 t_modified 索引的示意图。方框上面的数字就是 month() 函数对应的值。</p>\n<p><img src=\"1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg\" alt=\"图 1 t_modified 索引示意图\"></p>\n<p>如果你的 SQL 语句条件用的是 <code>where t_modified=&#39;2018-7-1’</code>的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified=’2018-7-1’需要的结果。\n实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。\n但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。\n也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。需要注意的是，优化器并不是要放弃使用这个索引。\n在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。\n接下来，我们使用 explain 命令，查看一下这条 SQL 语句的执行结果。</p>\n<p><img src=\"1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg\" alt=\"图 2 explain 结果\"></p>\n<p>key=”t_modified”表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows=100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引。\n也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。</p>\n<pre><code class=\"SQL\">mysql&gt; select count(*) from tradelog where\n    -&gt; (t_modified &gt;= &#39;2016-7-1&#39; and t_modified&lt;&#39;2016-8-1&#39;) or\n    -&gt; (t_modified &gt;= &#39;2017-7-1&#39; and t_modified&lt;&#39;2017-8-1&#39;) or \n    -&gt; (t_modified &gt;= &#39;2018-7-1&#39; and t_modified&lt;&#39;2018-8-1&#39;);\n</code></pre>\n<p>当然，如果你的系统上线时间更早，或者后面又插入了之后年份的数据的话，你就需要再把其他年份补齐。\n到这里我给你说明了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描。\n不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。</p>\n<br/>\n### 案例二：隐式类型转换\n\n<p>接下来我再跟你说一说，另一个经常让程序员掉坑里的例子。\n我们一起看一下这条 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from tradelog where tradeid=110717;\n</code></pre>\n<p>交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果却显示，这条语句需要走全表扫描。你可能也发现了，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。</p>\n<p>那么，现在这里就有两个问题：</p>\n<ol>\n<li>数据类型转换的规则是什么？</li>\n<li>为什么有数据类型转换，就需要走全索引扫描？\n先来看第一个问题，你可能会说，数据库里面类型这么多，这种数据类型转换规则更多，我记不住，应该怎么办呢？</li>\n</ol>\n<p>这里有一个简单的方法，看 <code>select “10” &gt; 9</code> 的结果：</p>\n<ol>\n<li>如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1；</li>\n<li>如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。\n验证结果如图 3 所示。</li>\n</ol>\n<p><img src=\"1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg\" alt=\"图 3 MySQL 中字符串和数字转换的效果示意图\"></p>\n<p>从图中可知，select “10” &gt; 9 返回的是 1，所以你就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。\n这时，你再看这个全表扫描的语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from tradelog where tradeid=110717;\n</code></pre>\n<p>就知道对于优化器来说，这个语句相当于：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from tradelog where  CAST(tradid AS signed int) = 110717;\n</code></pre>\n<p>也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n现在，我留给你一个小问题，id 的类型是 int，如果执行下面这个语句，是否会导致全表扫描呢？</p>\n<pre><code class=\"SQL\">select * from tradelog where id=&quot;83126&quot;;\n</code></pre>\n<p>你可以先自己分析一下，再到数据库里面去验证确认。\n接下来，我们再来看一个稍微复杂点的例子。</p>\n<br/>\n### 案例三：隐式字符编码转换\n\n<p>假设系统里还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据。</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `trade_detail` (\n  `id` int(11) NOT NULL,\n  `tradeid` varchar(32) DEFAULT NULL,\n  `trade_step` int(11) DEFAULT NULL, /* 操作步骤 */\n  `step_info` varchar(32) DEFAULT NULL, /* 步骤信息 */\n  PRIMARY KEY (`id`),\n  KEY `tradeid` (`tradeid`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n \ninsert into tradelog values(1, &#39;aaaaaaaa&#39;, 1000, now());\ninsert into tradelog values(2, &#39;aaaaaaab&#39;, 1000, now());\ninsert into tradelog values(3, &#39;aaaaaaac&#39;, 1000, now());\n \ninsert into trade_detail values(1, &#39;aaaaaaaa&#39;, 1, &#39;add&#39;);\ninsert into trade_detail values(2, &#39;aaaaaaaa&#39;, 2, &#39;update&#39;);\ninsert into trade_detail values(3, &#39;aaaaaaaa&#39;, 3, &#39;commit&#39;);\ninsert into trade_detail values(4, &#39;aaaaaaab&#39;, 1, &#39;add&#39;);\ninsert into trade_detail values(5, &#39;aaaaaaab&#39;, 2, &#39;update&#39;);\ninsert into trade_detail values(6, &#39;aaaaaaab&#39;, 3, &#39;update again&#39;);\ninsert into trade_detail values(7, &#39;aaaaaaab&#39;, 4, &#39;commit&#39;);\ninsert into trade_detail values(8, &#39;aaaaaaac&#39;, 1, &#39;add&#39;);\ninsert into trade_detail values(9, &#39;aaaaaaac&#39;, 2, &#39;update&#39;);\ninsert into trade_detail values(10, &#39;aaaaaaac&#39;, 3, &#39;update again&#39;);\ninsert into trade_detail values(11, &#39;aaaaaaac&#39;, 4, &#39;commit&#39;);\n</code></pre>\n<p>这时候，如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：</p>\n<pre><code class=\"SQL\">/* 语句 Q1*/\nmysql&gt; select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; \n</code></pre>\n<p><img src=\"1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg\" alt=\"图 4 语句 Q1 的 explain 结果\"></p>\n<p>我们一起来看下这个结果：</p>\n<ol>\n<li>第一行显示优化器会先在交易记录表 tradelog 上查到 id=2 的行，这个步骤用上了主键索引，rows=1 表示只扫描一行；</li>\n<li>第二行 key=NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描。\n在这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 称为关联字段。\n接下来，我们看下这个 explain 结果表示的执行流程：</li>\n</ol>\n<p><img src=\"1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg\" alt=\"图 5 语句 Q1 的执行过程\"></p>\n<p>图中：</p>\n<ol>\n<li>是根据 id 在 tradelog 表里找到 L2 这一行；</li>\n<li>是从 L2 中取出 tradeid 字段的值；</li>\n<li>是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key=NULL 表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配。\n进行到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 里 tradeid 字段上是有索引的，我们本来是希望通过使用 tradeid 索引能够快速定位到等值的行。但，这里并没有。\n如果你去问 DBA 同学，他们可能会告诉你，因为这两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。\n但是你应该再追问一下，为什么字符集不同就用不上索引呢？\n我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是：</li>\n</ol>\n<pre><code class=\"SQL\">mysql&gt; select * from trade_detail where tradeid=$L2.tradeid.value;\n</code></pre>\n<p>其中，$L2.tradeid.value 的字符集是 utf8mb4。\n参照前面的两个例子，你肯定就想到了，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。\n这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。\n也就是说，实际上这个语句等同于下面这个写法：</p>\n<pre><code class=\"SQL\">select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; \n</code></pre>\n<p>CONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。\n这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n到这里，你终于明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。\n作为对比验证，我给你提另外一个需求，“查找 trade_detail 表里 id=4 的操作，对应的操作者是谁”，再来看下这个语句和它的执行计划。\nmysql&gt;select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4;</p>\n<p><img src=\"1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg\" alt=\"图 6 explain 结果\"></p>\n<p>这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1。\n这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？我们来分析一下。\n假设驱动表 trade_detail 里 id=4 的行记为 R4，那么在连接的时候（图 5 的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句：</p>\n<pre><code class=\"SQL\">select operator from tradelog  where traideid =$R4.tradeid.value; \n</code></pre>\n<p>这时候 $R4.tradeid.value 的字符集是 utf8, 按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成：</p>\n<pre><code class=\"SQL\">select operator from tradelog  where traideid =CONVERT($R4.tradeid.value USING utf8mb4); \n</code></pre>\n<p>你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 traideid 索引。\n理解了原理以后，就可以用来指导操作了。如果要优化语句</p>\n<pre><code class=\"SQL\">select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2;\n</code></pre>\n<p>的执行过程，有两种做法：\n比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。</p>\n<pre><code class=\"SQL\">alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;\n</code></pre>\n<p>如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。</p>\n<pre><code class=\"SQL\">mysql&gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; \n</code></pre>\n<p><img src=\"1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg\" alt=\"图 7 SQL 语句优化后的 explain 结果\"></p>\n<p>这里，我主动把 l.tradeid 转成 <code>utf8</code>，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。</p>\n<br/>\n### 小结\n\n<p>今天我给你举了三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n第二个例子是隐式类型转换，第三个例子是隐式字符编码转换，它们都跟第一个例子一样，因为要求在索引字段上做函数操作而导致了全索引扫描。\nMySQL 的优化器确实有“偷懒”的嫌疑，即使简单地把 where id+1=1000 改写成 where id=1000-1 就能够用上索引快速查找，也不会主动做这个语句重写。\n因此，每次你的业务代码升级时，把可能出现的、新的 SQL 语句 explain 一下，是一个很好的习惯。\n今天我留给你的课后问题是，你遇到过别的、类似今天我们提到的性能问题吗？你认为原因是什么，又是怎么解决的呢？\n@封建的风 提到一个有趣的场景，值得一说。我把他的问题重写一下，表结构如下：</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `table_a` (\n  `id` int(11) NOT NULL,\n  `b` varchar(10) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB;\n</code></pre>\n<p>假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’， 假设现在执行语句是这么写的:</p>\n<pre><code class=\"SQL\">mysql&gt; select * from table_a where b=&#39;1234567890abcd&#39;;\n</code></pre>\n<p>这时候，MySQL 会怎么执行呢？\n最理想的情况是，MySQL 看到字段 b 定义的是 varchar(10)，那肯定返回空呀。可惜，MySQL 并没有这么做。那要不，就是把’1234567890abcd’拿到索引里面去做匹配，肯定也没能够快速判断出索引树 b 上并没有这个值，也很快就能返回空结果。\n但实际上，MySQL 也不是这么做的。</p>\n<p>这条 SQL 语句的执行很慢，流程是这样的：</p>\n<ol>\n<li>在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配；这样满足条件的数据有 10 万行；</li>\n<li>因为是 select *， 所以要做 10 万次回表；</li>\n<li>但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’;</li>\n<li>返回结果是空。\n这个例子，是我们文章内容的一个很好的补充。虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。</li>\n</ol>\n"},{"title":"19 | 为什么我只查一行的语句，也执行这么慢","date":"2019-06-02T16:00:00.000Z","_content":"一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话题，看看什么情况下，会出现这个现象。\n需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。\n为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。\n\n```SQL\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata();\n```\n\n接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看能不能一眼看穿，来检验一下吧。\n\n## 第一类：查询长时间不返回\n\n如图 1 所示，在表 t 执行下面的 SQL 语句：\n\n```SQL\nmysql> select * from t where id=1;\n```\n\n查询结果长时间不返回\n\n![图 1 查询长时间不返回](1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg)\n\n一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。\n然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。\n\n### 等 MDL 锁\n\n如图 2 所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。\n\n![图 2 Waiting for table metadata lock 状态示意图](1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg)\n\n出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。\n在第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现方法。但需要说明的是，那个复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。(online-ddl过程写锁转读锁)\n不过，在 MySQL 5.7 版本下复现这个场景，也很容易。如图 3 所示，我给出了简单的复现步骤。\n\n![图 3 MySQL 5.7 中 Waiting for table metadata lock 的复现步骤](1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg)\n\nsession A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。\n这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。\n但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。\n\n![图 4 查获加表锁的线程 id](1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg)\n\n<br/>\n### 等 flush\n\n接下来，我给你举另外一种查询被堵住的情况。\n我在表 t 上，执行下面的 SQL 语句：\n\n```SQL\n mysql> select * from t where id=1;\n```\n\n这里，我先卖个关子。\n你可以看一下图 5。我查出来这个线程的状态是 Waiting for table flush，你可以设想一下这是什么原因。\n\n![图 5 Waiting for table flush 状态示意图](1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg)\n\n这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：\n\n1. flush tables t with read lock;\n2. flush tables with read lock;\n这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n现在，我们一起来复现一下这种情况，复现步骤如图 6 所示：\n\n![图 6 Waiting for table flush 的复现步骤](1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg)\n\n在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。\n图 7 是这个复现步骤的 show processlist 结果。这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。\n\n![图 7 Waiting for table flush 的 show processlist 结果](1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg)\n\n\n<br/>\n### 等行锁\n\n现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。\nmysql> select * from t where id=1 lock in share mode; \n上面这条语句的用法你也很熟悉了，我们在第 8 篇《事务到底是隔离的还是不隔离的？》文章介绍当前读时提到过。\n由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n复现步骤和现场如下：\n\n![图 8 行锁复现](1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg)\n\n![图 9 行锁 show processlist 现场](1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg)\n\n显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。\n查询方法是：\n```SQL\nmysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\\G\n```\n\n![图 10 通过 sys.innodb_lock_waits 查行锁](1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg)\n\n可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。\n不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。\n实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。\n\n## 第二类：查询慢\n\n经过了重重封“锁”，我们再来看看一些查询慢的例子。\n先来看一条你一定知道原因的 SQL 语句：\n\n```SQL\nmysql> select * from t where c=50000 limit 1;\n```\n\n由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 万行。\n作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。\n\n![图 11 全表扫描 5 万行的 slow log](1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg)\n\nRows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。\n扫描行数多，所以执行慢，这个很好理解。\n但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。\n如图 12 所示，是这个例子的 slow log。可以看到，执行的语句是\n\n```SQL\nmysql> select * from t where id=1；\n```\n\n虽然扫描行数是 1，但执行时间却长达 800 毫秒。\n\n![图 12 扫描一行却执行得很慢](1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg)\n\n是不是有点奇怪呢，这些时间都花在哪里了？\n如果我把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。\n\n![图 13 加上 lock in share mode 的 slow log](1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg)\n\n看上去是不是更奇怪了？按理说 lock in share mode 还要加锁，时间应该更长才对啊。\n可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图 14 是这两个语句的执行输出结果。\n\n![图 14 两个语句的输出结果](1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg)\n\n第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。\n\n![图 15 复现步骤](1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg)\n\n你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。\nsession B 执行完 100 万次 update 语句后，id=1 这一行处于什么状态呢？你可以从图 16 中找到答案。\n\n![图 16 id=1 的数据状态](1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg)\n\nsession B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。\n带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便你看图。\n\n\n## 小结\n\n今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。\n在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来定位并解决问题。\n最后，我给你留一个问题吧。\n我们在举例加锁读的时候，用的是这个语句，select * from t where id=1 lock in share mode。由于 id 上有索引，所以可以直接定位到 id=1 这一行，因此读锁也是只加在了这一行上。\n但如果是下面的 SQL 语句，\n\n```SQL\nbegin;\nselect * from t where c=5 for update;\ncommit;\n```\n\n这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？\n在可重复读读提交隔离级别下，在语句执行完成后，是只有行锁的。而且语句执行完成后，InnoDB 就会把不满足条件的行行锁去掉。当然了，c=5 这一行的行锁，还是会等到 commit 的时候才释放的。","source":"_posts/19-为什么我只查一行的语句，也执行这么慢.md","raw":"---\ntitle: 19 | 为什么我只查一行的语句，也执行这么慢\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话题，看看什么情况下，会出现这个现象。\n需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。\n为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。\n\n```SQL\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata();\n```\n\n接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看能不能一眼看穿，来检验一下吧。\n\n## 第一类：查询长时间不返回\n\n如图 1 所示，在表 t 执行下面的 SQL 语句：\n\n```SQL\nmysql> select * from t where id=1;\n```\n\n查询结果长时间不返回\n\n![图 1 查询长时间不返回](1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg)\n\n一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。\n然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。\n\n### 等 MDL 锁\n\n如图 2 所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。\n\n![图 2 Waiting for table metadata lock 状态示意图](1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg)\n\n出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。\n在第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现方法。但需要说明的是，那个复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。(online-ddl过程写锁转读锁)\n不过，在 MySQL 5.7 版本下复现这个场景，也很容易。如图 3 所示，我给出了简单的复现步骤。\n\n![图 3 MySQL 5.7 中 Waiting for table metadata lock 的复现步骤](1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg)\n\nsession A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。\n这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。\n但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。\n\n![图 4 查获加表锁的线程 id](1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg)\n\n<br/>\n### 等 flush\n\n接下来，我给你举另外一种查询被堵住的情况。\n我在表 t 上，执行下面的 SQL 语句：\n\n```SQL\n mysql> select * from t where id=1;\n```\n\n这里，我先卖个关子。\n你可以看一下图 5。我查出来这个线程的状态是 Waiting for table flush，你可以设想一下这是什么原因。\n\n![图 5 Waiting for table flush 状态示意图](1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg)\n\n这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：\n\n1. flush tables t with read lock;\n2. flush tables with read lock;\n这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n现在，我们一起来复现一下这种情况，复现步骤如图 6 所示：\n\n![图 6 Waiting for table flush 的复现步骤](1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg)\n\n在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。\n图 7 是这个复现步骤的 show processlist 结果。这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。\n\n![图 7 Waiting for table flush 的 show processlist 结果](1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg)\n\n\n<br/>\n### 等行锁\n\n现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。\nmysql> select * from t where id=1 lock in share mode; \n上面这条语句的用法你也很熟悉了，我们在第 8 篇《事务到底是隔离的还是不隔离的？》文章介绍当前读时提到过。\n由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n复现步骤和现场如下：\n\n![图 8 行锁复现](1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg)\n\n![图 9 行锁 show processlist 现场](1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg)\n\n显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。\n查询方法是：\n```SQL\nmysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\\G\n```\n\n![图 10 通过 sys.innodb_lock_waits 查行锁](1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg)\n\n可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。\n不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。\n实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。\n\n## 第二类：查询慢\n\n经过了重重封“锁”，我们再来看看一些查询慢的例子。\n先来看一条你一定知道原因的 SQL 语句：\n\n```SQL\nmysql> select * from t where c=50000 limit 1;\n```\n\n由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 万行。\n作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。\n\n![图 11 全表扫描 5 万行的 slow log](1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg)\n\nRows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。\n扫描行数多，所以执行慢，这个很好理解。\n但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。\n如图 12 所示，是这个例子的 slow log。可以看到，执行的语句是\n\n```SQL\nmysql> select * from t where id=1；\n```\n\n虽然扫描行数是 1，但执行时间却长达 800 毫秒。\n\n![图 12 扫描一行却执行得很慢](1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg)\n\n是不是有点奇怪呢，这些时间都花在哪里了？\n如果我把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。\n\n![图 13 加上 lock in share mode 的 slow log](1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg)\n\n看上去是不是更奇怪了？按理说 lock in share mode 还要加锁，时间应该更长才对啊。\n可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图 14 是这两个语句的执行输出结果。\n\n![图 14 两个语句的输出结果](1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg)\n\n第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。\n\n![图 15 复现步骤](1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg)\n\n你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。\nsession B 执行完 100 万次 update 语句后，id=1 这一行处于什么状态呢？你可以从图 16 中找到答案。\n\n![图 16 id=1 的数据状态](1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg)\n\nsession B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。\n带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便你看图。\n\n\n## 小结\n\n今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。\n在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来定位并解决问题。\n最后，我给你留一个问题吧。\n我们在举例加锁读的时候，用的是这个语句，select * from t where id=1 lock in share mode。由于 id 上有索引，所以可以直接定位到 id=1 这一行，因此读锁也是只加在了这一行上。\n但如果是下面的 SQL 语句，\n\n```SQL\nbegin;\nselect * from t where c=5 for update;\ncommit;\n```\n\n这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？\n在可重复读读提交隔离级别下，在语句执行完成后，是只有行锁的。而且语句执行完成后，InnoDB 就会把不满足条件的行行锁去掉。当然了，c=5 这一行的行锁，还是会等到 commit 的时候才释放的。","slug":"19-为什么我只查一行的语句，也执行这么慢","published":1,"updated":"2021-06-30T02:33:24.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvi001lr5p74qow6dpr","content":"<p>一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话题，看看什么情况下，会出现这个现象。\n需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。\n为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata();\n</code></pre>\n<p>接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看能不能一眼看穿，来检验一下吧。</p>\n<h2 id=\"第一类：查询长时间不返回\"><a href=\"#第一类：查询长时间不返回\" class=\"headerlink\" title=\"第一类：查询长时间不返回\"></a>第一类：查询长时间不返回</h2><p>如图 1 所示，在表 t 执行下面的 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where id=1;\n</code></pre>\n<p>查询结果长时间不返回</p>\n<p><img src=\"1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg\" alt=\"图 1 查询长时间不返回\"></p>\n<p>一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。\n然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。</p>\n<h3 id=\"等-MDL-锁\"><a href=\"#等-MDL-锁\" class=\"headerlink\" title=\"等 MDL 锁\"></a>等 MDL 锁</h3><p>如图 2 所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。</p>\n<p><img src=\"1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg\" alt=\"图 2 Waiting for table metadata lock 状态示意图\"></p>\n<p>出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。\n在第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现方法。但需要说明的是，那个复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。(online-ddl过程写锁转读锁)\n不过，在 MySQL 5.7 版本下复现这个场景，也很容易。如图 3 所示，我给出了简单的复现步骤。</p>\n<p><img src=\"1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg\" alt=\"图 3 MySQL 5.7 中 Waiting for table metadata lock 的复现步骤\"></p>\n<p>session A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。\n这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。\n但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。</p>\n<p><img src=\"1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg\" alt=\"图 4 查获加表锁的线程 id\"></p>\n<br>\n### 等 flush\n\n<p>接下来，我给你举另外一种查询被堵住的情况。\n我在表 t 上，执行下面的 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\"> mysql> select * from t where id=1;\n</code></pre>\n<p>这里，我先卖个关子。\n你可以看一下图 5。我查出来这个线程的状态是 Waiting for table flush，你可以设想一下这是什么原因。</p>\n<p><img src=\"1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg\" alt=\"图 5 Waiting for table flush 状态示意图\"></p>\n<p>这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：</p>\n<ol>\n<li>flush tables t with read lock;</li>\n<li>flush tables with read lock;\n这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n现在，我们一起来复现一下这种情况，复现步骤如图 6 所示：</li>\n</ol>\n<p><img src=\"1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg\" alt=\"图 6 Waiting for table flush 的复现步骤\"></p>\n<p>在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。\n图 7 是这个复现步骤的 show processlist 结果。这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。</p>\n<p><img src=\"1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg\" alt=\"图 7 Waiting for table flush 的 show processlist 结果\"></p>\n<br>\n### 等行锁\n\n<p>现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。\nmysql&gt; select * from t where id=1 lock in share mode; \n上面这条语句的用法你也很熟悉了，我们在第 8 篇《事务到底是隔离的还是不隔离的？》文章介绍当前读时提到过。\n由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n复现步骤和现场如下：</p>\n<p><img src=\"1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg\" alt=\"图 8 行锁复现\"></p>\n<p><img src=\"1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg\" alt=\"图 9 行锁 show processlist 现场\"></p>\n<p>显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。\n查询方法是：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\\G\n</code></pre>\n<p><img src=\"1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg\" alt=\"图 10 通过 sys.innodb_lock_waits 查行锁\"></p>\n<p>可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。\n不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。\n实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。</p>\n<h2 id=\"第二类：查询慢\"><a href=\"#第二类：查询慢\" class=\"headerlink\" title=\"第二类：查询慢\"></a>第二类：查询慢</h2><p>经过了重重封“锁”，我们再来看看一些查询慢的例子。\n先来看一条你一定知道原因的 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where c=50000 limit 1;\n</code></pre>\n<p>由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 万行。\n作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。</p>\n<p><img src=\"1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg\" alt=\"图 11 全表扫描 5 万行的 slow log\"></p>\n<p>Rows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。\n扫描行数多，所以执行慢，这个很好理解。\n但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。\n如图 12 所示，是这个例子的 slow log。可以看到，执行的语句是</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where id=1；\n</code></pre>\n<p>虽然扫描行数是 1，但执行时间却长达 800 毫秒。</p>\n<p><img src=\"1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg\" alt=\"图 12 扫描一行却执行得很慢\"></p>\n<p>是不是有点奇怪呢，这些时间都花在哪里了？\n如果我把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。</p>\n<p><img src=\"1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg\" alt=\"图 13 加上 lock in share mode 的 slow log\"></p>\n<p>看上去是不是更奇怪了？按理说 lock in share mode 还要加锁，时间应该更长才对啊。\n可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图 14 是这两个语句的执行输出结果。</p>\n<p><img src=\"1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg\" alt=\"图 14 两个语句的输出结果\"></p>\n<p>第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。</p>\n<p><img src=\"1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg\" alt=\"图 15 复现步骤\"></p>\n<p>你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。\nsession B 执行完 100 万次 update 语句后，id=1 这一行处于什么状态呢？你可以从图 16 中找到答案。</p>\n<p><img src=\"1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg\" alt=\"图 16 id=1 的数据状态\"></p>\n<p>session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。\n带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便你看图。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。\n在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来定位并解决问题。\n最后，我给你留一个问题吧。\n我们在举例加锁读的时候，用的是这个语句，select * from t where id=1 lock in share mode。由于 id 上有索引，所以可以直接定位到 id=1 这一行，因此读锁也是只加在了这一行上。\n但如果是下面的 SQL 语句，</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">begin;\nselect * from t where c=5 for update;\ncommit;\n</code></pre>\n<p>这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？\n在可重复读读提交隔离级别下，在语句执行完成后，是只有行锁的。而且语句执行完成后，InnoDB 就会把不满足条件的行行锁去掉。当然了，c=5 这一行的行锁，还是会等到 commit 的时候才释放的。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>一般情况下，如果我跟你说查询性能优化，你首先会想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，我就跟你聊聊这个有趣的话题，看看什么情况下，会出现这个现象。\n需要说明的是，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于我们今天的讨论范围。\n为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段 id 和 c，并且我在里面插入了 10 万行记录。</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i&lt;=100000)do\n    insert into t values(i,i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\n\ncall idata();\n</code></pre>\n<p>接下来，我会用几个不同的场景来举例，有些是前面的文章中我们已经介绍过的知识点，你看看能不能一眼看穿，来检验一下吧。</p>\n<h2 id=\"第一类：查询长时间不返回\"><a href=\"#第一类：查询长时间不返回\" class=\"headerlink\" title=\"第一类：查询长时间不返回\"></a>第一类：查询长时间不返回</h2><p>如图 1 所示，在表 t 执行下面的 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where id=1;\n</code></pre>\n<p>查询结果长时间不返回</p>\n<p><img src=\"1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg\" alt=\"图 1 查询长时间不返回\"></p>\n<p>一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。\n然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。</p>\n<h3 id=\"等-MDL-锁\"><a href=\"#等-MDL-锁\" class=\"headerlink\" title=\"等 MDL 锁\"></a>等 MDL 锁</h3><p>如图 2 所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。</p>\n<p><img src=\"1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg\" alt=\"图 2 Waiting for table metadata lock 状态示意图\"></p>\n<p>出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。\n在第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》中，我给你介绍过一种复现方法。但需要说明的是，那个复现过程是基于 MySQL 5.6 版本的。而 MySQL 5.7 版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。(online-ddl过程写锁转读锁)\n不过，在 MySQL 5.7 版本下复现这个场景，也很容易。如图 3 所示，我给出了简单的复现步骤。</p>\n<p><img src=\"1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg\" alt=\"图 3 MySQL 5.7 中 Waiting for table metadata lock 的复现步骤\"></p>\n<p>session A 通过 lock table 命令持有表 t 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。\n这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。\n但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。</p>\n<p><img src=\"1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg\" alt=\"图 4 查获加表锁的线程 id\"></p>\n<br/>\n### 等 flush\n\n<p>接下来，我给你举另外一种查询被堵住的情况。\n我在表 t 上，执行下面的 SQL 语句：</p>\n<pre><code class=\"SQL\"> mysql&gt; select * from t where id=1;\n</code></pre>\n<p>这里，我先卖个关子。\n你可以看一下图 5。我查出来这个线程的状态是 Waiting for table flush，你可以设想一下这是什么原因。</p>\n<p><img src=\"1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg\" alt=\"图 5 Waiting for table flush 状态示意图\"></p>\n<p>这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：</p>\n<ol>\n<li>flush tables t with read lock;</li>\n<li>flush tables with read lock;\n这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n现在，我们一起来复现一下这种情况，复现步骤如图 6 所示：</li>\n</ol>\n<p><img src=\"1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg\" alt=\"图 6 Waiting for table flush 的复现步骤\"></p>\n<p>在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 10 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。\n图 7 是这个复现步骤的 show processlist 结果。这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。</p>\n<p><img src=\"1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg\" alt=\"图 7 Waiting for table flush 的 show processlist 结果\"></p>\n<br/>\n### 等行锁\n\n<p>现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。\nmysql&gt; select * from t where id=1 lock in share mode; \n上面这条语句的用法你也很熟悉了，我们在第 8 篇《事务到底是隔离的还是不隔离的？》文章介绍当前读时提到过。\n由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n复现步骤和现场如下：</p>\n<p><img src=\"1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg\" alt=\"图 8 行锁复现\"></p>\n<p><img src=\"1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg\" alt=\"图 9 行锁 show processlist 现场\"></p>\n<p>显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。\n查询方法是：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t sys.innodb_lock_waits where locked_table=`&#39;test&#39;.&#39;t&#39;`\\G\n</code></pre>\n<p><img src=\"1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg\" alt=\"图 10 通过 sys.innodb_lock_waits 查行锁\"></p>\n<p>可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。\n不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。\n实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。</p>\n<h2 id=\"第二类：查询慢\"><a href=\"#第二类：查询慢\" class=\"headerlink\" title=\"第二类：查询慢\"></a>第二类：查询慢</h2><p>经过了重重封“锁”，我们再来看看一些查询慢的例子。\n先来看一条你一定知道原因的 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where c=50000 limit 1;\n</code></pre>\n<p>由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 万行。\n作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。</p>\n<p><img src=\"1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg\" alt=\"图 11 全表扫描 5 万行的 slow log\"></p>\n<p>Rows_examined 显示扫描了 50000 行。你可能会说，不是很慢呀，11.5 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只有 10 万行记录，数据量大起来的话，执行时间就线性涨上去了。\n扫描行数多，所以执行慢，这个很好理解。\n但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。\n如图 12 所示，是这个例子的 slow log。可以看到，执行的语句是</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where id=1；\n</code></pre>\n<p>虽然扫描行数是 1，但执行时间却长达 800 毫秒。</p>\n<p><img src=\"1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg\" alt=\"图 12 扫描一行却执行得很慢\"></p>\n<p>是不是有点奇怪呢，这些时间都花在哪里了？\n如果我把这个 slow log 的截图再往下拉一点，你可以看到下一个语句，select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。</p>\n<p><img src=\"1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg\" alt=\"图 13 加上 lock in share mode 的 slow log\"></p>\n<p>看上去是不是更奇怪了？按理说 lock in share mode 还要加锁，时间应该更长才对啊。\n可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图 14 是这两个语句的执行输出结果。</p>\n<p><img src=\"1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg\" alt=\"图 14 两个语句的输出结果\"></p>\n<p>第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。</p>\n<p><img src=\"1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg\" alt=\"图 15 复现步骤\"></p>\n<p>你看到了，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。\nsession B 执行完 100 万次 update 语句后，id=1 这一行处于什么状态呢？你可以从图 16 中找到答案。</p>\n<p><img src=\"1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg\" alt=\"图 16 id=1 的数据状态\"></p>\n<p>session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。\n带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑，画成减 1 的目的是方便你看图。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天我给你举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。\n在实际使用中，碰到的场景会更复杂。但大同小异，你可以按照我在文章中介绍的定位方法，来定位并解决问题。\n最后，我给你留一个问题吧。\n我们在举例加锁读的时候，用的是这个语句，select * from t where id=1 lock in share mode。由于 id 上有索引，所以可以直接定位到 id=1 这一行，因此读锁也是只加在了这一行上。\n但如果是下面的 SQL 语句，</p>\n<pre><code class=\"SQL\">begin;\nselect * from t where c=5 for update;\ncommit;\n</code></pre>\n<p>这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？\n在可重复读读提交隔离级别下，在语句执行完成后，是只有行锁的。而且语句执行完成后，InnoDB 就会把不满足条件的行行锁去掉。当然了，c=5 这一行的行锁，还是会等到 commit 的时候才释放的。</p>\n"},{"title":"20 | 幻读是什么，幻读有什么问题","date":"2019-06-02T16:00:00.000Z","_content":"在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。\n为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。\n上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？\n\n```SQL\nbegin;\nselect * from t where d=5 for update;\ncommit;\n```\n\n比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。\n由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？\n我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。\n\n<br/>\n### 幻读是什么\n\n现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。\n下面先来看一下这个场景：\n\n![图 1 假设只在 id=5 这一行加行锁](1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg)\n\n可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。\n\n1. Q1 只返回 id=5 这一行；\n2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；\n3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。\n其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n这里，我需要对“幻读”做一个说明：在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n如果只从第 8 篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。\n因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。\n但是，这是不是真的没问题呢？\n不，这里还真就有问题。\n\n<br/>\n### 幻读有什么问题\n\n首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。\n\n![图 2 假设只在 id=5 这一行加行锁 -- 语义被破坏](1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg)\n\nsession B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。\n由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。\nsession C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。\n其次，是数据一致性的问题。\n我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：update t set d=100 where d=5。\n\n![图 3 假设只在 id=5 这一行加行锁 -- 数据一致性问题](1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg)\n\nupdate 的加锁语义和 select ...for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。\n现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。\n\n1. 经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;\n2. 经过 T2 时刻，id=0 这一行变成 (0,5,5);\n3. 经过 T4 时刻，表里面多了一行 (1,5,5);\n其他行跟这个执行序列无关，保持不变。\n\n这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。\nT2 时刻，session B 事务提交，写入了两条语句；\nT4 时刻，session C 事务提交，写入了两条语句；\nT6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。\n\n我统一放到一起的话，就是这样的：\n\n```SQL\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\n```\n\n好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。\n也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。\n到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？\n我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。\n所以我们认为，上面的设定不合理，要改。\n那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。\n\n![图 4 假设扫描到的行都被加上了行锁](1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg)\n\n由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。\n这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：\n\n```SQL\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n```\n\n可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。\n但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？\n原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。\n也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。\n到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。\n接下来，我们再看看 InnoDB 怎么解决幻读的问题。\n\n<br/>\n### 如何解决幻读\n\n现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n\n![图 5 表 t 主键索引上的行锁和间隙锁](1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg)\n\n这样，当你执行 `select * from t where d=5 for update` 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。\n比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。\n\n![图 6 两种行锁间的冲突关系](1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg)\n\n也就是说，跟行锁有冲突关系的是“另外一个行锁”。\n但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n这句话不太好理解，我给你举个例子：\n\n![图 7 间隙锁之间不互锁](1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg)\n\n这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。\n备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。\n你可能会问说，这个 suprenum 从哪儿来的呢？\n这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 suprenum，这样才符合我们前面说的“都是前开后闭区间”。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：\n\n```SQL\nbegin;\nselect * from t where id=N for update;\n \n/* 如果行不存在 */\ninsert into t values(N,N,N);\n/* 如果行存在 */\nupdate t set d=N set id=N;\n \ncommit;\n```\n\n可能你会说，这个不是 insert ... on duplicate key update 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。\n现在，我们就只讨论这个逻辑。\n这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n这里，我用两个 session 来模拟并发，并假设 N=9。\n\n![图 8 间隙锁导致的死锁](1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg)\n\n你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n• session A 执行 select ... for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);\n• session B 执行 select ... for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n• session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；\n• session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。\n\n至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。\n\n你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例子。\n\n你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。\n\n我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。\n\n前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加 binlog_format=row 的组合。他曾问他们公司的 DBA 说，你为什么要这么配置。DBA 直接答复说，因为大家都这么用呀。\n\n所以，这个同学在评论区就问说，这个配置到底合不合理。\n\n关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。\n但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。\n但是，如果 DBA 认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出问题。\n比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》的内容）\n\n1. 然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？\n2. 进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？\n如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。\n\n<br/>\n### 小结\n\n今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。\n\n我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务 SQL 语句的时候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由于间隙锁导致的死锁现象。\n行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循。下一篇文章，我就会为你讲解 InnoDB 的加锁规则，帮你理顺这其中的“章法”。\n作为对下一篇文章的预习，我给你留下一个思考题。\n\n![图 9 事务进入锁等待状态](1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg)\n\n如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。\n你可以试着分析一下，出现这种情况的原因是什么？\n这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预习的，其中 session C 被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会在下一篇文章和你详细说明。\n你也可以说说，你的线上 MySQL 配置的是什么隔离级别，为什么会这么配置？你有没有碰到什么场景，是必须使用可重复读隔离级别的呢？\n你可以把你的碰到的场景和分析写在留言区里，我会在下一篇文章选取有趣的评论跟大家一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。","source":"_posts/20-幻读是什么，幻读有什么问题.md","raw":"---\ntitle: 20 | 幻读是什么，幻读有什么问题\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。\n为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。\n上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？\n\n```SQL\nbegin;\nselect * from t where d=5 for update;\ncommit;\n```\n\n比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。\n由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？\n我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。\n\n<br/>\n### 幻读是什么\n\n现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。\n下面先来看一下这个场景：\n\n![图 1 假设只在 id=5 这一行加行锁](1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg)\n\n可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。\n\n1. Q1 只返回 id=5 这一行；\n2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；\n3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。\n其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n这里，我需要对“幻读”做一个说明：在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n如果只从第 8 篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。\n因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。\n但是，这是不是真的没问题呢？\n不，这里还真就有问题。\n\n<br/>\n### 幻读有什么问题\n\n首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。\n\n![图 2 假设只在 id=5 这一行加行锁 -- 语义被破坏](1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg)\n\nsession B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。\n由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。\nsession C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。\n其次，是数据一致性的问题。\n我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：update t set d=100 where d=5。\n\n![图 3 假设只在 id=5 这一行加行锁 -- 数据一致性问题](1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg)\n\nupdate 的加锁语义和 select ...for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。\n现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。\n\n1. 经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;\n2. 经过 T2 时刻，id=0 这一行变成 (0,5,5);\n3. 经过 T4 时刻，表里面多了一行 (1,5,5);\n其他行跟这个执行序列无关，保持不变。\n\n这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。\nT2 时刻，session B 事务提交，写入了两条语句；\nT4 时刻，session C 事务提交，写入了两条语句；\nT6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。\n\n我统一放到一起的话，就是这样的：\n\n```SQL\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\n```\n\n好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。\n也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。\n到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？\n我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。\n所以我们认为，上面的设定不合理，要改。\n那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。\n\n![图 4 假设扫描到的行都被加上了行锁](1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg)\n\n由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。\n这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：\n\n```SQL\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n```\n\n可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。\n但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？\n原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。\n也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。\n到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。\n接下来，我们再看看 InnoDB 怎么解决幻读的问题。\n\n<br/>\n### 如何解决幻读\n\n现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n\n![图 5 表 t 主键索引上的行锁和间隙锁](1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg)\n\n这样，当你执行 `select * from t where d=5 for update` 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。\n比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。\n\n![图 6 两种行锁间的冲突关系](1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg)\n\n也就是说，跟行锁有冲突关系的是“另外一个行锁”。\n但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n这句话不太好理解，我给你举个例子：\n\n![图 7 间隙锁之间不互锁](1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg)\n\n这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。\n备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。\n你可能会问说，这个 suprenum 从哪儿来的呢？\n这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 suprenum，这样才符合我们前面说的“都是前开后闭区间”。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：\n\n```SQL\nbegin;\nselect * from t where id=N for update;\n \n/* 如果行不存在 */\ninsert into t values(N,N,N);\n/* 如果行存在 */\nupdate t set d=N set id=N;\n \ncommit;\n```\n\n可能你会说，这个不是 insert ... on duplicate key update 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。\n现在，我们就只讨论这个逻辑。\n这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n这里，我用两个 session 来模拟并发，并假设 N=9。\n\n![图 8 间隙锁导致的死锁](1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg)\n\n你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n• session A 执行 select ... for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);\n• session B 执行 select ... for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n• session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；\n• session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。\n\n至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。\n\n你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例子。\n\n你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。\n\n我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。\n\n前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加 binlog_format=row 的组合。他曾问他们公司的 DBA 说，你为什么要这么配置。DBA 直接答复说，因为大家都这么用呀。\n\n所以，这个同学在评论区就问说，这个配置到底合不合理。\n\n关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。\n但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。\n但是，如果 DBA 认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出问题。\n比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》的内容）\n\n1. 然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？\n2. 进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？\n如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。\n\n<br/>\n### 小结\n\n今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。\n\n我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务 SQL 语句的时候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由于间隙锁导致的死锁现象。\n行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循。下一篇文章，我就会为你讲解 InnoDB 的加锁规则，帮你理顺这其中的“章法”。\n作为对下一篇文章的预习，我给你留下一个思考题。\n\n![图 9 事务进入锁等待状态](1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg)\n\n如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。\n你可以试着分析一下，出现这种情况的原因是什么？\n这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预习的，其中 session C 被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会在下一篇文章和你详细说明。\n你也可以说说，你的线上 MySQL 配置的是什么隔离级别，为什么会这么配置？你有没有碰到什么场景，是必须使用可重复读隔离级别的呢？\n你可以把你的碰到的场景和分析写在留言区里，我会在下一篇文章选取有趣的评论跟大家一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。","slug":"20-幻读是什么，幻读有什么问题","published":1,"updated":"2021-06-30T02:33:24.645Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvi001or5p7hu986o59","content":"<p>在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。\n为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n</code></pre>\n<p>这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。\n上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">begin;\nselect * from t where d=5 for update;\ncommit;\n</code></pre>\n<p>比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。\n由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？\n我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。</p>\n<br>\n### 幻读是什么\n\n<p>现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。\n下面先来看一下这个场景：</p>\n<p><img src=\"1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg\" alt=\"图 1 假设只在 id=5 这一行加行锁\"></p>\n<p>可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。</p>\n<ol>\n<li>Q1 只返回 id=5 这一行；</li>\n<li>在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；</li>\n<li>在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。\n其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n这里，我需要对“幻读”做一个说明：在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n如果只从第 8 篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。\n因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。\n但是，这是不是真的没问题呢？\n不，这里还真就有问题。</li>\n</ol>\n<br>\n### 幻读有什么问题\n\n<p>首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。</p>\n<p><img src=\"1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg\" alt=\"图 2 假设只在 id=5 这一行加行锁 -- 语义被破坏\"></p>\n<p>session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。\n由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。\nsession C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。\n其次，是数据一致性的问题。\n我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：update t set d=100 where d=5。</p>\n<p><img src=\"1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg\" alt=\"图 3 假设只在 id=5 这一行加行锁 -- 数据一致性问题\"></p>\n<p>update 的加锁语义和 select …for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。\n现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。</p>\n<ol>\n<li>经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;</li>\n<li>经过 T2 时刻，id=0 这一行变成 (0,5,5);</li>\n<li>经过 T4 时刻，表里面多了一行 (1,5,5);\n其他行跟这个执行序列无关，保持不变。</li>\n</ol>\n<p>这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。\nT2 时刻，session B 事务提交，写入了两条语句；\nT4 时刻，session C 事务提交，写入了两条语句；\nT6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。</p>\n<p>我统一放到一起的话，就是这样的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">update t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\n</code></pre>\n<p>好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。\n也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。\n到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？\n我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。\n所以我们认为，上面的设定不合理，要改。\n那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。</p>\n<p><img src=\"1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg\" alt=\"图 4 假设扫描到的行都被加上了行锁\"></p>\n<p>由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。\n这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">insert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n</code></pre>\n<p>可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。\n但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？\n原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。\n也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。\n到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。\n接下来，我们再看看 InnoDB 怎么解决幻读的问题。</p>\n<br>\n### 如何解决幻读\n\n<p>现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。</p>\n<p><img src=\"1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg\" alt=\"图 5 表 t 主键索引上的行锁和间隙锁\"></p>\n<p>这样，当你执行 <code>select * from t where d=5 for update</code> 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。\n比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。</p>\n<p><img src=\"1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg\" alt=\"图 6 两种行锁间的冲突关系\"></p>\n<p>也就是说，跟行锁有冲突关系的是“另外一个行锁”。\n但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n这句话不太好理解，我给你举个例子：</p>\n<p><img src=\"1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg\" alt=\"图 7 间隙锁之间不互锁\"></p>\n<p>这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。\n备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。\n你可能会问说，这个 suprenum 从哪儿来的呢？\n这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 suprenum，这样才符合我们前面说的“都是前开后闭区间”。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">begin;\nselect * from t where id=N for update;\n \n/* 如果行不存在 */\ninsert into t values(N,N,N);\n/* 如果行存在 */\nupdate t set d=N set id=N;\n \ncommit;\n</code></pre>\n<p>可能你会说，这个不是 insert … on duplicate key update 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。\n现在，我们就只讨论这个逻辑。\n这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n这里，我用两个 session 来模拟并发，并假设 N=9。</p>\n<p><img src=\"1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg\" alt=\"图 8 间隙锁导致的死锁\"></p>\n<p>你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n• session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);\n• session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n• session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；\n• session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</p>\n<p>至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。</p>\n<p>你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例子。</p>\n<p>你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。</p>\n<p>我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。</p>\n<p>前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加 binlog_format=row 的组合。他曾问他们公司的 DBA 说，你为什么要这么配置。DBA 直接答复说，因为大家都这么用呀。</p>\n<p>所以，这个同学在评论区就问说，这个配置到底合不合理。</p>\n<p>关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。\n但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。\n但是，如果 DBA 认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出问题。\n比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》的内容）</p>\n<ol>\n<li>然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？</li>\n<li>进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？\n如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。</li>\n</ol>\n<br>\n### 小结\n\n<p>今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。</p>\n<p>我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务 SQL 语句的时候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由于间隙锁导致的死锁现象。\n行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循。下一篇文章，我就会为你讲解 InnoDB 的加锁规则，帮你理顺这其中的“章法”。\n作为对下一篇文章的预习，我给你留下一个思考题。</p>\n<p><img src=\"1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg\" alt=\"图 9 事务进入锁等待状态\"></p>\n<p>如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。\n你可以试着分析一下，出现这种情况的原因是什么？\n这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预习的，其中 session C 被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会在下一篇文章和你详细说明。\n你也可以说说，你的线上 MySQL 配置的是什么隔离级别，为什么会这么配置？你有没有碰到什么场景，是必须使用可重复读隔离级别的呢？\n你可以把你的碰到的场景和分析写在留言区里，我会在下一篇文章选取有趣的评论跟大家一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在上一篇文章最后，我给你留了一个关于加锁规则的问题。今天，我们就从这个问题说起吧。\n为了便于说明问题，这一篇文章，我们就先使用一个小一点儿的表。建表和初始化语句如下（为了便于本期的例子说明，我把上篇文章中用到的表结构做了点儿修改）：</p>\n<pre><code class=\"SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n</code></pre>\n<p>这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。\n上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？</p>\n<pre><code class=\"SQL\">begin;\nselect * from t where d=5 for update;\ncommit;\n</code></pre>\n<p>比较好理解的是，这个语句会命中 d=5 的这一行，对应的主键 id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。\n由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？\n我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。</p>\n<br/>\n### 幻读是什么\n\n<p>现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。\n下面先来看一下这个场景：</p>\n<p><img src=\"1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg\" alt=\"图 1 假设只在 id=5 这一行加行锁\"></p>\n<p>可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。</p>\n<ol>\n<li>Q1 只返回 id=5 这一行；</li>\n<li>在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；</li>\n<li>在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。\n其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n这里，我需要对“幻读”做一个说明：在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n如果只从第 8 篇文章《事务到底是隔离的还是不隔离的？》我们学到的事务可见性规则来分析的话，上面这三条 SQL 语句的返回结果都没有问题。\n因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。\n但是，这是不是真的没问题呢？\n不，这里还真就有问题。</li>\n</ol>\n<br/>\n### 幻读有什么问题\n\n<p>首先是语义上的。session A 在 T1 时刻就声明了，“我要把所有 d=5 的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。\n如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。</p>\n<p><img src=\"1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg\" alt=\"图 2 假设只在 id=5 这一行加行锁 -- 语义被破坏\"></p>\n<p>session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。\n由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。\nsession C 也是一样的道理，对 id=1 这一行的修改，也是破坏了 Q1 的加锁声明。\n其次，是数据一致性的问题。\n我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n为了说明这个问题，我给 session A 在 T1 时刻再加一个更新语句，即：update t set d=100 where d=5。</p>\n<p><img src=\"1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg\" alt=\"图 3 假设只在 id=5 这一行加行锁 -- 数据一致性问题\"></p>\n<p>update 的加锁语义和 select …for update 是一致的，所以这时候加上这条 update 语句也很合理。session A 声明说“要给 d=5 的语句加上锁”，就是为了要更新数据，新加的这条 update 语句就是把它认为加上了锁的这一行的 d 值修改成了 100。\n现在，我们来分析一下图 3 执行完成后，数据库里会是什么结果。</p>\n<ol>\n<li>经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ;</li>\n<li>经过 T2 时刻，id=0 这一行变成 (0,5,5);</li>\n<li>经过 T4 时刻，表里面多了一行 (1,5,5);\n其他行跟这个执行序列无关，保持不变。</li>\n</ol>\n<p>这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。\nT2 时刻，session B 事务提交，写入了两条语句；\nT4 时刻，session C 事务提交，写入了两条语句；\nT6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。</p>\n<p>我统一放到一起的话，就是这样的：</p>\n<pre><code class=\"SQL\">update t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\ninsert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\n</code></pre>\n<p>好，你应该看出问题了。这个语句序列，不论是拿到备库去执行，还是以后用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。\n也就是说，id=0 和 id=1 这两行，发生了数据不一致。这个问题很严重，是不行的。\n到这里，我们再回顾一下，这个数据不一致到底是怎么引入的？\n我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。\n所以我们认为，上面的设定不合理，要改。\n那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。</p>\n<p><img src=\"1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg\" alt=\"图 4 假设扫描到的行都被加上了行锁\"></p>\n<p>由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。\n这样对于 id=0 这一行，在数据库里的最终结果还是 (0,5,5)。在 binlog 里面，执行序列是这样的：</p>\n<pre><code class=\"SQL\">insert into t values(1,1,5); /*(1,1,5)*/\nupdate t set c=5 where id=1; /*(1,5,5)*/\nupdate t set d=100 where d=5;/* 所有 d=5 的行，d 改成 100*/\nupdate t set d=5 where id=0; /*(0,0,5)*/\nupdate t set c=5 where id=0; /*(0,5,5)*/\n</code></pre>\n<p>可以看到，按照日志顺序执行，id=0 这一行的最终结果也是 (0,5,5)。所以，id=0 这一行的问题解决了。\n但同时你也可以看到，id=1 这一行，在数据库里面的结果是 (1,5,5)，而根据 binlog 的执行结果是 (1,5,100)，也就是说幻读的问题还是没有解决。为什么我们已经这么“凶残”地，把所有的记录都上了锁，还是阻止不了 id=1 这一行的插入和更新呢？\n原因很简单。在 T3 时刻，我们给所有行加锁的时候，id=1 这一行还不存在，不存在也就加不上锁。\n也就是说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。\n到这里，其实我们刚说明完文章的标题 ：幻读的定义和幻读有什么问题。\n接下来，我们再看看 InnoDB 怎么解决幻读的问题。</p>\n<br/>\n### 如何解决幻读\n\n<p>现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。</p>\n<p><img src=\"1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg\" alt=\"图 5 表 t 主键索引上的行锁和间隙锁\"></p>\n<p>这样，当你执行 <code>select * from t where d=5 for update</code> 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。\n也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。\n现在你知道了，数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。\n比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。</p>\n<p><img src=\"1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg\" alt=\"图 6 两种行锁间的冲突关系\"></p>\n<p>也就是说，跟行锁有冲突关系的是“另外一个行锁”。\n但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n这句话不太好理解，我给你举个例子：</p>\n<p><img src=\"1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg\" alt=\"图 7 间隙锁之间不互锁\"></p>\n<p>这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。\n备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。\n你可能会问说，这个 suprenum 从哪儿来的呢？\n这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 suprenum，这样才符合我们前面说的“都是前开后闭区间”。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n在前面的文章中，就有同学提到了这个问题。我把他的问题转述一下，对应到我们这个例子的表来说，业务逻辑这样的：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据，代码如下：</p>\n<pre><code class=\"SQL\">begin;\nselect * from t where id=N for update;\n \n/* 如果行不存在 */\ninsert into t values(N,N,N);\n/* 如果行存在 */\nupdate t set d=N set id=N;\n \ncommit;\n</code></pre>\n<p>可能你会说，这个不是 insert … on duplicate key update 就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这位提问同学的需求的。至于为什么，我会在后面的文章中再展开说明。\n现在，我们就只讨论这个逻辑。\n这个同学碰到的现象是，这个逻辑一旦有并发，就会碰到死锁。你一定也觉得奇怪，这个逻辑每次操作前用 for update 锁起来，已经是最严格的模式了，怎么还会有死锁呢？\n这里，我用两个 session 来模拟并发，并假设 N=9。</p>\n<p><img src=\"1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg\" alt=\"图 8 间隙锁导致的死锁\"></p>\n<p>你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：\n• session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);\n• session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；\n• session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；\n• session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。</p>\n<p>至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。</p>\n<p>你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。其实，这还只是一个简单的例子，在下一篇文章中我们还会碰到更多、更复杂的例子。</p>\n<p>你可能会说，为了解决幻读的问题，我们引入了这么一大串内容，有没有更简单一点的处理方法呢。</p>\n<p>我在文章一开始就说过，如果没有特别说明，今天和你分析的问题都是在可重复读隔离级别下的，间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。</p>\n<p>前面文章的评论区有同学留言说，他们公司就使用的是读提交隔离级别加 binlog_format=row 的组合。他曾问他们公司的 DBA 说，你为什么要这么配置。DBA 直接答复说，因为大家都这么用呀。</p>\n<p>所以，这个同学在评论区就问说，这个配置到底合不合理。</p>\n<p>关于这个问题本身的答案是，如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。\n但其实我想说的是，配置是否合理，跟业务场景有关，需要具体问题具体分析。\n但是，如果 DBA 认为之所以这么用的原因是“大家都这么用”，那就有问题了，或者说，迟早会出问题。\n比如说，大家都用读提交，可是逻辑备份的时候，mysqldump 为什么要把备份线程设置成可重复读呢？（这个我在前面的文章中已经解释过了，你可以再回顾下第 6 篇文章《全局锁和表锁 ：给表加个字段怎么有这么多阻碍？》的内容）</p>\n<ol>\n<li>然后，在备份期间，备份线程用的是可重复读，而业务线程用的是读提交。同时存在两种事务隔离级别，会不会有问题？</li>\n<li>进一步地，这两个不同的隔离级别现象有什么不一样的，关于我们的业务，“用读提交就够了”这个结论是怎么得到的？\n如果业务开发和运维团队这些问题都没有弄清楚，那么“没问题”这个结论，本身就是有问题的。</li>\n</ol>\n<br/>\n### 小结\n\n<p>今天我们从上一篇文章的课后问题说起，提到了全表扫描的加锁方式。我们发现即使给所有的行都加上行锁，仍然无法解决幻读问题，因此引入了间隙锁的概念。</p>\n<p>我碰到过很多对数据库有一定了解的业务开发人员，他们在设计数据表结构和业务 SQL 语句的时候，对行锁有很准确的认识，但却很少考虑到间隙锁。最后的结果，就是生产库上会经常出现由于间隙锁导致的死锁现象。\n行锁确实比较直观，判断规则也相对简单，间隙锁的引入会影响系统的并发度，也增加了锁分析的复杂度，但也有章可循。下一篇文章，我就会为你讲解 InnoDB 的加锁规则，帮你理顺这其中的“章法”。\n作为对下一篇文章的预习，我给你留下一个思考题。</p>\n<p><img src=\"1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg\" alt=\"图 9 事务进入锁等待状态\"></p>\n<p>如果你之前没有了解过本篇文章的相关内容，一定觉得这三个语句简直是风马牛不相及。但实际上，这里 session B 和 session C 的 insert 语句都会进入锁等待状态。\n你可以试着分析一下，出现这种情况的原因是什么？\n这里需要说明的是，这其实是我在下一篇文章介绍加锁规则后才能回答的问题，是留给你作为预习的，其中 session C 被锁住这个分析是有点难度的。如果你没有分析出来，也不要气馁，我会在下一篇文章和你详细说明。\n你也可以说说，你的线上 MySQL 配置的是什么隔离级别，为什么会这么配置？你有没有碰到什么场景，是必须使用可重复读隔离级别的呢？\n你可以把你的碰到的场景和分析写在留言区里，我会在下一篇文章选取有趣的评论跟大家一起分享和分析。感谢你的收听，也欢迎你把这篇文章分享给更多的朋友一起阅读。</p>\n"},{"title":"22 | MySQL有哪些“饮鸩止渴”提高性能的方法","date":"2019-06-02T16:00:00.000Z","_content":"不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。\n我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。\n但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。\n\n## 短连接风暴\n\n正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。\n\n我在第 1 篇文章《基础架构：一条 SQL 查询语句是如何执行的？》中说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。\n\n在数据库压力比较小的时候，这些额外的成本并不明显。\n\n但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。\n\n在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。\n\n碰到这种情况时，一个比较自然的想法，就是调高 max_connections 的值。但这样做是有风险的。因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。\n\n那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。\n\n<br/>\n### 第一种方法：先处理掉那些占着连接但是不工作的线程\n\n`max_connections` 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 `kill connection` 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。\n但是需要注意，在 `show processlist` 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。\n\n![图 1 sleep 线程的两种状态](1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg)\n\n在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。\n但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。\n\n![图 2 sleep 线程的两种状态，show processlist 结果](1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg)\n\n图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。\n\n![图 3 从 information_schema.innodb_trx 查询事务状态](1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg)\n\n这个结果里，`trx_mysql_thread_id=4`，表示 id=4 的线程还处在事务中。\n因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。\n从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错`“ERROR 2013 (HY000): Lost connection to MySQL server during query”`。\n从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。\n你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。\n所以，如果你是一个支持业务的 DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。\n\n<br/>\n### 第二种方法：减少连接过程的消耗\n\n有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。\n跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。\n但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。\n在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 --skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。\n除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。\n\n## 慢查询性能问题\n\n在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：\n\n1. 索引没有设计好；\n2. SQL 语句没写好；\n3. MySQL 选错了索引。\n接下来，我们就具体分析一下这三种可能，以及对应的解决方案。\n\n<br/>\n### 导致慢查询的第一种可能是，索引没有设计好\n\n这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。\n比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：\n\n1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；\n2. 执行主备切换；\n3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。\n\n<br/>\n### 导致慢查询的第二种可能是，语句没写好\n\n比如，我们犯了在第 18 篇文章《为什么这些 SQL 语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。\n这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。\n比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。\n\n```SQL\nmysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (\"select * from t where id + 1 = ?\", \"select * from t where id = ? - 1\", \"db1\");\ncall query_rewrite.flush_rewrite_rules();\n```\n\n这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。你可以用图 4 中的方法来确认改写规则是否生效。\n\n![图 4 查询重写效果](1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg)\n\n<br/>\n### 导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章《MySQL 为什么有时候会选错索引？》中提到的情况，MySQL 选错了索引\n\n这时候，应急方案就是给这个语句加上 force index。\n同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。\n上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。\n\n1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；\n2. 在测试表里插入模拟线上的数据，做一遍回归测试；\n3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。\n\n不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。\n如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。\n\n## QPS 突增问题\n\n有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。\n我之前碰到过一类情况，是由一个新功能的 bug 导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。\n而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成\"select 1\"返回。\n当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：\n\n1. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；\n2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。\n\n所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。\n同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。\n\n## 小结\n\n今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。\n这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。\n在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。\nDBA 虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好 SQL 审计可以减少需要这类操作的机会。\n其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server 层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。\n最后，又到了我们的思考题时间了。\n今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？","source":"_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法.md","raw":"---\ntitle: 22 | MySQL有哪些“饮鸩止渴”提高性能的方法\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。\n我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。\n但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。\n\n## 短连接风暴\n\n正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。\n\n我在第 1 篇文章《基础架构：一条 SQL 查询语句是如何执行的？》中说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。\n\n在数据库压力比较小的时候，这些额外的成本并不明显。\n\n但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。\n\n在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。\n\n碰到这种情况时，一个比较自然的想法，就是调高 max_connections 的值。但这样做是有风险的。因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。\n\n那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。\n\n<br/>\n### 第一种方法：先处理掉那些占着连接但是不工作的线程\n\n`max_connections` 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 `kill connection` 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。\n但是需要注意，在 `show processlist` 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。\n\n![图 1 sleep 线程的两种状态](1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg)\n\n在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。\n但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。\n\n![图 2 sleep 线程的两种状态，show processlist 结果](1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg)\n\n图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。\n\n![图 3 从 information_schema.innodb_trx 查询事务状态](1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg)\n\n这个结果里，`trx_mysql_thread_id=4`，表示 id=4 的线程还处在事务中。\n因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。\n从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错`“ERROR 2013 (HY000): Lost connection to MySQL server during query”`。\n从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。\n你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。\n所以，如果你是一个支持业务的 DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。\n\n<br/>\n### 第二种方法：减少连接过程的消耗\n\n有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。\n跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。\n但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。\n在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 --skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。\n除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。\n\n## 慢查询性能问题\n\n在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：\n\n1. 索引没有设计好；\n2. SQL 语句没写好；\n3. MySQL 选错了索引。\n接下来，我们就具体分析一下这三种可能，以及对应的解决方案。\n\n<br/>\n### 导致慢查询的第一种可能是，索引没有设计好\n\n这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。\n比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：\n\n1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；\n2. 执行主备切换；\n3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。\n\n<br/>\n### 导致慢查询的第二种可能是，语句没写好\n\n比如，我们犯了在第 18 篇文章《为什么这些 SQL 语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。\n这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。\n比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。\n\n```SQL\nmysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (\"select * from t where id + 1 = ?\", \"select * from t where id = ? - 1\", \"db1\");\ncall query_rewrite.flush_rewrite_rules();\n```\n\n这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。你可以用图 4 中的方法来确认改写规则是否生效。\n\n![图 4 查询重写效果](1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg)\n\n<br/>\n### 导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章《MySQL 为什么有时候会选错索引？》中提到的情况，MySQL 选错了索引\n\n这时候，应急方案就是给这个语句加上 force index。\n同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。\n上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。\n\n1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；\n2. 在测试表里插入模拟线上的数据，做一遍回归测试；\n3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。\n\n不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。\n如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。\n\n## QPS 突增问题\n\n有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。\n我之前碰到过一类情况，是由一个新功能的 bug 导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。\n而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成\"select 1\"返回。\n当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：\n\n1. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；\n2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。\n\n所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。\n同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。\n\n## 小结\n\n今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。\n这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。\n在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。\nDBA 虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好 SQL 审计可以减少需要这类操作的机会。\n其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server 层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。\n最后，又到了我们的思考题时间了。\n今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？","slug":"22-MySQL有哪些“饮鸩止渴”提高性能的方法","published":1,"updated":"2021-06-30T02:33:24.659Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvj001rr5p78vne2uml","content":"<p>不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。\n我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。\n但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。</p>\n<h2 id=\"短连接风暴\"><a href=\"#短连接风暴\" class=\"headerlink\" title=\"短连接风暴\"></a>短连接风暴</h2><p>正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。</p>\n<p>我在第 1 篇文章《基础架构：一条 SQL 查询语句是如何执行的？》中说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。</p>\n<p>在数据库压力比较小的时候，这些额外的成本并不明显。</p>\n<p>但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。</p>\n<p>在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。</p>\n<p>碰到这种情况时，一个比较自然的想法，就是调高 max_connections 的值。但这样做是有风险的。因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。</p>\n<p>那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。</p>\n<br>\n### 第一种方法：先处理掉那些占着连接但是不工作的线程\n\n<p><code>max_connections</code> 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 <code>kill connection</code> 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。\n但是需要注意，在 <code>show processlist</code> 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。</p>\n<p><img src=\"1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg\" alt=\"图 1 sleep 线程的两种状态\"></p>\n<p>在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。\n但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。</p>\n<p><img src=\"1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg\" alt=\"图 2 sleep 线程的两种状态，show processlist 结果\"></p>\n<p>图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。</p>\n<p><img src=\"1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg\" alt=\"图 3 从 information_schema.innodb_trx 查询事务状态\"></p>\n<p>这个结果里，<code>trx_mysql_thread_id=4</code>，表示 id=4 的线程还处在事务中。\n因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。\n从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错<code>“ERROR 2013 (HY000): Lost connection to MySQL server during query”</code>。\n从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。\n你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。\n所以，如果你是一个支持业务的 DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。</p>\n<br>\n### 第二种方法：减少连接过程的消耗\n\n<p>有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。\n跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。\n但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。\n在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 –skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。\n除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。</p>\n<h2 id=\"慢查询性能问题\"><a href=\"#慢查询性能问题\" class=\"headerlink\" title=\"慢查询性能问题\"></a>慢查询性能问题</h2><p>在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：</p>\n<ol>\n<li>索引没有设计好；</li>\n<li>SQL 语句没写好；</li>\n<li>MySQL 选错了索引。\n接下来，我们就具体分析一下这三种可能，以及对应的解决方案。</li>\n</ol>\n<br>\n### 导致慢查询的第一种可能是，索引没有设计好\n\n<p>这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。\n比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：</p>\n<ol>\n<li>在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；</li>\n<li>执行主备切换；</li>\n<li>这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。</li>\n</ol>\n<br>\n### 导致慢查询的第二种可能是，语句没写好\n\n<p>比如，我们犯了在第 18 篇文章《为什么这些 SQL 语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。\n这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。\n比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (\"select * from t where id + 1 = ?\", \"select * from t where id = ? - 1\", \"db1\");\ncall query_rewrite.flush_rewrite_rules();\n</code></pre>\n<p>这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。你可以用图 4 中的方法来确认改写规则是否生效。</p>\n<p><img src=\"1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg\" alt=\"图 4 查询重写效果\"></p>\n<br>\n### 导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章《MySQL 为什么有时候会选错索引？》中提到的情况，MySQL 选错了索引\n\n<p>这时候，应急方案就是给这个语句加上 force index。\n同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。\n上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。</p>\n<ol>\n<li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；</li>\n<li>在测试表里插入模拟线上的数据，做一遍回归测试；</li>\n<li>观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。</li>\n</ol>\n<p>不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。\n如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(<a href=\"https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)%E3%80%82\">https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。</a></p>\n<h2 id=\"QPS-突增问题\"><a href=\"#QPS-突增问题\" class=\"headerlink\" title=\"QPS 突增问题\"></a>QPS 突增问题</h2><p>有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。\n我之前碰到过一类情况，是由一个新功能的 bug 导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。\n而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回。\n当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：</p>\n<ol>\n<li>如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；</li>\n<li>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。</li>\n</ol>\n<p>所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。\n同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。\n这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。\n在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。\nDBA 虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好 SQL 审计可以减少需要这类操作的机会。\n其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server 层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。\n最后，又到了我们的思考题时间了。\n今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？</p>\n","site":{"data":{}},"excerpt":"","more":"<p>不知道你在实际运维过程中有没有碰到这样的情景：业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。\n我以前做业务护航的时候，就偶尔会碰上这种场景。用户的开发负责人说，不管你用什么方案，让业务先跑起来再说。\n但，如果是无损方案的话，肯定不需要等到这个时候才上场。今天我们就来聊聊这些临时方案，并着重说一说它们可能存在的风险。</p>\n<h2 id=\"短连接风暴\"><a href=\"#短连接风暴\" class=\"headerlink\" title=\"短连接风暴\"></a>短连接风暴</h2><p>正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。</p>\n<p>我在第 1 篇文章《基础架构：一条 SQL 查询语句是如何执行的？》中说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。</p>\n<p>在数据库压力比较小的时候，这些额外的成本并不明显。</p>\n<p>但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。</p>\n<p>在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。</p>\n<p>碰到这种情况时，一个比较自然的想法，就是调高 max_connections 的值。但这样做是有风险的。因为设计 max_connections 这个参数的目的是想保护 MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。</p>\n<p>那么这种情况下，你还有没有别的建议呢？我这里还有两种方法，但要注意，这些方法都是有损的。</p>\n<br/>\n### 第一种方法：先处理掉那些占着连接但是不工作的线程\n\n<p><code>max_connections</code> 的计算，不是看谁在 running，是只要连着就占用一个计数位置。对于那些不需要保持的连接，我们可以通过 <code>kill connection</code> 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。\n但是需要注意，在 <code>show processlist</code> 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。</p>\n<p><img src=\"1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg\" alt=\"图 1 sleep 线程的两种状态\"></p>\n<p>在上面这个例子里，如果断开 session A 的连接，因为这时候 session A 还没有提交，所以 MySQL 只能按照回滚事务来处理；而断开 session B 的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像 session B 这样的事务外空闲的连接。\n但是，怎么判断哪些是事务外空闲的呢？session C 在 T 时刻之后的 30 秒执行 show processlist，看到的结果是这样的。</p>\n<p><img src=\"1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg\" alt=\"图 2 sleep 线程的两种状态，show processlist 结果\"></p>\n<p>图中 id=4 和 id=5 的两个会话都是 Sleep 状态。而要看事务具体状态的话，你可以查 information_schema 库的 innodb_trx 表。</p>\n<p><img src=\"1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg\" alt=\"图 3 从 information_schema.innodb_trx 查询事务状态\"></p>\n<p>这个结果里，<code>trx_mysql_thread_id=4</code>，表示 id=4 的线程还处在事务中。\n因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。\n从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错<code>“ERROR 2013 (HY000): Lost connection to MySQL server during query”</code>。\n从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。\n你可能觉得这是一个冷笑话，但实际上我碰到过不下 10 次。\n所以，如果你是一个支持业务的 DBA，不要假设所有的应用代码都会被正确地处理。即使只是一个断开连接的操作，也要确保通知到业务开发团队。</p>\n<br/>\n### 第二种方法：减少连接过程的消耗\n\n<p>有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。\n跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。\n但是，这种方法特别符合我们标题里说的“饮鸩止渴”，风险极高，是我特别不建议使用的方案。尤其你的库外网可访问的话，就更不能这么做了。\n在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 –skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。可见，MySQL 官方对 skip-grant-tables 这个参数的安全问题也很重视。\n除了短连接数暴增可能会带来性能问题外，实际上，我们在线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由 QPS（每秒查询数）突增导致的。而关于更新语句导致的性能问题，我会在下一篇文章和你展开说明。</p>\n<h2 id=\"慢查询性能问题\"><a href=\"#慢查询性能问题\" class=\"headerlink\" title=\"慢查询性能问题\"></a>慢查询性能问题</h2><p>在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能：</p>\n<ol>\n<li>索引没有设计好；</li>\n<li>SQL 语句没写好；</li>\n<li>MySQL 选错了索引。\n接下来，我们就具体分析一下这三种可能，以及对应的解决方案。</li>\n</ol>\n<br/>\n### 导致慢查询的第一种可能是，索引没有设计好\n\n<p>这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。\n比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：</p>\n<ol>\n<li>在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；</li>\n<li>执行主备切换；</li>\n<li>这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。</li>\n</ol>\n<br/>\n### 导致慢查询的第二种可能是，语句没写好\n\n<p>比如，我们犯了在第 18 篇文章《为什么这些 SQL 语句逻辑相同，性能却差异巨大？》中提到的那些错误，导致语句没有使用上索引。\n这时，我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。\n比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。</p>\n<pre><code class=\"SQL\">mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from t where id + 1 = ?&quot;, &quot;select * from t where id = ? - 1&quot;, &quot;db1&quot;);\ncall query_rewrite.flush_rewrite_rules();\n</code></pre>\n<p>这里，call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。你可以用图 4 中的方法来确认改写规则是否生效。</p>\n<p><img src=\"1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg\" alt=\"图 4 查询重写效果\"></p>\n<br/>\n### 导致慢查询的第三种可能，就是碰上了我们在第 10 篇文章《MySQL 为什么有时候会选错索引？》中提到的情况，MySQL 选错了索引\n\n<p>这时候，应急方案就是给这个语句加上 force index。\n同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。\n上面我和你讨论的由慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。</p>\n<ol>\n<li>上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；</li>\n<li>在测试表里插入模拟线上的数据，做一遍回归测试；</li>\n<li>观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。</li>\n</ol>\n<p>不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。\n如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest(<a href=\"https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)%E3%80%82\">https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html)。</a></p>\n<h2 id=\"QPS-突增问题\"><a href=\"#QPS-突增问题\" class=\"headerlink\" title=\"QPS 突增问题\"></a>QPS 突增问题</h2><p>有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。\n我之前碰到过一类情况，是由一个新功能的 bug 导致的。当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。\n而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下。\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回。\n当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用：</p>\n<ol>\n<li>如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；</li>\n<li>很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。</li>\n</ol>\n<p>所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。\n同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>今天这篇文章，我以业务高峰期的性能问题为背景，和你介绍了一些紧急处理的手段。\n这些处理手段中，既包括了粗暴地拒绝连接和断开连接，也有通过重写语句来绕过一些坑的方法；既有临时的高危方案，也有未雨绸缪的、相对安全的预案。\n在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。\nDBA 虽然可以通过语句重写来暂时处理问题，但是这本身是一个风险高的操作，做好 SQL 审计可以减少需要这类操作的机会。\n其实，你可以看得出来，在这篇文章中我提到的解决方法主要集中在 server 层。在下一篇文章中，我会继续和你讨论一些跟 InnoDB 有关的处理方法。\n最后，又到了我们的思考题时间了。\n今天，我留给你的课后问题是，你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？</p>\n"},{"title":"21 | 为什么我只改一行的语句，锁这么多","date":"2019-06-02T16:00:00.000Z","_content":"在上一篇文章中，我和你介绍了`间隙锁`和 `next-key lock` 的概念，但是并没有说明加锁规则。间隙锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问题上犯错。\n所以今天，我们就先从这个加锁规则开始吧。\n首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，这个规则有以下两条前提说明：\n\n- MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。\n- 如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。\n\n因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。\n我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。\n- 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n- 原则 2：查找过程中访问到的对象才会加锁。\n- 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。\n\n<br/>\n### 案例一：等值查询间隙锁\n\n第一个例子是关于等值条件操作间隙：\n\n![图 1 等值查询的间隙锁](1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg)\n\n由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：\n根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；\n同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。\n所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。\n\n<br/>\n### 案例二：非唯一索引等值锁\n\n第二个例子是关于覆盖索引上的锁：\n\n![图 2 只加在非唯一索引上的锁](1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg)\n\n看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。\n这里 session A 要给索引 c 上 c=5 的这一行加上读锁。\n根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 `next-key lock`。\n要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 `next-key lock`。\n但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。\n根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。\n但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。\n需要注意，在这个例子中，`lock in share mode` 只锁覆盖索引，但是如果是 `for update` 就不一样了。 执行 `for update` 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。\n这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 `lock in share mode` 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 `select d from t where c=5 lock in share mode`。你可以自己验证一下效果。\n\n<br/>\n### 案例三：主键索引范围锁\n\n第三个例子是关于范围查询的\n举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？\n\n```SQL\nmysql> select * from t where id=10 for update;\nmysql> select * from t where id>=10 and id<11 for update;\n```\n\n你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。\n在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。\n\n![图 3 主键索引上范围查询的锁](1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg)\n\n现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？\n开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。\n范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。\n所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。\n这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。\n\n<br/>\n### 案例四：非唯一索引范围锁\n\n接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。\n需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。\n\n![图 4 非唯一索引范围锁](1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg)\n\n这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。\n所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。\n这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。\n\n<br/>\n### 案例五：唯一索引范围锁 bug\n\n前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。\n\n![图 5 唯一索引范围锁的 bug](1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg)\n\nsession A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。\n但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。\n所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。\n照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。\n我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。\n\n<br/>\n### 案例六：非唯一索引上存在\"等值\"的例子\n\n接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。\nmysql> insert into t values(30,10,30);\n新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。\n\n![图 6 非唯一索引等值的例子](1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg)\n\n可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。\n图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。\n现在，我们来看一下案例六。\n这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。\n\n![图 7 delete 示例](1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg)\n\n这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。\n然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。\n也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。\n\n![图 8 delete 加锁效果示例](1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg)\n\n这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。\n案例七：limit 语句加锁\n例子 6 也有一个对照案例，场景如下所示：\n\n![图 9 limit 语句加锁](1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg)\n\n这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。\n这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。\n因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：\n图 10 带 limit 2 的加锁效果\n可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。\n这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。\n\n<br/>\n### 案例八：一个死锁的例子\n\n前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。\n你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：\n\n![图 11 案例八的操作序列](1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg)\n\n现在，我们按时间顺序来分析一下为什么是这样的结果。\nsession A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；\nsession B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；\n然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。\n你可能会问，session B 的 next-key lock 不是还没申请成功吗？\n其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。\n也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。\n\n<br/>\n### 小结\n\n这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。\n在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。\n其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。\n另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。\n也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。\n不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。\n在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。\n经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。\n我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6 条记录，图 12 的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？\n\n![图 12 锁分析思考题](1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg)\n\n另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。\n加锁规则来分析一下，看看 session A 的 select 语句加了哪些锁：\n\n1. 由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。\n2. 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。\n3. 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。\n因此，session A 的 select 语句锁的范围就是：\n1. 索引 c 上 (5, 25)；\n2. 主键索引上 id=10、15、20 三个行锁。\n这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在“哪个索引上”的。因为，锁就是加在索引上的，这是 InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。\n\n--- \n\n评论区留言点赞板：\n\n@Justin 同学提了个好问题，<= 到底是间隙锁还是行锁？其实，这个问题，你要跟“执行过程”配合起来分析。在 InnoDB 要去找“第一个值”的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。\n@信信 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个 select * from ... for update 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock 全加上。\n@nero 同学的问题，提示我需要提醒大家注意，“有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。当然，等值判断的时候，需要加上优化 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。）。\n@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。\n最后，我要为元旦期间还坚持学习的同学们，点个赞 ^_^","source":"_posts/21-为什么我只改一行的语句，锁这么多.md","raw":"---\ntitle: 21 | 为什么我只改一行的语句，锁这么多\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在上一篇文章中，我和你介绍了`间隙锁`和 `next-key lock` 的概念，但是并没有说明加锁规则。间隙锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问题上犯错。\n所以今天，我们就先从这个加锁规则开始吧。\n首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，这个规则有以下两条前提说明：\n\n- MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。\n- 如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。\n\n因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。\n我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。\n- 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n- 原则 2：查找过程中访问到的对象才会加锁。\n- 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。\n\n```SQL\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。\n\n<br/>\n### 案例一：等值查询间隙锁\n\n第一个例子是关于等值条件操作间隙：\n\n![图 1 等值查询的间隙锁](1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg)\n\n由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：\n根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；\n同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。\n所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。\n\n<br/>\n### 案例二：非唯一索引等值锁\n\n第二个例子是关于覆盖索引上的锁：\n\n![图 2 只加在非唯一索引上的锁](1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg)\n\n看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。\n这里 session A 要给索引 c 上 c=5 的这一行加上读锁。\n根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 `next-key lock`。\n要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 `next-key lock`。\n但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。\n根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。\n但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。\n需要注意，在这个例子中，`lock in share mode` 只锁覆盖索引，但是如果是 `for update` 就不一样了。 执行 `for update` 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。\n这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 `lock in share mode` 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 `select d from t where c=5 lock in share mode`。你可以自己验证一下效果。\n\n<br/>\n### 案例三：主键索引范围锁\n\n第三个例子是关于范围查询的\n举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？\n\n```SQL\nmysql> select * from t where id=10 for update;\nmysql> select * from t where id>=10 and id<11 for update;\n```\n\n你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。\n在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。\n\n![图 3 主键索引上范围查询的锁](1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg)\n\n现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？\n开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。\n范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。\n所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。\n这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。\n\n<br/>\n### 案例四：非唯一索引范围锁\n\n接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。\n需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。\n\n![图 4 非唯一索引范围锁](1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg)\n\n这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。\n所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。\n这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。\n\n<br/>\n### 案例五：唯一索引范围锁 bug\n\n前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。\n\n![图 5 唯一索引范围锁的 bug](1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg)\n\nsession A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。\n但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。\n所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。\n照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。\n我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。\n\n<br/>\n### 案例六：非唯一索引上存在\"等值\"的例子\n\n接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。\nmysql> insert into t values(30,10,30);\n新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。\n\n![图 6 非唯一索引等值的例子](1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg)\n\n可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。\n图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。\n现在，我们来看一下案例六。\n这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。\n\n![图 7 delete 示例](1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg)\n\n这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。\n然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。\n也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。\n\n![图 8 delete 加锁效果示例](1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg)\n\n这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。\n案例七：limit 语句加锁\n例子 6 也有一个对照案例，场景如下所示：\n\n![图 9 limit 语句加锁](1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg)\n\n这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。\n这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。\n因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：\n图 10 带 limit 2 的加锁效果\n可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。\n这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。\n\n<br/>\n### 案例八：一个死锁的例子\n\n前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。\n你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：\n\n![图 11 案例八的操作序列](1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg)\n\n现在，我们按时间顺序来分析一下为什么是这样的结果。\nsession A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；\nsession B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；\n然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。\n你可能会问，session B 的 next-key lock 不是还没申请成功吗？\n其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。\n也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。\n\n<br/>\n### 小结\n\n这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。\n在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。\n其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。\n另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。\n也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。\n不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。\n在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。\n经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。\n我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6 条记录，图 12 的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？\n\n![图 12 锁分析思考题](1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg)\n\n另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。\n加锁规则来分析一下，看看 session A 的 select 语句加了哪些锁：\n\n1. 由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。\n2. 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。\n3. 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。\n因此，session A 的 select 语句锁的范围就是：\n1. 索引 c 上 (5, 25)；\n2. 主键索引上 id=10、15、20 三个行锁。\n这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在“哪个索引上”的。因为，锁就是加在索引上的，这是 InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。\n\n--- \n\n评论区留言点赞板：\n\n@Justin 同学提了个好问题，<= 到底是间隙锁还是行锁？其实，这个问题，你要跟“执行过程”配合起来分析。在 InnoDB 要去找“第一个值”的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。\n@信信 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个 select * from ... for update 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock 全加上。\n@nero 同学的问题，提示我需要提醒大家注意，“有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。当然，等值判断的时候，需要加上优化 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。）。\n@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。\n最后，我要为元旦期间还坚持学习的同学们，点个赞 ^_^","slug":"21-为什么我只改一行的语句，锁这么多","published":1,"updated":"2021-06-30T02:33:24.651Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvk001ur5p73urk5fxe","content":"<p>在上一篇文章中，我和你介绍了<code>间隙锁</code>和 <code>next-key lock</code> 的概念，但是并没有说明加锁规则。间隙锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问题上犯错。\n所以今天，我们就先从这个加锁规则开始吧。\n首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，这个规则有以下两条前提说明：</p>\n<ul>\n<li>MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13。</li>\n<li>如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。</li>\n</ul>\n<p>因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。\n我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。</p>\n<ul>\n<li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。</li>\n<li>原则 2：查找过程中访问到的对象才会加锁。</li>\n<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>\n<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li>\n<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。</li>\n</ul>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n</code></pre>\n<p>接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。</p>\n<br>\n### 案例一：等值查询间隙锁\n\n<p>第一个例子是关于等值条件操作间隙：</p>\n<p><img src=\"1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg\" alt=\"图 1 等值查询的间隙锁\"></p>\n<p>由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：\n根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；\n同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。\n所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。</p>\n<br>\n### 案例二：非唯一索引等值锁\n\n<p>第二个例子是关于覆盖索引上的锁：</p>\n<p><img src=\"1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg\" alt=\"图 2 只加在非唯一索引上的锁\"></p>\n<p>看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。\n这里 session A 要给索引 c 上 c=5 的这一行加上读锁。\n根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 <code>next-key lock</code>。\n要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 <code>next-key lock</code>。\n但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。\n根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。\n但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。\n需要注意，在这个例子中，<code>lock in share mode</code> 只锁覆盖索引，但是如果是 <code>for update</code> 就不一样了。 执行 <code>for update</code> 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。\n这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 <code>lock in share mode</code> 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 <code>select d from t where c=5 lock in share mode</code>。你可以自己验证一下效果。</p>\n<br>\n### 案例三：主键索引范围锁\n\n<p>第三个例子是关于范围查询的\n举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> select * from t where id=10 for update;\nmysql> select * from t where id>=10 and id<11 for update;\n</code></pre>\n<p>你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。\n在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。</p>\n<p><img src=\"1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg\" alt=\"图 3 主键索引上范围查询的锁\"></p>\n<p>现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？\n开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。\n范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。\n所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。\n这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。</p>\n<br>\n### 案例四：非唯一索引范围锁\n\n<p>接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。\n需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。</p>\n<p><img src=\"1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg\" alt=\"图 4 非唯一索引范围锁\"></p>\n<p>这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。\n所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。\n这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。</p>\n<br>\n### 案例五：唯一索引范围锁 bug\n\n<p>前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。</p>\n<p><img src=\"1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg\" alt=\"图 5 唯一索引范围锁的 bug\"></p>\n<p>session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。\n但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。\n所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。\n照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。\n我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。</p>\n<br>\n### 案例六：非唯一索引上存在\"等值\"的例子\n\n<p>接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。\nmysql&gt; insert into t values(30,10,30);\n新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。</p>\n<p><img src=\"1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg\" alt=\"图 6 非唯一索引等值的例子\"></p>\n<p>可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。\n图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。\n现在，我们来看一下案例六。\n这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select … for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。</p>\n<p><img src=\"1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg\" alt=\"图 7 delete 示例\"></p>\n<p>这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。\n然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。\n也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。</p>\n<p><img src=\"1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg\" alt=\"图 8 delete 加锁效果示例\"></p>\n<p>这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。\n案例七：limit 语句加锁\n例子 6 也有一个对照案例，场景如下所示：</p>\n<p><img src=\"1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg\" alt=\"图 9 limit 语句加锁\"></p>\n<p>这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。\n这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。\n因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：\n图 10 带 limit 2 的加锁效果\n可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。\n这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。</p>\n<br>\n### 案例八：一个死锁的例子\n\n<p>前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。\n你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：</p>\n<p><img src=\"1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg\" alt=\"图 11 案例八的操作序列\"></p>\n<p>现在，我们按时间顺序来分析一下为什么是这样的结果。\nsession A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；\nsession B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；\n然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。\n你可能会问，session B 的 next-key lock 不是还没申请成功吗？\n其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。\n也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。</p>\n<br>\n### 小结\n\n<p>这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。\n在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。\n其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。\n另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。\n也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。\n不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。\n在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。\n经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。\n我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6 条记录，图 12 的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？</p>\n<p><img src=\"1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg\" alt=\"图 12 锁分析思考题\"></p>\n<p>另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。\n加锁规则来分析一下，看看 session A 的 select 语句加了哪些锁：</p>\n<ol>\n<li>由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。</li>\n<li>在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。</li>\n<li>在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。\n因此，session A 的 select 语句锁的范围就是：</li>\n<li>索引 c 上 (5, 25)；</li>\n<li>主键索引上 id=10、15、20 三个行锁。\n这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在“哪个索引上”的。因为，锁就是加在索引上的，这是 InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。</li>\n</ol>\n<hr>\n<p>评论区留言点赞板：</p>\n<p>@Justin 同学提了个好问题，&lt;= 到底是间隙锁还是行锁？其实，这个问题，你要跟“执行过程”配合起来分析。在 InnoDB 要去找“第一个值”的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。\n@信信 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个 select * from … for update 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock 全加上。\n@nero 同学的问题，提示我需要提醒大家注意，“有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。当然，等值判断的时候，需要加上优化 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。）。\n@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。\n最后，我要为元旦期间还坚持学习的同学们，点个赞 ^_^</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在上一篇文章中，我和你介绍了<code>间隙锁</code>和 <code>next-key lock</code> 的概念，但是并没有说明加锁规则。间隙锁的概念理解起来确实有点儿难，尤其在配合上行锁以后，很容易在判断是否会出现锁等待的问题上犯错。\n所以今天，我们就先从这个加锁规则开始吧。\n首先说明一下，这些加锁规则我没在别的地方看到过有类似的总结，以前我自己判断的时候都是想着代码里面的实现来脑补的。这次为了总结成不看代码的同学也能理解的规则，是我又重新刷了代码临时总结出来的。所以，这个规则有以下两条前提说明：</p>\n<ul>\n<li>MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13。</li>\n<li>如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。</li>\n</ul>\n<p>因为间隙锁在可重复读隔离级别下才有效，所以本篇文章接下来的描述，若没有特殊说明，默认是可重复读隔离级别。\n我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。</p>\n<ul>\n<li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。</li>\n<li>原则 2：查找过程中访问到的对象才会加锁。</li>\n<li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li>\n<li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li>\n<li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。</li>\n</ul>\n<pre><code class=\"SQL\">CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n</code></pre>\n<p>接下来的例子基本都是配合着图片说明的，所以我建议你可以对照着文稿看，有些例子可能会“毁三观”，也建议你读完文章后亲手实践一下。</p>\n<br/>\n### 案例一：等值查询间隙锁\n\n<p>第一个例子是关于等值条件操作间隙：</p>\n<p><img src=\"1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg\" alt=\"图 1 等值查询的间隙锁\"></p>\n<p>由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话：\n根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；\n同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。\n所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。</p>\n<br/>\n### 案例二：非唯一索引等值锁\n\n<p>第二个例子是关于覆盖索引上的锁：</p>\n<p><img src=\"1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg\" alt=\"图 2 只加在非唯一索引上的锁\"></p>\n<p>看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。\n这里 session A 要给索引 c 上 c=5 的这一行加上读锁。\n根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 <code>next-key lock</code>。\n要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 <code>next-key lock</code>。\n但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。\n根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。\n但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。\n需要注意，在这个例子中，<code>lock in share mode</code> 只锁覆盖索引，但是如果是 <code>for update</code> 就不一样了。 执行 <code>for update</code> 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。\n这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 <code>lock in share mode</code> 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 <code>select d from t where c=5 lock in share mode</code>。你可以自己验证一下效果。</p>\n<br/>\n### 案例三：主键索引范围锁\n\n<p>第三个例子是关于范围查询的\n举例之前，你可以先思考一下这个问题：对于我们这个表 t，下面这两条查询语句，加锁范围相同吗？</p>\n<pre><code class=\"SQL\">mysql&gt; select * from t where id=10 for update;\nmysql&gt; select * from t where id&gt;=10 and id&lt;11 for update;\n</code></pre>\n<p>你可能会想，id 定义为 int 类型，这两个语句就是等价的吧？其实，它们并不完全等价。\n在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。</p>\n<p><img src=\"1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg\" alt=\"图 3 主键索引上范围查询的锁\"></p>\n<p>现在我们就用前面提到的加锁规则，来分析一下 session A 会加什么锁呢？\n开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。\n范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。\n所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。\n这里你需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。</p>\n<br/>\n### 案例四：非唯一索引范围锁\n\n<p>接下来，我们再看两个范围查询加锁的例子，你可以对照着案例三来看。\n需要注意的是，与案例三不同的是，案例四中查询语句的 where 部分用的是字段 c。</p>\n<p><img src=\"1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg\" alt=\"图 4 非唯一索引范围锁\"></p>\n<p>这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。\n所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。\n这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。</p>\n<br/>\n### 案例五：唯一索引范围锁 bug\n\n<p>前面的四个案例，我们已经用到了加锁规则中的两个原则和两个优化，接下来再看一个关于加锁规则中 bug 的案例。</p>\n<p><img src=\"1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg\" alt=\"图 5 唯一索引范围锁的 bug\"></p>\n<p>session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。\n但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock 也会被锁上。\n所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。\n照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。\n我也曾找社区的专家讨论过，官方 bug 系统上也有提到，但是并未被 verified。所以，认为这是 bug 这个事儿，也只能算我的一家之言，如果你有其他见解的话，也欢迎你提出来。</p>\n<br/>\n### 案例六：非唯一索引上存在\"等值\"的例子\n\n<p>接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。\nmysql&gt; insert into t values(30,10,30);\n新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。那么，这时候索引 c 上的间隙是什么状态了呢？你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。</p>\n<p><img src=\"1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg\" alt=\"图 6 非唯一索引等值的例子\"></p>\n<p>可以看到，虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。\n图中我画出了索引 c 上的主键 id。为了跟间隙锁的开区间形式进行区别，我用 (c=10,id=30) 这样的形式，来表示索引上的一行。\n现在，我们来看一下案例六。\n这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select … for update 是类似的，也就是我在文章开始总结的两个“原则”、两个“优化”和一个“bug”。</p>\n<p><img src=\"1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg\" alt=\"图 7 delete 示例\"></p>\n<p>这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。\n然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。\n也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。</p>\n<p><img src=\"1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg\" alt=\"图 8 delete 加锁效果示例\"></p>\n<p>这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。\n案例七：limit 语句加锁\n例子 6 也有一个对照案例，场景如下所示：</p>\n<p><img src=\"1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg\" alt=\"图 9 limit 语句加锁\"></p>\n<p>这个例子里，session A 的 delete 语句加了 limit 2。你知道表 t 里 c=10 的记录其实只有两条，因此加不加 limit 2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，session B 的 insert 语句执行通过了，跟案例六的结果不同。\n这是因为，案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。\n因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：\n图 10 带 limit 2 的加锁效果\n可以看到，(c=10,id=30）之后的这个间隙并没有在加锁范围里，因此 insert 语句插入 c=12 是可以执行成功的。\n这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。</p>\n<br/>\n### 案例八：一个死锁的例子\n\n<p>前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。\n你一定会疑惑，这个概念不是一开始就说了吗？不要着急，我们先来看下面这个例子：</p>\n<p><img src=\"1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg\" alt=\"图 11 案例八的操作序列\"></p>\n<p>现在，我们按时间顺序来分析一下为什么是这样的结果。\nsession A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；\nsession B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；\n然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。\n你可能会问，session B 的 next-key lock 不是还没申请成功吗？\n其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。\n也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。</p>\n<br/>\n### 小结\n\n<p>这里我再次说明一下，我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。\n在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。\n其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂，我们今天先不展开。\n另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。\n也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。\n不过，我希望你学过今天的课程以后，可以对 next-key lock 的概念有更清晰的认识，并且会用加锁规则去判断语句的加锁范围。\n在业务需要使用可重复读隔离级别的时候，能够更细致地设计操作数据库的语句，解决幻读问题的同时，最大限度地提升系统并行处理事务的能力。\n经过这篇文章的介绍，你再看一下上一篇文章最后的思考题，再来尝试分析一次。\n我把题目重新描述和简化一下：还是我们在文章开头初始化的表 t，里面有 6 条记录，图 12 的语句序列中，为什么 session B 的 insert 操作，会被锁住呢？</p>\n<p><img src=\"1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg\" alt=\"图 12 锁分析思考题\"></p>\n<p>另外，如果你有兴趣多做一些实验的话，可以设计好语句序列，在执行之前先自己分析一下，然后实际地验证结果是否跟你的分析一致。\n加锁规则来分析一下，看看 session A 的 select 语句加了哪些锁：</p>\n<ol>\n<li>由于是 order by c desc，第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。</li>\n<li>在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。</li>\n<li>在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id 上加三个行锁。\n因此，session A 的 select 语句锁的范围就是：</li>\n<li>索引 c 上 (5, 25)；</li>\n<li>主键索引上 id=10、15、20 三个行锁。\n这里，我再啰嗦下，你会发现我在文章中，每次加锁都会说明是加在“哪个索引上”的。因为，锁就是加在索引上的，这是 InnoDB 的一个基础设定，需要你在分析问题的时候要一直记得。</li>\n</ol>\n<hr>\n<p>评论区留言点赞板：</p>\n<p>@Justin 同学提了个好问题，&lt;= 到底是间隙锁还是行锁？其实，这个问题，你要跟“执行过程”配合起来分析。在 InnoDB 要去找“第一个值”的时候，是按照等值去找的，用的是等值判断的规则；找到第一个值以后，要在索引内找“下一个值”，对应于我们规则中说的范围查找。\n@信信 提了一个不错的问题，要知道最终的加锁是根据实际执行情况来的。所以，如果一个 select * from … for update 语句，优化器决定使用全表扫描，那么就会把主键索引上 next-key lock 全加上。\n@nero 同学的问题，提示我需要提醒大家注意，“有行”才会加行锁。如果查询条件没有命中行，那就加 next-key lock。当然，等值判断的时候，需要加上优化 2（即：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。）。\n@小李子、@发条橙子同学，都提了很好的问题，这期高质量评论很多，你也都可以去看看。\n最后，我要为元旦期间还坚持学习的同学们，点个赞 ^_^</p>\n"},{"title":"23 | MySQL是怎么保证数据不丢的","date":"2019-06-02T16:00:00.000Z","_content":"今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL 是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。\n在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下第 2 篇、第 9 篇、第 12 篇和第 15 篇文章中的相关内容），得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\n评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log 真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程。\n\n## binlog 的写入机制\n\n其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。\n系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。\n\n![图 1 binlog 写盘状态](1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg)\n\n可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。\n图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。\n\nwrite 和 fsync 的时机，是由参数 sync_binlog 控制的：\n\n- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；\n- sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；\n- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。\n\n因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。\n但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。\n\n## redo log 的写入机制\n\n接下来，我们再说说 redo log 的写入机制。\n在专栏的第 15 篇答疑文章中，我给你介绍了 redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。\n然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？\n答案是，不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。\n那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？\n答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。\n\n![图 2 MySQL redo log 存储状态](1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg)\n\n这三种状态分别是：\n存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；\n写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；\n持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。\n日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n• 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n• 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n• 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\nInnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。\n实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。\n• redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n• 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。\n如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下第 15 篇文章中的相关内容）。\n每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。\n\n通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？\n\n解释这个问题，就要用到组提交（group commit）机制了。\n\n这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\n\nLSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。\n\n如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。\n\n![图 3 redo log 组提交](1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg)\n\n从图中可以看到，\n• trx1 是第一个到达的，会被选为这组的 leader；\n• 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；\n• trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；\n• trx2 和 trx3 就可以直接返回了。\n所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。\n\n![图 4 两阶段提交](1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.jpg)\n\n图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：\n\n- 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；\n- 调用 fsync 持久化。\n\nMySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：\n\n![图 5 两阶段提交细化](1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg)\n\n这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。\n\n不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。\n\n如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。\n\n所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。\n之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？\n\n现在你就能理解了，WAL 机制主要得益于两个方面：\n\n- redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；\n- 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。\n\n分析到这里，我们再来回答这个问题：如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？\n针对这个问题，可以考虑以下三种方法：\n\n1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。\n2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。\n3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。\n\n我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。\n\n## 小结\n\n在专栏的第 2 篇和第 15 篇文章中，我和你分析了，如果 redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe 的。今天这篇文章，我着重和你介绍的是 MySQL 是“怎么保证 redo log 和 binlog 是完整的”。\n希望这三篇文章串起来的内容，能够让你对 crash-safe 这个概念有更清晰的理解。之前的第 15 篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。\n\n#### 问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？\n回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。\n\n#### 问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\n回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。\n#### 问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？\n回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。\n\n#### 问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？\n\n回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。\n\n实际上数据库的 crash-safe 保证的是：\n\n1. 如果客户端收到事务成功的消息，事务就一定持久化了；\n2. 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；\n3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。\n\n课后问题\n今天我留给你的思考题是：你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？\n\n\n上期我留给你的问题是，你在什么时候会把线上生产库设置成“非双 1”。我目前知道的场景，有以下这些：\n业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。\n备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。\n用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。\n批量导入数据的时候。\n一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。\n评论区留言点赞板：\n@way 同学提到了一个有趣的现象，由于从库设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 导致一直延迟的情况。我们在主库设置这两个参数，是为了减少 binlog 的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这两个参数的拖累。一般追主备就用“非双 1”（追上记得改回来）。\n@一大只 同学验证了在 sync_binlog=0 的情况下，设置 sync_delay 和 sync_no_delay_count 的现象，点赞这种发现边界的意识和手动验证的好习惯。是这样的：sync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n@锅子 同学提到，设置 sync_binlog=0 的时候，还是可以看到 binlog 文件马上做了修改。这个是对的，我们说“写到了 page cache”，就是文件系统的 page cache。而你用 ls 命令看到的就是文件系统返回的结果。","source":"_posts/23-MySQL是怎么保证数据不丢的.md","raw":"---\ntitle: 23 | MySQL是怎么保证数据不丢的\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL 是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。\n在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下第 2 篇、第 9 篇、第 12 篇和第 15 篇文章中的相关内容），得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\n评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log 真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程。\n\n## binlog 的写入机制\n\n其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。\n系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。\n\n![图 1 binlog 写盘状态](1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg)\n\n可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。\n图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。\n\nwrite 和 fsync 的时机，是由参数 sync_binlog 控制的：\n\n- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；\n- sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；\n- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。\n\n因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。\n但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。\n\n## redo log 的写入机制\n\n接下来，我们再说说 redo log 的写入机制。\n在专栏的第 15 篇答疑文章中，我给你介绍了 redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。\n然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？\n答案是，不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。\n那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？\n答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。\n\n![图 2 MySQL redo log 存储状态](1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg)\n\n这三种状态分别是：\n存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；\n写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；\n持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。\n日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n• 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n• 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n• 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\nInnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。\n实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。\n• redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n• 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。\n如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下第 15 篇文章中的相关内容）。\n每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。\n\n通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？\n\n解释这个问题，就要用到组提交（group commit）机制了。\n\n这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\n\nLSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。\n\n如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。\n\n![图 3 redo log 组提交](1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg)\n\n从图中可以看到，\n• trx1 是第一个到达的，会被选为这组的 leader；\n• 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；\n• trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；\n• trx2 和 trx3 就可以直接返回了。\n所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。\n\n![图 4 两阶段提交](1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.jpg)\n\n图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：\n\n- 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；\n- 调用 fsync 持久化。\n\nMySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：\n\n![图 5 两阶段提交细化](1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg)\n\n这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。\n\n不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。\n\n如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。\n\n所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。\n之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？\n\n现在你就能理解了，WAL 机制主要得益于两个方面：\n\n- redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；\n- 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。\n\n分析到这里，我们再来回答这个问题：如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？\n针对这个问题，可以考虑以下三种方法：\n\n1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。\n2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。\n3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。\n\n我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。\n\n## 小结\n\n在专栏的第 2 篇和第 15 篇文章中，我和你分析了，如果 redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe 的。今天这篇文章，我着重和你介绍的是 MySQL 是“怎么保证 redo log 和 binlog 是完整的”。\n希望这三篇文章串起来的内容，能够让你对 crash-safe 这个概念有更清晰的理解。之前的第 15 篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。\n\n#### 问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？\n回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。\n\n#### 问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\n回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。\n#### 问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？\n回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。\n\n#### 问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？\n\n回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。\n\n实际上数据库的 crash-safe 保证的是：\n\n1. 如果客户端收到事务成功的消息，事务就一定持久化了；\n2. 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；\n3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。\n\n课后问题\n今天我留给你的思考题是：你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？\n\n\n上期我留给你的问题是，你在什么时候会把线上生产库设置成“非双 1”。我目前知道的场景，有以下这些：\n业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。\n备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。\n用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。\n批量导入数据的时候。\n一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。\n评论区留言点赞板：\n@way 同学提到了一个有趣的现象，由于从库设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 导致一直延迟的情况。我们在主库设置这两个参数，是为了减少 binlog 的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这两个参数的拖累。一般追主备就用“非双 1”（追上记得改回来）。\n@一大只 同学验证了在 sync_binlog=0 的情况下，设置 sync_delay 和 sync_no_delay_count 的现象，点赞这种发现边界的意识和手动验证的好习惯。是这样的：sync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n@锅子 同学提到，设置 sync_binlog=0 的时候，还是可以看到 binlog 文件马上做了修改。这个是对的，我们说“写到了 page cache”，就是文件系统的 page cache。而你用 ls 命令看到的就是文件系统返回的结果。","slug":"23-MySQL是怎么保证数据不丢的","published":1,"updated":"2021-06-30T02:33:24.664Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvl001xr5p72yyf3ze4","content":"<p>今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL 是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。\n在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下第 2 篇、第 9 篇、第 12 篇和第 15 篇文章中的相关内容），得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\n评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log 真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程。</p>\n<h2 id=\"binlog-的写入机制\"><a href=\"#binlog-的写入机制\" class=\"headerlink\" title=\"binlog 的写入机制\"></a>binlog 的写入机制</h2><p>其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。\n系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。</p>\n<p><img src=\"1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg\" alt=\"图 1 binlog 写盘状态\"></p>\n<p>可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。\n图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。</p>\n<p>write 和 fsync 的时机，是由参数 sync_binlog 控制的：</p>\n<ul>\n<li>sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；</li>\n<li>sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；</li>\n<li>sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>\n</ul>\n<p>因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。\n但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。</p>\n<h2 id=\"redo-log-的写入机制\"><a href=\"#redo-log-的写入机制\" class=\"headerlink\" title=\"redo log 的写入机制\"></a>redo log 的写入机制</h2><p>接下来，我们再说说 redo log 的写入机制。\n在专栏的第 15 篇答疑文章中，我给你介绍了 redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。\n然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？\n答案是，不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。\n那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？\n答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。</p>\n<p><img src=\"1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg\" alt=\"图 2 MySQL redo log 存储状态\"></p>\n<p>这三种状态分别是：\n存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；\n写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；\n持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。\n日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n• 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n• 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n• 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\nInnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。\n实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。\n• redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n• 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。\n如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下第 15 篇文章中的相关内容）。\n每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。</p>\n<p>通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？</p>\n<p>解释这个问题，就要用到组提交（group commit）机制了。</p>\n<p>这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。</p>\n<p>LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。</p>\n<p>如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。</p>\n<p><img src=\"1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg\" alt=\"图 3 redo log 组提交\"></p>\n<p>从图中可以看到，\n• trx1 是第一个到达的，会被选为这组的 leader；\n• 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；\n• trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；\n• trx2 和 trx3 就可以直接返回了。\n所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。</p>\n<p><img src=\"1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.jpg\" alt=\"图 4 两阶段提交\"></p>\n<p>图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：</p>\n<ul>\n<li>先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；</li>\n<li>调用 fsync 持久化。</li>\n</ul>\n<p>MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：</p>\n<p><img src=\"1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg\" alt=\"图 5 两阶段提交细化\"></p>\n<p>这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。</p>\n<p>不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。</p>\n<p>如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。</p>\n<p>这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。</p>\n<p>所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。\n之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？</p>\n<p>现在你就能理解了，WAL 机制主要得益于两个方面：</p>\n<ul>\n<li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li>\n<li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li>\n</ul>\n<p>分析到这里，我们再来回答这个问题：如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？\n针对这个问题，可以考虑以下三种方法：</p>\n<ol>\n<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。</li>\n<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li>\n<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。</li>\n</ol>\n<p>我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>在专栏的第 2 篇和第 15 篇文章中，我和你分析了，如果 redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe 的。今天这篇文章，我着重和你介绍的是 MySQL 是“怎么保证 redo log 和 binlog 是完整的”。\n希望这三篇文章串起来的内容，能够让你对 crash-safe 这个概念有更清晰的理解。之前的第 15 篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。</p>\n<h4 id=\"问题-1：执行一个-update-语句以后，我再去执行-hexdump-命令直接查看-ibd-文件内容，为什么没有看到数据有改变呢？\"><a href=\"#问题-1：执行一个-update-语句以后，我再去执行-hexdump-命令直接查看-ibd-文件内容，为什么没有看到数据有改变呢？\" class=\"headerlink\" title=\"问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？\"></a>问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？</h4><p>回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。</p>\n<h4 id=\"问题-2：为什么-binlog-cache-是每个线程自己维护的，而-redo-log-buffer-是全局共用的？\"><a href=\"#问题-2：为什么-binlog-cache-是每个线程自己维护的，而-redo-log-buffer-是全局共用的？\" class=\"headerlink\" title=\"问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\"></a>问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？</h4><p>回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</p>\n<h4 id=\"问题-3：事务执行期间，还没到提交阶段，如果发生-crash-的话，redo-log-肯定丢了，这会不会导致主备不一致呢？\"><a href=\"#问题-3：事务执行期间，还没到提交阶段，如果发生-crash-的话，redo-log-肯定丢了，这会不会导致主备不一致呢？\" class=\"headerlink\" title=\"问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？\"></a>问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？</h4><p>回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。</p>\n<h4 id=\"问题-4：如果-binlog-写完盘以后发生-crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是-bug？\"><a href=\"#问题-4：如果-binlog-写完盘以后发生-crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是-bug？\" class=\"headerlink\" title=\"问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？\"></a>问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？</h4><p>回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。</p>\n<p>实际上数据库的 crash-safe 保证的是：</p>\n<ol>\n<li>如果客户端收到事务成功的消息，事务就一定持久化了；</li>\n<li>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</li>\n<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。</li>\n</ol>\n<p>课后问题\n今天我留给你的思考题是：你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？</p>\n<p>上期我留给你的问题是，你在什么时候会把线上生产库设置成“非双 1”。我目前知道的场景，有以下这些：\n业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。\n备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。\n用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。\n批量导入数据的时候。\n一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。\n评论区留言点赞板：\n@way 同学提到了一个有趣的现象，由于从库设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 导致一直延迟的情况。我们在主库设置这两个参数，是为了减少 binlog 的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这两个参数的拖累。一般追主备就用“非双 1”（追上记得改回来）。\n@一大只 同学验证了在 sync_binlog=0 的情况下，设置 sync_delay 和 sync_no_delay_count 的现象，点赞这种发现边界的意识和手动验证的好习惯。是这样的：sync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n@锅子 同学提到，设置 sync_binlog=0 的时候，还是可以看到 binlog 文件马上做了修改。这个是对的，我们说“写到了 page cache”，就是文件系统的 page cache。而你用 ls 命令看到的就是文件系统返回的结果。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>今天这篇文章，我会继续和你介绍在业务高峰期临时提升性能的方法。从文章标题“MySQL 是怎么保证数据不丢的？”，你就可以看出来，今天我和你介绍的方法，跟数据的可靠性有关。\n在专栏前面文章和答疑篇中，我都着重介绍了 WAL 机制（你可以再回顾下第 2 篇、第 9 篇、第 12 篇和第 15 篇文章中的相关内容），得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\n评论区有同学又继续追问，redo log 的写入流程是怎么样的，如何保证 redo log 真实地写入了磁盘。那么今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程。</p>\n<h2 id=\"binlog-的写入机制\"><a href=\"#binlog-的写入机制\" class=\"headerlink\" title=\"binlog 的写入机制\"></a>binlog 的写入机制</h2><p>其实，binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。\n系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示。</p>\n<p><img src=\"1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg\" alt=\"图 1 binlog 写盘状态\"></p>\n<p>可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。\n图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。</p>\n<p>write 和 fsync 的时机，是由参数 sync_binlog 控制的：</p>\n<ul>\n<li>sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；</li>\n<li>sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；</li>\n<li>sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>\n</ul>\n<p>因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。\n但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。</p>\n<h2 id=\"redo-log-的写入机制\"><a href=\"#redo-log-的写入机制\" class=\"headerlink\" title=\"redo log 的写入机制\"></a>redo log 的写入机制</h2><p>接下来，我们再说说 redo log 的写入机制。\n在专栏的第 15 篇答疑文章中，我给你介绍了 redo log buffer。事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。\n然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？\n答案是，不需要。如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。\n那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？\n答案是，确实会有。这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。</p>\n<p><img src=\"1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg\" alt=\"图 2 MySQL redo log 存储状态\"></p>\n<p>这三种状态分别是：\n存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分；\n写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；\n持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。\n日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n• 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n• 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n• 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\nInnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。\n实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。\n• redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n• 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。\n如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。（如果你印象有点儿模糊了，可以再回顾下第 15 篇文章中的相关内容）。\n每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。</p>\n<p>通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？</p>\n<p>解释这个问题，就要用到组提交（group commit）机制了。</p>\n<p>这里，我需要先和你介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。</p>\n<p>LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。</p>\n<p>如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。</p>\n<p><img src=\"1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg\" alt=\"图 3 redo log 组提交\"></p>\n<p>从图中可以看到，\n• trx1 是第一个到达的，会被选为这组的 leader；\n• 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；\n• trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；\n• trx2 和 trx3 就可以直接返回了。\n所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。</p>\n<p><img src=\"1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.jpg\" alt=\"图 4 两阶段提交\"></p>\n<p>图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：</p>\n<ul>\n<li>先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；</li>\n<li>调用 fsync 持久化。</li>\n</ul>\n<p>MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样：</p>\n<p><img src=\"1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg\" alt=\"图 5 两阶段提交细化\"></p>\n<p>这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。</p>\n<p>不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。</p>\n<p>如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。</p>\n<p>这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。</p>\n<p>所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。\n之前有同学在评论区问到，WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？</p>\n<p>现在你就能理解了，WAL 机制主要得益于两个方面：</p>\n<ul>\n<li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；</li>\n<li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗。</li>\n</ul>\n<p>分析到这里，我们再来回答这个问题：如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？\n针对这个问题，可以考虑以下三种方法：</p>\n<ol>\n<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。</li>\n<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。</li>\n<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。</li>\n</ol>\n<p>我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。</p>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><p>在专栏的第 2 篇和第 15 篇文章中，我和你分析了，如果 redo log 和 binlog 是完整的，MySQL 是如何保证 crash-safe 的。今天这篇文章，我着重和你介绍的是 MySQL 是“怎么保证 redo log 和 binlog 是完整的”。\n希望这三篇文章串起来的内容，能够让你对 crash-safe 这个概念有更清晰的理解。之前的第 15 篇答疑文章发布之后，有同学继续留言问到了一些跟日志相关的问题，这里为了方便你回顾、学习，我再集中回答一次这些问题。</p>\n<h4 id=\"问题-1：执行一个-update-语句以后，我再去执行-hexdump-命令直接查看-ibd-文件内容，为什么没有看到数据有改变呢？\"><a href=\"#问题-1：执行一个-update-语句以后，我再去执行-hexdump-命令直接查看-ibd-文件内容，为什么没有看到数据有改变呢？\" class=\"headerlink\" title=\"问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？\"></a>问题 1：执行一个 update 语句以后，我再去执行 hexdump 命令直接查看 ibd 文件内容，为什么没有看到数据有改变呢？</h4><p>回答：这可能是因为 WAL 机制的原因。update 语句执行完成后，InnoDB 只保证写完了 redo log、内存，可能还没来得及将数据写到磁盘。</p>\n<h4 id=\"问题-2：为什么-binlog-cache-是每个线程自己维护的，而-redo-log-buffer-是全局共用的？\"><a href=\"#问题-2：为什么-binlog-cache-是每个线程自己维护的，而-redo-log-buffer-是全局共用的？\" class=\"headerlink\" title=\"问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\"></a>问题 2：为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？</h4><p>回答：MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。而 redo log 并没有这个要求，中间有生成的日志可以写到 redo log buffer 中。redo log buffer 中的内容还能“搭便车”，其他事务提交的时候可以被一起写到磁盘中。</p>\n<h4 id=\"问题-3：事务执行期间，还没到提交阶段，如果发生-crash-的话，redo-log-肯定丢了，这会不会导致主备不一致呢？\"><a href=\"#问题-3：事务执行期间，还没到提交阶段，如果发生-crash-的话，redo-log-肯定丢了，这会不会导致主备不一致呢？\" class=\"headerlink\" title=\"问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？\"></a>问题 3：事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？</h4><p>回答：不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。</p>\n<h4 id=\"问题-4：如果-binlog-写完盘以后发生-crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是-bug？\"><a href=\"#问题-4：如果-binlog-写完盘以后发生-crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是-bug？\" class=\"headerlink\" title=\"问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？\"></a>问题 4：如果 binlog 写完盘以后发生 crash，这时候还没给客户端答复就重启了。等客户端再重连进来，发现事务已经提交成功了，这是不是 bug？</h4><p>回答：不是。你可以设想一下更极端的情况，整个事务都提交成功了，redo log commit 完成了，备库也收到 binlog 并执行了。但是主库和客户端网络断开了，导致事务成功的包返回不回去，这时候客户端也会收到“网络断开”的异常。这种也只能算是事务成功的，不能认为是 bug。</p>\n<p>实际上数据库的 crash-safe 保证的是：</p>\n<ol>\n<li>如果客户端收到事务成功的消息，事务就一定持久化了；</li>\n<li>如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；</li>\n<li>如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。</li>\n</ol>\n<p>课后问题\n今天我留给你的思考题是：你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？另外，我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？</p>\n<p>上期我留给你的问题是，你在什么时候会把线上生产库设置成“非双 1”。我目前知道的场景，有以下这些：\n业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。\n备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。\n用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。\n批量导入数据的时候。\n一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。\n评论区留言点赞板：\n@way 同学提到了一个有趣的现象，由于从库设置了 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 导致一直延迟的情况。我们在主库设置这两个参数，是为了减少 binlog 的写盘压力。备库这么设置，尤其在“快要追上”的时候，就反而会受这两个参数的拖累。一般追主备就用“非双 1”（追上记得改回来）。\n@一大只 同学验证了在 sync_binlog=0 的情况下，设置 sync_delay 和 sync_no_delay_count 的现象，点赞这种发现边界的意识和手动验证的好习惯。是这样的：sync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n@锅子 同学提到，设置 sync_binlog=0 的时候，还是可以看到 binlog 文件马上做了修改。这个是对的，我们说“写到了 page cache”，就是文件系统的 page cache。而你用 ls 命令看到的就是文件系统返回的结果。</p>\n"},{"title":"24 | MySQL是怎么保证主备一致的","date":"2019-06-02T16:00:00.000Z","_content":"在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。\n毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。\n在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。\n今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。\n\n### MySQL 主备的基本原理\n\n如图 1 所示就是基本的主备切换流程。\n\n![图 1 MySQL 主备切换流程](1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg)\n\n在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：\n\n1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；\n2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；\n3. 可以用 readonly 状态，来判断节点的角色。\n\n你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？\n这个问题，你不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。\n接下来，我们再看看节点 A 到 B 这条线的内部流程是什么样的。图 2 中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。\n\n![图 2 主备流程图](1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg)\n\n图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log 的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n• 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n• 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n• 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n• 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n• sql_thread 读取中转日志，解析出日志里的命令，并执行。\n\n这里需要说明，后来由于多线程复制方案的引入，`sql_thread` 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。\n分析完了这个长连接的逻辑，我们再来看一个问题：`binlog` 里面到底是什么内容，为什么备库拿过去可以直接执行。\n\n<br/>\n### binlog 的三种格式对比\n\n我在第 15 篇答疑文章中，和你提到过 binlog 有两种格式，一种是 statement，一种是 row。可能你在其他资料上还会看到有第三种格式，叫作 mixed，其实它就是前两种格式的混合。\n为了便于描述 binlog 的这三种格式间的区别，我创建了一个表，并初始化几行数据。\n\n```SQL\nmysql> CREATE TABLE t (\n    id int(11) NOT NULL,\n    a int(11) DEFAULT NULL,\n    t_modified timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (id),\n    KEY a (a),\n    KEY t_modified(t_modified)\n) ENGINE=InnoDB;\ninsert into t values(1,1,'2018-11-13');\ninsert into t values(2,2,'2018-11-12');\ninsert into t values(3,3,'2018-11-11');\ninsert into t values(4,4,'2018-11-10');\ninsert into t values(5,5,'2018-11-09');\n```\n\n如果要在表中删除一行数据的话，我们来看看这个 delete 语句的 binlog 是怎么记录的。\n注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。\n\n```SQL\nmysql> delete from t /comment/  where a>=4 and t_modified<='2018-11-10' limit 1;\n```\n\n当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。你可以用\n\n```SQL\nmysql> show binlog events in 'master.000001';\n```\n\n命令看 binlog 中的内容。\n\n![图 3 statement 格式 binlog 示例](1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg)\n\n现在，我们来看一下图 3 的输出结果。\n• 第一行 SET @@SESSION.GTID_NEXT='ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；\n• 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n• 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。\n`use 'test’`命令之后的 `delete` 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n• 最后一行是一个 `COMMIT`。你可以看到里面写着 xid=61。你还记得这个 XID 是做什么用的吗？如果记忆模糊了，可以再回顾一下第 15 篇文章中的相关内容。\n为了说明 `statement` 和 `row` 格式的区别，我们来看一下这条 delete 命令的执行效果图：\n\n![图 4 delete 执行 warnings](1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg)\n\n可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。\n\n为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified='2018-11-09’也就是 a=5 这一行。\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。\n\n![图 5 row 格式 binlog 示例](1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg)\n\n可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n• Table_map event，用于说明接下来要操作的表是 test 库的表 t;\n• Delete_rows event，用于定义删除的行为。\n\n其实，我们通过图 5 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为图 5 中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析。\nmysqlbinlog  -vv data/master.000001 --start-position=8900;\n\n![图 6 row 格式 binlog 示例的详细信息](1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg)\n\n从这个图中，我们可以看到以下几个信息：\n• server id 1，表示这个事务是在 server_id=1 的这个库上执行的。\n• 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\n• Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n• 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。\n• binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。\n\n最后的 Xid event，用于表示事务被正确地提交了。\n\n你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。\n\n<br/>\n### mixed 格式的 binlog\n\n基于上面的信息，我们来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。\n\n但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。\n\n所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。\n\n因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。\n\n比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。\n当然我要说的是，现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。\n接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。\n• 通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。\n• 如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。\n• 如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。\n其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。\n虽然 mixed 格式的 binlog 现在已经用得不多了，但这里我还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：\n\n```SQL\nmysql> insert into t values(10,10, now());\n```\n\n如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？\n先不要着急说结果，我们一起来看一下这条语句执行的效果。\n\n![图 7 mixed 格式和 now()](1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg)\n\n可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？\n接下来，我们再用 mysqlbinlog 工具来看看：\n\n![图 8 TIMESTAMP 命令](1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg)\n\n从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。\n因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行，值都是固定的。也就是说，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性。\n我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。\n你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。\n所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：\nmysqlbinlog master.000001  --start-position=2738 --stop-position=2942 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2942 字节中间这段内容解析出来，放到 MySQL 去执行。\n\n<br/>\n### 循环复制问题\n\n通过上面对 MySQL 中 binlog 基本内容的理解，你现在可以知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。\n\n因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图 1 中 A、B 两个节点的内容是一致的。其实，图 1 中我画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是图 9 所示的主备切换流程。\n\n![图 9 MySQL 主备切换流程 -- 双 M 结构](1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg)\n\n对比图 9 和图 1，你可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。\n\n但是，双 M 结构还有一个问题需要解决。\n\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？\n\n从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：\n\n• 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n• 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n• 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n• 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n• 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n• 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。\n\n<br/>\n### 小结\n\n今天这篇文章，我给你介绍了 MySQL binlog 的格式和一些基本机制，是后面我要介绍的读写分离等系列文章的背景知识，希望你可以认真消化理解。\nbinlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。\n我也跟你介绍了 MySQL 不同格式 binlog 的优缺点，和设计者的思考。希望你在做系统开发时候，也能借鉴这些设计思想。\n\n\n### 思考题\n\n说到循环复制问题的时候，我们说 MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。\n\n你能构造出一个这样的场景吗？又应该怎么解决呢？\n\n• 在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。\n• 有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。\n\n![图 10 三节点循环复制](1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpg)\n\n这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了上述的两种循环复制场景，解决方法有两种：\n• 如果这时候 A 和 A’上没有任何更新，可以把其中一个节点（比如 A）的 server_id 临时改成 B 的 server_id，这样循环复制就会终止。终止循环复制之后，就要再设置回这个节点（比如 A）原来的 server_id 值。\n• 不过一般出现循环复制的情况，往往线上同时还有更新，这时就不能修改 server_id 了。这种情况下，我们需要先在节点 A 上执行 stop slave 命令，先停止同步；然后手动执行 change master 命令，指向 A’最后一个 binlog 文件的文件末尾，再 start slave 就可以结束循环复制了。","source":"_posts/24-MySQL是怎么保证主备一致的.md","raw":"---\ntitle: 24 | MySQL是怎么保证主备一致的\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。\n毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。\n在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。\n今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。\n\n### MySQL 主备的基本原理\n\n如图 1 所示就是基本的主备切换流程。\n\n![图 1 MySQL 主备切换流程](1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg)\n\n在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：\n\n1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；\n2. 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；\n3. 可以用 readonly 状态，来判断节点的角色。\n\n你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？\n这个问题，你不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。\n接下来，我们再看看节点 A 到 B 这条线的内部流程是什么样的。图 2 中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。\n\n![图 2 主备流程图](1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg)\n\n图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log 的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n• 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n• 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n• 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n• 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n• sql_thread 读取中转日志，解析出日志里的命令，并执行。\n\n这里需要说明，后来由于多线程复制方案的引入，`sql_thread` 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。\n分析完了这个长连接的逻辑，我们再来看一个问题：`binlog` 里面到底是什么内容，为什么备库拿过去可以直接执行。\n\n<br/>\n### binlog 的三种格式对比\n\n我在第 15 篇答疑文章中，和你提到过 binlog 有两种格式，一种是 statement，一种是 row。可能你在其他资料上还会看到有第三种格式，叫作 mixed，其实它就是前两种格式的混合。\n为了便于描述 binlog 的这三种格式间的区别，我创建了一个表，并初始化几行数据。\n\n```SQL\nmysql> CREATE TABLE t (\n    id int(11) NOT NULL,\n    a int(11) DEFAULT NULL,\n    t_modified timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (id),\n    KEY a (a),\n    KEY t_modified(t_modified)\n) ENGINE=InnoDB;\ninsert into t values(1,1,'2018-11-13');\ninsert into t values(2,2,'2018-11-12');\ninsert into t values(3,3,'2018-11-11');\ninsert into t values(4,4,'2018-11-10');\ninsert into t values(5,5,'2018-11-09');\n```\n\n如果要在表中删除一行数据的话，我们来看看这个 delete 语句的 binlog 是怎么记录的。\n注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。\n\n```SQL\nmysql> delete from t /comment/  where a>=4 and t_modified<='2018-11-10' limit 1;\n```\n\n当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。你可以用\n\n```SQL\nmysql> show binlog events in 'master.000001';\n```\n\n命令看 binlog 中的内容。\n\n![图 3 statement 格式 binlog 示例](1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg)\n\n现在，我们来看一下图 3 的输出结果。\n• 第一行 SET @@SESSION.GTID_NEXT='ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；\n• 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n• 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。\n`use 'test’`命令之后的 `delete` 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n• 最后一行是一个 `COMMIT`。你可以看到里面写着 xid=61。你还记得这个 XID 是做什么用的吗？如果记忆模糊了，可以再回顾一下第 15 篇文章中的相关内容。\n为了说明 `statement` 和 `row` 格式的区别，我们来看一下这条 delete 命令的执行效果图：\n\n![图 4 delete 执行 warnings](1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg)\n\n可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。\n\n为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified='2018-11-09’也就是 a=5 这一行。\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。\n\n![图 5 row 格式 binlog 示例](1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg)\n\n可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n• Table_map event，用于说明接下来要操作的表是 test 库的表 t;\n• Delete_rows event，用于定义删除的行为。\n\n其实，我们通过图 5 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为图 5 中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析。\nmysqlbinlog  -vv data/master.000001 --start-position=8900;\n\n![图 6 row 格式 binlog 示例的详细信息](1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg)\n\n从这个图中，我们可以看到以下几个信息：\n• server id 1，表示这个事务是在 server_id=1 的这个库上执行的。\n• 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\n• Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n• 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。\n• binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。\n\n最后的 Xid event，用于表示事务被正确地提交了。\n\n你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。\n\n<br/>\n### mixed 格式的 binlog\n\n基于上面的信息，我们来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。\n\n但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。\n\n所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。\n\n因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。\n\n比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。\n当然我要说的是，现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。\n接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。\n• 通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。\n• 如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。\n• 如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。\n其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。\n虽然 mixed 格式的 binlog 现在已经用得不多了，但这里我还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：\n\n```SQL\nmysql> insert into t values(10,10, now());\n```\n\n如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？\n先不要着急说结果，我们一起来看一下这条语句执行的效果。\n\n![图 7 mixed 格式和 now()](1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg)\n\n可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？\n接下来，我们再用 mysqlbinlog 工具来看看：\n\n![图 8 TIMESTAMP 命令](1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg)\n\n从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。\n因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行，值都是固定的。也就是说，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性。\n我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。\n你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。\n所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：\nmysqlbinlog master.000001  --start-position=2738 --stop-position=2942 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2942 字节中间这段内容解析出来，放到 MySQL 去执行。\n\n<br/>\n### 循环复制问题\n\n通过上面对 MySQL 中 binlog 基本内容的理解，你现在可以知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。\n\n因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图 1 中 A、B 两个节点的内容是一致的。其实，图 1 中我画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是图 9 所示的主备切换流程。\n\n![图 9 MySQL 主备切换流程 -- 双 M 结构](1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg)\n\n对比图 9 和图 1，你可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。\n\n但是，双 M 结构还有一个问题需要解决。\n\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？\n\n从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：\n\n• 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n• 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n• 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n• 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n• 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n• 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。\n\n<br/>\n### 小结\n\n今天这篇文章，我给你介绍了 MySQL binlog 的格式和一些基本机制，是后面我要介绍的读写分离等系列文章的背景知识，希望你可以认真消化理解。\nbinlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。\n我也跟你介绍了 MySQL 不同格式 binlog 的优缺点，和设计者的思考。希望你在做系统开发时候，也能借鉴这些设计思想。\n\n\n### 思考题\n\n说到循环复制问题的时候，我们说 MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。\n\n你能构造出一个这样的场景吗？又应该怎么解决呢？\n\n• 在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。\n• 有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。\n\n![图 10 三节点循环复制](1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpg)\n\n这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了上述的两种循环复制场景，解决方法有两种：\n• 如果这时候 A 和 A’上没有任何更新，可以把其中一个节点（比如 A）的 server_id 临时改成 B 的 server_id，这样循环复制就会终止。终止循环复制之后，就要再设置回这个节点（比如 A）原来的 server_id 值。\n• 不过一般出现循环复制的情况，往往线上同时还有更新，这时就不能修改 server_id 了。这种情况下，我们需要先在节点 A 上执行 stop slave 命令，先停止同步；然后手动执行 change master 命令，指向 A’最后一个 binlog 文件的文件末尾，再 start slave 就可以结束循环复制了。","slug":"24-MySQL是怎么保证主备一致的","published":1,"updated":"2021-06-30T02:33:24.671Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvm0020r5p75jmk1cvw","content":"<p>在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。\n毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。\n在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。\n今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。</p>\n<h3 id=\"MySQL-主备的基本原理\"><a href=\"#MySQL-主备的基本原理\" class=\"headerlink\" title=\"MySQL 主备的基本原理\"></a>MySQL 主备的基本原理</h3><p>如图 1 所示就是基本的主备切换流程。</p>\n<p><img src=\"1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg\" alt=\"图 1 MySQL 主备切换流程\"></p>\n<p>在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：</p>\n<ol>\n<li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</li>\n<li>防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；</li>\n<li>可以用 readonly 状态，来判断节点的角色。</li>\n</ol>\n<p>你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？\n这个问题，你不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。\n接下来，我们再看看节点 A 到 B 这条线的内部流程是什么样的。图 2 中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。</p>\n<p><img src=\"1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg\" alt=\"图 2 主备流程图\"></p>\n<p>图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log 的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n• 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n• 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n• 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n• 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n• sql_thread 读取中转日志，解析出日志里的命令，并执行。</p>\n<p>这里需要说明，后来由于多线程复制方案的引入，<code>sql_thread</code> 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。\n分析完了这个长连接的逻辑，我们再来看一个问题：<code>binlog</code> 里面到底是什么内容，为什么备库拿过去可以直接执行。</p>\n<br>\n### binlog 的三种格式对比\n\n<p>我在第 15 篇答疑文章中，和你提到过 binlog 有两种格式，一种是 statement，一种是 row。可能你在其他资料上还会看到有第三种格式，叫作 mixed，其实它就是前两种格式的混合。\n为了便于描述 binlog 的这三种格式间的区别，我创建了一个表，并初始化几行数据。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE t (\n    id int(11) NOT NULL,\n    a int(11) DEFAULT NULL,\n    t_modified timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (id),\n    KEY a (a),\n    KEY t_modified(t_modified)\n) ENGINE=InnoDB;\ninsert into t values(1,1,'2018-11-13');\ninsert into t values(2,2,'2018-11-12');\ninsert into t values(3,3,'2018-11-11');\ninsert into t values(4,4,'2018-11-10');\ninsert into t values(5,5,'2018-11-09');\n</code></pre>\n<p>如果要在表中删除一行数据的话，我们来看看这个 delete 语句的 binlog 是怎么记录的。\n注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> delete from t /comment/  where a>=4 and t_modified<='2018-11-10' limit 1;\n</code></pre>\n<p>当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。你可以用</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> show binlog events in 'master.000001';\n</code></pre>\n<p>命令看 binlog 中的内容。</p>\n<p><img src=\"1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg\" alt=\"图 3 statement 格式 binlog 示例\"></p>\n<p>现在，我们来看一下图 3 的输出结果。\n• 第一行 SET @@SESSION.GTID_NEXT=’ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；\n• 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n• 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。\n<code>use 'test’</code>命令之后的 <code>delete</code> 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n• 最后一行是一个 <code>COMMIT</code>。你可以看到里面写着 xid=61。你还记得这个 XID 是做什么用的吗？如果记忆模糊了，可以再回顾一下第 15 篇文章中的相关内容。\n为了说明 <code>statement</code> 和 <code>row</code> 格式的区别，我们来看一下这条 delete 命令的执行效果图：</p>\n<p><img src=\"1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg\" alt=\"图 4 delete 执行 warnings\"></p>\n<p>可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。</p>\n<p>为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified=’2018-11-09’也就是 a=5 这一行。\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。</p>\n<p><img src=\"1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg\" alt=\"图 5 row 格式 binlog 示例\"></p>\n<p>可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n• Table_map event，用于说明接下来要操作的表是 test 库的表 t;\n• Delete_rows event，用于定义删除的行为。</p>\n<p>其实，我们通过图 5 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为图 5 中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析。\nmysqlbinlog  -vv data/master.000001 –start-position=8900;</p>\n<p><img src=\"1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg\" alt=\"图 6 row 格式 binlog 示例的详细信息\"></p>\n<p>从这个图中，我们可以看到以下几个信息：\n• server id 1，表示这个事务是在 server_id=1 的这个库上执行的。\n• 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\n• Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n• 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。\n• binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。</p>\n<p>最后的 Xid event，用于表示事务被正确地提交了。</p>\n<p>你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。</p>\n<br>\n### mixed 格式的 binlog\n\n<p>基于上面的信息，我们来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。</p>\n<p>但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。</p>\n<p>所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。</p>\n<p>因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。</p>\n<p>比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。\n当然我要说的是，现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。\n接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。\n• 通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。\n• 如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。\n• 如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。\n其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。\n虽然 mixed 格式的 binlog 现在已经用得不多了，但这里我还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> insert into t values(10,10, now());\n</code></pre>\n<p>如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？\n先不要着急说结果，我们一起来看一下这条语句执行的效果。</p>\n<p><img src=\"1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg\" alt=\"图 7 mixed 格式和 now()\"></p>\n<p>可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？\n接下来，我们再用 mysqlbinlog 工具来看看：</p>\n<p><img src=\"1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg\" alt=\"图 8 TIMESTAMP 命令\"></p>\n<p>从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。\n因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行，值都是固定的。也就是说，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性。\n我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。\n你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。\n所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：\nmysqlbinlog master.000001  –start-position=2738 –stop-position=2942 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2942 字节中间这段内容解析出来，放到 MySQL 去执行。</p>\n<br>\n### 循环复制问题\n\n<p>通过上面对 MySQL 中 binlog 基本内容的理解，你现在可以知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。</p>\n<p>因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图 1 中 A、B 两个节点的内容是一致的。其实，图 1 中我画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是图 9 所示的主备切换流程。</p>\n<p><img src=\"1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg\" alt=\"图 9 MySQL 主备切换流程 -- 双 M 结构\"></p>\n<p>对比图 9 和图 1，你可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。</p>\n<p>但是，双 M 结构还有一个问题需要解决。</p>\n<p>业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？</p>\n<p>从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：</p>\n<p>• 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n• 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n• 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n• 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n• 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n• 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。</p>\n<br>\n### 小结\n\n<p>今天这篇文章，我给你介绍了 MySQL binlog 的格式和一些基本机制，是后面我要介绍的读写分离等系列文章的背景知识，希望你可以认真消化理解。\nbinlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。\n我也跟你介绍了 MySQL 不同格式 binlog 的优缺点，和设计者的思考。希望你在做系统开发时候，也能借鉴这些设计思想。</p>\n<h3 id=\"思考题\"><a href=\"#思考题\" class=\"headerlink\" title=\"思考题\"></a>思考题</h3><p>说到循环复制问题的时候，我们说 MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。</p>\n<p>你能构造出一个这样的场景吗？又应该怎么解决呢？</p>\n<p>• 在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。\n• 有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。</p>\n<p><img src=\"1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpg\" alt=\"图 10 三节点循环复制\"></p>\n<p>这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了上述的两种循环复制场景，解决方法有两种：\n• 如果这时候 A 和 A’上没有任何更新，可以把其中一个节点（比如 A）的 server_id 临时改成 B 的 server_id，这样循环复制就会终止。终止循环复制之后，就要再设置回这个节点（比如 A）原来的 server_id 值。\n• 不过一般出现循环复制的情况，往往线上同时还有更新，这时就不能修改 server_id 了。这种情况下，我们需要先在节点 A 上执行 stop slave 命令，先停止同步；然后手动执行 change master 命令，指向 A’最后一个 binlog 文件的文件末尾，再 start slave 就可以结束循环复制了。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在前面的文章中，我不止一次地和你提到了 binlog，大家知道 binlog 可以用来归档，也可以用来做主备同步，但它的内容是什么样的呢？为什么备库执行了 binlog 就可以跟主库保持一致了呢？今天我就正式地和你介绍一下它。\n毫不夸张地说，MySQL 能够成为现下最流行的开源数据库，binlog 功不可没。\n在最开始，MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。\n今天这篇文章我主要为你介绍主备的基本原理。理解了背后的设计原理，你也可以从业务开发的角度，来借鉴这些设计思想。</p>\n<h3 id=\"MySQL-主备的基本原理\"><a href=\"#MySQL-主备的基本原理\" class=\"headerlink\" title=\"MySQL 主备的基本原理\"></a>MySQL 主备的基本原理</h3><p>如图 1 所示就是基本的主备切换流程。</p>\n<p><img src=\"1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg\" alt=\"图 1 MySQL 主备切换流程\"></p>\n<p>在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：</p>\n<ol>\n<li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；</li>\n<li>防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；</li>\n<li>可以用 readonly 状态，来判断节点的角色。</li>\n</ol>\n<p>你可能会问，我把备库设置成只读了，还怎么跟主库保持同步更新呢？\n这个问题，你不用担心。因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。\n接下来，我们再看看节点 A 到 B 这条线的内部流程是什么样的。图 2 中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。</p>\n<p><img src=\"1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg\" alt=\"图 2 主备流程图\"></p>\n<p>图 2 中，包含了我在上一篇文章中讲到的 binlog 和 redo log 的写入机制相关的内容，可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n• 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n• 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n• 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n• 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n• sql_thread 读取中转日志，解析出日志里的命令，并执行。</p>\n<p>这里需要说明，后来由于多线程复制方案的引入，<code>sql_thread</code> 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。\n分析完了这个长连接的逻辑，我们再来看一个问题：<code>binlog</code> 里面到底是什么内容，为什么备库拿过去可以直接执行。</p>\n<br/>\n### binlog 的三种格式对比\n\n<p>我在第 15 篇答疑文章中，和你提到过 binlog 有两种格式，一种是 statement，一种是 row。可能你在其他资料上还会看到有第三种格式，叫作 mixed，其实它就是前两种格式的混合。\n为了便于描述 binlog 的这三种格式间的区别，我创建了一个表，并初始化几行数据。</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE t (\n    id int(11) NOT NULL,\n    a int(11) DEFAULT NULL,\n    t_modified timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (id),\n    KEY a (a),\n    KEY t_modified(t_modified)\n) ENGINE=InnoDB;\ninsert into t values(1,1,&#39;2018-11-13&#39;);\ninsert into t values(2,2,&#39;2018-11-12&#39;);\ninsert into t values(3,3,&#39;2018-11-11&#39;);\ninsert into t values(4,4,&#39;2018-11-10&#39;);\ninsert into t values(5,5,&#39;2018-11-09&#39;);\n</code></pre>\n<p>如果要在表中删除一行数据的话，我们来看看这个 delete 语句的 binlog 是怎么记录的。\n注意，下面这个语句包含注释，如果你用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。</p>\n<pre><code class=\"SQL\">mysql&gt; delete from t /comment/  where a&gt;=4 and t_modified&lt;=&#39;2018-11-10&#39; limit 1;\n</code></pre>\n<p>当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。你可以用</p>\n<pre><code class=\"SQL\">mysql&gt; show binlog events in &#39;master.000001&#39;;\n</code></pre>\n<p>命令看 binlog 中的内容。</p>\n<p><img src=\"1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg\" alt=\"图 3 statement 格式 binlog 示例\"></p>\n<p>现在，我们来看一下图 3 的输出结果。\n• 第一行 SET @@SESSION.GTID_NEXT=’ANONYMOUS’你可以先忽略，后面文章我们会在介绍主备切换的时候再提到；\n• 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n• 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。\n<code>use &#39;test’</code>命令之后的 <code>delete</code> 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n• 最后一行是一个 <code>COMMIT</code>。你可以看到里面写着 xid=61。你还记得这个 XID 是做什么用的吗？如果记忆模糊了，可以再回顾一下第 15 篇文章中的相关内容。\n为了说明 <code>statement</code> 和 <code>row</code> 格式的区别，我们来看一下这条 delete 命令的执行效果图：</p>\n<p><img src=\"1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg\" alt=\"图 4 delete 执行 warnings\"></p>\n<p>可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。</p>\n<p>为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a=4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified=’2018-11-09’也就是 a=5 这一行。\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n那么，如果我把 binlog 的格式改为 binlog_format=‘row’， 是不是就没有这个问题了呢？我们先来看看这时候 binog 中的内容吧。</p>\n<p><img src=\"1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg\" alt=\"图 5 row 格式 binlog 示例\"></p>\n<p>可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n• Table_map event，用于说明接下来要操作的表是 test 库的表 t;\n• Delete_rows event，用于定义删除的行为。</p>\n<p>其实，我们通过图 5 是看不到详细信息的，还需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容。因为图 5 中的信息显示，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析。\nmysqlbinlog  -vv data/master.000001 –start-position=8900;</p>\n<p><img src=\"1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg\" alt=\"图 6 row 格式 binlog 示例的详细信息\"></p>\n<p>从这个图中，我们可以看到以下几个信息：\n• server id 1，表示这个事务是在 server_id=1 的这个库上执行的。\n• 每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\n• Table_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n• 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值）。\n• binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。</p>\n<p>最后的 Xid event，用于表示事务被正确地提交了。</p>\n<p>你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。</p>\n<br/>\n### mixed 格式的 binlog\n\n<p>基于上面的信息，我们来讨论一个问题：为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。</p>\n<p>但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。</p>\n<p>所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。</p>\n<p>因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。</p>\n<p>比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式。\n当然我要说的是，现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。\n接下来，我们就分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题。\n• 通过图 6 你可以看出来，即使我执行的是 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了。\n• 如果你是执行错了 insert 语句呢？那就更直接了。row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了。\n• 如果执行的是 update 语句的话，binlog 里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。\n其实，由 delete、insert 或者 update 语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。MariaDB 的Flashback工具就是基于上面介绍的原理来回滚数据的。\n虽然 mixed 格式的 binlog 现在已经用得不多了，但这里我还是要再借用一下 mixed 格式来说明一个问题，来看一下这条 SQL 语句：</p>\n<pre><code class=\"SQL\">mysql&gt; insert into t values(10,10, now());\n</code></pre>\n<p>如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？\n先不要着急说结果，我们一起来看一下这条语句执行的效果。</p>\n<p><img src=\"1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg\" alt=\"图 7 mixed 格式和 now()\"></p>\n<p>可以看到，MySQL 用的居然是 statement 格式。你一定会奇怪，如果这个 binlog 过了 1 分钟才传给备库的话，那主备的数据不就不一致了吗？\n接下来，我们再用 mysqlbinlog 工具来看看：</p>\n<p><img src=\"1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg\" alt=\"图 8 TIMESTAMP 命令\"></p>\n<p>从图中的结果可以看到，原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。\n因此，不论这个 binlog 是 1 分钟之后被备库执行，还是 3 天后用来恢复这个库的备份，这个 insert 语句插入的行，值都是固定的。也就是说，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性。\n我之前看过有人在重放 binlog 数据的时候，是这么做的：用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。\n你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。\n所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：\nmysqlbinlog master.000001  –start-position=2738 –stop-position=2942 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2942 字节中间这段内容解析出来，放到 MySQL 去执行。</p>\n<br/>\n### 循环复制问题\n\n<p>通过上面对 MySQL 中 binlog 基本内容的理解，你现在可以知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态。</p>\n<p>因此，我们可以认为正常情况下主备的数据是一致的。也就是说，图 1 中 A、B 两个节点的内容是一致的。其实，图 1 中我画的是 M-S 结构，但实际生产上使用比较多的是双 M 结构，也就是图 9 所示的主备切换流程。</p>\n<p><img src=\"1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg\" alt=\"图 9 MySQL 主备切换流程 -- 双 M 结构\"></p>\n<p>对比图 9 和图 1，你可以发现，双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。</p>\n<p>但是，双 M 结构还有一个问题需要解决。</p>\n<p>业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？</p>\n<p>从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：</p>\n<p>• 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n• 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n• 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n• 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n• 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n• 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。</p>\n<br/>\n### 小结\n\n<p>今天这篇文章，我给你介绍了 MySQL binlog 的格式和一些基本机制，是后面我要介绍的读写分离等系列文章的背景知识，希望你可以认真消化理解。\nbinlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。\n我也跟你介绍了 MySQL 不同格式 binlog 的优缺点，和设计者的思考。希望你在做系统开发时候，也能借鉴这些设计思想。</p>\n<h3 id=\"思考题\"><a href=\"#思考题\" class=\"headerlink\" title=\"思考题\"></a>思考题</h3><p>说到循环复制问题的时候，我们说 MySQL 通过判断 server id 的方式，断掉死循环。但是，这个机制其实并不完备，在某些场景下，还是有可能出现死循环。</p>\n<p>你能构造出一个这样的场景吗？又应该怎么解决呢？</p>\n<p>• 在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。\n• 有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。</p>\n<p><img src=\"1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpg\" alt=\"图 10 三节点循环复制\"></p>\n<p>这种三节点复制的场景，做数据库迁移的时候会出现。如果出现了上述的两种循环复制场景，解决方法有两种：\n• 如果这时候 A 和 A’上没有任何更新，可以把其中一个节点（比如 A）的 server_id 临时改成 B 的 server_id，这样循环复制就会终止。终止循环复制之后，就要再设置回这个节点（比如 A）原来的 server_id 值。\n• 不过一般出现循环复制的情况，往往线上同时还有更新，这时就不能修改 server_id 了。这种情况下，我们需要先在节点 A 上执行 stop slave 命令，先停止同步；然后手动执行 change master 命令，指向 A’最后一个 binlog 文件的文件末尾，再 start slave 就可以结束循环复制了。</p>\n"},{"title":"25 | MySQL是怎么保证高可用的","date":"2019-06-02T16:00:00.000Z","_content":"在上一篇文章中，我和你介绍了 binlog 的基本内容，在一个主备关系中，每个备库接收主库的 binlog 并执行。\n正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。\n但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重和你分析一下。\n这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。\n\n![图 1 MySQL 主备切换流程 -- 双 M 结构](1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpg)\n\n<br/>\n### 主备延迟\n\n主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：\n\n• 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n• 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n• 备库 B 执行完成这个事务，我们把这个时刻记为 T3。\n\n所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。seconds_behind_master 的计算方法是这样的：\n\n• 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n• 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。\n\n可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，可以用seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？\n其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。\n需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。\n所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。\n\n<br/>\n### 主备延迟的来源\n\n首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。\n但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。\n\n#### 追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\n\n这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。\n这种情况，我们一般可以这么处理：\n\n1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。\n2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。\n\n其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。\n备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。\n\n#### 追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\n\n这就是第三种可能了，即大事务。\n大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。不知道你所在公司的 DBA 有没有跟你这么说过：不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。\n比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。\n另一种典型的大事务场景，就是大表 DDL。这个场景，我在前面的文章中介绍过。处理方案就是，计划内的 DDL，建议使用 gh-ost 方案（这里，你可以再回顾下第 13 篇文章《为什么表数据删掉一半，表文件大小不变？》中的相关内容）。\n\n#### 追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\n造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。这个话题，我会留在下一篇文章再和你详细介绍。\n其实还是有不少其他情况会导致主备延迟，如果你还碰到过其他场景，欢迎你在评论区给我留言，我来和你一起分析、讨论。\n由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。\n\n<br/>\n### 可靠性优先策略\n\n在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：\n\n1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；\n2. 把主库 A 改成只读状态，即把 readonly 设置为 true；\n3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；\n4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；\n5. 把业务请求切到备库 B。\n\n这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。\n\n![图 2 MySQL 可靠性优先主备切换流程](1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpg)\n\n备注：图中的 SBM，是 seconds_behind_master 参数的简写。\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略\n如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：\n\n```SQL\nmysql> CREATE TABLE t (\nid int(11) unsigned NOT NULL AUTO_INCREMENT,\nc int(11) unsigned DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ninsert into t(c) values(1),(2),(3);\n```\n\n这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：\n\n```SQL\ninsert into t(c) values(4);\ninsert into t(c) values(5);\n```\n\n假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。图 3 是可用性优先策略，且 `binlog_format=mixed`时的切换流程和数据结果。\n\n![图 3 可用性优先策略，且 binlog_format=mixed](1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpg)\n\n现在，我们一起分析下这个切换流程：\n\n1. 步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据（4,4），之后开始进行主备切换。\n2. 步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。\n3. 步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。\n4. 步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）。\n\n最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。那么，如果我还是用可用性优先策略，但设置 binlog_format=row，情况又会怎样呢？\n因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行。\n图 4 中我画出了详细过程，你可以自己再分析一下。\n\n![图 4 可用性优先策略，且 binlog_format=row](1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpg)\n\n从上面的分析中，你可以看到一些结论：\n• 使用 row 格式的 binlog 时，数据不一致（少了数据）的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。\n• 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。\n但事无绝对，有没有哪种情况数据的可用性优先级更高呢？\n答案是，有的。\n\n我曾经碰到过这样的一个场景：\n\n• 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。\n• 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。\n\n这时候，你可能就需要选择先强行切换，事后再补数据的策略。\n当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。\n接下来我们再看看，按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。\n\n![图 5 可靠性优先策略，主库不可用](1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpg)\n\n采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master=0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n你可能会问，那能不能直接切换到备库 B，但是保持 B 只读呢？\n这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。\n虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。聊到这里你就知道了，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。\n\n<br/>\n### 小结\n\n今天这篇文章，我先和你介绍了 MySQL 高可用系统的基础，就是主备切换逻辑。紧接着，我又和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。\n然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先和可用性优先策略的区别。\n在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。\n最后，我给你留下一个思考题吧。\n一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？\n\n![图 6 备库延迟](1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpg)\n","source":"_posts/25-MySQL是怎么保证高可用的.md","raw":"---\ntitle: 25 | MySQL是怎么保证高可用的\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在上一篇文章中，我和你介绍了 binlog 的基本内容，在一个主备关系中，每个备库接收主库的 binlog 并执行。\n正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。\n但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重和你分析一下。\n这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。\n\n![图 1 MySQL 主备切换流程 -- 双 M 结构](1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpg)\n\n<br/>\n### 主备延迟\n\n主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：\n\n• 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n• 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n• 备库 B 执行完成这个事务，我们把这个时刻记为 T3。\n\n所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。seconds_behind_master 的计算方法是这样的：\n\n• 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n• 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。\n\n可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，可以用seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？\n其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。\n需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。\n所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。\n\n<br/>\n### 主备延迟的来源\n\n首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。\n但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。\n\n#### 追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\n\n这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。\n这种情况，我们一般可以这么处理：\n\n1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。\n2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。\n\n其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。\n备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。\n\n#### 追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\n\n这就是第三种可能了，即大事务。\n大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。不知道你所在公司的 DBA 有没有跟你这么说过：不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。\n比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。\n另一种典型的大事务场景，就是大表 DDL。这个场景，我在前面的文章中介绍过。处理方案就是，计划内的 DDL，建议使用 gh-ost 方案（这里，你可以再回顾下第 13 篇文章《为什么表数据删掉一半，表文件大小不变？》中的相关内容）。\n\n#### 追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\n造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。这个话题，我会留在下一篇文章再和你详细介绍。\n其实还是有不少其他情况会导致主备延迟，如果你还碰到过其他场景，欢迎你在评论区给我留言，我来和你一起分析、讨论。\n由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。\n\n<br/>\n### 可靠性优先策略\n\n在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：\n\n1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；\n2. 把主库 A 改成只读状态，即把 readonly 设置为 true；\n3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；\n4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；\n5. 把业务请求切到备库 B。\n\n这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。\n\n![图 2 MySQL 可靠性优先主备切换流程](1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpg)\n\n备注：图中的 SBM，是 seconds_behind_master 参数的简写。\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略\n如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：\n\n```SQL\nmysql> CREATE TABLE t (\nid int(11) unsigned NOT NULL AUTO_INCREMENT,\nc int(11) unsigned DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ninsert into t(c) values(1),(2),(3);\n```\n\n这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：\n\n```SQL\ninsert into t(c) values(4);\ninsert into t(c) values(5);\n```\n\n假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。图 3 是可用性优先策略，且 `binlog_format=mixed`时的切换流程和数据结果。\n\n![图 3 可用性优先策略，且 binlog_format=mixed](1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpg)\n\n现在，我们一起分析下这个切换流程：\n\n1. 步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据（4,4），之后开始进行主备切换。\n2. 步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。\n3. 步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。\n4. 步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）。\n\n最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。那么，如果我还是用可用性优先策略，但设置 binlog_format=row，情况又会怎样呢？\n因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行。\n图 4 中我画出了详细过程，你可以自己再分析一下。\n\n![图 4 可用性优先策略，且 binlog_format=row](1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpg)\n\n从上面的分析中，你可以看到一些结论：\n• 使用 row 格式的 binlog 时，数据不一致（少了数据）的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。\n• 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。\n但事无绝对，有没有哪种情况数据的可用性优先级更高呢？\n答案是，有的。\n\n我曾经碰到过这样的一个场景：\n\n• 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。\n• 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。\n\n这时候，你可能就需要选择先强行切换，事后再补数据的策略。\n当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。\n接下来我们再看看，按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。\n\n![图 5 可靠性优先策略，主库不可用](1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpg)\n\n采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master=0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n你可能会问，那能不能直接切换到备库 B，但是保持 B 只读呢？\n这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。\n虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。聊到这里你就知道了，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。\n\n<br/>\n### 小结\n\n今天这篇文章，我先和你介绍了 MySQL 高可用系统的基础，就是主备切换逻辑。紧接着，我又和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。\n然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先和可用性优先策略的区别。\n在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。\n最后，我给你留下一个思考题吧。\n一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？\n\n![图 6 备库延迟](1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpg)\n","slug":"25-MySQL是怎么保证高可用的","published":1,"updated":"2021-06-30T02:33:24.683Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvm0023r5p7825ddr59","content":"<p>在上一篇文章中，我和你介绍了 binlog 的基本内容，在一个主备关系中，每个备库接收主库的 binlog 并执行。\n正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。\n但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重和你分析一下。\n这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。</p>\n<p><img src=\"1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpg\" alt=\"图 1 MySQL 主备切换流程 -- 双 M 结构\"></p>\n<br>\n### 主备延迟\n\n<p>主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：</p>\n<p>• 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n• 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n• 备库 B 执行完成这个事务，我们把这个时刻记为 T3。</p>\n<p>所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。seconds_behind_master 的计算方法是这样的：</p>\n<p>• 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n• 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。</p>\n<p>可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，可以用seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？\n其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。\n需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。\n所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。</p>\n<br>\n### 主备延迟的来源\n\n<p>首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。\n但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。</p>\n<h4 id=\"追问-1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\"><a href=\"#追问-1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\" class=\"headerlink\" title=\"追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\"></a>追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？</h4><p>这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。\n这种情况，我们一般可以这么处理：</p>\n<ol>\n<li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。</li>\n<li>通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。</li>\n</ol>\n<p>其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。\n备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。</p>\n<h4 id=\"追问-2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\"><a href=\"#追问-2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\" class=\"headerlink\" title=\"追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\"></a>追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？</h4><p>这就是第三种可能了，即大事务。\n大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。不知道你所在公司的 DBA 有没有跟你这么说过：不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。\n比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。\n另一种典型的大事务场景，就是大表 DDL。这个场景，我在前面的文章中介绍过。处理方案就是，计划内的 DDL，建议使用 gh-ost 方案（这里，你可以再回顾下第 13 篇文章《为什么表数据删掉一半，表文件大小不变？》中的相关内容）。</p>\n<h4 id=\"追问-3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\"><a href=\"#追问-3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\" class=\"headerlink\" title=\"追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\"></a>追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？</h4><p>造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。这个话题，我会留在下一篇文章再和你详细介绍。\n其实还是有不少其他情况会导致主备延迟，如果你还碰到过其他场景，欢迎你在评论区给我留言，我来和你一起分析、讨论。\n由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。</p>\n<br>\n### 可靠性优先策略\n\n<p>在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：</p>\n<ol>\n<li>判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li>\n<li>把主库 A 改成只读状态，即把 readonly 设置为 true；</li>\n<li>判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；</li>\n<li>把备库 B 改成可读写状态，也就是把 readonly 设置为 false；</li>\n<li>把业务请求切到备库 B。</li>\n</ol>\n<p>这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。</p>\n<p><img src=\"1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpg\" alt=\"图 2 MySQL 可靠性优先主备切换流程\"></p>\n<p>备注：图中的 SBM，是 seconds_behind_master 参数的简写。\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略\n如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">mysql> CREATE TABLE t (\nid int(11) unsigned NOT NULL AUTO_INCREMENT,\nc int(11) unsigned DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ninsert into t(c) values(1),(2),(3);\n</code></pre>\n<p>这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：</p>\n<pre class=\" language-SQL\"><code class=\"language-SQL\">insert into t(c) values(4);\ninsert into t(c) values(5);\n</code></pre>\n<p>假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。图 3 是可用性优先策略，且 <code>binlog_format=mixed</code>时的切换流程和数据结果。</p>\n<p><img src=\"1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpg\" alt=\"图 3 可用性优先策略，且 binlog_format=mixed\"></p>\n<p>现在，我们一起分析下这个切换流程：</p>\n<ol>\n<li>步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据（4,4），之后开始进行主备切换。</li>\n<li>步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。</li>\n<li>步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。</li>\n<li>步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）。</li>\n</ol>\n<p>最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。那么，如果我还是用可用性优先策略，但设置 binlog_format=row，情况又会怎样呢？\n因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行。\n图 4 中我画出了详细过程，你可以自己再分析一下。</p>\n<p><img src=\"1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpg\" alt=\"图 4 可用性优先策略，且 binlog_format=row\"></p>\n<p>从上面的分析中，你可以看到一些结论：\n• 使用 row 格式的 binlog 时，数据不一致（少了数据）的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。\n• 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。\n但事无绝对，有没有哪种情况数据的可用性优先级更高呢？\n答案是，有的。</p>\n<p>我曾经碰到过这样的一个场景：</p>\n<p>• 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。\n• 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。</p>\n<p>这时候，你可能就需要选择先强行切换，事后再补数据的策略。\n当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。\n接下来我们再看看，按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。</p>\n<p><img src=\"1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpg\" alt=\"图 5 可靠性优先策略，主库不可用\"></p>\n<p>采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master=0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n你可能会问，那能不能直接切换到备库 B，但是保持 B 只读呢？\n这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。\n虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。聊到这里你就知道了，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。</p>\n<br>\n### 小结\n\n<p>今天这篇文章，我先和你介绍了 MySQL 高可用系统的基础，就是主备切换逻辑。紧接着，我又和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。\n然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先和可用性优先策略的区别。\n在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。\n最后，我给你留下一个思考题吧。\n一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？</p>\n<p><img src=\"1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpg\" alt=\"图 6 备库延迟\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在上一篇文章中，我和你介绍了 binlog 的基本内容，在一个主备关系中，每个备库接收主库的 binlog 并执行。\n正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。\n但是，MySQL 要提供高可用能力，只有最终一致性是不够的。为什么这么说呢？今天我就着重和你分析一下。\n这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。</p>\n<p><img src=\"1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpg\" alt=\"图 1 MySQL 主备切换流程 -- 双 M 结构\"></p>\n<br/>\n### 主备延迟\n\n<p>主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：</p>\n<p>• 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n• 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n• 备库 B 执行完成这个事务，我们把这个时刻记为 T3。</p>\n<p>所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。seconds_behind_master 的计算方法是这样的：</p>\n<p>• 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n• 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。</p>\n<p>可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，可以用seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n你可能会问，如果主备库机器的系统时间设置不一致，会不会导致主备延迟的值不准？\n其实不会的。因为，备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。\n需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。\n所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。接下来，我就和你一起分析下，这可能是由哪些原因导致的。</p>\n<br/>\n### 主备延迟的来源\n\n<p>首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。\n但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。当然，这种部署现在比较少了。因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。</p>\n<h4 id=\"追问-1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\"><a href=\"#追问-1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\" class=\"headerlink\" title=\"追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？\"></a>追问 1：但是，做了对称部署以后，还可能会有延迟。这是为什么呢？</h4><p>这就是第二种常见的可能了，即备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。我真就见过不少这样的情况。由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。\n这种情况，我们一般可以这么处理：</p>\n<ol>\n<li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。</li>\n<li>通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。</li>\n</ol>\n<p>其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。\n备注：这里需要说明一下，从库和备库在概念上其实差不多。在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。</p>\n<h4 id=\"追问-2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\"><a href=\"#追问-2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\" class=\"headerlink\" title=\"追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？\"></a>追问 2：采用了一主多从，保证备库的压力不会超过主库，还有什么情况可能导致主备延迟吗？</h4><p>这就是第三种可能了，即大事务。\n大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。不知道你所在公司的 DBA 有没有跟你这么说过：不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。\n比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。结果，负责的 DBA 同学半夜就会收到延迟报警。然后，DBA 团队就要求你后续再删除数据的时候，要控制每个事务删除的数据量，分成多次删除。\n另一种典型的大事务场景，就是大表 DDL。这个场景，我在前面的文章中介绍过。处理方案就是，计划内的 DDL，建议使用 gh-ost 方案（这里，你可以再回顾下第 13 篇文章《为什么表数据删掉一半，表文件大小不变？》中的相关内容）。</p>\n<h4 id=\"追问-3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\"><a href=\"#追问-3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\" class=\"headerlink\" title=\"追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？\"></a>追问 3：如果主库上也不做大事务了，还有什么原因会导致主备延迟吗？</h4><p>造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。这个话题，我会留在下一篇文章再和你详细介绍。\n其实还是有不少其他情况会导致主备延迟，如果你还碰到过其他场景，欢迎你在评论区给我留言，我来和你一起分析、讨论。\n由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。</p>\n<br/>\n### 可靠性优先策略\n\n<p>在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：</p>\n<ol>\n<li>判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；</li>\n<li>把主库 A 改成只读状态，即把 readonly 设置为 true；</li>\n<li>判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；</li>\n<li>把备库 B 改成可读写状态，也就是把 readonly 设置为 false；</li>\n<li>把业务请求切到备库 B。</li>\n</ol>\n<p>这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。</p>\n<p><img src=\"1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpg\" alt=\"图 2 MySQL 可靠性优先主备切换流程\"></p>\n<p>备注：图中的 SBM，是 seconds_behind_master 参数的简写。\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略\n如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n接下来，我就和你分享一个可用性优先流程产生数据不一致的例子。假设有一个表 t：</p>\n<pre><code class=\"SQL\">mysql&gt; CREATE TABLE t (\nid int(11) unsigned NOT NULL AUTO_INCREMENT,\nc int(11) unsigned DEFAULT NULL,\nPRIMARY KEY (id)\n) ENGINE=InnoDB;\ninsert into t(c) values(1),(2),(3);\n</code></pre>\n<p>这个表定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在表 t 上执行两条插入语句的命令，依次是：</p>\n<pre><code class=\"SQL\">insert into t(c) values(4);\ninsert into t(c) values(5);\n</code></pre>\n<p>假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c=4 的语句后，发起了主备切换。图 3 是可用性优先策略，且 <code>binlog_format=mixed</code>时的切换流程和数据结果。</p>\n<p><img src=\"1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpg\" alt=\"图 3 可用性优先策略，且 binlog_format=mixed\"></p>\n<p>现在，我们一起分析下这个切换流程：</p>\n<ol>\n<li>步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据（4,4），之后开始进行主备切换。</li>\n<li>步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用“插入 c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。</li>\n<li>步骤 4 中，备库 B 插入了一行数据（4,5），并且把这个 binlog 发给主库 A。</li>\n<li>步骤 5 中，备库 B 执行“插入 c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库 B 执行的“插入 c=5”这个语句，传到主库 A，就插入了一行新数据（5,5）。</li>\n</ol>\n<p>最后的结果就是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的。那么，如果我还是用可用性优先策略，但设置 binlog_format=row，情况又会怎样呢？\n因为 row 格式在记录 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致。而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。也就是说，这种情况下，备库 B 的 (5,4) 和主库 A 的 (5,5) 这两行数据，都不会被对方执行。\n图 4 中我画出了详细过程，你可以自己再分析一下。</p>\n<p><img src=\"1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpg\" alt=\"图 4 可用性优先策略，且 binlog_format=row\"></p>\n<p>从上面的分析中，你可以看到一些结论：\n• 使用 row 格式的 binlog 时，数据不一致（少了数据）的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。\n• 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。\n但事无绝对，有没有哪种情况数据的可用性优先级更高呢？\n答案是，有的。</p>\n<p>我曾经碰到过这样的一个场景：</p>\n<p>• 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。\n• 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。</p>\n<p>这时候，你可能就需要选择先强行切换，事后再补数据的策略。\n当然，事后复盘的时候，我们想到了一个改进措施就是，让业务逻辑不要依赖于这类日志的写入。也就是说，日志写入这个逻辑模块应该可以降级，比如写到本地文件，或者写到另外一个临时库里面。这样的话，这种场景就又可以使用可靠性优先策略了。\n接下来我们再看看，按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。</p>\n<p><img src=\"1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpg\" alt=\"图 5 可靠性优先策略，主库不可用\"></p>\n<p>采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master=0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n你可能会问，那能不能直接切换到备库 B，但是保持 B 只读呢？\n这样也不行。因为，这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有“数据丢失”。\n虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到“暂时丢失数据的状态”也是不能被接受的。聊到这里你就知道了，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。</p>\n<br/>\n### 小结\n\n<p>今天这篇文章，我先和你介绍了 MySQL 高可用系统的基础，就是主备切换逻辑。紧接着，我又和你讨论了几种会导致主备延迟的情况，以及相应的改进方向。\n然后，由于主备延迟的存在，切换策略就有不同的选择。所以，我又和你一起分析了可靠性优先和可用性优先策略的区别。\n在实际的应用中，我更建议使用可靠性优先的策略。毕竟保证数据准确，应该是数据库服务的底线。在这个基础上，通过减少主备延迟，提升系统的可用性。\n最后，我给你留下一个思考题吧。\n一般现在的数据库运维系统都有备库延迟监控，其实就是在备库上执行 show slave status，采集 seconds_behind_master 的值。假设，现在你看到你维护的一个备库，它的延迟监控的图像类似图 6，是一个 45°斜向上的线段，你觉得可能是什么原因导致呢？你又会怎么去确认这个原因呢？</p>\n<p><img src=\"1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpg\" alt=\"图 6 备库延迟\"></p>\n"},{"title":"26 | 备库为什么会延迟好几个小时？－并发逻辑","date":"2019-06-02T16:00:00.000Z","_content":"在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。\n但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n这就涉及到今天我要给你介绍的话题：备库并行复制能力。为了便于你理解，我们再一起看一下第 24 篇文章《MySQL 是怎么保证主备一致的？》的主备流程图。\n\n![图 1 主备流程图]()\n\n谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说 MySQL 多线程复制的演进过程。\n其实说到底，所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：\n\n![图 2 多线程模型]()\n\n图 2 中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。\n接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：\n\n1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。\n2. 同一个事务不能被拆开，必须放到同一个 worker 中。\n\n各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策略。\n\nMySQL 5.5 版本的并行复制策略\n\n官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，我自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。\n这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解 MySQL 官方版本并行复制策略的迭代。\n按表分发策略\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图 3 所示，就是按表分发的规则。\n图 3 按表并行复制程模型\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。\n图 3 中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。\n1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。\n2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。\n3. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。\n4. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：\n1. 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n2. 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n3. 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。\n按行分发策略\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。\n按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：\nCREATE TABLE `t1` (\n `id` int(11) NOT NULL,\n `a` int(11) DEFAULT NULL,\n `b` int(11) DEFAULT NULL,\n PRIMARY KEY (`id`),\n UNIQUE KEY `a` (`a`)\n) ENGINE=InnoDB;\ninsert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);\n假设，接下来我们要在主库执行这两个事务：\n图 4 唯一键冲突示例\n可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。\n因此，基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n比如，在上面这个例子中，我要在表 t1 上执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:\n1. key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。\n2. key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。\n3. key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：\n1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n2. 表必须有主键；\n3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：\n1. 耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。\n2. 耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：\n1. coordinator 暂时先 hold 住这个事务；\n2. 等待所有 worker 都执行完成，变成空队列；\n3. coordinator 直接执行这个事务；\n4. 恢复并行模式。\n读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。\nMySQL 5.6 版本的并行复制策略\n官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：\n1. 构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。\n2. 不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略\n在第 23 篇文章中，我给你介绍了 redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：\n1. 能够在同一组里提交的事务，一定不会修改同一行；\n2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n在实现上，MariaDB 是这么做的：\n1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；\n2. commit_id 直接写到 binlog 里面；\n3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n4. 这一组全部执行完成后，coordinator 再去取下一批。\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n如图 5 所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。\n图 5 主库并行事务\n而按照 MariaDB 的并行复制策略，备库上的执行效果如图 6 所示。\n图 6 MariaDB 并行复制，备库并行效果\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n• 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n• 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？\n答案是，不能。\n因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。\n这时候，你可以再回顾一下两阶段提交，我把前面第 23 篇文章中介绍过的两阶段提交过程图贴过来。\n图 7 两阶段提交细化过程图\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n• 同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n• 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n我在第 23 篇文章，讲 binlog 的组提交的时候，介绍过两个参数：\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略\n在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n• COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n• WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n• WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n你可能看出来了，这跟我们前面介绍的基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：\n• writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n• 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n• 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。\n当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n小结\n在今天这篇文章中，我和你介绍了 MySQL 的各种多线程复制策略。\n为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。\n在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：\n• 如果你是 DBA，就需要根据不同的业务场景，选择不同的策略；\n• 如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。\n从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。\n官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。\n思考题:假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。\n在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？\n这个问题的答案：参数设置为 WRITESET。\n• 由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。\n• 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET","source":"_posts/26-备库为什么会延迟好几个小时？－并发逻辑.md","raw":"---\ntitle: 26 | 备库为什么会延迟好几个小时？－并发逻辑\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。\n但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n这就涉及到今天我要给你介绍的话题：备库并行复制能力。为了便于你理解，我们再一起看一下第 24 篇文章《MySQL 是怎么保证主备一致的？》的主备流程图。\n\n![图 1 主备流程图]()\n\n谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说 MySQL 多线程复制的演进过程。\n其实说到底，所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：\n\n![图 2 多线程模型]()\n\n图 2 中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。\n接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：\n\n1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。\n2. 同一个事务不能被拆开，必须放到同一个 worker 中。\n\n各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策略。\n\nMySQL 5.5 版本的并行复制策略\n\n官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，我自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。\n这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解 MySQL 官方版本并行复制策略的迭代。\n按表分发策略\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图 3 所示，就是按表分发的规则。\n图 3 按表并行复制程模型\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。\n图 3 中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。\n1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。\n2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。\n3. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。\n4. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：\n1. 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n2. 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n3. 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。\n按行分发策略\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。\n按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：\nCREATE TABLE `t1` (\n `id` int(11) NOT NULL,\n `a` int(11) DEFAULT NULL,\n `b` int(11) DEFAULT NULL,\n PRIMARY KEY (`id`),\n UNIQUE KEY `a` (`a`)\n) ENGINE=InnoDB;\ninsert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);\n假设，接下来我们要在主库执行这两个事务：\n图 4 唯一键冲突示例\n可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。\n因此，基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n比如，在上面这个例子中，我要在表 t1 上执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:\n1. key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。\n2. key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。\n3. key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：\n1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n2. 表必须有主键；\n3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：\n1. 耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。\n2. 耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：\n1. coordinator 暂时先 hold 住这个事务；\n2. 等待所有 worker 都执行完成，变成空队列；\n3. coordinator 直接执行这个事务；\n4. 恢复并行模式。\n读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。\nMySQL 5.6 版本的并行复制策略\n官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：\n1. 构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。\n2. 不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略\n在第 23 篇文章中，我给你介绍了 redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：\n1. 能够在同一组里提交的事务，一定不会修改同一行；\n2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n在实现上，MariaDB 是这么做的：\n1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；\n2. commit_id 直接写到 binlog 里面；\n3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n4. 这一组全部执行完成后，coordinator 再去取下一批。\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n如图 5 所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。\n图 5 主库并行事务\n而按照 MariaDB 的并行复制策略，备库上的执行效果如图 6 所示。\n图 6 MariaDB 并行复制，备库并行效果\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n• 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n• 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？\n答案是，不能。\n因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。\n这时候，你可以再回顾一下两阶段提交，我把前面第 23 篇文章中介绍过的两阶段提交过程图贴过来。\n图 7 两阶段提交细化过程图\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n• 同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n• 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n我在第 23 篇文章，讲 binlog 的组提交的时候，介绍过两个参数：\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略\n在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n• COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n• WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n• WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n你可能看出来了，这跟我们前面介绍的基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：\n• writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n• 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n• 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。\n当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n小结\n在今天这篇文章中，我和你介绍了 MySQL 的各种多线程复制策略。\n为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。\n在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：\n• 如果你是 DBA，就需要根据不同的业务场景，选择不同的策略；\n• 如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。\n从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。\n官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。\n思考题:假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。\n在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？\n这个问题的答案：参数设置为 WRITESET。\n• 由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。\n• 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET","slug":"26-备库为什么会延迟好几个小时？－并发逻辑","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvn0026r5p73e8eexpo","content":"<p>在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。\n但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n这就涉及到今天我要给你介绍的话题：备库并行复制能力。为了便于你理解，我们再一起看一下第 24 篇文章《MySQL 是怎么保证主备一致的？》的主备流程图。</p>\n<p><img src=\"\" alt=\"图 1 主备流程图\"></p>\n<p>谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说 MySQL 多线程复制的演进过程。\n其实说到底，所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：</p>\n<p><img src=\"\" alt=\"图 2 多线程模型\"></p>\n<p>图 2 中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。\n接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：</p>\n<ol>\n<li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。</li>\n<li>同一个事务不能被拆开，必须放到同一个 worker 中。</li>\n</ol>\n<p>各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策略。</p>\n<p>MySQL 5.5 版本的并行复制策略</p>\n<p>官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，我自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。\n这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解 MySQL 官方版本并行复制策略的迭代。\n按表分发策略\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图 3 所示，就是按表分发的规则。\n图 3 按表并行复制程模型\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。\n图 3 中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。</p>\n<ol>\n<li>由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。</li>\n<li>按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。</li>\n<li>每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。</li>\n<li>这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</li>\n<li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;</li>\n<li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；</li>\n<li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。\n按行分发策略\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。\n按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：\nCREATE TABLE <code>t1</code> (\n<code>id</code> int(11) NOT NULL,\n<code>a</code> int(11) DEFAULT NULL,\n<code>b</code> int(11) DEFAULT NULL,\nPRIMARY KEY (<code>id</code>),\nUNIQUE KEY <code>a</code> (<code>a</code>)\n) ENGINE=InnoDB;\ninsert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);\n假设，接下来我们要在主库执行这两个事务：\n图 4 唯一键冲突示例\n可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。\n因此，基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n比如，在上面这个例子中，我要在表 t1 上执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:</li>\n<li>key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。</li>\n<li>key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。</li>\n<li>key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：</li>\n<li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；</li>\n<li>表必须有主键；</li>\n<li>不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：</li>\n<li>耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。</li>\n<li>耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：</li>\n<li>coordinator 暂时先 hold 住这个事务；</li>\n<li>等待所有 worker 都执行完成，变成空队列；</li>\n<li>coordinator 直接执行这个事务；</li>\n<li>恢复并行模式。\n读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。\nMySQL 5.6 版本的并行复制策略\n官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：</li>\n<li>构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。</li>\n<li>不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略\n在第 23 篇文章中，我给你介绍了 redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：</li>\n<li>能够在同一组里提交的事务，一定不会修改同一行；</li>\n<li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n在实现上，MariaDB 是这么做的：</li>\n<li>在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；</li>\n<li>commit_id 直接写到 binlog 里面；</li>\n<li>传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；</li>\n<li>这一组全部执行完成后，coordinator 再去取下一批。\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n如图 5 所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。\n图 5 主库并行事务\n而按照 MariaDB 的并行复制策略，备库上的执行效果如图 6 所示。\n图 6 MariaDB 并行复制，备库并行效果\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n• 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n• 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？\n答案是，不能。\n因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。\n这时候，你可以再回顾一下两阶段提交，我把前面第 23 篇文章中介绍过的两阶段提交过程图贴过来。\n图 7 两阶段提交细化过程图\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n• 同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n• 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n我在第 23 篇文章，讲 binlog 的组提交的时候，介绍过两个参数：\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略\n在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n• COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n• WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n• WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n你可能看出来了，这跟我们前面介绍的基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：\n• writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n• 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n• 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。\n当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n小结\n在今天这篇文章中，我和你介绍了 MySQL 的各种多线程复制策略。\n为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。\n在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：\n• 如果你是 DBA，就需要根据不同的业务场景，选择不同的策略；\n• 如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。\n从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。\n官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。\n思考题:假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。\n在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？\n这个问题的答案：参数设置为 WRITESET。\n• 由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。\n• 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>在上一篇文章中，我和你介绍了几种可能导致备库延迟的原因。你会发现，这些场景里，不论是偶发性的查询压力，还是备份，对备库延迟的影响一般是分钟级的，而且在备库恢复正常以后都能够追上来。\n但是，如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n这就涉及到今天我要给你介绍的话题：备库并行复制能力。为了便于你理解，我们再一起看一下第 24 篇文章《MySQL 是怎么保证主备一致的？》的主备流程图。</p>\n<p><img src=\"\" alt=\"图 1 主备流程图\"></p>\n<p>谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。接下来，我就跟你说说 MySQL 多线程复制的演进过程。\n其实说到底，所有的多线程复制机制，都是要把图 1 中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：</p>\n<p><img src=\"\" alt=\"图 2 多线程模型\"></p>\n<p>图 2 中，coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。根据我的经验，把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。\n接下来，你需要先思考一个问题：事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n接下来，请你再设想一下另外一个问题：同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的原子性。\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：</p>\n<ol>\n<li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。</li>\n<li>同一个事务不能被拆开，必须放到同一个 worker 中。</li>\n</ol>\n<p>各个版本的多线程复制，都遵循了这两条基本原则。接下来，我们就看看各个版本的并行复制策略。</p>\n<p>MySQL 5.5 版本的并行复制策略</p>\n<p>官方 MySQL 5.5 版本是不支持并行复制的。但是，在 2012 年的时候，我自己服务的业务出现了严重的主备延迟，原因就是备库只有单线程复制。然后，我就先后写了两个版本的并行策略。\n这里，我给你介绍一下这两个版本的并行策略，即按表分发策略和按行分发策略，以帮助你理解 MySQL 官方版本并行复制策略的迭代。\n按表分发策略\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。当然，如果有跨表的事务，还是要把两张表放在一起考虑的。如图 3 所示，就是按表分发的规则。\n图 3 按表并行复制程模型\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。\n图 3 中，hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。</p>\n<ol>\n<li>由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。</li>\n<li>按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。</li>\n<li>每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。</li>\n<li>这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</li>\n<li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;</li>\n<li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；</li>\n<li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。\n按行分发策略\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。\n按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n但是，这个“唯一键”只有主键 id 还是不够的，我们还需要考虑下面这种场景，表 t1 中除了主键，还有唯一索引 a：\nCREATE TABLE <code>t1</code> (\n<code>id</code> int(11) NOT NULL,\n<code>a</code> int(11) DEFAULT NULL,\n<code>b</code> int(11) DEFAULT NULL,\nPRIMARY KEY (<code>id</code>),\nUNIQUE KEY <code>a</code> (<code>a</code>)\n) ENGINE=InnoDB;\ninsert into t1 values(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);\n假设，接下来我们要在主库执行这两个事务：\n图 4 唯一键冲突示例\n可以看到，这两个事务要更新的行的主键值不同，但是如果它们被分到不同的 worker，就有可能 session B 的语句先执行。这时候 id=1 的行的 a 的值还是 1，就会报唯一键冲突。\n因此，基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n比如，在上面这个例子中，我要在表 t1 上执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:</li>\n<li>key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。</li>\n<li>key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。</li>\n<li>key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：</li>\n<li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；</li>\n<li>表必须有主键；</li>\n<li>不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n但，好在这三条约束规则，本来就是 DBA 之前要求业务开发人员必须遵守的线上使用规范，所以这两个并行复制策略在应用上也没有碰到什么麻烦。\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：</li>\n<li>耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。</li>\n<li>耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n所以，我在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：</li>\n<li>coordinator 暂时先 hold 住这个事务；</li>\n<li>等待所有 worker 都执行完成，变成空队列；</li>\n<li>coordinator 直接执行这个事务；</li>\n<li>恢复并行模式。\n读到这里，你可能会感到奇怪，这两个策略又没有被合到官方，我为什么要介绍这么详细呢？其实，介绍这两个策略的目的是抛砖引玉，方便你理解后面要介绍的社区版本策略。\nMySQL 5.6 版本的并行复制策略\n官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：</li>\n<li>构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。</li>\n<li>不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略\n在第 23 篇文章中，我给你介绍了 redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：</li>\n<li>能够在同一组里提交的事务，一定不会修改同一行；</li>\n<li>主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n在实现上，MariaDB 是这么做的：</li>\n<li>在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；</li>\n<li>commit_id 直接写到 binlog 里面；</li>\n<li>传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；</li>\n<li>这一组全部执行完成后，coordinator 再去取下一批。\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n如图 5 所示，假设了三组事务在主库的执行情况，你可以看到在 trx1、trx2 和 trx3 提交的时候，trx4、trx5 和 trx6 是在执行的。这样，在第一组事务提交完成的时候，下一组事务很快就会进入 commit 状态。\n图 5 主库并行事务\n而按照 MariaDB 的并行复制策略，备库上的执行效果如图 6 所示。\n图 6 MariaDB 并行复制，备库并行效果\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n• 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n• 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n你可以先考虑这样一个问题：同时处于“执行状态”的所有事务，是不是可以并行？\n答案是，不能。\n因为，这里面可能有由于锁冲突而处于锁等待状态的事务。如果这些事务在备库上被分配到不同的 worker，就会出现备库跟主库不一致的情况。而上面提到的 MariaDB 这个策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了。\n这时候，你可以再回顾一下两阶段提交，我把前面第 23 篇文章中介绍过的两阶段提交过程图贴过来。\n图 7 两阶段提交细化过程图\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n• 同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n• 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n我在第 23 篇文章，讲 binlog 的组提交的时候，介绍过两个参数：\n• binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n• binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略\n在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n• COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n• WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n• WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n你可能看出来了，这跟我们前面介绍的基于 MySQL 5.5 版本的按行分发的策略是差不多的。不过，MySQL 官方的这个实现还是有很大的优势：\n• writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n• 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n• 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n因此，MySQL 5.7.22 的并行复制策略在通用性上还是有保证的。\n当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n小结\n在今天这篇文章中，我和你介绍了 MySQL 的各种多线程复制策略。\n为什么要有多线程复制呢？这是因为单线程复制的能力全面低于多线程复制，对于更新压力较大的主库，备库是可能一直追不上主库的。从现象上看就是，备库上 seconds_behind_master 的值越来越大。\n在介绍完每个并行复制策略后，我还和你分享了不同策略的优缺点：\n• 如果你是 DBA，就需要根据不同的业务场景，选择不同的策略；\n• 如果是你业务开发人员，也希望你能从中获取灵感用到平时的开发工作中。\n从这些分析中，你也会发现大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一。因此，在平时的开发工作中，我建议你尽量减少大事务操作，把大事务拆成小事务。\n官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。\n思考题:假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。这时候，你为了更快地让备库追上主库，要开并行复制。\n在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？如果设置另外两个参数，你认为会出现什么现象呢？\n这个问题的答案：参数设置为 WRITESET。\n• 由于主库是单线程压力模式，所以每个事务的 commit_id 都不同，那么设置为 COMMIT_ORDER 模式的话，从库也只能单线程执行。\n• 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n所以，应该将 binlog-transaction-dependency-tracking 设置为 WRITESET</li>\n</ol>\n"},{"title":"27 | 主库出问题了，从库怎么办？-GTID","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/27-主库出问题了，从库怎么办？-GTID.md","raw":"---\ntitle: 27 | 主库出问题了，从库怎么办？-GTID\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"27-主库出问题了，从库怎么办？-GTID","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvo0029r5p78w5cd450","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"28 | 读写分离有哪些坑","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/28-读写分离有哪些坑.md","raw":"---\ntitle: 28 | 读写分离有哪些坑\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"28-读写分离有哪些坑","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvo002cr5p75rva2n21","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"29 | 如何判断一个数据库是不是出问题了","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/29-如何判断一个数据库是不是出问题了.md","raw":"---\ntitle: 29 | 如何判断一个数据库是不是出问题了\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"29-如何判断一个数据库是不是出问题了","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvp002fr5p7d51iazoo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"30 | 答疑文章（二）：用动态的观点看加锁","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/30-答疑文章（二）：用动态的观点看加锁.md","raw":"---\ntitle: 30 | 答疑文章（二）：用动态的观点看加锁\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"30-答疑文章（二）：用动态的观点看加锁","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvq002ir5p771g568tg","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"31 | 误删数据后除了跑路，还能怎么办","date":"2020-09-29T06:08:49.000Z","_content":"","source":"_posts/31-误删数据后除了跑路，还能怎么办.md","raw":"---\ntitle: 31 | 误删数据后除了跑路，还能怎么办\ndate: 2020-09-29 14:08:49\ntags:\n---\n","slug":"31-误删数据后除了跑路，还能怎么办","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvr002lr5p7dak303tp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"32 | 为什么还有kill不掉的语句","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/32-为什么还有kill不掉的语句.md","raw":"---\ntitle: 32 | 为什么还有kill不掉的语句\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"32-为什么还有kill不掉的语句","published":1,"updated":"2021-06-30T02:33:24.689Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvs002or5p7bj8efrg4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"33 | 我查这么多数据，会不会把数据库内存打爆","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/33-我查这么多数据，会不会把数据库内存打爆.md","raw":"---\ntitle: 33 | 我查这么多数据，会不会把数据库内存打爆\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"33-我查这么多数据，会不会把数据库内存打爆","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvs002rr5p7ap0lhudo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"34 | 到底可不可以使用join","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/34-到底可不可以使用join.md","raw":"---\ntitle: 34 | 到底可不可以使用join\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"34-到底可不可以使用join","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvt002ur5p75fa8aey8","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"35 | join语句怎么优化","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/35-join语句怎么优化.md","raw":"---\ntitle: 35 | join语句怎么优化\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"35-join语句怎么优化","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvu002xr5p74lqw8k3i","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"36 | MySQL的limit用法和分页查询的性能分析及优化","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/36-MySQL的limit用法和分页查询的性能分析及优化.md","raw":"---\ntitle: 36 | MySQL的limit用法和分页查询的性能分析及优化\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"36-MySQL的limit用法和分页查询的性能分析及优化","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvu0030r5p764q45jf6","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"37 | MySQL 优化之 index merge (索引合并)","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/37-MySQL-优化之-index-merge-索引合并.md","raw":"---\ntitle: 37 | MySQL 优化之 index merge (索引合并)\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"37-MySQL-优化之-index-merge-索引合并","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvv0033r5p76l94cq3i","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"46 | 为什么临时表可以重名","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/46-为什么临时表可以重名.md","raw":"---\ntitle: 46 | 为什么临时表可以重名\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"46-为什么临时表可以重名","published":1,"updated":"2021-06-30T02:33:24.690Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvw0036r5p7fcyf20mz","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"47 | 什么时候会使用内部临时表","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/47-什么时候会使用内部临时表.md","raw":"---\ntitle: 47 | 什么时候会使用内部临时表\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"47-什么时候会使用内部临时表","published":1,"updated":"2021-06-30T02:33:24.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvx0039r5p7714b0tj5","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"48 | 都说InnoDB好，那还要不要使用Memory引擎","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/48-都说InnoDB好，那还要不要使用Memory引擎.md","raw":"---\ntitle: 48 | 都说InnoDB好，那还要不要使用Memory引擎\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"48-都说InnoDB好，那还要不要使用Memory引擎","published":1,"updated":"2021-06-30T02:33:24.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvx003cr5p77rn63fo7","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"49 | 自增主键为什么不是连续的","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/49-自增主键为什么不是连续的.md","raw":"---\ntitle: 49 | 自增主键为什么不是连续的\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"49-自增主键为什么不是连续的","published":1,"updated":"2021-06-30T02:33:24.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvy003fr5p7da5gh57h","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"50 | insert语句的锁为什么这么多","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/50-insert语句的锁为什么这么多.md","raw":"---\ntitle: 50 | insert语句的锁为什么这么多\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"50-insert语句的锁为什么这么多","published":1,"updated":"2021-06-30T02:33:24.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsvz003ir5p7he0kerkq","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"51 | 怎么最快地复制一张表","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/51-怎么最快地复制一张表.md","raw":"---\ntitle: 51 | 怎么最快地复制一张表\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"51-怎么最快地复制一张表","published":1,"updated":"2021-06-30T02:33:24.691Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw0003lr5p75q48eq3t","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"52 | grant之后要跟着flush privileges吗","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/52-grant之后要跟着flush-privileges吗.md","raw":"---\ntitle: 52 | grant之后要跟着flush privileges吗\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"52-grant之后要跟着flush-privileges吗","published":1,"updated":"2021-06-30T02:33:24.692Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw1003or5p7f5yp4ogj","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"53 | 要不要使用分区表","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/53-要不要使用分区表.md","raw":"---\ntitle: 53 | 要不要使用分区表\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"53-要不要使用分区表","published":1,"updated":"2021-06-30T02:33:24.692Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw2003rr5p7fyat6ksl","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"55 | 自增id用完怎么办","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/55-自增id用完怎么办.md","raw":"---\ntitle: 55 | 自增id用完怎么办\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"55-自增id用完怎么办","published":1,"updated":"2021-06-30T02:33:24.692Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw3003ur5p7gvgc7o3e","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"56｜InnoDB中的doublewrite buffer技术原理","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/56｜InnoDB中的doublewrite-buffer技术原理.md","raw":"---\ntitle: 56｜InnoDB中的doublewrite buffer技术原理\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"56｜InnoDB中的doublewrite-buffer技术原理","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw4003xr5p7hb7g19jr","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"54 | 答疑文章（三）：说一说这些好问题","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/54-答疑文章（三）：说一说这些好问题.md","raw":"---\ntitle: 54 | 答疑文章（三）：说一说这些好问题\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"54-答疑文章（三）：说一说这些好问题","published":1,"updated":"2021-06-30T02:33:24.692Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw40040r5p71k6530a9","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"57 |【bug】Mysql5.6 UK索引列过长","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/57-【bug】Mysql5-6-UK索引列过长.md","raw":"---\ntitle: 57 |【bug】Mysql5.6 UK索引列过长\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"57-【bug】Mysql5-6-UK索引列过长","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw50043r5p7aq4w5hh1","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"58 | MySQL侧如何分析服务响应速度","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/58-MySQL侧如何分析服务响应速度.md","raw":"---\ntitle: 58 | MySQL侧如何分析服务响应速度\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"58-MySQL侧如何分析服务响应速度","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw60046r5p734tr885a","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"59 | InnoDB 中buffer pool（bp）的技术原理","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/59-InnoDB-中buffer-pool（bp）的技术原理.md","raw":"---\ntitle: 59 | InnoDB 中buffer pool（bp）的技术原理\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"59-InnoDB-中buffer-pool（bp）的技术原理","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw70049r5p7doda01nb","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"60 | 倒排索引原理和实现","date":"2019-06-02T16:00:00.000Z","_content":"","source":"_posts/60-倒排索引原理和实现.md","raw":"---\ntitle: 60 | 倒排索引原理和实现\ndate: 2019-06-03\ncategories:\n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n","slug":"60-倒排索引原理和实现","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw7004cr5p706jbbqw7","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"C4.5算法","date":"2018-11-10T04:01:01.000Z","_content":"\n\n\n<!-- more -->\n\n---\n参考\n\n[wikipedia-C4.5算法](https://en.wikipedia.org/wiki/C4.5_algorithm)","source":"_posts/C4.5算法.md","raw":"---\ntitle: C4.5算法\ndate: 2018-11-10 12:01:01\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n    - 决策树\n---\n\n\n\n<!-- more -->\n\n---\n参考\n\n[wikipedia-C4.5算法](https://en.wikipedia.org/wiki/C4.5_algorithm)","slug":"C4.5算法","published":1,"updated":"2021-06-30T02:33:24.693Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsw9004fr5p7hytz1spx","content":"<span id=\"more\"></span>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/C4.5_algorithm\">wikipedia-C4.5算法</a></p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/C4.5_algorithm\">wikipedia-C4.5算法</a></p>"},{"title":"CART算法","date":"2018-11-09T07:01:41.000Z","_content":"\n\n\n<!-- more -->","source":"_posts/CART算法.md","raw":"---\ntitle: CART算法\ndate: 2018-11-09 15:01:41\ncategories:\n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n    - 决策树\n---\n\n\n\n<!-- more -->","slug":"CART算法","published":1,"updated":"2021-06-30T02:33:24.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswa004ir5p73mq49yit","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"EM算法","date":"2018-11-09T07:02:04.000Z","_content":"\n\n\n<!-- more -->","source":"_posts/EM算法.md","raw":"---\ntitle: EM算法\ndate: 2018-11-09 15:02:04\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n---\n\n\n\n<!-- more -->","slug":"EM算法","published":1,"updated":"2021-06-30T02:33:24.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswc004nr5p77232ehq8","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"Elasticsearch安装","date":"2019-01-15T06:15:53.000Z","_content":"\n\n---\n\n\n## 下载\n\n下载地址：https://www.elastic.co/downloads/elasticsearch\n\n## 安装\n\n```bash\n# 解压\ntar -zxvf elasticsearch-6.5.4.tar.gz\n# copy\n\n```\n\n### 单机\n```bash\n\n```\n\n\n### 集群\n\n#### 配置\n\n```bash\ndiscovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\", \"127.0.0.1:9301\", \"127.0.0.1:9302\"]\n\n```\n\n> elasticsearch 不推荐使用多播，推荐使用单播\n\n\n\n<br/>\n## 问题\n\n#### 异常详情\n```\nException in thread \"main\" java.nio.file.AccessDeniedException: /Library/elasticsearch-6.5.4/config/jvm.options\n\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n\tat sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n\tat java.nio.file.Files.newByteChannel(Files.java:361)\n\tat java.nio.file.Files.newByteChannel(Files.java:407)\n\tat java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n\tat java.nio.file.Files.newInputStream(Files.java:152)\n\tat org.elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:60)\n```\n#### 解决方案\n```bash\nsudo chown -R 用户名 elasticsearch-6.5.4\n```\n\n<br/>\n\n#### 异常详情\n```\nfailed to send join request to master [{node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}], reason [RemoteTransportException[[node-1][127.0.0.1:9300][internal:discovery/zen/join]]; nested: IllegalArgumentException[can't add node {node-2}{woYxlU_VRVOCKYgA9QXl5g}{aewcXbjZTq-brZG3gWiXPQ}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}, found existing node {node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true} with the same id but is a different node instance]; ]\n```\n#### 解决方案\n```bash\n是因为复制的elasticsearch文件夹下包含了data文件中示例一的节点数据，需要把data文件下的文件清空。\n```\n\n\n\n<br/>\n\n---\n参考\n","source":"_posts/Elasticsearch安装.md","raw":"---\ntitle: Elasticsearch安装\ndate: 2019-01-15 14:15:53\ncategories: \n    - Elasticsearch\ntags:\n    - 全文搜索\n    - Elasticsearch\n---\n\n\n---\n\n\n## 下载\n\n下载地址：https://www.elastic.co/downloads/elasticsearch\n\n## 安装\n\n```bash\n# 解压\ntar -zxvf elasticsearch-6.5.4.tar.gz\n# copy\n\n```\n\n### 单机\n```bash\n\n```\n\n\n### 集群\n\n#### 配置\n\n```bash\ndiscovery.zen.ping.unicast.hosts: [\"127.0.0.1:9300\", \"127.0.0.1:9301\", \"127.0.0.1:9302\"]\n\n```\n\n> elasticsearch 不推荐使用多播，推荐使用单播\n\n\n\n<br/>\n## 问题\n\n#### 异常详情\n```\nException in thread \"main\" java.nio.file.AccessDeniedException: /Library/elasticsearch-6.5.4/config/jvm.options\n\tat sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n\tat sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n\tat sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n\tat java.nio.file.Files.newByteChannel(Files.java:361)\n\tat java.nio.file.Files.newByteChannel(Files.java:407)\n\tat java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n\tat java.nio.file.Files.newInputStream(Files.java:152)\n\tat org.elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:60)\n```\n#### 解决方案\n```bash\nsudo chown -R 用户名 elasticsearch-6.5.4\n```\n\n<br/>\n\n#### 异常详情\n```\nfailed to send join request to master [{node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}], reason [RemoteTransportException[[node-1][127.0.0.1:9300][internal:discovery/zen/join]]; nested: IllegalArgumentException[can't add node {node-2}{woYxlU_VRVOCKYgA9QXl5g}{aewcXbjZTq-brZG3gWiXPQ}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}, found existing node {node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true} with the same id but is a different node instance]; ]\n```\n#### 解决方案\n```bash\n是因为复制的elasticsearch文件夹下包含了data文件中示例一的节点数据，需要把data文件下的文件清空。\n```\n\n\n\n<br/>\n\n---\n参考\n","slug":"Elasticsearch安装","published":1,"updated":"2021-06-30T02:33:24.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswc004qr5p7fhlrenml","content":"<hr>\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"https://www.elastic.co/downloads/elasticsearch\">https://www.elastic.co/downloads/elasticsearch</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 解压</span>\n<span class=\"token function\">tar</span> -zxvf elasticsearch-6.5.4.tar.gz\n<span class=\"token comment\" spellcheck=\"true\"># copy</span>\n</code></pre>\n<h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><pre class=\" language-bash\"><code class=\"language-bash\">\n</code></pre>\n<h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><pre class=\" language-bash\"><code class=\"language-bash\">discovery.zen.ping.unicast.hosts: <span class=\"token punctuation\">[</span><span class=\"token string\">\"127.0.0.1:9300\"</span>, <span class=\"token string\">\"127.0.0.1:9301\"</span>, <span class=\"token string\">\"127.0.0.1:9302\"</span><span class=\"token punctuation\">]</span>\n</code></pre>\n<blockquote>\n<p>elasticsearch 不推荐使用多播，推荐使用单播</p>\n</blockquote>\n<br>\n## 问题\n\n<h4 id=\"异常详情\"><a href=\"#异常详情\" class=\"headerlink\" title=\"异常详情\"></a>异常详情</h4><pre><code>Exception in thread \"main\" java.nio.file.AccessDeniedException: /Library/elasticsearch-6.5.4/config/jvm.options\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n    at java.nio.file.Files.newByteChannel(Files.java:361)\n    at java.nio.file.Files.newByteChannel(Files.java:407)\n    at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n    at java.nio.file.Files.newInputStream(Files.java:152)\n    at org.elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:60)\n</code></pre>\n<h4 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">chown</span> -R 用户名 elasticsearch-6.5.4\n</code></pre>\n<br>\n\n<h4 id=\"异常详情-1\"><a href=\"#异常详情-1\" class=\"headerlink\" title=\"异常详情\"></a>异常详情</h4><pre><code>failed to send join request to master [{node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}], reason [RemoteTransportException[[node-1][127.0.0.1:9300][internal:discovery/zen/join]]; nested: IllegalArgumentException[can't add node {node-2}{woYxlU_VRVOCKYgA9QXl5g}{aewcXbjZTq-brZG3gWiXPQ}{127.0.0.1}{127.0.0.1:9301}{ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}, found existing node {node-1}{woYxlU_VRVOCKYgA9QXl5g}{GQW9C2dXTV2KkaPaYP76Jw}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=17179869184, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true} with the same id but is a different node instance]; ]\n</code></pre>\n<h4 id=\"解决方案-1\"><a href=\"#解决方案-1\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><pre class=\" language-bash\"><code class=\"language-bash\">是因为复制的elasticsearch文件夹下包含了data文件中示例一的节点数据，需要把data文件下的文件清空。\n</code></pre>\n<br>\n\n<hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"https://www.elastic.co/downloads/elasticsearch\">https://www.elastic.co/downloads/elasticsearch</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><pre><code class=\"bash\"># 解压\ntar -zxvf elasticsearch-6.5.4.tar.gz\n# copy\n</code></pre>\n<h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><pre><code class=\"bash\">\n</code></pre>\n<h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><pre><code class=\"bash\">discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;, &quot;127.0.0.1:9301&quot;, &quot;127.0.0.1:9302&quot;]\n</code></pre>\n<blockquote>\n<p>elasticsearch 不推荐使用多播，推荐使用单播</p>\n</blockquote>\n<br/>\n## 问题\n\n<h4 id=\"异常详情\"><a href=\"#异常详情\" class=\"headerlink\" title=\"异常详情\"></a>异常详情</h4><pre><code>Exception in thread &quot;main&quot; java.nio.file.AccessDeniedException: /Library/elasticsearch-6.5.4/config/jvm.options\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:84)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n    at java.nio.file.Files.newByteChannel(Files.java:361)\n    at java.nio.file.Files.newByteChannel(Files.java:407)\n    at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n    at java.nio.file.Files.newInputStream(Files.java:152)\n    at org.elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:60)\n</code></pre>\n<h4 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><pre><code class=\"bash\">sudo chown -R 用户名 elasticsearch-6.5.4\n</code></pre>\n<br/>\n\n<h4 id=\"异常详情-1\"><a href=\"#异常详情-1\" class=\"headerlink\" title=\"异常详情\"></a>异常详情</h4><pre><code>failed to send join request to master [&#123;node-1&#125;&#123;woYxlU_VRVOCKYgA9QXl5g&#125;&#123;GQW9C2dXTV2KkaPaYP76Jw&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;&#123;ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true&#125;], reason [RemoteTransportException[[node-1][127.0.0.1:9300][internal:discovery/zen/join]]; nested: IllegalArgumentException[can&#39;t add node &#123;node-2&#125;&#123;woYxlU_VRVOCKYgA9QXl5g&#125;&#123;aewcXbjZTq-brZG3gWiXPQ&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9301&#125;&#123;ml.machine_memory=17179869184, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true&#125;, found existing node &#123;node-1&#125;&#123;woYxlU_VRVOCKYgA9QXl5g&#125;&#123;GQW9C2dXTV2KkaPaYP76Jw&#125;&#123;127.0.0.1&#125;&#123;127.0.0.1:9300&#125;&#123;ml.machine_memory=17179869184, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true&#125; with the same id but is a different node instance]; ]\n</code></pre>\n<h4 id=\"解决方案-1\"><a href=\"#解决方案-1\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h4><pre><code class=\"bash\">是因为复制的elasticsearch文件夹下包含了data文件中示例一的节点数据，需要把data文件下的文件清空。\n</code></pre>\n<br/>\n\n<hr>\n<p>参考</p>\n"},{"title":"Gihub搭建Hexo","date":"2012-08-01T00:01:01.000Z","_content":"\n当前教程在Mac上面搭建Hexo\n\n## 环境准备\n\n### Nodejs安装\n\n``` bash\n# 测试是否安装\n$ node -v\n# 如果没有安装，请安装\n$ node install\n```\n\n<!-- more -->\n\n\n### Git安装\n\n参考：[Git 安装](/2012/08/01/Mac安装Git)\n\n\n### Hexo安装\n\n``` bash\n# 测试是否安装\n$ hexo -v\n# 如果没有版本信息，代表没有安装，请按照如下安装Hexo\n$ npm install -g hexo-cli\n```\n\n\n## Github搭建Hexo\n\n### 创建Hexo\n\n如果 https://github.com 没有注册账号，先注册: https://github.com/join\n\n在Github创建项目，格式必须要遵守：`账户名.github.io`\n创建地址：https://github.com/new\n\n我的账户名：https://github.com/Gumihoy\n我的创建项目：`Gumihoy.github.io`\n\n![创建项目](1542073066701.jpg)\n\n``` bash\n# 克隆下项目且初始化hexo\n\n$ git clone https://github.com/Gumihoy/Gumihoy.github.io.git\n$ hexo init\n```\n\n### Hexo 配置\n\n在 `Gumihoy.github.io` 目录修改 `_config.yml`文件\n``` yml\n# 图片\npost_asset_folder: true\n\n# 配置 github项目关联\ndeploy:\n  type: git\n  repo: https://github.com/Gumihoy/Gumihoy.github.io.git\n  branch: master\n```\n\n### 生成静态文件\n\n``` bash\n$ hexo g\n```\n\n### 启动\n\n``` bash\n$ hexo s\n```\n访问地址： http://127.0.0.1:4000\n\n\n### 创建分类页\n``` bash\n$ hexo new page categories\n```\n\n\n### 创建标签页\n``` bash\n$ hexo new page tags\n```\n\n\n### 创建404页面\n\n``` bash\n$ hexo new page 404\n```\n\n404\b内容\n``` markdown\n---\ntitle: 404 Not Found：该页无法显示\ncomments: false\npermalink: /404\nfancybox: false\nnoDate: \"true\"\n---\n\n<style type=\"text/css\">\n\t.article-title {\n\t\tfont-size: 2.1em;\n\t}\n\tstrong a {\n\t\tcolor: #747474;\n\t}\n\t.share {\n\t\tdisplay: none;\n\t}\n\t.player {\n\t\tmargin-left: -10px;\n\t}\n\t.sign {\n\t\ttext-align: right;\n\t\tfont-style: italic;\n\t}\n  \t#page-visit {\n\t\tdisplay: none;\n\t}\n\t.center {\n\t\ttext-align: center;\n\t\theight: 2.5em;\n\t\tfont-weight: bold;\n\t}\n\t.search2 {\n\t\theight: 2.2em;\n\t\tfont-size: 1em;\n\t\twidth: 50%;\n\t\tmargin: auto 24%;\n\t\tcolor: #727272;\n\t\topacity: .6;\n\t\tborder: 2px solid lightgray;\n\t}\n\t.search2:hover {\n\t\topacity: 1;\n\t\tbox-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n\t\t};\n\t.article-entry hr {\n\t\tmargin: 0;\n\t}\n\t.pic {\n\t\ttext-align: center;\n\t\tmargin: 0;\n\t}\n\t.pic br {\n  \t\tdisplay: none;\n  \t}\n</style>\n\n***\n\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"https//music.163.com/outchain/player?type=0&id=993980219&auto=1&height=430\"></iframe>\n</div>\n```\n\n### 主题\n在theme目录下面执行下面命令\n``` bash\ngit clone https://github.com/Gumihoy/hexo-theme-spfk.git\n```\n在 `Gumihoy.github.io` 目录下 `_config.yml` 文件\b修改配置\n\n``` yml\ntheme: hexo-theme-spfk\n```\n可以按照上面`生成静态页`、`启动`命令查看主题是否生效\n\n\n### 评论：gitalk\n\n在`hexo-theme-spfk`目录下面`_config.yml`文件找到 gitalk配置，配置如下\n``` yml\ngitalk:\n  on: true\n  owner: gumihoy\n  admin: gumihoy\n  repo: gumihoy.github.io\n  client_id: acedb7865ff08426fa73\n  client_secret: f80c2b21236d7eb803d6069c7424de26d957e1bf\n```\n\n`client_id`、`client_secret` 可以在Github创建OAuth Apps获取，地址：https://github.com/settings/developers\n![OAuth Apps](1542037823098.jpg)\n\n![OAuth Apps配置](1542074055382.jpg)\n\n用自己的 `client_id`、`client_secret` 替换\n\n## Hexo 使用\n\n<br/>\n### 创建一个文章\n\n``` bash\n$ hexo new xx\n```\n上面命令会在 `source/_posts`目录下面创建 `xx.md`一个文件，打开`xx.md`可以写文章了\n\n<br/>\n### 文章插入图片\n在 `Gumihoy.github.io` 目录下 `_config.xml`文件 配置\n``` yml\n# 图片\npost_asset_folder: true\n```\n\n按照上面命令创建一个文章，\b会同时生成一个同样名字的目录，\n把文章图片copy到目录中，再在文章引用，如下\n`目录下图片文件：1542074055382.jpg；引用：![OAuth Apps配置](1542074055382.jpg)`\n\n\n<br/>\n### 文章摘要设置\n\n在文章插入 `<!-- more -->` ，`<!-- more -->`之前的内容就是摘要\n\n\n\n\n------\n参考\n\n[Hexo官方文档](https://hexo.io/zh-cn/docs/)","source":"_posts/Github搭建Hexo.md","raw":"---\ntitle: Gihub搭建Hexo\ndate: 2012-08-01 08:01:01\ncategories: \n    - Hexo\ntags: \n    - Hexo\n---\n\n当前教程在Mac上面搭建Hexo\n\n## 环境准备\n\n### Nodejs安装\n\n``` bash\n# 测试是否安装\n$ node -v\n# 如果没有安装，请安装\n$ node install\n```\n\n<!-- more -->\n\n\n### Git安装\n\n参考：[Git 安装](/2012/08/01/Mac安装Git)\n\n\n### Hexo安装\n\n``` bash\n# 测试是否安装\n$ hexo -v\n# 如果没有版本信息，代表没有安装，请按照如下安装Hexo\n$ npm install -g hexo-cli\n```\n\n\n## Github搭建Hexo\n\n### 创建Hexo\n\n如果 https://github.com 没有注册账号，先注册: https://github.com/join\n\n在Github创建项目，格式必须要遵守：`账户名.github.io`\n创建地址：https://github.com/new\n\n我的账户名：https://github.com/Gumihoy\n我的创建项目：`Gumihoy.github.io`\n\n![创建项目](1542073066701.jpg)\n\n``` bash\n# 克隆下项目且初始化hexo\n\n$ git clone https://github.com/Gumihoy/Gumihoy.github.io.git\n$ hexo init\n```\n\n### Hexo 配置\n\n在 `Gumihoy.github.io` 目录修改 `_config.yml`文件\n``` yml\n# 图片\npost_asset_folder: true\n\n# 配置 github项目关联\ndeploy:\n  type: git\n  repo: https://github.com/Gumihoy/Gumihoy.github.io.git\n  branch: master\n```\n\n### 生成静态文件\n\n``` bash\n$ hexo g\n```\n\n### 启动\n\n``` bash\n$ hexo s\n```\n访问地址： http://127.0.0.1:4000\n\n\n### 创建分类页\n``` bash\n$ hexo new page categories\n```\n\n\n### 创建标签页\n``` bash\n$ hexo new page tags\n```\n\n\n### 创建404页面\n\n``` bash\n$ hexo new page 404\n```\n\n404\b内容\n``` markdown\n---\ntitle: 404 Not Found：该页无法显示\ncomments: false\npermalink: /404\nfancybox: false\nnoDate: \"true\"\n---\n\n<style type=\"text/css\">\n\t.article-title {\n\t\tfont-size: 2.1em;\n\t}\n\tstrong a {\n\t\tcolor: #747474;\n\t}\n\t.share {\n\t\tdisplay: none;\n\t}\n\t.player {\n\t\tmargin-left: -10px;\n\t}\n\t.sign {\n\t\ttext-align: right;\n\t\tfont-style: italic;\n\t}\n  \t#page-visit {\n\t\tdisplay: none;\n\t}\n\t.center {\n\t\ttext-align: center;\n\t\theight: 2.5em;\n\t\tfont-weight: bold;\n\t}\n\t.search2 {\n\t\theight: 2.2em;\n\t\tfont-size: 1em;\n\t\twidth: 50%;\n\t\tmargin: auto 24%;\n\t\tcolor: #727272;\n\t\topacity: .6;\n\t\tborder: 2px solid lightgray;\n\t}\n\t.search2:hover {\n\t\topacity: 1;\n\t\tbox-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n\t\t};\n\t.article-entry hr {\n\t\tmargin: 0;\n\t}\n\t.pic {\n\t\ttext-align: center;\n\t\tmargin: 0;\n\t}\n\t.pic br {\n  \t\tdisplay: none;\n  \t}\n</style>\n\n***\n\n<p class=\"center\">很抱歉，您所访问的地址并不存在: </p>\n\n<p class=\"center\"><a href=\"/\">回主页</a> · <a href=\"/archives\">所有文章</a> · <a href=\"/about\">留言板</a></p>\n\n<p class=\"center\">可在边栏搜索框中对本站进行检索，以获取相关信息。</p>\n\n<div style=\"text-align: center\">\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=450 src=\"https//music.163.com/outchain/player?type=0&id=993980219&auto=1&height=430\"></iframe>\n</div>\n```\n\n### 主题\n在theme目录下面执行下面命令\n``` bash\ngit clone https://github.com/Gumihoy/hexo-theme-spfk.git\n```\n在 `Gumihoy.github.io` 目录下 `_config.yml` 文件\b修改配置\n\n``` yml\ntheme: hexo-theme-spfk\n```\n可以按照上面`生成静态页`、`启动`命令查看主题是否生效\n\n\n### 评论：gitalk\n\n在`hexo-theme-spfk`目录下面`_config.yml`文件找到 gitalk配置，配置如下\n``` yml\ngitalk:\n  on: true\n  owner: gumihoy\n  admin: gumihoy\n  repo: gumihoy.github.io\n  client_id: acedb7865ff08426fa73\n  client_secret: f80c2b21236d7eb803d6069c7424de26d957e1bf\n```\n\n`client_id`、`client_secret` 可以在Github创建OAuth Apps获取，地址：https://github.com/settings/developers\n![OAuth Apps](1542037823098.jpg)\n\n![OAuth Apps配置](1542074055382.jpg)\n\n用自己的 `client_id`、`client_secret` 替换\n\n## Hexo 使用\n\n<br/>\n### 创建一个文章\n\n``` bash\n$ hexo new xx\n```\n上面命令会在 `source/_posts`目录下面创建 `xx.md`一个文件，打开`xx.md`可以写文章了\n\n<br/>\n### 文章插入图片\n在 `Gumihoy.github.io` 目录下 `_config.xml`文件 配置\n``` yml\n# 图片\npost_asset_folder: true\n```\n\n按照上面命令创建一个文章，\b会同时生成一个同样名字的目录，\n把文章图片copy到目录中，再在文章引用，如下\n`目录下图片文件：1542074055382.jpg；引用：![OAuth Apps配置](1542074055382.jpg)`\n\n\n<br/>\n### 文章摘要设置\n\n在文章插入 `<!-- more -->` ，`<!-- more -->`之前的内容就是摘要\n\n\n\n\n------\n参考\n\n[Hexo官方文档](https://hexo.io/zh-cn/docs/)","slug":"Github搭建Hexo","published":1,"updated":"2021-06-30T02:33:24.694Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswd004tr5p7anegal9r","content":"<p>当前教程在Mac上面搭建Hexo</p>\n<h2 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h2><h3 id=\"Nodejs安装\"><a href=\"#Nodejs安装\" class=\"headerlink\" title=\"Nodejs安装\"></a>Nodejs安装</h3><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 测试是否安装</span>\n$ node -v\n<span class=\"token comment\" spellcheck=\"true\"># 如果没有安装，请安装</span>\n$ node <span class=\"token function\">install</span>\n</code></pre>\n<span id=\"more\"></span>\n\n\n<h3 id=\"Git安装\"><a href=\"#Git安装\" class=\"headerlink\" title=\"Git安装\"></a>Git安装</h3><p>参考：<a href=\"/2012/08/01/Mac%E5%AE%89%E8%A3%85Git\">Git 安装</a></p>\n<h3 id=\"Hexo安装\"><a href=\"#Hexo安装\" class=\"headerlink\" title=\"Hexo安装\"></a>Hexo安装</h3><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 测试是否安装</span>\n$ hexo -v\n<span class=\"token comment\" spellcheck=\"true\"># 如果没有版本信息，代表没有安装，请按照如下安装Hexo</span>\n$ <span class=\"token function\">npm</span> <span class=\"token function\">install</span> -g hexo-cli\n</code></pre>\n<h2 id=\"Github搭建Hexo\"><a href=\"#Github搭建Hexo\" class=\"headerlink\" title=\"Github搭建Hexo\"></a>Github搭建Hexo</h2><h3 id=\"创建Hexo\"><a href=\"#创建Hexo\" class=\"headerlink\" title=\"创建Hexo\"></a>创建Hexo</h3><p>如果 <a href=\"https://github.com/\">https://github.com</a> 没有注册账号，先注册: <a href=\"https://github.com/join\">https://github.com/join</a></p>\n<p>在Github创建项目，格式必须要遵守：<code>账户名.github.io</code>\n创建地址：<a href=\"https://github.com/new\">https://github.com/new</a></p>\n<p>我的账户名：<a href=\"https://github.com/Gumihoy\">https://github.com/Gumihoy</a>\n我的创建项目：<code>Gumihoy.github.io</code></p>\n<p><img src=\"1542073066701.jpg\" alt=\"创建项目\"></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 克隆下项目且初始化hexo</span>\n\n$ <span class=\"token function\">git</span> clone https://github.com/Gumihoy/Gumihoy.github.io.git\n$ hexo init\n</code></pre>\n<h3 id=\"Hexo-配置\"><a href=\"#Hexo-配置\" class=\"headerlink\" title=\"Hexo 配置\"></a>Hexo 配置</h3><p>在 <code>Gumihoy.github.io</code> 目录修改 <code>_config.yml</code>文件</p>\n<pre class=\" language-yml\"><code class=\"language-yml\"># 图片\npost_asset_folder: true\n\n# 配置 github项目关联\ndeploy:\n  type: git\n  repo: https://github.com/Gumihoy/Gumihoy.github.io.git\n  branch: master\n</code></pre>\n<h3 id=\"生成静态文件\"><a href=\"#生成静态文件\" class=\"headerlink\" title=\"生成静态文件\"></a>生成静态文件</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo g\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo s\n</code></pre>\n<p>访问地址： <a href=\"http://127.0.0.1:4000/\">http://127.0.0.1:4000</a></p>\n<h3 id=\"创建分类页\"><a href=\"#创建分类页\" class=\"headerlink\" title=\"创建分类页\"></a>创建分类页</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new page categories\n</code></pre>\n<h3 id=\"创建标签页\"><a href=\"#创建标签页\" class=\"headerlink\" title=\"创建标签页\"></a>创建标签页</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new page tags\n</code></pre>\n<h3 id=\"创建404页面\"><a href=\"#创建404页面\" class=\"headerlink\" title=\"创建404页面\"></a>创建404页面</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new page 404\n</code></pre>\n<p>404\b内容</p>\n<pre class=\" language-markdown\"><code class=\"language-markdown\"><span class=\"token hr punctuation\">---</span>\ntitle: 404 Not Found：该页无法显示\ncomments: false\npermalink: /404\nfancybox: false\n<span class=\"token title important\">noDate: \"true\"\n<span class=\"token punctuation\">---</span></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>style</span> <span class=\"token attr-name\">type</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>text/css<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n<span class=\"token code keyword\">    .article-title {</span>\n<span class=\"token code keyword\">        font-size: 2.1em;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    strong a {</span>\n<span class=\"token code keyword\">        color: #747474;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .share {</span>\n<span class=\"token code keyword\">        display: none;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .player {</span>\n<span class=\"token code keyword\">        margin-left: -10px;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .sign {</span>\n<span class=\"token code keyword\">        text-align: right;</span>\n<span class=\"token code keyword\">        font-style: italic;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">      #page-visit {</span>\n<span class=\"token code keyword\">        display: none;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .center {</span>\n<span class=\"token code keyword\">        text-align: center;</span>\n<span class=\"token code keyword\">        height: 2.5em;</span>\n<span class=\"token code keyword\">        font-weight: bold;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .search2 {</span>\n<span class=\"token code keyword\">        height: 2.2em;</span>\n<span class=\"token code keyword\">        font-size: 1em;</span>\n<span class=\"token code keyword\">        width: 50%;</span>\n<span class=\"token code keyword\">        margin: auto 24%;</span>\n<span class=\"token code keyword\">        color: #727272;</span>\n<span class=\"token code keyword\">        opacity: .6;</span>\n<span class=\"token code keyword\">        border: 2px solid lightgray;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .search2:hover {</span>\n<span class=\"token code keyword\">        opacity: 1;</span>\n<span class=\"token code keyword\">        box-shadow: 0 0 10px rgba(0, 0, 0, 0.3)</span>\n<span class=\"token code keyword\">        };</span>\n<span class=\"token code keyword\">    .article-entry hr {</span>\n<span class=\"token code keyword\">        margin: 0;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .pic {</span>\n<span class=\"token code keyword\">        text-align: center;</span>\n<span class=\"token code keyword\">        margin: 0;</span>\n<span class=\"token code keyword\">    }</span>\n<span class=\"token code keyword\">    .pic br {</span>\n<span class=\"token code keyword\">          display: none;</span>\n<span class=\"token code keyword\">      }</span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>style</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token hr punctuation\">***</span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span> <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>center<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>很抱歉，您所访问的地址并不存在: <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span> <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>center<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>a</span> <span class=\"token attr-name\">href</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>/<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>回主页<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>a</span><span class=\"token punctuation\">></span></span> · <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>a</span> <span class=\"token attr-name\">href</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>/archives<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>所有文章<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>a</span><span class=\"token punctuation\">></span></span> · <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>a</span> <span class=\"token attr-name\">href</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>/about<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>留言板<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>a</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span> <span class=\"token attr-name\">class</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>center<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>可在边栏搜索框中对本站进行检索，以获取相关信息。<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>div</span><span class=\"token style-attr language-css\"><span class=\"token attr-name\"> <span class=\"token attr-name\">style</span></span><span class=\"token punctuation\">=\"</span><span class=\"token attr-value\"><span class=\"token property\">text-align</span><span class=\"token punctuation\">:</span> center</span><span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>iframe</span> <span class=\"token attr-name\">frameborder</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>no<span class=\"token punctuation\">\"</span></span> <span class=\"token attr-name\">border</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>0<span class=\"token punctuation\">\"</span></span> <span class=\"token attr-name\">marginwidth</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>0<span class=\"token punctuation\">\"</span></span> <span class=\"token attr-name\">marginheight</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>0<span class=\"token punctuation\">\"</span></span> <span class=\"token attr-name\">width</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span>330</span> <span class=\"token attr-name\">height</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span>450</span> <span class=\"token attr-name\">src</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>https//music.163.com/outchain/player?type<span class=\"token punctuation\">=</span>0&amp;id<span class=\"token punctuation\">=</span>993980219&amp;auto<span class=\"token punctuation\">=</span>1&amp;height<span class=\"token punctuation\">=</span>430<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>iframe</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>div</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<h3 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h3><p>在theme目录下面执行下面命令</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/Gumihoy/hexo-theme-spfk.git\n</code></pre>\n<p>在 <code>Gumihoy.github.io</code> 目录下 <code>_config.yml</code> 文件\b修改配置</p>\n<pre class=\" language-yml\"><code class=\"language-yml\">theme: hexo-theme-spfk\n</code></pre>\n<p>可以按照上面<code>生成静态页</code>、<code>启动</code>命令查看主题是否生效</p>\n<h3 id=\"评论：gitalk\"><a href=\"#评论：gitalk\" class=\"headerlink\" title=\"评论：gitalk\"></a>评论：gitalk</h3><p>在<code>hexo-theme-spfk</code>目录下面<code>_config.yml</code>文件找到 gitalk配置，配置如下</p>\n<pre class=\" language-yml\"><code class=\"language-yml\">gitalk:\n  on: true\n  owner: gumihoy\n  admin: gumihoy\n  repo: gumihoy.github.io\n  client_id: acedb7865ff08426fa73\n  client_secret: f80c2b21236d7eb803d6069c7424de26d957e1bf\n</code></pre>\n<p><code>client_id</code>、<code>client_secret</code> 可以在Github创建OAuth Apps获取，地址：<a href=\"https://github.com/settings/developers\">https://github.com/settings/developers</a>\n<img src=\"1542037823098.jpg\" alt=\"OAuth Apps\"></p>\n<p><img src=\"1542074055382.jpg\" alt=\"OAuth Apps配置\"></p>\n<p>用自己的 <code>client_id</code>、<code>client_secret</code> 替换</p>\n<h2 id=\"Hexo-使用\"><a href=\"#Hexo-使用\" class=\"headerlink\" title=\"Hexo 使用\"></a>Hexo 使用</h2><br>\n### 创建一个文章\n\n<pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new xx\n</code></pre>\n<p>上面命令会在 <code>source/_posts</code>目录下面创建 <code>xx.md</code>一个文件，打开<code>xx.md</code>可以写文章了</p>\n<br>\n### 文章插入图片\n在 `Gumihoy.github.io` 目录下 `_config.xml`文件 配置\n``` yml\n# 图片\npost_asset_folder: true\n```\n\n<p>按照上面命令创建一个文章，\b会同时生成一个同样名字的目录，\n把文章图片copy到目录中，再在文章引用，如下\n<code>目录下图片文件：1542074055382.jpg；引用：![OAuth Apps配置](1542074055382.jpg)</code></p>\n<br>\n### 文章摘要设置\n\n<p>在文章插入 <code>&lt;!-- more --&gt;</code> ，<code>&lt;!-- more --&gt;</code>之前的内容就是摘要</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://hexo.io/zh-cn/docs/\">Hexo官方文档</a></p>\n","site":{"data":{}},"excerpt":"<p>当前教程在Mac上面搭建Hexo</p>\n<h2 id=\"环境准备\"><a href=\"#环境准备\" class=\"headerlink\" title=\"环境准备\"></a>环境准备</h2><h3 id=\"Nodejs安装\"><a href=\"#Nodejs安装\" class=\"headerlink\" title=\"Nodejs安装\"></a>Nodejs安装</h3><pre><code class=\"bash\"># 测试是否安装\n$ node -v\n# 如果没有安装，请安装\n$ node install\n</code></pre>","more":"<h3 id=\"Git安装\"><a href=\"#Git安装\" class=\"headerlink\" title=\"Git安装\"></a>Git安装</h3><p>参考：<a href=\"/2012/08/01/Mac%E5%AE%89%E8%A3%85Git\">Git 安装</a></p>\n<h3 id=\"Hexo安装\"><a href=\"#Hexo安装\" class=\"headerlink\" title=\"Hexo安装\"></a>Hexo安装</h3><pre><code class=\"bash\"># 测试是否安装\n$ hexo -v\n# 如果没有版本信息，代表没有安装，请按照如下安装Hexo\n$ npm install -g hexo-cli\n</code></pre>\n<h2 id=\"Github搭建Hexo\"><a href=\"#Github搭建Hexo\" class=\"headerlink\" title=\"Github搭建Hexo\"></a>Github搭建Hexo</h2><h3 id=\"创建Hexo\"><a href=\"#创建Hexo\" class=\"headerlink\" title=\"创建Hexo\"></a>创建Hexo</h3><p>如果 <a href=\"https://github.com/\">https://github.com</a> 没有注册账号，先注册: <a href=\"https://github.com/join\">https://github.com/join</a></p>\n<p>在Github创建项目，格式必须要遵守：<code>账户名.github.io</code>\n创建地址：<a href=\"https://github.com/new\">https://github.com/new</a></p>\n<p>我的账户名：<a href=\"https://github.com/Gumihoy\">https://github.com/Gumihoy</a>\n我的创建项目：<code>Gumihoy.github.io</code></p>\n<p><img src=\"1542073066701.jpg\" alt=\"创建项目\"></p>\n<pre><code class=\"bash\"># 克隆下项目且初始化hexo\n\n$ git clone https://github.com/Gumihoy/Gumihoy.github.io.git\n$ hexo init\n</code></pre>\n<h3 id=\"Hexo-配置\"><a href=\"#Hexo-配置\" class=\"headerlink\" title=\"Hexo 配置\"></a>Hexo 配置</h3><p>在 <code>Gumihoy.github.io</code> 目录修改 <code>_config.yml</code>文件</p>\n<pre><code class=\"yml\"># 图片\npost_asset_folder: true\n\n# 配置 github项目关联\ndeploy:\n  type: git\n  repo: https://github.com/Gumihoy/Gumihoy.github.io.git\n  branch: master\n</code></pre>\n<h3 id=\"生成静态文件\"><a href=\"#生成静态文件\" class=\"headerlink\" title=\"生成静态文件\"></a>生成静态文件</h3><pre><code class=\"bash\">$ hexo g\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><pre><code class=\"bash\">$ hexo s\n</code></pre>\n<p>访问地址： <a href=\"http://127.0.0.1:4000/\">http://127.0.0.1:4000</a></p>\n<h3 id=\"创建分类页\"><a href=\"#创建分类页\" class=\"headerlink\" title=\"创建分类页\"></a>创建分类页</h3><pre><code class=\"bash\">$ hexo new page categories\n</code></pre>\n<h3 id=\"创建标签页\"><a href=\"#创建标签页\" class=\"headerlink\" title=\"创建标签页\"></a>创建标签页</h3><pre><code class=\"bash\">$ hexo new page tags\n</code></pre>\n<h3 id=\"创建404页面\"><a href=\"#创建404页面\" class=\"headerlink\" title=\"创建404页面\"></a>创建404页面</h3><pre><code class=\"bash\">$ hexo new page 404\n</code></pre>\n<p>404\b内容</p>\n<pre><code class=\"markdown\">---\ntitle: 404 Not Found：该页无法显示\ncomments: false\npermalink: /404\nfancybox: false\nnoDate: &quot;true&quot;\n---\n\n&lt;style type=&quot;text/css&quot;&gt;\n    .article-title &#123;\n        font-size: 2.1em;\n    &#125;\n    strong a &#123;\n        color: #747474;\n    &#125;\n    .share &#123;\n        display: none;\n    &#125;\n    .player &#123;\n        margin-left: -10px;\n    &#125;\n    .sign &#123;\n        text-align: right;\n        font-style: italic;\n    &#125;\n      #page-visit &#123;\n        display: none;\n    &#125;\n    .center &#123;\n        text-align: center;\n        height: 2.5em;\n        font-weight: bold;\n    &#125;\n    .search2 &#123;\n        height: 2.2em;\n        font-size: 1em;\n        width: 50%;\n        margin: auto 24%;\n        color: #727272;\n        opacity: .6;\n        border: 2px solid lightgray;\n    &#125;\n    .search2:hover &#123;\n        opacity: 1;\n        box-shadow: 0 0 10px rgba(0, 0, 0, 0.3)\n        &#125;;\n    .article-entry hr &#123;\n        margin: 0;\n    &#125;\n    .pic &#123;\n        text-align: center;\n        margin: 0;\n    &#125;\n    .pic br &#123;\n          display: none;\n      &#125;\n&lt;/style&gt;\n\n***\n\n&lt;p class=&quot;center&quot;&gt;很抱歉，您所访问的地址并不存在: &lt;/p&gt;\n\n&lt;p class=&quot;center&quot;&gt;&lt;a href=&quot;/&quot;&gt;回主页&lt;/a&gt; · &lt;a href=&quot;/archives&quot;&gt;所有文章&lt;/a&gt; · &lt;a href=&quot;/about&quot;&gt;留言板&lt;/a&gt;&lt;/p&gt;\n\n&lt;p class=&quot;center&quot;&gt;可在边栏搜索框中对本站进行检索，以获取相关信息。&lt;/p&gt;\n\n&lt;div style=&quot;text-align: center&quot;&gt;\n以下是博主喜欢的一些歌曲，可以听听，稍作休息~\n&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=450 src=&quot;https//music.163.com/outchain/player?type=0&amp;id=993980219&amp;auto=1&amp;height=430&quot;&gt;&lt;/iframe&gt;\n&lt;/div&gt;\n</code></pre>\n<h3 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h3><p>在theme目录下面执行下面命令</p>\n<pre><code class=\"bash\">git clone https://github.com/Gumihoy/hexo-theme-spfk.git\n</code></pre>\n<p>在 <code>Gumihoy.github.io</code> 目录下 <code>_config.yml</code> 文件\b修改配置</p>\n<pre><code class=\"yml\">theme: hexo-theme-spfk\n</code></pre>\n<p>可以按照上面<code>生成静态页</code>、<code>启动</code>命令查看主题是否生效</p>\n<h3 id=\"评论：gitalk\"><a href=\"#评论：gitalk\" class=\"headerlink\" title=\"评论：gitalk\"></a>评论：gitalk</h3><p>在<code>hexo-theme-spfk</code>目录下面<code>_config.yml</code>文件找到 gitalk配置，配置如下</p>\n<pre><code class=\"yml\">gitalk:\n  on: true\n  owner: gumihoy\n  admin: gumihoy\n  repo: gumihoy.github.io\n  client_id: acedb7865ff08426fa73\n  client_secret: f80c2b21236d7eb803d6069c7424de26d957e1bf\n</code></pre>\n<p><code>client_id</code>、<code>client_secret</code> 可以在Github创建OAuth Apps获取，地址：<a href=\"https://github.com/settings/developers\">https://github.com/settings/developers</a>\n<img src=\"1542037823098.jpg\" alt=\"OAuth Apps\"></p>\n<p><img src=\"1542074055382.jpg\" alt=\"OAuth Apps配置\"></p>\n<p>用自己的 <code>client_id</code>、<code>client_secret</code> 替换</p>\n<h2 id=\"Hexo-使用\"><a href=\"#Hexo-使用\" class=\"headerlink\" title=\"Hexo 使用\"></a>Hexo 使用</h2><br/>\n### 创建一个文章\n\n<pre><code class=\"bash\">$ hexo new xx\n</code></pre>\n<p>上面命令会在 <code>source/_posts</code>目录下面创建 <code>xx.md</code>一个文件，打开<code>xx.md</code>可以写文章了</p>\n<br/>\n### 文章插入图片\n在 `Gumihoy.github.io` 目录下 `_config.xml`文件 配置\n``` yml\n# 图片\npost_asset_folder: true\n```\n\n<p>按照上面命令创建一个文章，\b会同时生成一个同样名字的目录，\n把文章图片copy到目录中，再在文章引用，如下\n<code>目录下图片文件：1542074055382.jpg；引用：![OAuth Apps配置](1542074055382.jpg)</code></p>\n<br/>\n### 文章摘要设置\n\n<p>在文章插入 <code>&lt;!-- more --&gt;</code> ，<code>&lt;!-- more --&gt;</code>之前的内容就是摘要</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://hexo.io/zh-cn/docs/\">Hexo官方文档</a></p>"},{"title":"Homebrew","date":"2012-07-15T01:00:00.000Z","_content":"\n> 摘要：记录汇总Homebrew，方便后续使用查阅\n\nHomebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。\n\n官网：https://brew.sh/index_zh-cn\n\n---\n\n## 介绍\n`Homebrew`以Ruby语言写成，针对于Mac OS X操作系统自带Ruby的版本。默认安装在`/usr/local`，由一个核心git版本库构成，以使用户能更新Homebrew。\n包管理器使用一种称为“公式”（formula）的DSL脚本来管理依赖、下载源代码及配置和编译软件，从源代码中构建软件。\n\n`Homebrew` 会将软件包安装到独立目录，并将其文件软链接至`/usr/local`\n```bash\ncd /usr/local\nfind Cellar\n```\n\n## 安装\n- 查看是否已经安装\n```bash\nbrew -v\n```\n\n- 安装(推荐)\n```bash\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```\n\n## 命令\n- 帮助命令\n```bash\nbrew -h\n```\n\n- 搜索指定的软件\n```bash\nbrew search <formula>\n```\n\n- 安装指定的软件\n```bash\nbrew install <formula>\n```\n\n- 卸载指定的软件\n```bash\nbrew uninstall <formula>\n```\n\n- 更新指定的软件\n```bash\nbrew upgrade <formula>\n```\n\n- 展示brew安装的所有软件\n```bash\nbrew list\n```\n\n- 展示brew信息\n```bash\nbrew info\n```\n\n- 检测过时软件\n```bash\nbrew outdated\n```\n\n## 软件推荐\n- Git\n```bash\n# 检查是否安装\ngit --version\n# 安装\nbrew install git\n```\n\n- wget\n```bash\n# 检查是否安装\nwget --version\n# 安装\nbrew install wget\n```\n\n- 目录树形结构\n```bash\n# 检查是否安装\ntree --version\n# 安装\nbrew install tree\n# 展示目录结构 -N 解决中文乱码\ntree -N\n```\n\n---\n\n## 参考\n- brew文档：https://docs.brew.sh/","source":"_posts/Homebrew.md","raw":"---\ntitle: Homebrew\ndate: 2012-07-15 09:00:00\ncategories: \n    - [Mac]\n    - [Homebrew]\ntags:\n    - Mac\n    - Homebrew\n---\n\n> 摘要：记录汇总Homebrew，方便后续使用查阅\n\nHomebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。\n\n官网：https://brew.sh/index_zh-cn\n\n---\n\n## 介绍\n`Homebrew`以Ruby语言写成，针对于Mac OS X操作系统自带Ruby的版本。默认安装在`/usr/local`，由一个核心git版本库构成，以使用户能更新Homebrew。\n包管理器使用一种称为“公式”（formula）的DSL脚本来管理依赖、下载源代码及配置和编译软件，从源代码中构建软件。\n\n`Homebrew` 会将软件包安装到独立目录，并将其文件软链接至`/usr/local`\n```bash\ncd /usr/local\nfind Cellar\n```\n\n## 安装\n- 查看是否已经安装\n```bash\nbrew -v\n```\n\n- 安装(推荐)\n```bash\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```\n\n## 命令\n- 帮助命令\n```bash\nbrew -h\n```\n\n- 搜索指定的软件\n```bash\nbrew search <formula>\n```\n\n- 安装指定的软件\n```bash\nbrew install <formula>\n```\n\n- 卸载指定的软件\n```bash\nbrew uninstall <formula>\n```\n\n- 更新指定的软件\n```bash\nbrew upgrade <formula>\n```\n\n- 展示brew安装的所有软件\n```bash\nbrew list\n```\n\n- 展示brew信息\n```bash\nbrew info\n```\n\n- 检测过时软件\n```bash\nbrew outdated\n```\n\n## 软件推荐\n- Git\n```bash\n# 检查是否安装\ngit --version\n# 安装\nbrew install git\n```\n\n- wget\n```bash\n# 检查是否安装\nwget --version\n# 安装\nbrew install wget\n```\n\n- 目录树形结构\n```bash\n# 检查是否安装\ntree --version\n# 安装\nbrew install tree\n# 展示目录结构 -N 解决中文乱码\ntree -N\n```\n\n---\n\n## 参考\n- brew文档：https://docs.brew.sh/","slug":"Homebrew","published":1,"updated":"2021-07-16T08:21:23.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswe004yr5p7bs70703a","content":"<blockquote>\n<p>摘要：记录汇总Homebrew，方便后续使用查阅</p>\n</blockquote>\n<p>Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。</p>\n<p>官网：<a href=\"https://brew.sh/index_zh-cn\">https://brew.sh/index_zh-cn</a></p>\n<hr>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p><code>Homebrew</code>以Ruby语言写成，针对于Mac OS X操作系统自带Ruby的版本。默认安装在<code>/usr/local</code>，由一个核心git版本库构成，以使用户能更新Homebrew。\n包管理器使用一种称为“公式”（formula）的DSL脚本来管理依赖、下载源代码及配置和编译软件，从源代码中构建软件。</p>\n<p><code>Homebrew</code> 会将软件包安装到独立目录，并将其文件软链接至<code>/usr/local</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cd</span> /usr/local\n<span class=\"token function\">find</span> Cellar\n</code></pre>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><ul>\n<li><p>查看是否已经安装</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew -v\n</code></pre>\n</li>\n<li><p>安装(推荐)</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">/usr/bin/ruby -e <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span>curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install<span class=\"token variable\">)</span></span>\"</span>\n</code></pre>\n</li>\n</ul>\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><ul>\n<li><p>帮助命令</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew -h\n</code></pre>\n</li>\n<li><p>搜索指定的软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew search <span class=\"token operator\">&lt;</span>formula<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>安装指定的软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> <span class=\"token operator\">&lt;</span>formula<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>卸载指定的软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew uninstall <span class=\"token operator\">&lt;</span>formula<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>更新指定的软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew upgrade <span class=\"token operator\">&lt;</span>formula<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>展示brew安装的所有软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew list\n</code></pre>\n</li>\n<li><p>展示brew信息</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew info\n</code></pre>\n</li>\n<li><p>检测过时软件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew outdated\n</code></pre>\n</li>\n</ul>\n<h2 id=\"软件推荐\"><a href=\"#软件推荐\" class=\"headerlink\" title=\"软件推荐\"></a>软件推荐</h2><ul>\n<li><p>Git</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 检查是否安装</span>\n<span class=\"token function\">git</span> --version\n<span class=\"token comment\" spellcheck=\"true\"># 安装</span>\nbrew <span class=\"token function\">install</span> <span class=\"token function\">git</span>\n</code></pre>\n</li>\n<li><p>wget</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 检查是否安装</span>\n<span class=\"token function\">wget</span> --version\n<span class=\"token comment\" spellcheck=\"true\"># 安装</span>\nbrew <span class=\"token function\">install</span> <span class=\"token function\">wget</span>\n</code></pre>\n</li>\n<li><p>目录树形结构</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 检查是否安装</span>\ntree --version\n<span class=\"token comment\" spellcheck=\"true\"># 安装</span>\nbrew <span class=\"token function\">install</span> tree\n<span class=\"token comment\" spellcheck=\"true\"># 展示目录结构 -N 解决中文乱码</span>\ntree -N\n</code></pre>\n</li>\n</ul>\n<hr>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>brew文档：<a href=\"https://docs.brew.sh/\">https://docs.brew.sh/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：记录汇总Homebrew，方便后续使用查阅</p>\n</blockquote>\n<p>Homebrew是一款Mac OS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能。简单的一条指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。</p>\n<p>官网：<a href=\"https://brew.sh/index_zh-cn\">https://brew.sh/index_zh-cn</a></p>\n<hr>\n<h2 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h2><p><code>Homebrew</code>以Ruby语言写成，针对于Mac OS X操作系统自带Ruby的版本。默认安装在<code>/usr/local</code>，由一个核心git版本库构成，以使用户能更新Homebrew。\n包管理器使用一种称为“公式”（formula）的DSL脚本来管理依赖、下载源代码及配置和编译软件，从源代码中构建软件。</p>\n<p><code>Homebrew</code> 会将软件包安装到独立目录，并将其文件软链接至<code>/usr/local</code></p>\n<pre><code class=\"bash\">cd /usr/local\nfind Cellar\n</code></pre>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><ul>\n<li><p>查看是否已经安装</p>\n<pre><code class=\"bash\">brew -v\n</code></pre>\n</li>\n<li><p>安装(推荐)</p>\n<pre><code class=\"bash\">/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;\n</code></pre>\n</li>\n</ul>\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><ul>\n<li><p>帮助命令</p>\n<pre><code class=\"bash\">brew -h\n</code></pre>\n</li>\n<li><p>搜索指定的软件</p>\n<pre><code class=\"bash\">brew search &lt;formula&gt;\n</code></pre>\n</li>\n<li><p>安装指定的软件</p>\n<pre><code class=\"bash\">brew install &lt;formula&gt;\n</code></pre>\n</li>\n<li><p>卸载指定的软件</p>\n<pre><code class=\"bash\">brew uninstall &lt;formula&gt;\n</code></pre>\n</li>\n<li><p>更新指定的软件</p>\n<pre><code class=\"bash\">brew upgrade &lt;formula&gt;\n</code></pre>\n</li>\n<li><p>展示brew安装的所有软件</p>\n<pre><code class=\"bash\">brew list\n</code></pre>\n</li>\n<li><p>展示brew信息</p>\n<pre><code class=\"bash\">brew info\n</code></pre>\n</li>\n<li><p>检测过时软件</p>\n<pre><code class=\"bash\">brew outdated\n</code></pre>\n</li>\n</ul>\n<h2 id=\"软件推荐\"><a href=\"#软件推荐\" class=\"headerlink\" title=\"软件推荐\"></a>软件推荐</h2><ul>\n<li><p>Git</p>\n<pre><code class=\"bash\"># 检查是否安装\ngit --version\n# 安装\nbrew install git\n</code></pre>\n</li>\n<li><p>wget</p>\n<pre><code class=\"bash\"># 检查是否安装\nwget --version\n# 安装\nbrew install wget\n</code></pre>\n</li>\n<li><p>目录树形结构</p>\n<pre><code class=\"bash\"># 检查是否安装\ntree --version\n# 安装\nbrew install tree\n# 展示目录结构 -N 解决中文乱码\ntree -N\n</code></pre>\n</li>\n</ul>\n<hr>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>brew文档：<a href=\"https://docs.brew.sh/\">https://docs.brew.sh/</a></li>\n</ul>\n"},{"title":"ID3算法","date":"2018-11-10T02:01:01.000Z","_content":"\n\n\n\n\n<!-- more -->\n\n\n--- \n参考\n\n[wikipedia-ID3算法](https://en.wikipedia.org/wiki/ID3_algorithm)","source":"_posts/ID3算法.md","raw":"---\ntitle: ID3算法\ndate: 2018-11-10 10:01:01\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n    - 决策树\n---\n\n\n\n\n\n<!-- more -->\n\n\n--- \n参考\n\n[wikipedia-ID3算法](https://en.wikipedia.org/wiki/ID3_algorithm)","slug":"ID3算法","published":1,"updated":"2021-06-30T02:33:24.699Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswf0050r5p7hqtr45w2","content":"<span id=\"more\"></span>\n\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/ID3_algorithm\">wikipedia-ID3算法</a></p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/ID3_algorithm\">wikipedia-ID3算法</a></p>"},{"title":"Java Agent详解","date":"2019-08-13T03:29:09.000Z","_content":"\n\n`Java Agent`就是利用 `Java5` 提供的 `Instrumentation` 机制。\n在 `Java SE 5` 中，`Instrument` 要求与应用一块启动（设置参数启动 `-javaagent:agent.jar` ）\n在 `Java SE 6` 里面，`Instrumentation` 被赋予了更强大的功能：启动后的 instrument、本地代码（native code）instrument，以及动态改变 classpath 等等.\n\n\n`Java Agent`在不侵入代码字节码注入的方式对应用功能的增强和修改。\n\n\n<!-- more -->\n\n\n## 代码实现步骤\n\n### 1、代码\n\n**一、以vm参数的方式载入，在Java程序的main方法执行之前执行（JDK1.5和以上）**\n\n```java\n// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void premain(String arguments, Instrumentation instrumentation) {\n}\n\npublic static void premain(String arguments) {\n}\n\n```\n\n\n**二、以Attach的方式载入，在Java程序启动后执行（JDK1.6和以上）**\n\n```java\n// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void agentmain(String arguments, Instrumentation instrumentation) {\n\n}\npublic static void agentmain(String arguments) {\n\n}\n```\n\n\n\n<br/>\n### 2、配置\n#### 打包配置\n`META-INF/MANIFEST.MF`文件必须有以下参数配置\n```java\nManifest-Version: 1.0\n// JDK1.5，必须与应用一块启动\nPremain-Class: com.gumihoy.apm.agent.APMAgent\n// JDK1.6, 可以在应用启动之后再启动\nAgent-Class: com.gumihoy.apm.agent.APMAgent\n// 布尔值（true 或 false，与大小写无关）, 是否能重定义此代理所需的类\nCan-Redefine-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能重转换此代理所需的类\nCan-Retransform-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能设置此代理所需的本机方法前缀\nCan-Set-Native-Method-Prefix: true\n空行\n```\n> 最后一行（空行）必须要有\n\n<br/>\n#### 实现方式\n##### 一、Maven\n\n**方法一：使用插件maven-jar-plugin**\n只有一个包：\n- agent.jar: 包含第三方jar\n\n```xml\n <plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <version>3.1.2</version>\n    <configuration>\n        <archive>\n            <manifest>\n                <addClasspath>true</addClasspath>\n            </manifest>\n            <manifestEntries>\n                <Premain-Class>com.gumihoy.apm.agent.APMAgent</Premain-Class>\n                <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                <Can-Retransform-Classes>true</Can-Retransform-Classes>\n            </manifestEntries>\n        </archive>\n    </configuration>\n</plugin>\n```\n\n**方法二：使用插件maven-shade-plugin**\n两个包：\n- agent.jar: 包含第三方jar\n- original-agent.jar: 不饱和第三方jar，原始包\n\n```xml\n<plugin>\n    <artifactId>maven-shade-plugin</artifactId>\n    <executions>\n        <execution>\n            <phase>package</phase>\n            <goals>\n                <goal>shade</goal>\n            </goals>\n            <configuration>\n                <shadedArtifactAttached>false</shadedArtifactAttached>\n                <createDependencyReducedPom>true</createDependencyReducedPom>\n                <createSourcesJar>true</createSourcesJar>\n                <shadeSourcesContent>true</shadeSourcesContent>\n                <transformers>\n                    <transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\">\n                        <manifestEntries>\n                            <Premain-Class>${premain.class}</Premain-Class>\n                            <Can-Redefine-Classes>${can.redefine.classes}</Can-Redefine-Classes>\n                            <Can-Retransform-Classes>${can.retransform.classes}</Can-Retransform-Classes>\n                        </manifestEntries>\n                    </transformer>\n                </transformers>\n            </configuration>\n        </execution>\n    </executions>\n</plugin>\n```\n\n**方法三：使用插件maven-assembly-plugin**\n两个包：\n- agent.jar: 不饱和第三方jar，原始包\n- agent-jar-with-dependencies.jar: 包含第三方jar\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <version>2.4.1</version>\n    <configuration>\n        <!-- get all project dependencies -->\n        <descriptorRefs>\n            <descriptorRef>jar-with-dependencies</descriptorRef>\n        </descriptorRefs>\n        <!-- MainClass in mainfest make a executable jar -->\n        <archive> \n            <manifest>\n                <addClasspath>true</addClasspath>\n            </manifest>\n            <manifestEntries>\n                <Premain-Class>com.gumihoy.apm.agent.APMAgent</Premain-Class>\n                <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                <Can-Retransform-Classes>true</Can-Retransform-Classes>\n            </manifestEntries>\n                    \n        </archive>\n    </configuration>\n    <executions>\n        <execution>\n            <id>make-assembly</id>\n            <!-- bind to the packaging phase -->\n            <phase>package</phase>\n            <goals>\n                <goal>single</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n##### 二、Gradle\n```gradle\njar {\n    manifest {\n        attributes(\n                'Premain-Class': 'xx.Agent',\n                'Agent-Class': 'cxx.Agent',\n                'Can-Redefine-Classes': 'true',\n                'Can-Retransform-Classes': 'true',\n                'Can-Set-Native-Method-Prefix': 'true',\n                'Implementation-Title': \"CallSpy\",\n                'Implementation-Version': rootProject.version,\n                'Built-By': System.getProperty('user.name'),\n                'Built-Date': new Date(),\n                'Built-JDK': System.getProperty('java.version')\n        )\n    }\n}\n\n```\n\n\n<br/>\n### 3、启动\n**一、vm参数配置启动**\n```java\n-javaagent:agent.jar[=arguments]\n```\n> arguments: 参数，String 类型。多个参数后端必须处理（如a=1,b=2 or a=1;b=2）\n\n\n<br/>\n## 框架\n\n | baseline | Byte Buddy | cglib | Javassist | Java proxy\n-|----------|------------|-------|-----------|-----------\ntrivial class creation | 0.003 (0.001) | 142.772 (1.390) | 515.174 (26.753) | 193.733 (4.430) | 70.712 (0.645)\ninterface implementation | 0.004 (0.001) | 1'126.364 (10.328) | 960.527 (11.788) | 1'070.766 (59.865) | 1'060.766 (12.231)\nstub method invocation | 0.002 (0.001) | 0.002 (0.001) | 0.003 (0.001) | 0.011 (0.001) | 0.008 (0.001)\nclass extension | 0.004 (0.001) | 885.983 5'408.329 | (7.901) (52.437) | 1'632.730 (52.737) | 683.478 (6.735) | –\nsuper method invocation | 0.004 (0.001) | 0.004 <br/> 0.004 | (0.001) <br/> (0.001) | 0.021 (0.001) | 0.025 (0.001) | –\n\n\n> - javassist更偏向底层，比较难于使用并且在动态组合字符串以实现更复杂的逻辑时很容易出错\n> - cglib现在维护的则相当慢了，基本处于无人维护的阶段了，而这些缺点ByteBuddy都没有\n> - ByteBuddy性能相对来说在三者中是最优的\n\n\n### 使用 Byte Buddy 实现 JavaAgent\n\n#### 一、导入`jar`\n```xml\n<!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy -->\n<dependency>\n    <groupId>net.bytebuddy</groupId>\n    <artifactId>byte-buddy</artifactId>\n    <version>1.10.0</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy-agent -->\n<dependency>\n    <groupId>net.bytebuddy</groupId>\n    <artifactId>byte-buddy-agent</artifactId>\n    <version>1.10.0</version>\n</dependency>\n```\n\n#### 二、`Agent`代码\n```java\npublic class APMAgent {\n\n\n    /**\n     * http://bytebuddy.net/#/tutorialTypeValidation\n     *\n     * @param arguments\n     * @param instrumentation\n     */\n    public static void premain(String arguments, Instrumentation instrumentation) {\n        System.out.println(\"xx\");\n//        ByteBuddy buddy = new ByteBuddy().with(TypeValidation.of(false)).with(ClassFileVersion.JAVA_V8);\n        new AgentBuilder.Default()\n                .type(ElementMatchers.nameStartsWith(\"com.gumihoy.apm.agent.demo\"))\n                .transform(new AgentTransformer())\n                .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION)\n                .with(new AgentListener())\n                .installOn(instrumentation);\n    }\n\n    public static void agentmain(String arguments, Instrumentation instrumentation) {\n\n    }\n\n    protected static ElementMatcher<? super TypeDescription> buildIgnoreMatcher() {\n        return ElementMatchers.nameStartsWith(\"net.bytebuddy.*\");\n    }\n\n\n    static class AgentTransformer implements AgentBuilder.Transformer {\n        @Override\n        public DynamicType.Builder<?> transform(DynamicType.Builder<?> builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) {\n            return builder\n                    .method(ElementMatchers.any()) // 拦截任意方法\n                    .intercept(MethodDelegation.to(MethodIntercept.class)); // 委托\n        }\n    }\n\n\n    static class AgentListener implements AgentBuilder.Listener {\n        @Override\n        public void onDiscovery(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n\n        @Override\n        public void onTransformation(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded, DynamicType dynamicType) {\n\n        }\n\n        @Override\n        public void onIgnored(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n\n        @Override\n        public void onError(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded, Throwable throwable) {\n\n        }\n\n        @Override\n        public void onComplete(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n    }\n\n}\n\n\npublic class MethodIntercept {\n\n    @RuntimeType\n    public static Object intercept(@Origin Method method,\n                                   @SuperCall Callable<?> callable) throws Throwable {\n        long start = System.currentTimeMillis();\n        try {\n            // 原有函数执行\n            return callable.call();\n        } finally {\n            System.out.println(method + \": took \" + (System.currentTimeMillis() - start) + \"ms\");\n        }\n    }\n}\n```\n\n#### 三、应用代码\n```\npackage com.gumihoy.apm.agent.demo;\n\npublic class AgentTest {\n\n    public void fun1() throws Exception {\n        System.out.println(\"this is fun 1.\");\n        Thread.sleep(500);\n    }\n\n    private void fun2() throws Exception {\n        System.out.println(\"this is fun 2.\");\n        Thread.sleep(500);\n    }\n\n    public static void main(String[] args) throws Exception {\n        AgentTest test = new AgentTest();\n        test.fun1();\n        test.fun2();\n    }\n}\n```\n\n#### 四、打包\n[pom.xml配置](#实现方式)\n```\nmvn clean package\n```\n\n#### 五、启动\n![](1565784207465.jpg)\n\n\n#### 六、运行结果\n![](1565786297241.jpg)\n\n\n\n\n\n如何自定义类加载器，避免污染目前进程\n如何实现字节码的修改\n如何实现字节码的多次修改\n如何恢复被修改过的字节码\n如何卸载Java Agent的类\n卸载自定义类加载器遇到的一些坑\n\n---\n参考\n\n[Instrumentation介绍](https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html)","source":"_posts/Java-Agent详解.md","raw":"---\ntitle: Java Agent详解\ndate: 2019-08-13 11:29:09\ncategories: \n    - Java\n    - JavaAgent\ntags:\n    - Java\n    - JavaAgent\n---\n\n\n`Java Agent`就是利用 `Java5` 提供的 `Instrumentation` 机制。\n在 `Java SE 5` 中，`Instrument` 要求与应用一块启动（设置参数启动 `-javaagent:agent.jar` ）\n在 `Java SE 6` 里面，`Instrumentation` 被赋予了更强大的功能：启动后的 instrument、本地代码（native code）instrument，以及动态改变 classpath 等等.\n\n\n`Java Agent`在不侵入代码字节码注入的方式对应用功能的增强和修改。\n\n\n<!-- more -->\n\n\n## 代码实现步骤\n\n### 1、代码\n\n**一、以vm参数的方式载入，在Java程序的main方法执行之前执行（JDK1.5和以上）**\n\n```java\n// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void premain(String arguments, Instrumentation instrumentation) {\n}\n\npublic static void premain(String arguments) {\n}\n\n```\n\n\n**二、以Attach的方式载入，在Java程序启动后执行（JDK1.6和以上）**\n\n```java\n// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void agentmain(String arguments, Instrumentation instrumentation) {\n\n}\npublic static void agentmain(String arguments) {\n\n}\n```\n\n\n\n<br/>\n### 2、配置\n#### 打包配置\n`META-INF/MANIFEST.MF`文件必须有以下参数配置\n```java\nManifest-Version: 1.0\n// JDK1.5，必须与应用一块启动\nPremain-Class: com.gumihoy.apm.agent.APMAgent\n// JDK1.6, 可以在应用启动之后再启动\nAgent-Class: com.gumihoy.apm.agent.APMAgent\n// 布尔值（true 或 false，与大小写无关）, 是否能重定义此代理所需的类\nCan-Redefine-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能重转换此代理所需的类\nCan-Retransform-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能设置此代理所需的本机方法前缀\nCan-Set-Native-Method-Prefix: true\n空行\n```\n> 最后一行（空行）必须要有\n\n<br/>\n#### 实现方式\n##### 一、Maven\n\n**方法一：使用插件maven-jar-plugin**\n只有一个包：\n- agent.jar: 包含第三方jar\n\n```xml\n <plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-jar-plugin</artifactId>\n    <version>3.1.2</version>\n    <configuration>\n        <archive>\n            <manifest>\n                <addClasspath>true</addClasspath>\n            </manifest>\n            <manifestEntries>\n                <Premain-Class>com.gumihoy.apm.agent.APMAgent</Premain-Class>\n                <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                <Can-Retransform-Classes>true</Can-Retransform-Classes>\n            </manifestEntries>\n        </archive>\n    </configuration>\n</plugin>\n```\n\n**方法二：使用插件maven-shade-plugin**\n两个包：\n- agent.jar: 包含第三方jar\n- original-agent.jar: 不饱和第三方jar，原始包\n\n```xml\n<plugin>\n    <artifactId>maven-shade-plugin</artifactId>\n    <executions>\n        <execution>\n            <phase>package</phase>\n            <goals>\n                <goal>shade</goal>\n            </goals>\n            <configuration>\n                <shadedArtifactAttached>false</shadedArtifactAttached>\n                <createDependencyReducedPom>true</createDependencyReducedPom>\n                <createSourcesJar>true</createSourcesJar>\n                <shadeSourcesContent>true</shadeSourcesContent>\n                <transformers>\n                    <transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\">\n                        <manifestEntries>\n                            <Premain-Class>${premain.class}</Premain-Class>\n                            <Can-Redefine-Classes>${can.redefine.classes}</Can-Redefine-Classes>\n                            <Can-Retransform-Classes>${can.retransform.classes}</Can-Retransform-Classes>\n                        </manifestEntries>\n                    </transformer>\n                </transformers>\n            </configuration>\n        </execution>\n    </executions>\n</plugin>\n```\n\n**方法三：使用插件maven-assembly-plugin**\n两个包：\n- agent.jar: 不饱和第三方jar，原始包\n- agent-jar-with-dependencies.jar: 包含第三方jar\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <version>2.4.1</version>\n    <configuration>\n        <!-- get all project dependencies -->\n        <descriptorRefs>\n            <descriptorRef>jar-with-dependencies</descriptorRef>\n        </descriptorRefs>\n        <!-- MainClass in mainfest make a executable jar -->\n        <archive> \n            <manifest>\n                <addClasspath>true</addClasspath>\n            </manifest>\n            <manifestEntries>\n                <Premain-Class>com.gumihoy.apm.agent.APMAgent</Premain-Class>\n                <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                <Can-Retransform-Classes>true</Can-Retransform-Classes>\n            </manifestEntries>\n                    \n        </archive>\n    </configuration>\n    <executions>\n        <execution>\n            <id>make-assembly</id>\n            <!-- bind to the packaging phase -->\n            <phase>package</phase>\n            <goals>\n                <goal>single</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n##### 二、Gradle\n```gradle\njar {\n    manifest {\n        attributes(\n                'Premain-Class': 'xx.Agent',\n                'Agent-Class': 'cxx.Agent',\n                'Can-Redefine-Classes': 'true',\n                'Can-Retransform-Classes': 'true',\n                'Can-Set-Native-Method-Prefix': 'true',\n                'Implementation-Title': \"CallSpy\",\n                'Implementation-Version': rootProject.version,\n                'Built-By': System.getProperty('user.name'),\n                'Built-Date': new Date(),\n                'Built-JDK': System.getProperty('java.version')\n        )\n    }\n}\n\n```\n\n\n<br/>\n### 3、启动\n**一、vm参数配置启动**\n```java\n-javaagent:agent.jar[=arguments]\n```\n> arguments: 参数，String 类型。多个参数后端必须处理（如a=1,b=2 or a=1;b=2）\n\n\n<br/>\n## 框架\n\n | baseline | Byte Buddy | cglib | Javassist | Java proxy\n-|----------|------------|-------|-----------|-----------\ntrivial class creation | 0.003 (0.001) | 142.772 (1.390) | 515.174 (26.753) | 193.733 (4.430) | 70.712 (0.645)\ninterface implementation | 0.004 (0.001) | 1'126.364 (10.328) | 960.527 (11.788) | 1'070.766 (59.865) | 1'060.766 (12.231)\nstub method invocation | 0.002 (0.001) | 0.002 (0.001) | 0.003 (0.001) | 0.011 (0.001) | 0.008 (0.001)\nclass extension | 0.004 (0.001) | 885.983 5'408.329 | (7.901) (52.437) | 1'632.730 (52.737) | 683.478 (6.735) | –\nsuper method invocation | 0.004 (0.001) | 0.004 <br/> 0.004 | (0.001) <br/> (0.001) | 0.021 (0.001) | 0.025 (0.001) | –\n\n\n> - javassist更偏向底层，比较难于使用并且在动态组合字符串以实现更复杂的逻辑时很容易出错\n> - cglib现在维护的则相当慢了，基本处于无人维护的阶段了，而这些缺点ByteBuddy都没有\n> - ByteBuddy性能相对来说在三者中是最优的\n\n\n### 使用 Byte Buddy 实现 JavaAgent\n\n#### 一、导入`jar`\n```xml\n<!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy -->\n<dependency>\n    <groupId>net.bytebuddy</groupId>\n    <artifactId>byte-buddy</artifactId>\n    <version>1.10.0</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy-agent -->\n<dependency>\n    <groupId>net.bytebuddy</groupId>\n    <artifactId>byte-buddy-agent</artifactId>\n    <version>1.10.0</version>\n</dependency>\n```\n\n#### 二、`Agent`代码\n```java\npublic class APMAgent {\n\n\n    /**\n     * http://bytebuddy.net/#/tutorialTypeValidation\n     *\n     * @param arguments\n     * @param instrumentation\n     */\n    public static void premain(String arguments, Instrumentation instrumentation) {\n        System.out.println(\"xx\");\n//        ByteBuddy buddy = new ByteBuddy().with(TypeValidation.of(false)).with(ClassFileVersion.JAVA_V8);\n        new AgentBuilder.Default()\n                .type(ElementMatchers.nameStartsWith(\"com.gumihoy.apm.agent.demo\"))\n                .transform(new AgentTransformer())\n                .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION)\n                .with(new AgentListener())\n                .installOn(instrumentation);\n    }\n\n    public static void agentmain(String arguments, Instrumentation instrumentation) {\n\n    }\n\n    protected static ElementMatcher<? super TypeDescription> buildIgnoreMatcher() {\n        return ElementMatchers.nameStartsWith(\"net.bytebuddy.*\");\n    }\n\n\n    static class AgentTransformer implements AgentBuilder.Transformer {\n        @Override\n        public DynamicType.Builder<?> transform(DynamicType.Builder<?> builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) {\n            return builder\n                    .method(ElementMatchers.any()) // 拦截任意方法\n                    .intercept(MethodDelegation.to(MethodIntercept.class)); // 委托\n        }\n    }\n\n\n    static class AgentListener implements AgentBuilder.Listener {\n        @Override\n        public void onDiscovery(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n\n        @Override\n        public void onTransformation(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded, DynamicType dynamicType) {\n\n        }\n\n        @Override\n        public void onIgnored(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n\n        @Override\n        public void onError(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded, Throwable throwable) {\n\n        }\n\n        @Override\n        public void onComplete(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) {\n\n        }\n    }\n\n}\n\n\npublic class MethodIntercept {\n\n    @RuntimeType\n    public static Object intercept(@Origin Method method,\n                                   @SuperCall Callable<?> callable) throws Throwable {\n        long start = System.currentTimeMillis();\n        try {\n            // 原有函数执行\n            return callable.call();\n        } finally {\n            System.out.println(method + \": took \" + (System.currentTimeMillis() - start) + \"ms\");\n        }\n    }\n}\n```\n\n#### 三、应用代码\n```\npackage com.gumihoy.apm.agent.demo;\n\npublic class AgentTest {\n\n    public void fun1() throws Exception {\n        System.out.println(\"this is fun 1.\");\n        Thread.sleep(500);\n    }\n\n    private void fun2() throws Exception {\n        System.out.println(\"this is fun 2.\");\n        Thread.sleep(500);\n    }\n\n    public static void main(String[] args) throws Exception {\n        AgentTest test = new AgentTest();\n        test.fun1();\n        test.fun2();\n    }\n}\n```\n\n#### 四、打包\n[pom.xml配置](#实现方式)\n```\nmvn clean package\n```\n\n#### 五、启动\n![](1565784207465.jpg)\n\n\n#### 六、运行结果\n![](1565786297241.jpg)\n\n\n\n\n\n如何自定义类加载器，避免污染目前进程\n如何实现字节码的修改\n如何实现字节码的多次修改\n如何恢复被修改过的字节码\n如何卸载Java Agent的类\n卸载自定义类加载器遇到的一些坑\n\n---\n参考\n\n[Instrumentation介绍](https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html)","slug":"Java-Agent详解","published":1,"updated":"2021-06-30T02:33:24.699Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswh0055r5p7346o5ppb","content":"<p><code>Java Agent</code>就是利用 <code>Java5</code> 提供的 <code>Instrumentation</code> 机制。\n在 <code>Java SE 5</code> 中，<code>Instrument</code> 要求与应用一块启动（设置参数启动 <code>-javaagent:agent.jar</code> ）\n在 <code>Java SE 6</code> 里面，<code>Instrumentation</code> 被赋予了更强大的功能：启动后的 instrument、本地代码（native code）instrument，以及动态改变 classpath 等等.</p>\n<p><code>Java Agent</code>在不侵入代码字节码注入的方式对应用功能的增强和修改。</p>\n<span id=\"more\"></span>\n\n\n<h2 id=\"代码实现步骤\"><a href=\"#代码实现步骤\" class=\"headerlink\" title=\"代码实现步骤\"></a>代码实现步骤</h2><h3 id=\"1、代码\"><a href=\"#1、代码\" class=\"headerlink\" title=\"1、代码\"></a>1、代码</h3><p><strong>一、以vm参数的方式载入，在Java程序的main方法执行之前执行（JDK1.5和以上）</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 如果同时存在下面两个方法，第一个方法先执行</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">premain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">,</span> Instrumentation instrumentation<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">premain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p><strong>二、以Attach的方式载入，在Java程序启动后执行（JDK1.6和以上）</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 如果同时存在下面两个方法，第一个方法先执行</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">agentmain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">,</span> Instrumentation instrumentation<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">agentmain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<br>\n### 2、配置\n#### 打包配置\n`META-INF/MANIFEST.MF`文件必须有以下参数配置\n```java\nManifest-Version: 1.0\n// JDK1.5，必须与应用一块启动\nPremain-Class: com.gumihoy.apm.agent.APMAgent\n// JDK1.6, 可以在应用启动之后再启动\nAgent-Class: com.gumihoy.apm.agent.APMAgent\n// 布尔值（true 或 false，与大小写无关）, 是否能重定义此代理所需的类\nCan-Redefine-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能重转换此代理所需的类\nCan-Retransform-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能设置此代理所需的本机方法前缀\nCan-Set-Native-Method-Prefix: true\n空行\n```\n&gt; 最后一行（空行）必须要有\n\n<br>\n#### 实现方式\n##### 一、Maven\n\n<p><strong>方法一：使用插件maven-jar-plugin</strong>\n只有一个包：</p>\n<ul>\n<li>agent.jar: 包含第三方jar</li>\n</ul>\n<pre class=\" language-xml\"><code class=\"language-xml\"> <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>plugin</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.maven.plugins<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>maven-jar-plugin<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>3.1.2<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>archive</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifest</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>addClasspath</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>addClasspath</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifest</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Premain-Class</span><span class=\"token punctuation\">></span></span>com.gumihoy.apm.agent.APMAgent<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Premain-Class</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>archive</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>plugin</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<p><strong>方法二：使用插件maven-shade-plugin</strong>\n两个包：</p>\n<ul>\n<li>agent.jar: 包含第三方jar</li>\n<li>original-agent.jar: 不饱和第三方jar，原始包</li>\n</ul>\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>plugin</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>maven-shade-plugin<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>executions</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>execution</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>phase</span><span class=\"token punctuation\">></span></span>package<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>phase</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>goals</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>goal</span><span class=\"token punctuation\">></span></span>shade<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>goal</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>goals</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>shadedArtifactAttached</span><span class=\"token punctuation\">></span></span>false<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>shadedArtifactAttached</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>createDependencyReducedPom</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>createDependencyReducedPom</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>createSourcesJar</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>createSourcesJar</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>shadeSourcesContent</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>shadeSourcesContent</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>transformers</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>transformer</span> <span class=\"token attr-name\">implementation</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>org.apache.maven.plugins.shade.resource.ManifestResourceTransformer<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n                        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Premain-Class</span><span class=\"token punctuation\">></span></span>${premain.class}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Premain-Class</span><span class=\"token punctuation\">></span></span>\n                            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>${can.redefine.classes}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>\n                            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>${can.retransform.classes}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>\n                        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>transformer</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>transformers</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>execution</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>executions</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>plugin</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<p><strong>方法三：使用插件maven-assembly-plugin</strong>\n两个包：</p>\n<ul>\n<li>agent.jar: 不饱和第三方jar，原始包</li>\n<li>agent-jar-with-dependencies.jar: 包含第三方jar</li>\n</ul>\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>plugin</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.maven.plugins<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>maven-assembly-plugin<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>2.4.1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token comment\" spellcheck=\"true\">&lt;!-- get all project dependencies --></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>descriptorRefs</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>descriptorRef</span><span class=\"token punctuation\">></span></span>jar-with-dependencies<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>descriptorRef</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>descriptorRefs</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token comment\" spellcheck=\"true\">&lt;!-- MainClass in mainfest make a executable jar --></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>archive</span><span class=\"token punctuation\">></span></span> \n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifest</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>addClasspath</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>addClasspath</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifest</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Premain-Class</span><span class=\"token punctuation\">></span></span>com.gumihoy.apm.agent.APMAgent<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Premain-Class</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                    \n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>archive</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>executions</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>execution</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>id</span><span class=\"token punctuation\">></span></span>make-assembly<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>id</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token comment\" spellcheck=\"true\">&lt;!-- bind to the packaging phase --></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>phase</span><span class=\"token punctuation\">></span></span>package<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>phase</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>goals</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>goal</span><span class=\"token punctuation\">></span></span>single<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>goal</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>goals</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>execution</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>executions</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>plugin</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<h5 id=\"二、Gradle\"><a href=\"#二、Gradle\" class=\"headerlink\" title=\"二、Gradle\"></a>二、Gradle</h5><pre class=\" language-gradle\"><code class=\"language-gradle\">jar {\n    manifest {\n        attributes(\n                'Premain-Class': 'xx.Agent',\n                'Agent-Class': 'cxx.Agent',\n                'Can-Redefine-Classes': 'true',\n                'Can-Retransform-Classes': 'true',\n                'Can-Set-Native-Method-Prefix': 'true',\n                'Implementation-Title': \"CallSpy\",\n                'Implementation-Version': rootProject.version,\n                'Built-By': System.getProperty('user.name'),\n                'Built-Date': new Date(),\n                'Built-JDK': System.getProperty('java.version')\n        )\n    }\n}\n</code></pre>\n<br>\n### 3、启动\n**一、vm参数配置启动**\n```java\n-javaagent:agent.jar[=arguments]\n```\n&gt; arguments: 参数，String 类型。多个参数后端必须处理（如a=1,b=2 or a=1;b=2）\n\n\n<br>\n## 框架\n\n<p> | baseline | Byte Buddy | cglib | Javassist | Java proxy\n-|———-|————|——-|———–|———–\ntrivial class creation | 0.003 (0.001) | 142.772 (1.390) | 515.174 (26.753) | 193.733 (4.430) | 70.712 (0.645)\ninterface implementation | 0.004 (0.001) | 1’126.364 (10.328) | 960.527 (11.788) | 1’070.766 (59.865) | 1’060.766 (12.231)\nstub method invocation | 0.002 (0.001) | 0.002 (0.001) | 0.003 (0.001) | 0.011 (0.001) | 0.008 (0.001)\nclass extension | 0.004 (0.001) | 885.983 5’408.329 | (7.901) (52.437) | 1’632.730 (52.737) | 683.478 (6.735) | –\nsuper method invocation | 0.004 (0.001) | 0.004 <br> 0.004 | (0.001) <br> (0.001) | 0.021 (0.001) | 0.025 (0.001) | –</p>\n<blockquote>\n<ul>\n<li>javassist更偏向底层，比较难于使用并且在动态组合字符串以实现更复杂的逻辑时很容易出错</li>\n<li>cglib现在维护的则相当慢了，基本处于无人维护的阶段了，而这些缺点ByteBuddy都没有</li>\n<li>ByteBuddy性能相对来说在三者中是最优的</li>\n</ul>\n</blockquote>\n<h3 id=\"使用-Byte-Buddy-实现-JavaAgent\"><a href=\"#使用-Byte-Buddy-实现-JavaAgent\" class=\"headerlink\" title=\"使用 Byte Buddy 实现 JavaAgent\"></a>使用 Byte Buddy 实现 JavaAgent</h3><h4 id=\"一、导入jar\"><a href=\"#一、导入jar\" class=\"headerlink\" title=\"一、导入jar\"></a>一、导入<code>jar</code></h4><pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>net.bytebuddy<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>byte-buddy<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.10.0<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy-agent --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>net.bytebuddy<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>byte-buddy-agent<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.10.0<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<h4 id=\"二、Agent代码\"><a href=\"#二、Agent代码\" class=\"headerlink\" title=\"二、Agent代码\"></a>二、<code>Agent</code>代码</h4><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">APMAgent</span> <span class=\"token punctuation\">{</span>\n\n\n    <span class=\"token comment\" spellcheck=\"true\">/**\n     * http://bytebuddy.net/#/tutorialTypeValidation\n     *\n     * @param arguments\n     * @param instrumentation\n     */</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">premain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">,</span> Instrumentation instrumentation<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"xx\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\" spellcheck=\"true\">//        ByteBuddy buddy = new ByteBuddy().with(TypeValidation.of(false)).with(ClassFileVersion.JAVA_V8);</span>\n        <span class=\"token keyword\">new</span> <span class=\"token class-name\">AgentBuilder<span class=\"token punctuation\">.</span>Default</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">type</span><span class=\"token punctuation\">(</span>ElementMatchers<span class=\"token punctuation\">.</span><span class=\"token function\">nameStartsWith</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"com.gumihoy.apm.agent.demo\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">transform</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">AgentTransformer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">with</span><span class=\"token punctuation\">(</span>AgentBuilder<span class=\"token punctuation\">.</span>RedefinitionStrategy<span class=\"token punctuation\">.</span>RETRANSFORMATION<span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">with</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">AgentListener</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">installOn</span><span class=\"token punctuation\">(</span>instrumentation<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">agentmain</span><span class=\"token punctuation\">(</span>String arguments<span class=\"token punctuation\">,</span> Instrumentation instrumentation<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">protected</span> <span class=\"token keyword\">static</span> ElementMatcher<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span> <span class=\"token keyword\">super</span> TypeDescription<span class=\"token operator\">></span> <span class=\"token function\">buildIgnoreMatcher</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> ElementMatchers<span class=\"token punctuation\">.</span><span class=\"token function\">nameStartsWith</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"net.bytebuddy.*\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AgentTransformer</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">AgentBuilder<span class=\"token punctuation\">.</span>Transformer</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> DynamicType<span class=\"token punctuation\">.</span>Builder<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span><span class=\"token operator\">></span> <span class=\"token function\">transform</span><span class=\"token punctuation\">(</span>DynamicType<span class=\"token punctuation\">.</span>Builder<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span><span class=\"token operator\">></span> builder<span class=\"token punctuation\">,</span> TypeDescription typeDescription<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> builder\n                    <span class=\"token punctuation\">.</span><span class=\"token function\">method</span><span class=\"token punctuation\">(</span>ElementMatchers<span class=\"token punctuation\">.</span><span class=\"token function\">any</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\" spellcheck=\"true\">// 拦截任意方法</span>\n                    <span class=\"token punctuation\">.</span><span class=\"token function\">intercept</span><span class=\"token punctuation\">(</span>MethodDelegation<span class=\"token punctuation\">.</span><span class=\"token function\">to</span><span class=\"token punctuation\">(</span>MethodIntercept<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\" spellcheck=\"true\">// 委托</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n\n    <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">AgentListener</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">AgentBuilder<span class=\"token punctuation\">.</span>Listener</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onDiscovery</span><span class=\"token punctuation\">(</span>String typeName<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> loaded<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onTransformation</span><span class=\"token punctuation\">(</span>TypeDescription typeDescription<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> loaded<span class=\"token punctuation\">,</span> DynamicType dynamicType<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onIgnored</span><span class=\"token punctuation\">(</span>TypeDescription typeDescription<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> loaded<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onError</span><span class=\"token punctuation\">(</span>String typeName<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> loaded<span class=\"token punctuation\">,</span> Throwable throwable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onComplete</span><span class=\"token punctuation\">(</span>String typeName<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">,</span> JavaModule module<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> loaded<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">MethodIntercept</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token annotation punctuation\">@RuntimeType</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Object <span class=\"token function\">intercept</span><span class=\"token punctuation\">(</span><span class=\"token annotation punctuation\">@Origin</span> Method method<span class=\"token punctuation\">,</span>\n                                   <span class=\"token annotation punctuation\">@SuperCall</span> Callable<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span><span class=\"token operator\">></span> callable<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> Throwable <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">long</span> start <span class=\"token operator\">=</span> System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 原有函数执行</span>\n            <span class=\"token keyword\">return</span> callable<span class=\"token punctuation\">.</span><span class=\"token function\">call</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n            System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>method <span class=\"token operator\">+</span> <span class=\"token string\">\": took \"</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"ms\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h4 id=\"三、应用代码\"><a href=\"#三、应用代码\" class=\"headerlink\" title=\"三、应用代码\"></a>三、应用代码</h4><pre><code>package com.gumihoy.apm.agent.demo;\n\npublic class AgentTest {\n\n    public void fun1() throws Exception {\n        System.out.println(\"this is fun 1.\");\n        Thread.sleep(500);\n    }\n\n    private void fun2() throws Exception {\n        System.out.println(\"this is fun 2.\");\n        Thread.sleep(500);\n    }\n\n    public static void main(String[] args) throws Exception {\n        AgentTest test = new AgentTest();\n        test.fun1();\n        test.fun2();\n    }\n}\n</code></pre>\n<h4 id=\"四、打包\"><a href=\"#四、打包\" class=\"headerlink\" title=\"四、打包\"></a>四、打包</h4><p><a href=\"#%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F\">pom.xml配置</a></p>\n<pre><code>mvn clean package\n</code></pre>\n<h4 id=\"五、启动\"><a href=\"#五、启动\" class=\"headerlink\" title=\"五、启动\"></a>五、启动</h4><p><img src=\"1565784207465.jpg\"></p>\n<h4 id=\"六、运行结果\"><a href=\"#六、运行结果\" class=\"headerlink\" title=\"六、运行结果\"></a>六、运行结果</h4><p><img src=\"1565786297241.jpg\"></p>\n<p>如何自定义类加载器，避免污染目前进程\n如何实现字节码的修改\n如何实现字节码的多次修改\n如何恢复被修改过的字节码\n如何卸载Java Agent的类\n卸载自定义类加载器遇到的一些坑</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html\">Instrumentation介绍</a></p>\n","site":{"data":{}},"excerpt":"<p><code>Java Agent</code>就是利用 <code>Java5</code> 提供的 <code>Instrumentation</code> 机制。\n在 <code>Java SE 5</code> 中，<code>Instrument</code> 要求与应用一块启动（设置参数启动 <code>-javaagent:agent.jar</code> ）\n在 <code>Java SE 6</code> 里面，<code>Instrumentation</code> 被赋予了更强大的功能：启动后的 instrument、本地代码（native code）instrument，以及动态改变 classpath 等等.</p>\n<p><code>Java Agent</code>在不侵入代码字节码注入的方式对应用功能的增强和修改。</p>","more":"<h2 id=\"代码实现步骤\"><a href=\"#代码实现步骤\" class=\"headerlink\" title=\"代码实现步骤\"></a>代码实现步骤</h2><h3 id=\"1、代码\"><a href=\"#1、代码\" class=\"headerlink\" title=\"1、代码\"></a>1、代码</h3><p><strong>一、以vm参数的方式载入，在Java程序的main方法执行之前执行（JDK1.5和以上）</strong></p>\n<pre><code class=\"java\">// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void premain(String arguments, Instrumentation instrumentation) &#123;\n&#125;\n\npublic static void premain(String arguments) &#123;\n&#125;\n</code></pre>\n<p><strong>二、以Attach的方式载入，在Java程序启动后执行（JDK1.6和以上）</strong></p>\n<pre><code class=\"java\">// 如果同时存在下面两个方法，第一个方法先执行\n\npublic static void agentmain(String arguments, Instrumentation instrumentation) &#123;\n\n&#125;\npublic static void agentmain(String arguments) &#123;\n\n&#125;\n</code></pre>\n<br/>\n### 2、配置\n#### 打包配置\n`META-INF/MANIFEST.MF`文件必须有以下参数配置\n```java\nManifest-Version: 1.0\n// JDK1.5，必须与应用一块启动\nPremain-Class: com.gumihoy.apm.agent.APMAgent\n// JDK1.6, 可以在应用启动之后再启动\nAgent-Class: com.gumihoy.apm.agent.APMAgent\n// 布尔值（true 或 false，与大小写无关）, 是否能重定义此代理所需的类\nCan-Redefine-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能重转换此代理所需的类\nCan-Retransform-Classes: true\n// 布尔值（true 或 false，与大小写无关）, 是否能设置此代理所需的本机方法前缀\nCan-Set-Native-Method-Prefix: true\n空行\n```\n> 最后一行（空行）必须要有\n\n<br/>\n#### 实现方式\n##### 一、Maven\n\n<p><strong>方法一：使用插件maven-jar-plugin</strong>\n只有一个包：</p>\n<ul>\n<li>agent.jar: 包含第三方jar</li>\n</ul>\n<pre><code class=\"xml\"> &lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n    &lt;version&gt;3.1.2&lt;/version&gt;\n    &lt;configuration&gt;\n        &lt;archive&gt;\n            &lt;manifest&gt;\n                &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n            &lt;/manifest&gt;\n            &lt;manifestEntries&gt;\n                &lt;Premain-Class&gt;com.gumihoy.apm.agent.APMAgent&lt;/Premain-Class&gt;\n                &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt;\n                &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt;\n            &lt;/manifestEntries&gt;\n        &lt;/archive&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>\n<p><strong>方法二：使用插件maven-shade-plugin</strong>\n两个包：</p>\n<ul>\n<li>agent.jar: 包含第三方jar</li>\n<li>original-agent.jar: 不饱和第三方jar，原始包</li>\n</ul>\n<pre><code class=\"xml\">&lt;plugin&gt;\n    &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;shade&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;configuration&gt;\n                &lt;shadedArtifactAttached&gt;false&lt;/shadedArtifactAttached&gt;\n                &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt;\n                &lt;createSourcesJar&gt;true&lt;/createSourcesJar&gt;\n                &lt;shadeSourcesContent&gt;true&lt;/shadeSourcesContent&gt;\n                &lt;transformers&gt;\n                    &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt;\n                        &lt;manifestEntries&gt;\n                            &lt;Premain-Class&gt;$&#123;premain.class&#125;&lt;/Premain-Class&gt;\n                            &lt;Can-Redefine-Classes&gt;$&#123;can.redefine.classes&#125;&lt;/Can-Redefine-Classes&gt;\n                            &lt;Can-Retransform-Classes&gt;$&#123;can.retransform.classes&#125;&lt;/Can-Retransform-Classes&gt;\n                        &lt;/manifestEntries&gt;\n                    &lt;/transformer&gt;\n                &lt;/transformers&gt;\n            &lt;/configuration&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre>\n<p><strong>方法三：使用插件maven-assembly-plugin</strong>\n两个包：</p>\n<ul>\n<li>agent.jar: 不饱和第三方jar，原始包</li>\n<li>agent-jar-with-dependencies.jar: 包含第三方jar</li>\n</ul>\n<pre><code class=\"xml\">&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n    &lt;version&gt;2.4.1&lt;/version&gt;\n    &lt;configuration&gt;\n        &lt;!-- get all project dependencies --&gt;\n        &lt;descriptorRefs&gt;\n            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;\n        &lt;/descriptorRefs&gt;\n        &lt;!-- MainClass in mainfest make a executable jar --&gt;\n        &lt;archive&gt; \n            &lt;manifest&gt;\n                &lt;addClasspath&gt;true&lt;/addClasspath&gt;\n            &lt;/manifest&gt;\n            &lt;manifestEntries&gt;\n                &lt;Premain-Class&gt;com.gumihoy.apm.agent.APMAgent&lt;/Premain-Class&gt;\n                &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt;\n                &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt;\n            &lt;/manifestEntries&gt;\n                    \n        &lt;/archive&gt;\n    &lt;/configuration&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;id&gt;make-assembly&lt;/id&gt;\n            &lt;!-- bind to the packaging phase --&gt;\n            &lt;phase&gt;package&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;single&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre>\n<h5 id=\"二、Gradle\"><a href=\"#二、Gradle\" class=\"headerlink\" title=\"二、Gradle\"></a>二、Gradle</h5><pre><code class=\"gradle\">jar &#123;\n    manifest &#123;\n        attributes(\n                &#39;Premain-Class&#39;: &#39;xx.Agent&#39;,\n                &#39;Agent-Class&#39;: &#39;cxx.Agent&#39;,\n                &#39;Can-Redefine-Classes&#39;: &#39;true&#39;,\n                &#39;Can-Retransform-Classes&#39;: &#39;true&#39;,\n                &#39;Can-Set-Native-Method-Prefix&#39;: &#39;true&#39;,\n                &#39;Implementation-Title&#39;: &quot;CallSpy&quot;,\n                &#39;Implementation-Version&#39;: rootProject.version,\n                &#39;Built-By&#39;: System.getProperty(&#39;user.name&#39;),\n                &#39;Built-Date&#39;: new Date(),\n                &#39;Built-JDK&#39;: System.getProperty(&#39;java.version&#39;)\n        )\n    &#125;\n&#125;\n</code></pre>\n<br/>\n### 3、启动\n**一、vm参数配置启动**\n```java\n-javaagent:agent.jar[=arguments]\n```\n> arguments: 参数，String 类型。多个参数后端必须处理（如a=1,b=2 or a=1;b=2）\n\n\n<br/>\n## 框架\n\n<p> | baseline | Byte Buddy | cglib | Javassist | Java proxy\n-|———-|————|——-|———–|———–\ntrivial class creation | 0.003 (0.001) | 142.772 (1.390) | 515.174 (26.753) | 193.733 (4.430) | 70.712 (0.645)\ninterface implementation | 0.004 (0.001) | 1’126.364 (10.328) | 960.527 (11.788) | 1’070.766 (59.865) | 1’060.766 (12.231)\nstub method invocation | 0.002 (0.001) | 0.002 (0.001) | 0.003 (0.001) | 0.011 (0.001) | 0.008 (0.001)\nclass extension | 0.004 (0.001) | 885.983 5’408.329 | (7.901) (52.437) | 1’632.730 (52.737) | 683.478 (6.735) | –\nsuper method invocation | 0.004 (0.001) | 0.004 <br/> 0.004 | (0.001) <br/> (0.001) | 0.021 (0.001) | 0.025 (0.001) | –</p>\n<blockquote>\n<ul>\n<li>javassist更偏向底层，比较难于使用并且在动态组合字符串以实现更复杂的逻辑时很容易出错</li>\n<li>cglib现在维护的则相当慢了，基本处于无人维护的阶段了，而这些缺点ByteBuddy都没有</li>\n<li>ByteBuddy性能相对来说在三者中是最优的</li>\n</ul>\n</blockquote>\n<h3 id=\"使用-Byte-Buddy-实现-JavaAgent\"><a href=\"#使用-Byte-Buddy-实现-JavaAgent\" class=\"headerlink\" title=\"使用 Byte Buddy 实现 JavaAgent\"></a>使用 Byte Buddy 实现 JavaAgent</h3><h4 id=\"一、导入jar\"><a href=\"#一、导入jar\" class=\"headerlink\" title=\"一、导入jar\"></a>一、导入<code>jar</code></h4><pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\n    &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\n    &lt;version&gt;1.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;!-- https://mvnrepository.com/artifact/net.bytebuddy/byte-buddy-agent --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\n    &lt;artifactId&gt;byte-buddy-agent&lt;/artifactId&gt;\n    &lt;version&gt;1.10.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h4 id=\"二、Agent代码\"><a href=\"#二、Agent代码\" class=\"headerlink\" title=\"二、Agent代码\"></a>二、<code>Agent</code>代码</h4><pre><code class=\"java\">public class APMAgent &#123;\n\n\n    /**\n     * http://bytebuddy.net/#/tutorialTypeValidation\n     *\n     * @param arguments\n     * @param instrumentation\n     */\n    public static void premain(String arguments, Instrumentation instrumentation) &#123;\n        System.out.println(&quot;xx&quot;);\n//        ByteBuddy buddy = new ByteBuddy().with(TypeValidation.of(false)).with(ClassFileVersion.JAVA_V8);\n        new AgentBuilder.Default()\n                .type(ElementMatchers.nameStartsWith(&quot;com.gumihoy.apm.agent.demo&quot;))\n                .transform(new AgentTransformer())\n                .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION)\n                .with(new AgentListener())\n                .installOn(instrumentation);\n    &#125;\n\n    public static void agentmain(String arguments, Instrumentation instrumentation) &#123;\n\n    &#125;\n\n    protected static ElementMatcher&lt;? super TypeDescription&gt; buildIgnoreMatcher() &#123;\n        return ElementMatchers.nameStartsWith(&quot;net.bytebuddy.*&quot;);\n    &#125;\n\n\n    static class AgentTransformer implements AgentBuilder.Transformer &#123;\n        @Override\n        public DynamicType.Builder&lt;?&gt; transform(DynamicType.Builder&lt;?&gt; builder, TypeDescription typeDescription, ClassLoader classLoader, JavaModule module) &#123;\n            return builder\n                    .method(ElementMatchers.any()) // 拦截任意方法\n                    .intercept(MethodDelegation.to(MethodIntercept.class)); // 委托\n        &#125;\n    &#125;\n\n\n    static class AgentListener implements AgentBuilder.Listener &#123;\n        @Override\n        public void onDiscovery(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) &#123;\n\n        &#125;\n\n        @Override\n        public void onTransformation(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded, DynamicType dynamicType) &#123;\n\n        &#125;\n\n        @Override\n        public void onIgnored(TypeDescription typeDescription, ClassLoader classLoader, JavaModule module, boolean loaded) &#123;\n\n        &#125;\n\n        @Override\n        public void onError(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded, Throwable throwable) &#123;\n\n        &#125;\n\n        @Override\n        public void onComplete(String typeName, ClassLoader classLoader, JavaModule module, boolean loaded) &#123;\n\n        &#125;\n    &#125;\n\n&#125;\n\n\npublic class MethodIntercept &#123;\n\n    @RuntimeType\n    public static Object intercept(@Origin Method method,\n                                   @SuperCall Callable&lt;?&gt; callable) throws Throwable &#123;\n        long start = System.currentTimeMillis();\n        try &#123;\n            // 原有函数执行\n            return callable.call();\n        &#125; finally &#123;\n            System.out.println(method + &quot;: took &quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;);\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<h4 id=\"三、应用代码\"><a href=\"#三、应用代码\" class=\"headerlink\" title=\"三、应用代码\"></a>三、应用代码</h4><pre><code>package com.gumihoy.apm.agent.demo;\n\npublic class AgentTest &#123;\n\n    public void fun1() throws Exception &#123;\n        System.out.println(&quot;this is fun 1.&quot;);\n        Thread.sleep(500);\n    &#125;\n\n    private void fun2() throws Exception &#123;\n        System.out.println(&quot;this is fun 2.&quot;);\n        Thread.sleep(500);\n    &#125;\n\n    public static void main(String[] args) throws Exception &#123;\n        AgentTest test = new AgentTest();\n        test.fun1();\n        test.fun2();\n    &#125;\n&#125;\n</code></pre>\n<h4 id=\"四、打包\"><a href=\"#四、打包\" class=\"headerlink\" title=\"四、打包\"></a>四、打包</h4><p><a href=\"#%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F\">pom.xml配置</a></p>\n<pre><code>mvn clean package\n</code></pre>\n<h4 id=\"五、启动\"><a href=\"#五、启动\" class=\"headerlink\" title=\"五、启动\"></a>五、启动</h4><p><img src=\"1565784207465.jpg\"></p>\n<h4 id=\"六、运行结果\"><a href=\"#六、运行结果\" class=\"headerlink\" title=\"六、运行结果\"></a>六、运行结果</h4><p><img src=\"1565786297241.jpg\"></p>\n<p>如何自定义类加载器，避免污染目前进程\n如何实现字节码的修改\n如何实现字节码的多次修改\n如何恢复被修改过的字节码\n如何卸载Java Agent的类\n卸载自定义类加载器遇到的一些坑</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html\">Instrumentation介绍</a></p>"},{"title":"Java使用Redis","date":"2018-12-06T01:22:22.000Z","_content":"\nRedis 支持很多种语言客户端：`ActionScript` `Bash` `C` `C#` `C++` `Clojure` `Common Lisp`  `Crystal`  `D`  `Dart`  `Elixir`  `emacs lisp` `Erlang`  `Fancy`  `gawk`  `GNU Prolog`  `Go`  `Haskell` `Haxe`  `Io`  `Java`  `Javascript`  `Julia`  `Lua` `Matlab`  `Nim`  `Node.js`  `Objective-C`  `OCaml`  `Pascal` `Perl`  `PHP`  `Pure Data`  `Python`  `R`  `Racket` `Rebol`  `Ruby`  `Rust`  `Scala`  `Scheme`  `Smalltalk` `Swift`  `Tcl`  `VB` `VCL`\n\n官网客户端选择：https://redis.io/clients\n\n<!-- more -->\n---\n\n<br/>\n\n在Redis官网推荐的Java客户端有`Jedis`、`Lettuce`和`Redisson`。对这三个客户端的介绍如下：\n\n- Jedis：一个非常小而且健全的redis java客户端。\n- Lettuce：高级Redis客户端，用于线程安全同步，异步和反应使用。支持群集，哨兵，管道和编解码器。\n- Redisson：Redis服务器之上的分布式和可伸缩的Java数据结构。\n\n<br/>\n### Jedis\nGithub：https://github.com/xetorthio/jedis\n\n```xml\n<!-- https://mvnrepository.com/artifact/redis.clients/jedis -->\n\n```\n\n\n\n\n\n<br/>\n### Lettuce\nGithub：https://github.com/lettuce-io/lettuce-core\n\n```xml\n<!-- https://mvnrepository.com/artifact/io.lettuce/lettuce-core -->\n\n```\n\n\n\n<br/>\n### Redisson\nGithub：https://github.com/redisson/redisson\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.redisson/redisson -->\n\n\n```\n","source":"_posts/Java使用Redis.md","raw":"---\ntitle: Java使用Redis\ndate: 2018-12-06 09:22:22\ncategories: \n    - Redis\ntags:\n    - NoSQL\n    - Redis\n---\n\nRedis 支持很多种语言客户端：`ActionScript` `Bash` `C` `C#` `C++` `Clojure` `Common Lisp`  `Crystal`  `D`  `Dart`  `Elixir`  `emacs lisp` `Erlang`  `Fancy`  `gawk`  `GNU Prolog`  `Go`  `Haskell` `Haxe`  `Io`  `Java`  `Javascript`  `Julia`  `Lua` `Matlab`  `Nim`  `Node.js`  `Objective-C`  `OCaml`  `Pascal` `Perl`  `PHP`  `Pure Data`  `Python`  `R`  `Racket` `Rebol`  `Ruby`  `Rust`  `Scala`  `Scheme`  `Smalltalk` `Swift`  `Tcl`  `VB` `VCL`\n\n官网客户端选择：https://redis.io/clients\n\n<!-- more -->\n---\n\n<br/>\n\n在Redis官网推荐的Java客户端有`Jedis`、`Lettuce`和`Redisson`。对这三个客户端的介绍如下：\n\n- Jedis：一个非常小而且健全的redis java客户端。\n- Lettuce：高级Redis客户端，用于线程安全同步，异步和反应使用。支持群集，哨兵，管道和编解码器。\n- Redisson：Redis服务器之上的分布式和可伸缩的Java数据结构。\n\n<br/>\n### Jedis\nGithub：https://github.com/xetorthio/jedis\n\n```xml\n<!-- https://mvnrepository.com/artifact/redis.clients/jedis -->\n\n```\n\n\n\n\n\n<br/>\n### Lettuce\nGithub：https://github.com/lettuce-io/lettuce-core\n\n```xml\n<!-- https://mvnrepository.com/artifact/io.lettuce/lettuce-core -->\n\n```\n\n\n\n<br/>\n### Redisson\nGithub：https://github.com/redisson/redisson\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.redisson/redisson -->\n\n\n```\n","slug":"Java使用Redis","published":1,"updated":"2021-06-30T02:33:24.703Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswi0057r5p72kfjdcte","content":"<p>Redis 支持很多种语言客户端：<code>ActionScript</code> <code>Bash</code> <code>C</code> <code>C#</code> <code>C++</code> <code>Clojure</code> <code>Common Lisp</code>  <code>Crystal</code>  <code>D</code>  <code>Dart</code>  <code>Elixir</code>  <code>emacs lisp</code> <code>Erlang</code>  <code>Fancy</code>  <code>gawk</code>  <code>GNU Prolog</code>  <code>Go</code>  <code>Haskell</code> <code>Haxe</code>  <code>Io</code>  <code>Java</code>  <code>Javascript</code>  <code>Julia</code>  <code>Lua</code> <code>Matlab</code>  <code>Nim</code>  <code>Node.js</code>  <code>Objective-C</code>  <code>OCaml</code>  <code>Pascal</code> <code>Perl</code>  <code>PHP</code>  <code>Pure Data</code>  <code>Python</code>  <code>R</code>  <code>Racket</code> <code>Rebol</code>  <code>Ruby</code>  <code>Rust</code>  <code>Scala</code>  <code>Scheme</code>  <code>Smalltalk</code> <code>Swift</code>  <code>Tcl</code>  <code>VB</code> <code>VCL</code></p>\n<p>官网客户端选择：<a href=\"https://redis.io/clients\">https://redis.io/clients</a></p>\n<span id=\"more\"></span>\n<hr>\n<br>\n\n<p>在Redis官网推荐的Java客户端有<code>Jedis</code>、<code>Lettuce</code>和<code>Redisson</code>。对这三个客户端的介绍如下：</p>\n<ul>\n<li>Jedis：一个非常小而且健全的redis java客户端。</li>\n<li>Lettuce：高级Redis客户端，用于线程安全同步，异步和反应使用。支持群集，哨兵，管道和编解码器。</li>\n<li>Redisson：Redis服务器之上的分布式和可伸缩的Java数据结构。</li>\n</ul>\n<br>\n### Jedis\nGithub：https://github.com/xetorthio/jedis\n\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --></span>\n</code></pre>\n<br>\n### Lettuce\nGithub：https://github.com/lettuce-io/lettuce-core\n\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/io.lettuce/lettuce-core --></span>\n</code></pre>\n<br>\n### Redisson\nGithub：https://github.com/redisson/redisson\n\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --></span>\n\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>Redis 支持很多种语言客户端：<code>ActionScript</code> <code>Bash</code> <code>C</code> <code>C#</code> <code>C++</code> <code>Clojure</code> <code>Common Lisp</code>  <code>Crystal</code>  <code>D</code>  <code>Dart</code>  <code>Elixir</code>  <code>emacs lisp</code> <code>Erlang</code>  <code>Fancy</code>  <code>gawk</code>  <code>GNU Prolog</code>  <code>Go</code>  <code>Haskell</code> <code>Haxe</code>  <code>Io</code>  <code>Java</code>  <code>Javascript</code>  <code>Julia</code>  <code>Lua</code> <code>Matlab</code>  <code>Nim</code>  <code>Node.js</code>  <code>Objective-C</code>  <code>OCaml</code>  <code>Pascal</code> <code>Perl</code>  <code>PHP</code>  <code>Pure Data</code>  <code>Python</code>  <code>R</code>  <code>Racket</code> <code>Rebol</code>  <code>Ruby</code>  <code>Rust</code>  <code>Scala</code>  <code>Scheme</code>  <code>Smalltalk</code> <code>Swift</code>  <code>Tcl</code>  <code>VB</code> <code>VCL</code></p>\n<p>官网客户端选择：<a href=\"https://redis.io/clients\">https://redis.io/clients</a></p>","more":"<hr>\n<br/>\n\n<p>在Redis官网推荐的Java客户端有<code>Jedis</code>、<code>Lettuce</code>和<code>Redisson</code>。对这三个客户端的介绍如下：</p>\n<ul>\n<li>Jedis：一个非常小而且健全的redis java客户端。</li>\n<li>Lettuce：高级Redis客户端，用于线程安全同步，异步和反应使用。支持群集，哨兵，管道和编解码器。</li>\n<li>Redisson：Redis服务器之上的分布式和可伸缩的Java数据结构。</li>\n</ul>\n<br/>\n### Jedis\nGithub：https://github.com/xetorthio/jedis\n\n<pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt;\n</code></pre>\n<br/>\n### Lettuce\nGithub：https://github.com/lettuce-io/lettuce-core\n\n<pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/io.lettuce/lettuce-core --&gt;\n</code></pre>\n<br/>\n### Redisson\nGithub：https://github.com/redisson/redisson\n\n<pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/org.redisson/redisson --&gt;\n\n</code></pre>"},{"title":"Java常见问题总结","date":"2019-01-28T01:38:14.000Z","_content":"\n\n\n---\n\n### NoSuchMethodException\n#### 原因\n- Java ClassLoader机制\n- Jar版本冲突问题\n\n#### 排查方法\n\n\n<br>\n### 应用没响应\n\n<br>\n### 调用另一应用超时\n\n<br>\n### java.lang.OutOfMemoryError\n\n\n<br>\n### CPU us高\n\n\n<br>\n### CPU sy高\n\n\n<br>\n### CPU iowait高\n\n\n<br>\n### Java进程退出\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/Java常见问题总结.md","raw":"---\ntitle: Java常见问题总结\ndate: 2019-01-28 09:38:14\ncategories: \n    - Java\ntags:\n    - Java\n---\n\n\n\n---\n\n### NoSuchMethodException\n#### 原因\n- Java ClassLoader机制\n- Jar版本冲突问题\n\n#### 排查方法\n\n\n<br>\n### 应用没响应\n\n<br>\n### 调用另一应用超时\n\n<br>\n### java.lang.OutOfMemoryError\n\n\n<br>\n### CPU us高\n\n\n<br>\n### CPU sy高\n\n\n<br>\n### CPU iowait高\n\n\n<br>\n### Java进程退出\n\n\n\n\n\n\n\n\n\n\n","slug":"Java常见问题总结","published":1,"updated":"2021-06-30T02:33:24.703Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswj005cr5p7gnipfc7l","content":"<hr>\n<h3 id=\"NoSuchMethodException\"><a href=\"#NoSuchMethodException\" class=\"headerlink\" title=\"NoSuchMethodException\"></a>NoSuchMethodException</h3><h4 id=\"原因\"><a href=\"#原因\" class=\"headerlink\" title=\"原因\"></a>原因</h4><ul>\n<li>Java ClassLoader机制</li>\n<li>Jar版本冲突问题</li>\n</ul>\n<h4 id=\"排查方法\"><a href=\"#排查方法\" class=\"headerlink\" title=\"排查方法\"></a>排查方法</h4><br>\n### 应用没响应\n\n<br>\n### 调用另一应用超时\n\n<br>\n### java.lang.OutOfMemoryError\n\n\n<br>\n### CPU us高\n\n\n<br>\n### CPU sy高\n\n\n<br>\n### CPU iowait高\n\n\n<br>\n### Java进程退出\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<h3 id=\"NoSuchMethodException\"><a href=\"#NoSuchMethodException\" class=\"headerlink\" title=\"NoSuchMethodException\"></a>NoSuchMethodException</h3><h4 id=\"原因\"><a href=\"#原因\" class=\"headerlink\" title=\"原因\"></a>原因</h4><ul>\n<li>Java ClassLoader机制</li>\n<li>Jar版本冲突问题</li>\n</ul>\n<h4 id=\"排查方法\"><a href=\"#排查方法\" class=\"headerlink\" title=\"排查方法\"></a>排查方法</h4><br>\n### 应用没响应\n\n<br>\n### 调用另一应用超时\n\n<br>\n### java.lang.OutOfMemoryError\n\n\n<br>\n### CPU us高\n\n\n<br>\n### CPU sy高\n\n\n<br>\n### CPU iowait高\n\n\n<br>\n### Java进程退出\n\n\n\n\n\n\n\n\n\n\n"},{"title":"Java环境配置","date":"2021-07-15T10:23:37.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：汇总Java开发环境配置，方便后续使用查阅.\n\n# Mac环境\n\n## 安装Xcode工具链\n新的Mac电脑没有默认安装Xcode工具链，可以在【终端】中通过输入以下命令进行安装：\n```bash\nxcode-select --install \n```\n\n## OpenJDK安装、配置\n\n### Intel\n\n- #### 安装：方式一\nadopt openjdk下载地址：https://adoptopenjdk.net\n<br/>\n选择openjdk 一个dmg版本下载安装\n\n\n- #### 安装：方式二（选择一个版本安装）\nbrew openjdk：(https://formulae.brew.sh/formula/openjdk)\n\n-  安装最新版本\n```bash\nbrew install openjdk\n```\n\n- 安装 openjdk 11\n```bash\nbrew install openjdk@11\n```\n\n- 安装 openjdk 8\n```bash\nbrew install openjdk@8\n```\n\n### Apple M1\n\nApple M1芯片的macOS可选使用以下aarch64架构的JDK\n\n下载地址：https://cdn.azul.com/zulu/bin/\n选择 aarch64.dmg 一个版本下载安装\n\n\n### 配置\n安装完成后，执行下列命令配置JAVA_HOME环境变量，并确认输出的JAVA_HOME指向安装的JDK，以便固定使用此版本的JDK。或者选择手工进行配置\n```bash\nexport JAVA_HOME=$(/usr/libexec/java_home)\necho $JAVA_HOME\ntest -r ~/.bash_profile && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.bash_profile\ntest -r ~/.profile && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.profile\ntest -r ~/.zshrc && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.zshrc\n```\n\n\n## Maven安装、配置\n\nbrew maven：https://formulae.brew.sh/formula/maven\n\n```bash\nbrew install maven\n```\n\n## IntelliJ IDEA 配置\n\n\n---\n\n参考：\n- [brew opnejdk](https://formulae.brew.sh/formula/openjdk)\n-[brew maven](https://formulae.brew.sh/formula/maven)\n- [s](ss)","source":"_posts/Java环境配置.md","raw":"---\ntitle: Java环境配置\ndate: 2021-07-15 18:23:37\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java在Mac系统中的开发环境配置\ncategories:\n    - [Java环境配置]\ntags:\n    - Java\n    - Mac\n---\n\n> 摘要：汇总Java开发环境配置，方便后续使用查阅.\n\n# Mac环境\n\n## 安装Xcode工具链\n新的Mac电脑没有默认安装Xcode工具链，可以在【终端】中通过输入以下命令进行安装：\n```bash\nxcode-select --install \n```\n\n## OpenJDK安装、配置\n\n### Intel\n\n- #### 安装：方式一\nadopt openjdk下载地址：https://adoptopenjdk.net\n<br/>\n选择openjdk 一个dmg版本下载安装\n\n\n- #### 安装：方式二（选择一个版本安装）\nbrew openjdk：(https://formulae.brew.sh/formula/openjdk)\n\n-  安装最新版本\n```bash\nbrew install openjdk\n```\n\n- 安装 openjdk 11\n```bash\nbrew install openjdk@11\n```\n\n- 安装 openjdk 8\n```bash\nbrew install openjdk@8\n```\n\n### Apple M1\n\nApple M1芯片的macOS可选使用以下aarch64架构的JDK\n\n下载地址：https://cdn.azul.com/zulu/bin/\n选择 aarch64.dmg 一个版本下载安装\n\n\n### 配置\n安装完成后，执行下列命令配置JAVA_HOME环境变量，并确认输出的JAVA_HOME指向安装的JDK，以便固定使用此版本的JDK。或者选择手工进行配置\n```bash\nexport JAVA_HOME=$(/usr/libexec/java_home)\necho $JAVA_HOME\ntest -r ~/.bash_profile && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.bash_profile\ntest -r ~/.profile && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.profile\ntest -r ~/.zshrc && echo \"export JAVA_HOME=$JAVA_HOME\" >>~/.zshrc\n```\n\n\n## Maven安装、配置\n\nbrew maven：https://formulae.brew.sh/formula/maven\n\n```bash\nbrew install maven\n```\n\n## IntelliJ IDEA 配置\n\n\n---\n\n参考：\n- [brew opnejdk](https://formulae.brew.sh/formula/openjdk)\n-[brew maven](https://formulae.brew.sh/formula/maven)\n- [s](ss)","slug":"Java环境配置","published":1,"updated":"2021-07-15T14:03:53.394Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswk005fr5p7evsy0vnr","content":"<blockquote>\n<p>摘要：汇总Java开发环境配置，方便后续使用查阅.</p>\n</blockquote>\n<h1 id=\"Mac环境\"><a href=\"#Mac环境\" class=\"headerlink\" title=\"Mac环境\"></a>Mac环境</h1><h2 id=\"安装Xcode工具链\"><a href=\"#安装Xcode工具链\" class=\"headerlink\" title=\"安装Xcode工具链\"></a>安装Xcode工具链</h2><p>新的Mac电脑没有默认安装Xcode工具链，可以在【终端】中通过输入以下命令进行安装：</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">xcode-select --install \n</code></pre>\n<h2 id=\"OpenJDK安装、配置\"><a href=\"#OpenJDK安装、配置\" class=\"headerlink\" title=\"OpenJDK安装、配置\"></a>OpenJDK安装、配置</h2><h3 id=\"Intel\"><a href=\"#Intel\" class=\"headerlink\" title=\"Intel\"></a>Intel</h3><ul>\n<li><h4 id=\"安装：方式一\"><a href=\"#安装：方式一\" class=\"headerlink\" title=\"安装：方式一\"></a>安装：方式一</h4>adopt openjdk下载地址：<a href=\"https://adoptopenjdk.net/\">https://adoptopenjdk.net</a><br>\n选择openjdk 一个dmg版本下载安装</li>\n</ul>\n<ul>\n<li><h4 id=\"安装：方式二（选择一个版本安装）\"><a href=\"#安装：方式二（选择一个版本安装）\" class=\"headerlink\" title=\"安装：方式二（选择一个版本安装）\"></a>安装：方式二（选择一个版本安装）</h4><p>brew openjdk：(<a href=\"https://formulae.brew.sh/formula/openjdk\">https://formulae.brew.sh/formula/openjdk</a>)</p>\n</li>\n<li><p> 安装最新版本</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> openjdk\n</code></pre>\n</li>\n<li><p>安装 openjdk 11</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> openjdk@11\n</code></pre>\n</li>\n<li><p>安装 openjdk 8</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> openjdk@8\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Apple-M1\"><a href=\"#Apple-M1\" class=\"headerlink\" title=\"Apple M1\"></a>Apple M1</h3><p>Apple M1芯片的macOS可选使用以下aarch64架构的JDK</p>\n<p>下载地址：<a href=\"https://cdn.azul.com/zulu/bin/\">https://cdn.azul.com/zulu/bin/</a>\n选择 aarch64.dmg 一个版本下载安装</p>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>安装完成后，执行下列命令配置JAVA_HOME环境变量，并确认输出的JAVA_HOME指向安装的JDK，以便固定使用此版本的JDK。或者选择手工进行配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">export</span> JAVA_HOME<span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span>/usr/libexec/java_home<span class=\"token variable\">)</span></span>\n<span class=\"token keyword\">echo</span> <span class=\"token variable\">$JAVA_HOME</span>\n<span class=\"token function\">test</span> -r ~/.bash_profile <span class=\"token operator\">&amp;&amp;</span> <span class=\"token keyword\">echo</span> <span class=\"token string\">\"export JAVA_HOME=<span class=\"token variable\">$JAVA_HOME</span>\"</span> <span class=\"token operator\">>></span>~/.bash_profile\n<span class=\"token function\">test</span> -r ~/.profile <span class=\"token operator\">&amp;&amp;</span> <span class=\"token keyword\">echo</span> <span class=\"token string\">\"export JAVA_HOME=<span class=\"token variable\">$JAVA_HOME</span>\"</span> <span class=\"token operator\">>></span>~/.profile\n<span class=\"token function\">test</span> -r ~/.zshrc <span class=\"token operator\">&amp;&amp;</span> <span class=\"token keyword\">echo</span> <span class=\"token string\">\"export JAVA_HOME=<span class=\"token variable\">$JAVA_HOME</span>\"</span> <span class=\"token operator\">>></span>~/.zshrc\n</code></pre>\n<h2 id=\"Maven安装、配置\"><a href=\"#Maven安装、配置\" class=\"headerlink\" title=\"Maven安装、配置\"></a>Maven安装、配置</h2><p>brew maven：<a href=\"https://formulae.brew.sh/formula/maven\">https://formulae.brew.sh/formula/maven</a></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> maven\n</code></pre>\n<h2 id=\"IntelliJ-IDEA-配置\"><a href=\"#IntelliJ-IDEA-配置\" class=\"headerlink\" title=\"IntelliJ IDEA 配置\"></a>IntelliJ IDEA 配置</h2><hr>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://formulae.brew.sh/formula/openjdk\">brew opnejdk</a></li>\n<li><a href=\"https://formulae.brew.sh/formula/maven\">brew maven</a></li>\n<li><a href=\"ss\">s</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：汇总Java开发环境配置，方便后续使用查阅.</p>\n</blockquote>\n<h1 id=\"Mac环境\"><a href=\"#Mac环境\" class=\"headerlink\" title=\"Mac环境\"></a>Mac环境</h1><h2 id=\"安装Xcode工具链\"><a href=\"#安装Xcode工具链\" class=\"headerlink\" title=\"安装Xcode工具链\"></a>安装Xcode工具链</h2><p>新的Mac电脑没有默认安装Xcode工具链，可以在【终端】中通过输入以下命令进行安装：</p>\n<pre><code class=\"bash\">xcode-select --install \n</code></pre>\n<h2 id=\"OpenJDK安装、配置\"><a href=\"#OpenJDK安装、配置\" class=\"headerlink\" title=\"OpenJDK安装、配置\"></a>OpenJDK安装、配置</h2><h3 id=\"Intel\"><a href=\"#Intel\" class=\"headerlink\" title=\"Intel\"></a>Intel</h3><ul>\n<li><h4 id=\"安装：方式一\"><a href=\"#安装：方式一\" class=\"headerlink\" title=\"安装：方式一\"></a>安装：方式一</h4>adopt openjdk下载地址：<a href=\"https://adoptopenjdk.net/\">https://adoptopenjdk.net</a><br/>\n选择openjdk 一个dmg版本下载安装</li>\n</ul>\n<ul>\n<li><h4 id=\"安装：方式二（选择一个版本安装）\"><a href=\"#安装：方式二（选择一个版本安装）\" class=\"headerlink\" title=\"安装：方式二（选择一个版本安装）\"></a>安装：方式二（选择一个版本安装）</h4><p>brew openjdk：(<a href=\"https://formulae.brew.sh/formula/openjdk\">https://formulae.brew.sh/formula/openjdk</a>)</p>\n</li>\n<li><p> 安装最新版本</p>\n<pre><code class=\"bash\">brew install openjdk\n</code></pre>\n</li>\n<li><p>安装 openjdk 11</p>\n<pre><code class=\"bash\">brew install openjdk@11\n</code></pre>\n</li>\n<li><p>安装 openjdk 8</p>\n<pre><code class=\"bash\">brew install openjdk@8\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Apple-M1\"><a href=\"#Apple-M1\" class=\"headerlink\" title=\"Apple M1\"></a>Apple M1</h3><p>Apple M1芯片的macOS可选使用以下aarch64架构的JDK</p>\n<p>下载地址：<a href=\"https://cdn.azul.com/zulu/bin/\">https://cdn.azul.com/zulu/bin/</a>\n选择 aarch64.dmg 一个版本下载安装</p>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>安装完成后，执行下列命令配置JAVA_HOME环境变量，并确认输出的JAVA_HOME指向安装的JDK，以便固定使用此版本的JDK。或者选择手工进行配置</p>\n<pre><code class=\"bash\">export JAVA_HOME=$(/usr/libexec/java_home)\necho $JAVA_HOME\ntest -r ~/.bash_profile &amp;&amp; echo &quot;export JAVA_HOME=$JAVA_HOME&quot; &gt;&gt;~/.bash_profile\ntest -r ~/.profile &amp;&amp; echo &quot;export JAVA_HOME=$JAVA_HOME&quot; &gt;&gt;~/.profile\ntest -r ~/.zshrc &amp;&amp; echo &quot;export JAVA_HOME=$JAVA_HOME&quot; &gt;&gt;~/.zshrc\n</code></pre>\n<h2 id=\"Maven安装、配置\"><a href=\"#Maven安装、配置\" class=\"headerlink\" title=\"Maven安装、配置\"></a>Maven安装、配置</h2><p>brew maven：<a href=\"https://formulae.brew.sh/formula/maven\">https://formulae.brew.sh/formula/maven</a></p>\n<pre><code class=\"bash\">brew install maven\n</code></pre>\n<h2 id=\"IntelliJ-IDEA-配置\"><a href=\"#IntelliJ-IDEA-配置\" class=\"headerlink\" title=\"IntelliJ IDEA 配置\"></a>IntelliJ IDEA 配置</h2><hr>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://formulae.brew.sh/formula/openjdk\">brew opnejdk</a></li>\n<li><a href=\"https://formulae.brew.sh/formula/maven\">brew maven</a></li>\n<li><a href=\"ss\">s</a></li>\n</ul>\n"},{"title":"Joda Time总结","date":"2019-08-13T11:26:55.000Z","_content":"\n\n官网：https://www.joda.org/joda-time/index.html\n\n为啥用`Joda Time`\n- 1. 易于使用:Calendar让获取\"正常的\"的日期变得很困难，使它没办法提供简单的方法，而Joda-Time能够 直接进行访问域并且索引值1就是代表January。\n- 2. 易于扩展：JDK支持多日历系统是通过Calendar的子类来实现，这样就显示的非常笨重而且事实 上要实现其它日历系统是很困难的。Joda-Time支持多日历系统是通过基于Chronology类的插件体系来实现。\n- 3. 提供一组完整的功能：它打算提供 所有关系到date-time计算的功能．Joda-Time当前支持8种日历系统，而且在将来还会继续添加，有着比JDK Calendar更好的整体性能等等。\n- \n\n\n\n> 大部分人使用`SimpleDateFormat`处理时间格式化过程，但是`SimpleDateFormat`存在并发问题。使用`Joda Time`替代\n\n\n## 使用\n\n导入jar，地址： https://mvnrepository.com/artifact/joda-time\n``` maven\n<dependency>\n    <groupId>joda-time</groupId>\n    <artifactId>joda-time</artifactId>\n    <version>2.10.3</version>\n</dependency>\n```\n\n### `Java`日期对象 与 `Joda Time`日期对象相互转换\n\n#### 毫秒 与 DateTime\n\n**毫秒  =>  DateTime**\n```java\nlong milliseconds = System.currentTimeMillis();\nDateTime dateTime = new DateTime(milliseconds);\n```\n\n**DateTime  =>  毫秒**\n```java\nDateTime dateTime = new DateTime();\nlong milliseconds = dateTime.getMillis();\n```\n\n\n#### Date 与 DateTime\n\n**Date  =>  DateTime**\n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\n```\n\n**DateTime  =>  Date**\n```java\nDateTime dateTime = new DateTime();\nDate d = dateTime.toDate();\n```\n\n\n#### Calendar 与 DateTime\n\n**Calendar  =>  DateTime**\n```java\nCalendar c = Calendar.getInstance();\nDateTime dateTime = new DateTime(c);\n```\n\n**DateTime  =>  Calendar**\n```java\nDateTime dateTime = new DateTime();\nCalendar c = dateTime.toCalendar(null);\n```\n\n\n### 时间 => 字符串 （时间转换字符串、时间格式化）\n\n**第一种方式** \n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\ndateTime.toString(\"yyyy-MM-dd HH:mm:ss);\n```\n\n**第二种方式** \n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\nDateTimeFormatter formatter = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\");\nformatter.print(dateTime);\n```\n\n\n### 字符串 => 时间\n\n\n\n\n### 日期计算\n\n","source":"_posts/Joda-Time总结.md","raw":"---\ntitle: Joda Time总结\ndate: 2019-08-13 19:26:55\ntags:\n---\n\n\n官网：https://www.joda.org/joda-time/index.html\n\n为啥用`Joda Time`\n- 1. 易于使用:Calendar让获取\"正常的\"的日期变得很困难，使它没办法提供简单的方法，而Joda-Time能够 直接进行访问域并且索引值1就是代表January。\n- 2. 易于扩展：JDK支持多日历系统是通过Calendar的子类来实现，这样就显示的非常笨重而且事实 上要实现其它日历系统是很困难的。Joda-Time支持多日历系统是通过基于Chronology类的插件体系来实现。\n- 3. 提供一组完整的功能：它打算提供 所有关系到date-time计算的功能．Joda-Time当前支持8种日历系统，而且在将来还会继续添加，有着比JDK Calendar更好的整体性能等等。\n- \n\n\n\n> 大部分人使用`SimpleDateFormat`处理时间格式化过程，但是`SimpleDateFormat`存在并发问题。使用`Joda Time`替代\n\n\n## 使用\n\n导入jar，地址： https://mvnrepository.com/artifact/joda-time\n``` maven\n<dependency>\n    <groupId>joda-time</groupId>\n    <artifactId>joda-time</artifactId>\n    <version>2.10.3</version>\n</dependency>\n```\n\n### `Java`日期对象 与 `Joda Time`日期对象相互转换\n\n#### 毫秒 与 DateTime\n\n**毫秒  =>  DateTime**\n```java\nlong milliseconds = System.currentTimeMillis();\nDateTime dateTime = new DateTime(milliseconds);\n```\n\n**DateTime  =>  毫秒**\n```java\nDateTime dateTime = new DateTime();\nlong milliseconds = dateTime.getMillis();\n```\n\n\n#### Date 与 DateTime\n\n**Date  =>  DateTime**\n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\n```\n\n**DateTime  =>  Date**\n```java\nDateTime dateTime = new DateTime();\nDate d = dateTime.toDate();\n```\n\n\n#### Calendar 与 DateTime\n\n**Calendar  =>  DateTime**\n```java\nCalendar c = Calendar.getInstance();\nDateTime dateTime = new DateTime(c);\n```\n\n**DateTime  =>  Calendar**\n```java\nDateTime dateTime = new DateTime();\nCalendar c = dateTime.toCalendar(null);\n```\n\n\n### 时间 => 字符串 （时间转换字符串、时间格式化）\n\n**第一种方式** \n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\ndateTime.toString(\"yyyy-MM-dd HH:mm:ss);\n```\n\n**第二种方式** \n```java\nDate d = new Date();\nDateTime dateTime = new DateTime(d);\nDateTimeFormatter formatter = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\");\nformatter.print(dateTime);\n```\n\n\n### 字符串 => 时间\n\n\n\n\n### 日期计算\n\n","slug":"Joda-Time总结","published":1,"updated":"2021-06-30T02:33:24.703Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswl005kr5p70fi4fw13","content":"<p>官网：<a href=\"https://www.joda.org/joda-time/index.html\">https://www.joda.org/joda-time/index.html</a></p>\n<p>为啥用<code>Joda Time</code></p>\n<ul>\n<li><ol>\n<li>易于使用:Calendar让获取”正常的”的日期变得很困难，使它没办法提供简单的方法，而Joda-Time能够 直接进行访问域并且索引值1就是代表January。</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>易于扩展：JDK支持多日历系统是通过Calendar的子类来实现，这样就显示的非常笨重而且事实 上要实现其它日历系统是很困难的。Joda-Time支持多日历系统是通过基于Chronology类的插件体系来实现。</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>提供一组完整的功能：它打算提供 所有关系到date-time计算的功能．Joda-Time当前支持8种日历系统，而且在将来还会继续添加，有着比JDK Calendar更好的整体性能等等。</li>\n</ol>\n</li>\n<li></li>\n</ul>\n<blockquote>\n<p>大部分人使用<code>SimpleDateFormat</code>处理时间格式化过程，但是<code>SimpleDateFormat</code>存在并发问题。使用<code>Joda Time</code>替代</p>\n</blockquote>\n<h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><p>导入jar，地址： <a href=\"https://mvnrepository.com/artifact/joda-time\">https://mvnrepository.com/artifact/joda-time</a></p>\n<pre class=\" language-maven\"><code class=\"language-maven\"><dependency>\n    <groupId>joda-time</groupId>\n    <artifactId>joda-time</artifactId>\n    <version>2.10.3</version>\n</dependency>\n</code></pre>\n<h3 id=\"Java日期对象-与-Joda-Time日期对象相互转换\"><a href=\"#Java日期对象-与-Joda-Time日期对象相互转换\" class=\"headerlink\" title=\"Java日期对象 与 Joda Time日期对象相互转换\"></a><code>Java</code>日期对象 与 <code>Joda Time</code>日期对象相互转换</h3><h4 id=\"毫秒-与-DateTime\"><a href=\"#毫秒-与-DateTime\" class=\"headerlink\" title=\"毫秒 与 DateTime\"></a>毫秒 与 DateTime</h4><p><strong>毫秒  =&gt;  DateTime</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">long</span> milliseconds <span class=\"token operator\">=</span> System<span class=\"token punctuation\">.</span><span class=\"token function\">currentTimeMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span>milliseconds<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p><strong>DateTime  =&gt;  毫秒</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\">DateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">long</span> milliseconds <span class=\"token operator\">=</span> dateTime<span class=\"token punctuation\">.</span><span class=\"token function\">getMillis</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h4 id=\"Date-与-DateTime\"><a href=\"#Date-与-DateTime\" class=\"headerlink\" title=\"Date 与 DateTime\"></a>Date 与 DateTime</h4><p><strong>Date  =&gt;  DateTime</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\">Date d <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Date</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p><strong>DateTime  =&gt;  Date</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\">DateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDate d <span class=\"token operator\">=</span> dateTime<span class=\"token punctuation\">.</span><span class=\"token function\">toDate</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h4 id=\"Calendar-与-DateTime\"><a href=\"#Calendar-与-DateTime\" class=\"headerlink\" title=\"Calendar 与 DateTime\"></a>Calendar 与 DateTime</h4><p><strong>Calendar  =&gt;  DateTime</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\">Calendar c <span class=\"token operator\">=</span> Calendar<span class=\"token punctuation\">.</span><span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p><strong>DateTime  =&gt;  Calendar</strong></p>\n<pre class=\" language-java\"><code class=\"language-java\">DateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nCalendar c <span class=\"token operator\">=</span> dateTime<span class=\"token punctuation\">.</span><span class=\"token function\">toCalendar</span><span class=\"token punctuation\">(</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"时间-gt-字符串-（时间转换字符串、时间格式化）\"><a href=\"#时间-gt-字符串-（时间转换字符串、时间格式化）\" class=\"headerlink\" title=\"时间 => 字符串 （时间转换字符串、时间格式化）\"></a>时间 =&gt; 字符串 （时间转换字符串、时间格式化）</h3><p><strong>第一种方式</strong> </p>\n<pre class=\" language-java\"><code class=\"language-java\">Date d <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Date</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndateTime<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span>\"yyyy<span class=\"token operator\">-</span>MM<span class=\"token operator\">-</span>dd HH<span class=\"token operator\">:</span>mm<span class=\"token operator\">:</span>ss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<p><strong>第二种方式</strong> </p>\n<pre class=\" language-java\"><code class=\"language-java\">Date d <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Date</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTime dateTime <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DateTime</span><span class=\"token punctuation\">(</span>d<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDateTimeFormatter formatter <span class=\"token operator\">=</span> DateTimeFormat<span class=\"token punctuation\">.</span><span class=\"token function\">forPattern</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"yyyy-MM-dd HH:mm:ss\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nformatter<span class=\"token punctuation\">.</span><span class=\"token function\">print</span><span class=\"token punctuation\">(</span>dateTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<h3 id=\"字符串-gt-时间\"><a href=\"#字符串-gt-时间\" class=\"headerlink\" title=\"字符串 => 时间\"></a>字符串 =&gt; 时间</h3><h3 id=\"日期计算\"><a href=\"#日期计算\" class=\"headerlink\" title=\"日期计算\"></a>日期计算</h3>","site":{"data":{}},"excerpt":"","more":"<p>官网：<a href=\"https://www.joda.org/joda-time/index.html\">https://www.joda.org/joda-time/index.html</a></p>\n<p>为啥用<code>Joda Time</code></p>\n<ul>\n<li><ol>\n<li>易于使用:Calendar让获取”正常的”的日期变得很困难，使它没办法提供简单的方法，而Joda-Time能够 直接进行访问域并且索引值1就是代表January。</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>易于扩展：JDK支持多日历系统是通过Calendar的子类来实现，这样就显示的非常笨重而且事实 上要实现其它日历系统是很困难的。Joda-Time支持多日历系统是通过基于Chronology类的插件体系来实现。</li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li>提供一组完整的功能：它打算提供 所有关系到date-time计算的功能．Joda-Time当前支持8种日历系统，而且在将来还会继续添加，有着比JDK Calendar更好的整体性能等等。</li>\n</ol>\n</li>\n<li></li>\n</ul>\n<blockquote>\n<p>大部分人使用<code>SimpleDateFormat</code>处理时间格式化过程，但是<code>SimpleDateFormat</code>存在并发问题。使用<code>Joda Time</code>替代</p>\n</blockquote>\n<h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><p>导入jar，地址： <a href=\"https://mvnrepository.com/artifact/joda-time\">https://mvnrepository.com/artifact/joda-time</a></p>\n<pre><code class=\"maven\">&lt;dependency&gt;\n    &lt;groupId&gt;joda-time&lt;/groupId&gt;\n    &lt;artifactId&gt;joda-time&lt;/artifactId&gt;\n    &lt;version&gt;2.10.3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h3 id=\"Java日期对象-与-Joda-Time日期对象相互转换\"><a href=\"#Java日期对象-与-Joda-Time日期对象相互转换\" class=\"headerlink\" title=\"Java日期对象 与 Joda Time日期对象相互转换\"></a><code>Java</code>日期对象 与 <code>Joda Time</code>日期对象相互转换</h3><h4 id=\"毫秒-与-DateTime\"><a href=\"#毫秒-与-DateTime\" class=\"headerlink\" title=\"毫秒 与 DateTime\"></a>毫秒 与 DateTime</h4><p><strong>毫秒  =&gt;  DateTime</strong></p>\n<pre><code class=\"java\">long milliseconds = System.currentTimeMillis();\nDateTime dateTime = new DateTime(milliseconds);\n</code></pre>\n<p><strong>DateTime  =&gt;  毫秒</strong></p>\n<pre><code class=\"java\">DateTime dateTime = new DateTime();\nlong milliseconds = dateTime.getMillis();\n</code></pre>\n<h4 id=\"Date-与-DateTime\"><a href=\"#Date-与-DateTime\" class=\"headerlink\" title=\"Date 与 DateTime\"></a>Date 与 DateTime</h4><p><strong>Date  =&gt;  DateTime</strong></p>\n<pre><code class=\"java\">Date d = new Date();\nDateTime dateTime = new DateTime(d);\n</code></pre>\n<p><strong>DateTime  =&gt;  Date</strong></p>\n<pre><code class=\"java\">DateTime dateTime = new DateTime();\nDate d = dateTime.toDate();\n</code></pre>\n<h4 id=\"Calendar-与-DateTime\"><a href=\"#Calendar-与-DateTime\" class=\"headerlink\" title=\"Calendar 与 DateTime\"></a>Calendar 与 DateTime</h4><p><strong>Calendar  =&gt;  DateTime</strong></p>\n<pre><code class=\"java\">Calendar c = Calendar.getInstance();\nDateTime dateTime = new DateTime(c);\n</code></pre>\n<p><strong>DateTime  =&gt;  Calendar</strong></p>\n<pre><code class=\"java\">DateTime dateTime = new DateTime();\nCalendar c = dateTime.toCalendar(null);\n</code></pre>\n<h3 id=\"时间-gt-字符串-（时间转换字符串、时间格式化）\"><a href=\"#时间-gt-字符串-（时间转换字符串、时间格式化）\" class=\"headerlink\" title=\"时间 =&gt; 字符串 （时间转换字符串、时间格式化）\"></a>时间 =&gt; 字符串 （时间转换字符串、时间格式化）</h3><p><strong>第一种方式</strong> </p>\n<pre><code class=\"java\">Date d = new Date();\nDateTime dateTime = new DateTime(d);\ndateTime.toString(&quot;yyyy-MM-dd HH:mm:ss);\n</code></pre>\n<p><strong>第二种方式</strong> </p>\n<pre><code class=\"java\">Date d = new Date();\nDateTime dateTime = new DateTime(d);\nDateTimeFormatter formatter = DateTimeFormat.forPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);\nformatter.print(dateTime);\n</code></pre>\n<h3 id=\"字符串-gt-时间\"><a href=\"#字符串-gt-时间\" class=\"headerlink\" title=\"字符串 =&gt; 时间\"></a>字符串 =&gt; 时间</h3><h3 id=\"日期计算\"><a href=\"#日期计算\" class=\"headerlink\" title=\"日期计算\"></a>日期计算</h3>"},{"title":"K近邻算法","date":"2018-11-13T02:25:59.000Z","_content":"\n\n\n\n<!-- more -->","source":"_posts/K近邻算法.md","raw":"---\ntitle: K近邻算法\ndate: 2018-11-13 10:25:59\ncategories: \n    - 机器学习\ntags: \n    - 算法\n    - 机器学习\n    - 监督学习\n    - KNN\n---\n\n\n\n\n<!-- more -->","slug":"K近邻算法","published":1,"updated":"2021-06-30T02:33:24.704Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswm005mr5p7eswp9yoe","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"Kafka安装","date":"2019-01-09T07:08:43.000Z","_content":"\n\n## 下载\n\n下载地址：http://kafka.apache.org/downloads\n\n\n## 安装\n\n\n\n### 单机\n#### 配置\n\n### 集群\n#### 配置\n\n\n### 启动\n\n\n\n<!-- more -->\n\n\n\n\n\n<br/>\n\n---\n\n参考\n官网：http://kafka.apache.org/","source":"_posts/Kafka安装.md","raw":"---\ntitle: Kafka安装\ndate: 2019-01-09 15:08:43\ncategories: \n    - Kafka\ntags:\n    - 消息队列\n    - Kafka\n---\n\n\n## 下载\n\n下载地址：http://kafka.apache.org/downloads\n\n\n## 安装\n\n\n\n### 单机\n#### 配置\n\n### 集群\n#### 配置\n\n\n### 启动\n\n\n\n<!-- more -->\n\n\n\n\n\n<br/>\n\n---\n\n参考\n官网：http://kafka.apache.org/","slug":"Kafka安装","published":1,"updated":"2021-06-30T02:33:24.703Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswn005rr5p79bip2adw","content":"<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"http://kafka.apache.org/downloads\">http://kafka.apache.org/downloads</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><h4 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h4><h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><span id=\"more\"></span>\n\n\n\n\n\n<br>\n\n<hr>\n<p>参考\n官网：<a href=\"http://kafka.apache.org/\">http://kafka.apache.org/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"http://kafka.apache.org/downloads\">http://kafka.apache.org/downloads</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><h4 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h4><h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><h4 id=\"配置-1\"><a href=\"#配置-1\" class=\"headerlink\" title=\"配置\"></a>配置</h4><h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3>","more":"<br/>\n\n<hr>\n<p>参考\n官网：<a href=\"http://kafka.apache.org/\">http://kafka.apache.org/</a></p>"},{"title":"LaTeX教程","date":"2012-09-02T01:01:01.000Z","_content":"\n\nLaTeX，是一种基于TEX的排版系统，由美国计算机科学家莱斯利·兰伯特在20世纪80年代初期开发，利用这种格式系统的处理，即使使用者没有排版和程序设计的知识也可以充分发挥由TEX所提供的强大功能，不必一一亲自去设计或校对，能在几天，甚至几小时内生成很多具有书籍品质的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、物理文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　—————摘自《维基百科》\n\n\n<!-- more -->\n\n<br/>\n\n---\n\n<br/>\n\nLaTeX 公式 必须要用 `$...$` 或者 `$$...$$` 包裹\n\n`$...$` 、`$$...$$` 区别：`$...$` 排版在左边，`$$...$$` 排版在中间，如：\n\n``` markdown\n$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$\n```\n$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$\n\n\n<br/>\n\n``` markdown\n$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$\n```\n$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$\n\n\n<br/>\n\n### 分数 \\frac{a}{b}\n\n``` bash\n# a：分子，b：分母\n$\\frac{a}{b}$\n```\n$$【例】\\frac{a}{b}$$\n\n<br/>\n### 指数 a^{b}\n\n``` bash\n$a^{b}$\n```\n\n\n<br/>\n### 根号 \\sqrt{a}\n``` bash\n$\\sqrt{a}$\n```\n\n\n\n<br/>\n### 根号 \\sqrt[n]{a}\n``` bash\n$\\sqrt[n]{a}$\n```\n\n\n<br/>\n### 极限 \\lim\\limits_{x \\to \\infty}\n``` bash\n$\\lim\\limits_{x\\to\\infty}$\n```\n$【例】\\lim\\limits_{x \\to 0}$\n$【例】\\lim\\limits_{x \\to \\infty}$\n\n\n<br/>\n### 对数 \\log_{b}{a}\n``` bash\n$\\log_{b}{a}$\n```\n$【例】\\log_{b}{a}$\n\n<br/>\n### 和 \\sum \\limits_{n=0}^{\\infty}\n``` bash\n$\\sum \\limits_{n=0}^{\\infty}$\n```\n$【例】\\sum \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\prod \\limits_{n=0}^{\\infty}\n``` bash\n$\\prod \\limits_{n=0}^{\\infty}$\n```\n$【例】\\prod \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n$【例】\\int_{a}^{b}$\n\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n\n\nbr/>\n### 函数定义 \\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}\n``` bash\n\\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}\n```\n$【例】\\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}$\n\n---\n参考\n\n[mathjax-basic-tutorial-and-quick-reference](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)\n[mathjax-latex-basic-tutorial-und-referenz-deutsch](https://www.mathelounge.de/509545/mathjax-latex-basic-tutorial-und-referenz-deutsch)\n[在线编辑LaTeX](https://www.matheretter.de/rechner/latex/)","source":"_posts/LaTeX教程.md","raw":"---\ntitle: LaTeX教程\ndate: 2012-09-02 09:01:01\ncategories:\n    - LaTeX\ntags:\n    - LaTeX\n    - 公式\n---\n\n\nLaTeX，是一种基于TEX的排版系统，由美国计算机科学家莱斯利·兰伯特在20世纪80年代初期开发，利用这种格式系统的处理，即使使用者没有排版和程序设计的知识也可以充分发挥由TEX所提供的强大功能，不必一一亲自去设计或校对，能在几天，甚至几小时内生成很多具有书籍品质的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、物理文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　—————摘自《维基百科》\n\n\n<!-- more -->\n\n<br/>\n\n---\n\n<br/>\n\nLaTeX 公式 必须要用 `$...$` 或者 `$$...$$` 包裹\n\n`$...$` 、`$$...$$` 区别：`$...$` 排版在左边，`$$...$$` 排版在中间，如：\n\n``` markdown\n$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$\n```\n$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$\n\n\n<br/>\n\n``` markdown\n$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$\n```\n$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$\n\n\n<br/>\n\n### 分数 \\frac{a}{b}\n\n``` bash\n# a：分子，b：分母\n$\\frac{a}{b}$\n```\n$$【例】\\frac{a}{b}$$\n\n<br/>\n### 指数 a^{b}\n\n``` bash\n$a^{b}$\n```\n\n\n<br/>\n### 根号 \\sqrt{a}\n``` bash\n$\\sqrt{a}$\n```\n\n\n\n<br/>\n### 根号 \\sqrt[n]{a}\n``` bash\n$\\sqrt[n]{a}$\n```\n\n\n<br/>\n### 极限 \\lim\\limits_{x \\to \\infty}\n``` bash\n$\\lim\\limits_{x\\to\\infty}$\n```\n$【例】\\lim\\limits_{x \\to 0}$\n$【例】\\lim\\limits_{x \\to \\infty}$\n\n\n<br/>\n### 对数 \\log_{b}{a}\n``` bash\n$\\log_{b}{a}$\n```\n$【例】\\log_{b}{a}$\n\n<br/>\n### 和 \\sum \\limits_{n=0}^{\\infty}\n``` bash\n$\\sum \\limits_{n=0}^{\\infty}$\n```\n$【例】\\sum \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\prod \\limits_{n=0}^{\\infty}\n``` bash\n$\\prod \\limits_{n=0}^{\\infty}$\n```\n$【例】\\prod \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n$【例】\\int_{a}^{b}$\n\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n\n\nbr/>\n### 函数定义 \\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}\n``` bash\n\\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}\n```\n$【例】\\begin{cases} xx & 描述 \\\\\\ 0 & 描述 \\end{cases}$\n\n---\n参考\n\n[mathjax-basic-tutorial-and-quick-reference](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)\n[mathjax-latex-basic-tutorial-und-referenz-deutsch](https://www.mathelounge.de/509545/mathjax-latex-basic-tutorial-und-referenz-deutsch)\n[在线编辑LaTeX](https://www.matheretter.de/rechner/latex/)","slug":"LaTeX教程","published":1,"updated":"2021-06-30T02:33:24.704Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswn005tr5p7f1qua03j","content":"<p>LaTeX，是一种基于TEX的排版系统，由美国计算机科学家莱斯利·兰伯特在20世纪80年代初期开发，利用这种格式系统的处理，即使使用者没有排版和程序设计的知识也可以充分发挥由TEX所提供的强大功能，不必一一亲自去设计或校对，能在几天，甚至几小时内生成很多具有书籍品质的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、物理文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　—————摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n<br>\n\n<hr>\n<br>\n\n<p>LaTeX 公式 必须要用 <code>$...$</code> 或者 <code>$$...$$</code> 包裹</p>\n<p><code>$...$</code> 、<code>$$...$$</code> 区别：<code>$...$</code> 排版在左边，<code>$$...$$</code> 排版在中间，如：</p>\n<pre class=\" language-markdown\"><code class=\"language-markdown\">$H(X)=-\\sum<span class=\"token italic\"><span class=\"token punctuation\">_</span>{i=0} P(X<span class=\"token punctuation\">_</span></span>{i}) \\log<span class=\"token italic\"><span class=\"token punctuation\">_</span>b P(X<span class=\"token punctuation\">_</span></span>{i})$\n</code></pre>\n<p>$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$</p>\n<br>\n\n<pre class=\" language-markdown\"><code class=\"language-markdown\">$$H(X)=-\\sum<span class=\"token italic\"><span class=\"token punctuation\">_</span>{i=0} P(X<span class=\"token punctuation\">_</span></span>{i}) \\log<span class=\"token italic\"><span class=\"token punctuation\">_</span>b P(X<span class=\"token punctuation\">_</span></span>{i})$$\n</code></pre>\n<p>$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$</p>\n<br>\n\n<h3 id=\"分数-frac-a-b\"><a href=\"#分数-frac-a-b\" class=\"headerlink\" title=\"分数 \\frac{a}{b}\"></a>分数 \\frac{a}{b}</h3><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># a：分子，b：分母</span>\n$\\frac<span class=\"token punctuation\">{</span>a<span class=\"token punctuation\">}</span><span class=\"token punctuation\">{</span>b<span class=\"token punctuation\">}</span>$\n</code></pre>\n<p>$$【例】\\frac{a}{b}$$</p>\n<br>\n### 指数 a^{b}\n\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token variable\">$a</span>^<span class=\"token punctuation\">{</span>b<span class=\"token punctuation\">}</span>$\n</code></pre>\n<br>\n### 根号 \\sqrt{a}\n``` bash\n$\\sqrt{a}$\n```\n\n\n\n<br>\n### 根号 \\sqrt[n]{a}\n``` bash\n$\\sqrt[n]{a}$\n```\n\n\n<br>\n### 极限 \\lim\\limits_{x \\to \\infty}\n``` bash\n$\\lim\\limits_{x\\to\\infty}$\n```\n$【例】\\lim\\limits_{x \\to 0}$\n$【例】\\lim\\limits_{x \\to \\infty}$\n\n\n<br>\n### 对数 \\log_{b}{a}\n``` bash\n$\\log_{b}{a}$\n```\n$【例】\\log_{b}{a}$\n\n<br>\n### 和 \\sum \\limits_{n=0}^{\\infty}\n``` bash\n$\\sum \\limits_{n=0}^{\\infty}$\n```\n$【例】\\sum \\limits_{n=0}^{\\infty}$\n\n\n\n<br>\n### 和 \\prod \\limits_{n=0}^{\\infty}\n``` bash\n$\\prod \\limits_{n=0}^{\\infty}$\n```\n$【例】\\prod \\limits_{n=0}^{\\infty}$\n\n\n\n<br>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n$【例】\\int_{a}^{b}$\n\n\n\n\n<br>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n\n\n<p>br/&gt;</p>\n<h3 id=\"函数定义-begin-cases-xx-amp-描述-0-amp-描述-end-cases\"><a href=\"#函数定义-begin-cases-xx-amp-描述-0-amp-描述-end-cases\" class=\"headerlink\" title=\"函数定义 \\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}\"></a>函数定义 \\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}</h3><pre class=\" language-bash\"><code class=\"language-bash\">\\begin<span class=\"token punctuation\">{</span>cases<span class=\"token punctuation\">}</span> xx <span class=\"token operator\">&amp;</span> 描述 \\\\\\ 0 <span class=\"token operator\">&amp;</span> 描述 \\end<span class=\"token punctuation\">{</span>cases<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>$【例】\\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}$</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference\">mathjax-basic-tutorial-and-quick-reference</a>\n<a href=\"https://www.mathelounge.de/509545/mathjax-latex-basic-tutorial-und-referenz-deutsch\">mathjax-latex-basic-tutorial-und-referenz-deutsch</a>\n<a href=\"https://www.matheretter.de/rechner/latex/\">在线编辑LaTeX</a></p>\n","site":{"data":{}},"excerpt":"<p>LaTeX，是一种基于TEX的排版系统，由美国计算机科学家莱斯利·兰伯特在20世纪80年代初期开发，利用这种格式系统的处理，即使使用者没有排版和程序设计的知识也可以充分发挥由TEX所提供的强大功能，不必一一亲自去设计或校对，能在几天，甚至几小时内生成很多具有书籍品质的印刷品。对于生成复杂表格和数学公式，这一点表现得尤为突出。因此它非常适用于生成高印刷质量的科技和数学、物理文档。这个系统同样适用于生成从简单的信件到完整书籍的所有其他种类的文档。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　—————摘自《维基百科》</p>","more":"<br/>\n\n<hr>\n<br/>\n\n<p>LaTeX 公式 必须要用 <code>$...$</code> 或者 <code>$$...$$</code> 包裹</p>\n<p><code>$...$</code> 、<code>$$...$$</code> 区别：<code>$...$</code> 排版在左边，<code>$$...$$</code> 排版在中间，如：</p>\n<pre><code class=\"markdown\">$H(X)=-\\sum_&#123;i=0&#125; P(X_&#123;i&#125;) \\log_b P(X_&#123;i&#125;)$\n</code></pre>\n<p>$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$</p>\n<br/>\n\n<pre><code class=\"markdown\">$$H(X)=-\\sum_&#123;i=0&#125; P(X_&#123;i&#125;) \\log_b P(X_&#123;i&#125;)$$\n</code></pre>\n<p>$$H(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})$$</p>\n<br/>\n\n<h3 id=\"分数-frac-a-b\"><a href=\"#分数-frac-a-b\" class=\"headerlink\" title=\"分数 \\frac{a}{b}\"></a>分数 \\frac{a}{b}</h3><pre><code class=\"bash\"># a：分子，b：分母\n$\\frac&#123;a&#125;&#123;b&#125;$\n</code></pre>\n<p>$$【例】\\frac{a}{b}$$</p>\n<br/>\n### 指数 a^{b}\n\n<pre><code class=\"bash\">$a^&#123;b&#125;$\n</code></pre>\n<br/>\n### 根号 \\sqrt{a}\n``` bash\n$\\sqrt{a}$\n```\n\n\n\n<br/>\n### 根号 \\sqrt[n]{a}\n``` bash\n$\\sqrt[n]{a}$\n```\n\n\n<br/>\n### 极限 \\lim\\limits_{x \\to \\infty}\n``` bash\n$\\lim\\limits_{x\\to\\infty}$\n```\n$【例】\\lim\\limits_{x \\to 0}$\n$【例】\\lim\\limits_{x \\to \\infty}$\n\n\n<br/>\n### 对数 \\log_{b}{a}\n``` bash\n$\\log_{b}{a}$\n```\n$【例】\\log_{b}{a}$\n\n<br/>\n### 和 \\sum \\limits_{n=0}^{\\infty}\n``` bash\n$\\sum \\limits_{n=0}^{\\infty}$\n```\n$【例】\\sum \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\prod \\limits_{n=0}^{\\infty}\n``` bash\n$\\prod \\limits_{n=0}^{\\infty}$\n```\n$【例】\\prod \\limits_{n=0}^{\\infty}$\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n$【例】\\int_{a}^{b}$\n\n\n\n\n<br/>\n### 和 \\int_{a}^{b}\n``` bash\n$\\int_{a}^{b}$\n```\n\n\n<p>br/&gt;</p>\n<h3 id=\"函数定义-begin-cases-xx-amp-描述-0-amp-描述-end-cases\"><a href=\"#函数定义-begin-cases-xx-amp-描述-0-amp-描述-end-cases\" class=\"headerlink\" title=\"函数定义 \\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}\"></a>函数定义 \\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}</h3><pre><code class=\"bash\">\\begin&#123;cases&#125; xx &amp; 描述 \\\\\\ 0 &amp; 描述 \\end&#123;cases&#125;\n</code></pre>\n<p>$【例】\\begin{cases} xx &amp; 描述 \\\\ 0 &amp; 描述 \\end{cases}$</p>\n<hr>\n<p>参考</p>\n<p><a href=\"https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference\">mathjax-basic-tutorial-and-quick-reference</a>\n<a href=\"https://www.mathelounge.de/509545/mathjax-latex-basic-tutorial-und-referenz-deutsch\">mathjax-latex-basic-tutorial-und-referenz-deutsch</a>\n<a href=\"https://www.matheretter.de/rechner/latex/\">在线编辑LaTeX</a></p>"},{"title":"Linux","date":"2021-07-16T02:02:44.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：汇总Linux使用和命令，方便后续使用查阅\n\n\n# 命令\n","source":"_posts/Linux.md","raw":"---\ntitle: Linux\ndate: 2021-07-16 10:02:44\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java在Mac系统中的开发环境配置\ncategories:\n    - [Linux]\ntags:\n    - Linux\n---\n\n> 摘要：汇总Linux使用和命令，方便后续使用查阅\n\n\n# 命令\n","slug":"Linux","published":1,"updated":"2021-07-16T02:04:08.380Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswo005yr5p722n44n4j","content":"<blockquote>\n<p>摘要：汇总Linux使用和命令，方便后续使用查阅</p>\n</blockquote>\n<h1 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h1>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：汇总Linux使用和命令，方便后续使用查阅</p>\n</blockquote>\n<h1 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h1>"},{"title":"Mac","date":"2012-07-15T00:00:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：汇总Mac 配置、使用和效率工具，方便后续使用查阅\n\n\n## 命令\n\n---\n \n## 效率工具\n\n### Homebrew\nmacOS（或 Linux）缺失的软件包的管理器：{% post_link Homebrew Homebrew汇总 %}\n\n### iTerm2\niTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能：{% post_link iTerm2 iTerm2汇总 %}\n\n### lrzsz\n`lrzsz` 是 zmodem/xmodem/ymodem 文件传输 {% post_link lrzsz lrzsz汇总 %}\n\n### Alfred\n通过热键、关键字、文本扩展等提高您的效率。 搜索您的 Mac 和网络，并通过自定义操作来控制您的 Mac 提高工作效率：https://www.alfredapp.com/\n\n---\n\n## 常用软件\n\n### Sequel Pro\nMySQL链接客户端：https://sequelpro.com/\n\n### XMind\n思维导图：https://www.xmind.cn/\n\n### Axure RP\nUX 专业人员能够构建逼真的功能原型的 UX 工具：https://www.axure.com/\n\n### Charles\n一个 HTTP 代理/HTTP 监视器/反向代理，它使开发人员能够查看他们的机器和 Internet 之间的所有 HTTP 和 SSL/HTTPS 流量：https://www.charlesproxy.com/","source":"_posts/Mac.md","raw":"---\ntitle: Mac\ndate: 2012-07-15 08:00:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java在Mac系统中的开发环境配置\ncategories:\n    - [Mac]\ntags:\n    - Mac\n---\n\n> 摘要：汇总Mac 配置、使用和效率工具，方便后续使用查阅\n\n\n## 命令\n\n---\n \n## 效率工具\n\n### Homebrew\nmacOS（或 Linux）缺失的软件包的管理器：{% post_link Homebrew Homebrew汇总 %}\n\n### iTerm2\niTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能：{% post_link iTerm2 iTerm2汇总 %}\n\n### lrzsz\n`lrzsz` 是 zmodem/xmodem/ymodem 文件传输 {% post_link lrzsz lrzsz汇总 %}\n\n### Alfred\n通过热键、关键字、文本扩展等提高您的效率。 搜索您的 Mac 和网络，并通过自定义操作来控制您的 Mac 提高工作效率：https://www.alfredapp.com/\n\n---\n\n## 常用软件\n\n### Sequel Pro\nMySQL链接客户端：https://sequelpro.com/\n\n### XMind\n思维导图：https://www.xmind.cn/\n\n### Axure RP\nUX 专业人员能够构建逼真的功能原型的 UX 工具：https://www.axure.com/\n\n### Charles\n一个 HTTP 代理/HTTP 监视器/反向代理，它使开发人员能够查看他们的机器和 Internet 之间的所有 HTTP 和 SSL/HTTPS 流量：https://www.charlesproxy.com/","slug":"Mac","published":1,"updated":"2021-07-18T04:42:52.679Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswp0061r5p7gamd7u9h","content":"<blockquote>\n<p>摘要：汇总Mac 配置、使用和效率工具，方便后续使用查阅</p>\n</blockquote>\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><hr>\n<h2 id=\"效率工具\"><a href=\"#效率工具\" class=\"headerlink\" title=\"效率工具\"></a>效率工具</h2><h3 id=\"Homebrew\"><a href=\"#Homebrew\" class=\"headerlink\" title=\"Homebrew\"></a>Homebrew</h3><p>macOS（或 Linux）缺失的软件包的管理器：<a href=\"/2012/07/15/homebrew/\" title=\"Homebrew汇总\">Homebrew汇总</a></p>\n<h3 id=\"iTerm2\"><a href=\"#iTerm2\" class=\"headerlink\" title=\"iTerm2\"></a>iTerm2</h3><p>iTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能：<a href=\"/2012/07/15/iterm2/\" title=\"iTerm2汇总\">iTerm2汇总</a></p>\n<h3 id=\"lrzsz\"><a href=\"#lrzsz\" class=\"headerlink\" title=\"lrzsz\"></a>lrzsz</h3><p><code>lrzsz</code> 是 zmodem/xmodem/ymodem 文件传输 <a href=\"/2015/08/30/lrzsz/\" title=\"lrzsz汇总\">lrzsz汇总</a></p>\n<h3 id=\"Alfred\"><a href=\"#Alfred\" class=\"headerlink\" title=\"Alfred\"></a>Alfred</h3><p>通过热键、关键字、文本扩展等提高您的效率。 搜索您的 Mac 和网络，并通过自定义操作来控制您的 Mac 提高工作效率：<a href=\"https://www.alfredapp.com/\">https://www.alfredapp.com/</a></p>\n<hr>\n<h2 id=\"常用软件\"><a href=\"#常用软件\" class=\"headerlink\" title=\"常用软件\"></a>常用软件</h2><h3 id=\"Sequel-Pro\"><a href=\"#Sequel-Pro\" class=\"headerlink\" title=\"Sequel Pro\"></a>Sequel Pro</h3><p>MySQL链接客户端：<a href=\"https://sequelpro.com/\">https://sequelpro.com/</a></p>\n<h3 id=\"XMind\"><a href=\"#XMind\" class=\"headerlink\" title=\"XMind\"></a>XMind</h3><p>思维导图：<a href=\"https://www.xmind.cn/\">https://www.xmind.cn/</a></p>\n<h3 id=\"Axure-RP\"><a href=\"#Axure-RP\" class=\"headerlink\" title=\"Axure RP\"></a>Axure RP</h3><p>UX 专业人员能够构建逼真的功能原型的 UX 工具：<a href=\"https://www.axure.com/\">https://www.axure.com/</a></p>\n<h3 id=\"Charles\"><a href=\"#Charles\" class=\"headerlink\" title=\"Charles\"></a>Charles</h3><p>一个 HTTP 代理/HTTP 监视器/反向代理，它使开发人员能够查看他们的机器和 Internet 之间的所有 HTTP 和 SSL/HTTPS 流量：<a href=\"https://www.charlesproxy.com/\">https://www.charlesproxy.com/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：汇总Mac 配置、使用和效率工具，方便后续使用查阅</p>\n</blockquote>\n<h2 id=\"命令\"><a href=\"#命令\" class=\"headerlink\" title=\"命令\"></a>命令</h2><hr>\n<h2 id=\"效率工具\"><a href=\"#效率工具\" class=\"headerlink\" title=\"效率工具\"></a>效率工具</h2><h3 id=\"Homebrew\"><a href=\"#Homebrew\" class=\"headerlink\" title=\"Homebrew\"></a>Homebrew</h3><p>macOS（或 Linux）缺失的软件包的管理器：<a href=\"/2012/07/15/homebrew/\" title=\"Homebrew汇总\">Homebrew汇总</a></p>\n<h3 id=\"iTerm2\"><a href=\"#iTerm2\" class=\"headerlink\" title=\"iTerm2\"></a>iTerm2</h3><p>iTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能：<a href=\"/2012/07/15/iterm2/\" title=\"iTerm2汇总\">iTerm2汇总</a></p>\n<h3 id=\"lrzsz\"><a href=\"#lrzsz\" class=\"headerlink\" title=\"lrzsz\"></a>lrzsz</h3><p><code>lrzsz</code> 是 zmodem/xmodem/ymodem 文件传输 <a href=\"/2015/08/30/lrzsz/\" title=\"lrzsz汇总\">lrzsz汇总</a></p>\n<h3 id=\"Alfred\"><a href=\"#Alfred\" class=\"headerlink\" title=\"Alfred\"></a>Alfred</h3><p>通过热键、关键字、文本扩展等提高您的效率。 搜索您的 Mac 和网络，并通过自定义操作来控制您的 Mac 提高工作效率：<a href=\"https://www.alfredapp.com/\">https://www.alfredapp.com/</a></p>\n<hr>\n<h2 id=\"常用软件\"><a href=\"#常用软件\" class=\"headerlink\" title=\"常用软件\"></a>常用软件</h2><h3 id=\"Sequel-Pro\"><a href=\"#Sequel-Pro\" class=\"headerlink\" title=\"Sequel Pro\"></a>Sequel Pro</h3><p>MySQL链接客户端：<a href=\"https://sequelpro.com/\">https://sequelpro.com/</a></p>\n<h3 id=\"XMind\"><a href=\"#XMind\" class=\"headerlink\" title=\"XMind\"></a>XMind</h3><p>思维导图：<a href=\"https://www.xmind.cn/\">https://www.xmind.cn/</a></p>\n<h3 id=\"Axure-RP\"><a href=\"#Axure-RP\" class=\"headerlink\" title=\"Axure RP\"></a>Axure RP</h3><p>UX 专业人员能够构建逼真的功能原型的 UX 工具：<a href=\"https://www.axure.com/\">https://www.axure.com/</a></p>\n<h3 id=\"Charles\"><a href=\"#Charles\" class=\"headerlink\" title=\"Charles\"></a>Charles</h3><p>一个 HTTP 代理/HTTP 监视器/反向代理，它使开发人员能够查看他们的机器和 Internet 之间的所有 HTTP 和 SSL/HTTPS 流量：<a href=\"https://www.charlesproxy.com/\">https://www.charlesproxy.com/</a></p>\n"},{"title":"Markdown教程","date":"2012-08-31T17:01:01.000Z","_content":"\n<br/>\n### 标题\n\n\n<br/>\n### 表格\n\n<!-- more -->\n\n\n<br/>\n### 换行 `<br/>`\n\n在md文件中输入`<br/>`换行\n\n\n\n<br/>\n### 代码高亮显示语言\n\n\n| 名称\t|关键字\t|调用的js\t|说明   |\n| :--------   | :-----  | :----  | :---- |\n| AppleScript |\tapplescript\t| shBrushAppleScript.js\t| - |\n| ActionScript 3.0\t| actionscript3 , as3\t| shBrushAS3.js | - |\n| Shell |\tbash , shell\t| shBrushBash.js\t| - |\n| ColdFusion |\tcoldfusion , cf\t| shBrushColdFusion.js\t| - |\n| C\t| cpp , c\t| shBrushCpp.js\t| - |\n| C#\t| c# , c-sharp , csharp\t| shBrushCSharp.js\t| - |\n| CSS\t|css | shBrushCss.js\t| - |\n| Delphi\t| delphi , pascal , pas\t| shBrushDelphi.js\t| - |\n| diff&patch |\tdiff patch | shBrushDiff.js\t| 用代码版本库时,遇到代码冲突,其语法就是这个. |\n| Erlang |\terl , erlang\t| shBrushErlang.js\t| - |\n| Groovy |\tgroovy\t| shBrushGroovy.js\t| - |\n| Java |\tjava\t| shBrushJava.js\t| - |\n| JavaFX |\tjfx , javafx\t| shBrushJavaFX.js\t| - |\n| JavaScript |\tjs , jscript , javascript\t| shBrushJScript.js\t| - |\n| Perl |\tperl , pl , Perl\t| shBrushPerl.js\t| - |\n| PHP |\tphp\t| shBrushPhp.js\t\n| text |\ttext , plain\t| shBrushPlain.js\t| 就是普通文本.|\n| Python |\tpy , python\t| shBrushPython.js\t|\n| Ruby |\truby , rails , ror , rb |\tshBrushRuby.js\t| - |\n| SASS&SCSS\tsass , scss\t| shBrushSass.js | - |\n| Scala |\tscala\t| shBrushScala.js\t| - |\n| SQL |\tsql\t| shBrushSql.js\t|\n| Visual Basic\t| vb , vbnet\t| shBrushVb.js\t| - |\n| XML |\txml , xhtml , xslt , html\t| shBrushXml.js\t| - |\n| Objective C\t| objc , obj-c\t| shBrushObjectiveC.js\t| - |\n| F# |\tf# f-sharp , fsharp\t| shBrushFSharp.js\t| - |\n| - | xpp , dynamics-xpp\t| shBrushDynamics.js\t| - |\n| R\t| r , s , splus\t| shBrushR.js\t| - |\n| matlab |\tmatlab\t| shBrushMatlab.js | - |\t\n| swift |\tswift\t| shBrushSwift.js\t | - |\n| GO |\tgo , golang\t| shBrushGo.js\t | - |\n\n\n\n\n<br/>\n\n----\n参考\n\n[Github-Markdown](https://guides.github.com/features/mastering-markdown/)","source":"_posts/Markdown教程.md","raw":"---\ntitle: Markdown教程\ndate: 2012-09-01 01:01:01\ncategories: \n    - Markdown\ntags: \n    - Markdown\n---\n\n<br/>\n### 标题\n\n\n<br/>\n### 表格\n\n<!-- more -->\n\n\n<br/>\n### 换行 `<br/>`\n\n在md文件中输入`<br/>`换行\n\n\n\n<br/>\n### 代码高亮显示语言\n\n\n| 名称\t|关键字\t|调用的js\t|说明   |\n| :--------   | :-----  | :----  | :---- |\n| AppleScript |\tapplescript\t| shBrushAppleScript.js\t| - |\n| ActionScript 3.0\t| actionscript3 , as3\t| shBrushAS3.js | - |\n| Shell |\tbash , shell\t| shBrushBash.js\t| - |\n| ColdFusion |\tcoldfusion , cf\t| shBrushColdFusion.js\t| - |\n| C\t| cpp , c\t| shBrushCpp.js\t| - |\n| C#\t| c# , c-sharp , csharp\t| shBrushCSharp.js\t| - |\n| CSS\t|css | shBrushCss.js\t| - |\n| Delphi\t| delphi , pascal , pas\t| shBrushDelphi.js\t| - |\n| diff&patch |\tdiff patch | shBrushDiff.js\t| 用代码版本库时,遇到代码冲突,其语法就是这个. |\n| Erlang |\terl , erlang\t| shBrushErlang.js\t| - |\n| Groovy |\tgroovy\t| shBrushGroovy.js\t| - |\n| Java |\tjava\t| shBrushJava.js\t| - |\n| JavaFX |\tjfx , javafx\t| shBrushJavaFX.js\t| - |\n| JavaScript |\tjs , jscript , javascript\t| shBrushJScript.js\t| - |\n| Perl |\tperl , pl , Perl\t| shBrushPerl.js\t| - |\n| PHP |\tphp\t| shBrushPhp.js\t\n| text |\ttext , plain\t| shBrushPlain.js\t| 就是普通文本.|\n| Python |\tpy , python\t| shBrushPython.js\t|\n| Ruby |\truby , rails , ror , rb |\tshBrushRuby.js\t| - |\n| SASS&SCSS\tsass , scss\t| shBrushSass.js | - |\n| Scala |\tscala\t| shBrushScala.js\t| - |\n| SQL |\tsql\t| shBrushSql.js\t|\n| Visual Basic\t| vb , vbnet\t| shBrushVb.js\t| - |\n| XML |\txml , xhtml , xslt , html\t| shBrushXml.js\t| - |\n| Objective C\t| objc , obj-c\t| shBrushObjectiveC.js\t| - |\n| F# |\tf# f-sharp , fsharp\t| shBrushFSharp.js\t| - |\n| - | xpp , dynamics-xpp\t| shBrushDynamics.js\t| - |\n| R\t| r , s , splus\t| shBrushR.js\t| - |\n| matlab |\tmatlab\t| shBrushMatlab.js | - |\t\n| swift |\tswift\t| shBrushSwift.js\t | - |\n| GO |\tgo , golang\t| shBrushGo.js\t | - |\n\n\n\n\n<br/>\n\n----\n参考\n\n[Github-Markdown](https://guides.github.com/features/mastering-markdown/)","slug":"Markdown教程","published":1,"updated":"2021-06-30T02:33:24.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswr0067r5p71pqg2p5y","content":"<br>\n### 标题\n\n\n<br>\n### 表格\n\n<span id=\"more\"></span>\n\n\n<br>\n### 换行 `<br>`\n\n<p>在md文件中输入<code>&lt;br/&gt;</code>换行</p>\n<br>\n### 代码高亮显示语言\n\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">名称</th>\n<th align=\"left\">关键字</th>\n<th align=\"left\">调用的js</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">AppleScript</td>\n<td align=\"left\">applescript</td>\n<td align=\"left\">shBrushAppleScript.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">ActionScript 3.0</td>\n<td align=\"left\">actionscript3 , as3</td>\n<td align=\"left\">shBrushAS3.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Shell</td>\n<td align=\"left\">bash , shell</td>\n<td align=\"left\">shBrushBash.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">ColdFusion</td>\n<td align=\"left\">coldfusion , cf</td>\n<td align=\"left\">shBrushColdFusion.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">cpp , c</td>\n<td align=\"left\">shBrushCpp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">C#</td>\n<td align=\"left\">c# , c-sharp , csharp</td>\n<td align=\"left\">shBrushCSharp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">CSS</td>\n<td align=\"left\">css</td>\n<td align=\"left\">shBrushCss.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Delphi</td>\n<td align=\"left\">delphi , pascal , pas</td>\n<td align=\"left\">shBrushDelphi.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">diff&amp;patch</td>\n<td align=\"left\">diff patch</td>\n<td align=\"left\">shBrushDiff.js</td>\n<td align=\"left\">用代码版本库时,遇到代码冲突,其语法就是这个.</td>\n</tr>\n<tr>\n<td align=\"left\">Erlang</td>\n<td align=\"left\">erl , erlang</td>\n<td align=\"left\">shBrushErlang.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Groovy</td>\n<td align=\"left\">groovy</td>\n<td align=\"left\">shBrushGroovy.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Java</td>\n<td align=\"left\">java</td>\n<td align=\"left\">shBrushJava.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">JavaFX</td>\n<td align=\"left\">jfx , javafx</td>\n<td align=\"left\">shBrushJavaFX.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">JavaScript</td>\n<td align=\"left\">js , jscript , javascript</td>\n<td align=\"left\">shBrushJScript.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Perl</td>\n<td align=\"left\">perl , pl , Perl</td>\n<td align=\"left\">shBrushPerl.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">PHP</td>\n<td align=\"left\">php</td>\n<td align=\"left\">shBrushPhp.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">text</td>\n<td align=\"left\">text , plain</td>\n<td align=\"left\">shBrushPlain.js</td>\n<td align=\"left\">就是普通文本.</td>\n</tr>\n<tr>\n<td align=\"left\">Python</td>\n<td align=\"left\">py , python</td>\n<td align=\"left\">shBrushPython.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Ruby</td>\n<td align=\"left\">ruby , rails , ror , rb</td>\n<td align=\"left\">shBrushRuby.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">SASS&amp;SCSS    sass , scss</td>\n<td align=\"left\">shBrushSass.js</td>\n<td align=\"left\">-</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Scala</td>\n<td align=\"left\">scala</td>\n<td align=\"left\">shBrushScala.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">SQL</td>\n<td align=\"left\">sql</td>\n<td align=\"left\">shBrushSql.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Visual Basic</td>\n<td align=\"left\">vb , vbnet</td>\n<td align=\"left\">shBrushVb.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">XML</td>\n<td align=\"left\">xml , xhtml , xslt , html</td>\n<td align=\"left\">shBrushXml.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Objective C</td>\n<td align=\"left\">objc , obj-c</td>\n<td align=\"left\">shBrushObjectiveC.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">F#</td>\n<td align=\"left\">f# f-sharp , fsharp</td>\n<td align=\"left\">shBrushFSharp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">-</td>\n<td align=\"left\">xpp , dynamics-xpp</td>\n<td align=\"left\">shBrushDynamics.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">R</td>\n<td align=\"left\">r , s , splus</td>\n<td align=\"left\">shBrushR.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">matlab</td>\n<td align=\"left\">matlab</td>\n<td align=\"left\">shBrushMatlab.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">swift</td>\n<td align=\"left\">swift</td>\n<td align=\"left\">shBrushSwift.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">GO</td>\n<td align=\"left\">go , golang</td>\n<td align=\"left\">shBrushGo.js</td>\n<td align=\"left\">-</td>\n</tr>\n</tbody></table>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://guides.github.com/features/mastering-markdown/\">Github-Markdown</a></p>\n","site":{"data":{}},"excerpt":"<br>\n### 标题\n\n\n<br>\n### 表格","more":"<br/>\n### 换行 `<br/>`\n\n<p>在md文件中输入<code>&lt;br/&gt;</code>换行</p>\n<br/>\n### 代码高亮显示语言\n\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">名称</th>\n<th align=\"left\">关键字</th>\n<th align=\"left\">调用的js</th>\n<th align=\"left\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">AppleScript</td>\n<td align=\"left\">applescript</td>\n<td align=\"left\">shBrushAppleScript.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">ActionScript 3.0</td>\n<td align=\"left\">actionscript3 , as3</td>\n<td align=\"left\">shBrushAS3.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Shell</td>\n<td align=\"left\">bash , shell</td>\n<td align=\"left\">shBrushBash.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">ColdFusion</td>\n<td align=\"left\">coldfusion , cf</td>\n<td align=\"left\">shBrushColdFusion.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">C</td>\n<td align=\"left\">cpp , c</td>\n<td align=\"left\">shBrushCpp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">C#</td>\n<td align=\"left\">c# , c-sharp , csharp</td>\n<td align=\"left\">shBrushCSharp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">CSS</td>\n<td align=\"left\">css</td>\n<td align=\"left\">shBrushCss.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Delphi</td>\n<td align=\"left\">delphi , pascal , pas</td>\n<td align=\"left\">shBrushDelphi.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">diff&amp;patch</td>\n<td align=\"left\">diff patch</td>\n<td align=\"left\">shBrushDiff.js</td>\n<td align=\"left\">用代码版本库时,遇到代码冲突,其语法就是这个.</td>\n</tr>\n<tr>\n<td align=\"left\">Erlang</td>\n<td align=\"left\">erl , erlang</td>\n<td align=\"left\">shBrushErlang.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Groovy</td>\n<td align=\"left\">groovy</td>\n<td align=\"left\">shBrushGroovy.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Java</td>\n<td align=\"left\">java</td>\n<td align=\"left\">shBrushJava.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">JavaFX</td>\n<td align=\"left\">jfx , javafx</td>\n<td align=\"left\">shBrushJavaFX.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">JavaScript</td>\n<td align=\"left\">js , jscript , javascript</td>\n<td align=\"left\">shBrushJScript.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Perl</td>\n<td align=\"left\">perl , pl , Perl</td>\n<td align=\"left\">shBrushPerl.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">PHP</td>\n<td align=\"left\">php</td>\n<td align=\"left\">shBrushPhp.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">text</td>\n<td align=\"left\">text , plain</td>\n<td align=\"left\">shBrushPlain.js</td>\n<td align=\"left\">就是普通文本.</td>\n</tr>\n<tr>\n<td align=\"left\">Python</td>\n<td align=\"left\">py , python</td>\n<td align=\"left\">shBrushPython.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Ruby</td>\n<td align=\"left\">ruby , rails , ror , rb</td>\n<td align=\"left\">shBrushRuby.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">SASS&amp;SCSS    sass , scss</td>\n<td align=\"left\">shBrushSass.js</td>\n<td align=\"left\">-</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Scala</td>\n<td align=\"left\">scala</td>\n<td align=\"left\">shBrushScala.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">SQL</td>\n<td align=\"left\">sql</td>\n<td align=\"left\">shBrushSql.js</td>\n<td align=\"left\"></td>\n</tr>\n<tr>\n<td align=\"left\">Visual Basic</td>\n<td align=\"left\">vb , vbnet</td>\n<td align=\"left\">shBrushVb.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">XML</td>\n<td align=\"left\">xml , xhtml , xslt , html</td>\n<td align=\"left\">shBrushXml.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">Objective C</td>\n<td align=\"left\">objc , obj-c</td>\n<td align=\"left\">shBrushObjectiveC.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">F#</td>\n<td align=\"left\">f# f-sharp , fsharp</td>\n<td align=\"left\">shBrushFSharp.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">-</td>\n<td align=\"left\">xpp , dynamics-xpp</td>\n<td align=\"left\">shBrushDynamics.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">R</td>\n<td align=\"left\">r , s , splus</td>\n<td align=\"left\">shBrushR.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">matlab</td>\n<td align=\"left\">matlab</td>\n<td align=\"left\">shBrushMatlab.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">swift</td>\n<td align=\"left\">swift</td>\n<td align=\"left\">shBrushSwift.js</td>\n<td align=\"left\">-</td>\n</tr>\n<tr>\n<td align=\"left\">GO</td>\n<td align=\"left\">go , golang</td>\n<td align=\"left\">shBrushGo.js</td>\n<td align=\"left\">-</td>\n</tr>\n</tbody></table>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://guides.github.com/features/mastering-markdown/\">Github-Markdown</a></p>"},{"title":"MongoDB安装","date":"2018-12-26T02:13:18.000Z","_content":"\n\nhttps://www.mongodb.com/\n\n\n## 安装&配置\n\nhttps://docs.mongodb.com/manual/installation/\n\n### 下载\n\n### 配置\n\n\n```conf\n#数据库路径\ndbpath=/Library/mongodb-osx-x86_64-4.0.5/data/\n\n#日志输出文件路径\nlogpath=/Library/mongodb-osx-x86_64-4.0.5/log/mongodb.log\n\n#错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\nlogappend=true\n\n#启用日志文件，默认启用\njournal=true\n\n#这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nquiet=false\n\n#是否后台启动，有这个参数，就可以实现后台运行\nfork=true\n\n#端口号 默认为27017\nport=27017\n\n#指定存储引擎（默认不需要指定）\n#storageEngine=mmapv1\n\n#开启网页日志监控，有这个参数就可以在浏览器上用28017查看监控界面\nhttpinterface=true\n```\n\n### 启动\n\n```\n$ cd bin\n$ sudo ./mongod -f /Library/mongodb-osx-x86_64-4.0.5/conf/mongo.conf\n\nabout to fork child process, waiting until server is ready for connections.\nforked process: 13313\nchild process started successfully, parent exiting\n```\n\n### 关闭\n$ cd bin\n$ ./mongo\n```\n\n\n\n\n\n## MongoDB可视化界面\n\b\n### 安装&启动\n\n```bash\nsudo git clone https://github.com/mrvautin/adminMongo.git && cd adminMongo\nsudo npm install\nsudo npm start\n```\n\n访问：http://127.0.0.1:1234\n\n\n\n\n<br/>\n\n---\n\n参考\n\nhttps://github.com/mrvautin/adminMongo\nhttps://adminmongo.markmoffat.com/docs/","source":"_posts/MongoDB安装.md","raw":"---\ntitle: MongoDB安装\ndate: 2018-12-26 10:13:18\ntags:\n---\n\n\nhttps://www.mongodb.com/\n\n\n## 安装&配置\n\nhttps://docs.mongodb.com/manual/installation/\n\n### 下载\n\n### 配置\n\n\n```conf\n#数据库路径\ndbpath=/Library/mongodb-osx-x86_64-4.0.5/data/\n\n#日志输出文件路径\nlogpath=/Library/mongodb-osx-x86_64-4.0.5/log/mongodb.log\n\n#错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\nlogappend=true\n\n#启用日志文件，默认启用\njournal=true\n\n#这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nquiet=false\n\n#是否后台启动，有这个参数，就可以实现后台运行\nfork=true\n\n#端口号 默认为27017\nport=27017\n\n#指定存储引擎（默认不需要指定）\n#storageEngine=mmapv1\n\n#开启网页日志监控，有这个参数就可以在浏览器上用28017查看监控界面\nhttpinterface=true\n```\n\n### 启动\n\n```\n$ cd bin\n$ sudo ./mongod -f /Library/mongodb-osx-x86_64-4.0.5/conf/mongo.conf\n\nabout to fork child process, waiting until server is ready for connections.\nforked process: 13313\nchild process started successfully, parent exiting\n```\n\n### 关闭\n$ cd bin\n$ ./mongo\n```\n\n\n\n\n\n## MongoDB可视化界面\n\b\n### 安装&启动\n\n```bash\nsudo git clone https://github.com/mrvautin/adminMongo.git && cd adminMongo\nsudo npm install\nsudo npm start\n```\n\n访问：http://127.0.0.1:1234\n\n\n\n\n<br/>\n\n---\n\n参考\n\nhttps://github.com/mrvautin/adminMongo\nhttps://adminmongo.markmoffat.com/docs/","slug":"MongoDB安装","published":1,"updated":"2021-06-30T02:33:24.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswr006ar5p7fch2dzj0","content":"<p><a href=\"https://www.mongodb.com/\">https://www.mongodb.com/</a></p>\n<h2 id=\"安装-amp-配置\"><a href=\"#安装-amp-配置\" class=\"headerlink\" title=\"安装&amp;配置\"></a>安装&amp;配置</h2><p><a href=\"https://docs.mongodb.com/manual/installation/\">https://docs.mongodb.com/manual/installation/</a></p>\n<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><pre class=\" language-conf\"><code class=\"language-conf\">#数据库路径\ndbpath=/Library/mongodb-osx-x86_64-4.0.5/data/\n\n#日志输出文件路径\nlogpath=/Library/mongodb-osx-x86_64-4.0.5/log/mongodb.log\n\n#错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\nlogappend=true\n\n#启用日志文件，默认启用\njournal=true\n\n#这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nquiet=false\n\n#是否后台启动，有这个参数，就可以实现后台运行\nfork=true\n\n#端口号 默认为27017\nport=27017\n\n#指定存储引擎（默认不需要指定）\n#storageEngine=mmapv1\n\n#开启网页日志监控，有这个参数就可以在浏览器上用28017查看监控界面\nhttpinterface=true\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><pre><code>$ cd bin\n$ sudo ./mongod -f /Library/mongodb-osx-x86_64-4.0.5/conf/mongo.conf\n\nabout to fork child process, waiting until server is ready for connections.\nforked process: 13313\nchild process started successfully, parent exiting\n</code></pre>\n<h3 id=\"关闭\"><a href=\"#关闭\" class=\"headerlink\" title=\"关闭\"></a>关闭</h3><p>$ cd bin\n$ ./mongo</p>\n<pre><code>\n\n\n\n\n## MongoDB可视化界面\n\b\n### 安装&amp;启动\n\n```bash\nsudo git clone https://github.com/mrvautin/adminMongo.git &amp;&amp; cd adminMongo\nsudo npm install\nsudo npm start\n</code></pre>\n<p>访问：<a href=\"http://127.0.0.1:1234/\">http://127.0.0.1:1234</a></p>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://github.com/mrvautin/adminMongo\">https://github.com/mrvautin/adminMongo</a>\n<a href=\"https://adminmongo.markmoffat.com/docs/\">https://adminmongo.markmoffat.com/docs/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.mongodb.com/\">https://www.mongodb.com/</a></p>\n<h2 id=\"安装-amp-配置\"><a href=\"#安装-amp-配置\" class=\"headerlink\" title=\"安装&amp;配置\"></a>安装&amp;配置</h2><p><a href=\"https://docs.mongodb.com/manual/installation/\">https://docs.mongodb.com/manual/installation/</a></p>\n<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><pre><code class=\"conf\">#数据库路径\ndbpath=/Library/mongodb-osx-x86_64-4.0.5/data/\n\n#日志输出文件路径\nlogpath=/Library/mongodb-osx-x86_64-4.0.5/log/mongodb.log\n\n#错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件，而不是从新创建一个新文件\nlogappend=true\n\n#启用日志文件，默认启用\njournal=true\n\n#这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为false\nquiet=false\n\n#是否后台启动，有这个参数，就可以实现后台运行\nfork=true\n\n#端口号 默认为27017\nport=27017\n\n#指定存储引擎（默认不需要指定）\n#storageEngine=mmapv1\n\n#开启网页日志监控，有这个参数就可以在浏览器上用28017查看监控界面\nhttpinterface=true\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><pre><code>$ cd bin\n$ sudo ./mongod -f /Library/mongodb-osx-x86_64-4.0.5/conf/mongo.conf\n\nabout to fork child process, waiting until server is ready for connections.\nforked process: 13313\nchild process started successfully, parent exiting\n</code></pre>\n<h3 id=\"关闭\"><a href=\"#关闭\" class=\"headerlink\" title=\"关闭\"></a>关闭</h3><p>$ cd bin\n$ ./mongo</p>\n<pre><code>\n\n\n\n\n## MongoDB可视化界面\n\b\n### 安装&amp;启动\n\n```bash\nsudo git clone https://github.com/mrvautin/adminMongo.git &amp;&amp; cd adminMongo\nsudo npm install\nsudo npm start\n</code></pre>\n<p>访问：<a href=\"http://127.0.0.1:1234/\">http://127.0.0.1:1234</a></p>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://github.com/mrvautin/adminMongo\">https://github.com/mrvautin/adminMongo</a>\n<a href=\"https://adminmongo.markmoffat.com/docs/\">https://adminmongo.markmoffat.com/docs/</a></p>\n"},{"title":"MongoDB教程","date":"2018-12-26T02:13:30.000Z","_content":"","source":"_posts/MongoDB教程.md","raw":"---\ntitle: MongoDB教程\ndate: 2018-12-26 10:13:30\ntags:\n---\n","slug":"MongoDB教程","published":1,"updated":"2021-06-30T02:33:24.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswt006dr5p7ars808rc","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"《MySQL实战45讲》","date":"2019-06-03T07:05:30.000Z","_content":"\n\n<br/>\n\n{% post_link 01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的 《01 | 基础架构：一条SQL查询语句是如何执行的》%}\n\n<hr/>\n\n{% post_link 02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的 《02 | 日志系统：一条SQL更新语句是如何执行的》%}\n\n<hr/>\n\n{% post_link 03-MySQL实战45讲-事务隔离：为什么你改了我还看不见 《03-事务隔离：为什么你改了我还看不见》%}\n\n<hr/>\n\n{% post_link 04-MySQL实战45讲-深入浅出索引（上） 《04 | 深入浅出索引（上）》%}\n\n<hr/>\n\n{% post_link 05-MySQL实战45讲-深入浅出索引（下） 《05 | 深入浅出索引（下）》%}\n\n<hr/>\n\n{% post_link 06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍   《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》%}\n\n<hr/>\n\n{% post_link 07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响    《07 | 行锁功过：怎么减少行锁对性能的影响》%}\n\n<hr/>\n\n{% post_link 08-MySQL实战45讲-事务到底是隔离的还是不隔离的  《08 | 事务到底是隔离的还是不隔离的》%}\n\n<hr/>\n\n{% post_link 09-MySQL实战45讲-普通索引和唯一索引，应该怎么选择  《09 | 普通索引和唯一索引，应该怎么选择》%}\n\n\n","source":"_posts/MySQL实战45讲.md","raw":"---\ntitle: 《MySQL实战45讲》\ndate: 2019-06-03 15:05:30\ncategories: \n    - MySQL\ntags:\n    - MySQL\n    - MySQL实战45讲\n---\n\n\n<br/>\n\n{% post_link 01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的 《01 | 基础架构：一条SQL查询语句是如何执行的》%}\n\n<hr/>\n\n{% post_link 02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的 《02 | 日志系统：一条SQL更新语句是如何执行的》%}\n\n<hr/>\n\n{% post_link 03-MySQL实战45讲-事务隔离：为什么你改了我还看不见 《03-事务隔离：为什么你改了我还看不见》%}\n\n<hr/>\n\n{% post_link 04-MySQL实战45讲-深入浅出索引（上） 《04 | 深入浅出索引（上）》%}\n\n<hr/>\n\n{% post_link 05-MySQL实战45讲-深入浅出索引（下） 《05 | 深入浅出索引（下）》%}\n\n<hr/>\n\n{% post_link 06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍   《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》%}\n\n<hr/>\n\n{% post_link 07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响    《07 | 行锁功过：怎么减少行锁对性能的影响》%}\n\n<hr/>\n\n{% post_link 08-MySQL实战45讲-事务到底是隔离的还是不隔离的  《08 | 事务到底是隔离的还是不隔离的》%}\n\n<hr/>\n\n{% post_link 09-MySQL实战45讲-普通索引和唯一索引，应该怎么选择  《09 | 普通索引和唯一索引，应该怎么选择》%}\n\n\n","slug":"MySQL实战45讲","published":1,"updated":"2021-06-30T02:33:24.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswt006hr5p7an4r0gvu","content":"<br>\n\n<a href=\"/2019/06/03/01-mysql-shi-zhan-45-jiang-ji-chu-jia-gou-yi-tiao-sql-cha-xun-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《01 | 基础架构：一条SQL查询语句是如何执行的》\">《01 | 基础架构：一条SQL查询语句是如何执行的》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/02-mysql-shi-zhan-45-jiang-ri-zhi-xi-tong-yi-tiao-sql-geng-xin-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《02 | 日志系统：一条SQL更新语句是如何执行的》\">《02 | 日志系统：一条SQL更新语句是如何执行的》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/03-mysql-shi-zhan-45-jiang-shi-wu-ge-chi-wei-shi-me-ni-gai-liao-wo-huan-kan-bu-jian/\" title=\"《03-事务隔离：为什么你改了我还看不见》\">《03-事务隔离：为什么你改了我还看不见》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/04-mysql-shi-zhan-45-jiang-shen-ru-qian-chu-suo-yin-shang/\" title=\"《04 | 深入浅出索引（上）》\">《04 | 深入浅出索引（上）》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/05-mysql-shi-zhan-45-jiang-shen-ru-qian-chu-suo-yin-xia/\" title=\"《05 | 深入浅出索引（下）》\">《05 | 深入浅出索引（下）》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/06-mysql-shi-zhan-45-jiang-quan-ju-suo-he-biao-suo-gei-biao-jia-ge-zi-duan-zen-me-you-zhe-me-duo-zu-ai/\" title=\"《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》\">《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/07-mysql-shi-zhan-45-jiang-xing-suo-gong-guo-zen-me-jian-shao-xing-suo-dui-xing-neng-de-ying-xiang/\" title=\"《07 | 行锁功过：怎么减少行锁对性能的影响》\">《07 | 行锁功过：怎么减少行锁对性能的影响》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/08-mysql-shi-zhan-45-jiang-shi-wu-dao-di-shi-ge-chi-de-huan-shi-bu-ge-chi-de/\" title=\"《08 | 事务到底是隔离的还是不隔离的》\">《08 | 事务到底是隔离的还是不隔离的》</a>\n\n<hr>\n\n<a href=\"/2019/06/03/09-mysql-shi-zhan-45-jiang-pu-tong-suo-yin-he-wei-yi-suo-yin-ying-gai-zen-me-xuan-ze/\" title=\"《09 | 普通索引和唯一索引，应该怎么选择》\">《09 | 普通索引和唯一索引，应该怎么选择》</a>\n\n\n","site":{"data":{}},"excerpt":"","more":"<br/>\n\n<a href=\"/2019/06/03/01-mysql-shi-zhan-45-jiang-ji-chu-jia-gou-yi-tiao-sql-cha-xun-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《01 | 基础架构：一条SQL查询语句是如何执行的》\">《01 | 基础架构：一条SQL查询语句是如何执行的》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/02-mysql-shi-zhan-45-jiang-ri-zhi-xi-tong-yi-tiao-sql-geng-xin-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《02 | 日志系统：一条SQL更新语句是如何执行的》\">《02 | 日志系统：一条SQL更新语句是如何执行的》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/03-mysql-shi-zhan-45-jiang-shi-wu-ge-chi-wei-shi-me-ni-gai-liao-wo-huan-kan-bu-jian/\" title=\"《03-事务隔离：为什么你改了我还看不见》\">《03-事务隔离：为什么你改了我还看不见》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/04-mysql-shi-zhan-45-jiang-shen-ru-qian-chu-suo-yin-shang/\" title=\"《04 | 深入浅出索引（上）》\">《04 | 深入浅出索引（上）》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/05-mysql-shi-zhan-45-jiang-shen-ru-qian-chu-suo-yin-xia/\" title=\"《05 | 深入浅出索引（下）》\">《05 | 深入浅出索引（下）》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/06-mysql-shi-zhan-45-jiang-quan-ju-suo-he-biao-suo-gei-biao-jia-ge-zi-duan-zen-me-you-zhe-me-duo-zu-ai/\" title=\"《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》\">《06 | 全局锁和表锁：给表加个字段怎么有这么多阻碍》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/07-mysql-shi-zhan-45-jiang-xing-suo-gong-guo-zen-me-jian-shao-xing-suo-dui-xing-neng-de-ying-xiang/\" title=\"《07 | 行锁功过：怎么减少行锁对性能的影响》\">《07 | 行锁功过：怎么减少行锁对性能的影响》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/08-mysql-shi-zhan-45-jiang-shi-wu-dao-di-shi-ge-chi-de-huan-shi-bu-ge-chi-de/\" title=\"《08 | 事务到底是隔离的还是不隔离的》\">《08 | 事务到底是隔离的还是不隔离的》</a>\n\n<hr/>\n\n<a href=\"/2019/06/03/09-mysql-shi-zhan-45-jiang-pu-tong-suo-yin-he-wei-yi-suo-yin-ying-gai-zen-me-xuan-ze/\" title=\"《09 | 普通索引和唯一索引，应该怎么选择》\">《09 | 普通索引和唯一索引，应该怎么选择》</a>\n\n\n"},{"title":"MySQL汇总","date":"9999-12-30T16:00:00.000Z","_content":"\n<br/>\n\n&zwj;{% post_link MySQL索引 《MySQL索引》%}\n{% post_link MySQL锁 《MySQL锁》%}\n\n<hr/>\n\n<br/>\n### 《MySQL实战45讲》\n&emsp;&emsp;    {% post_link 01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的 《01 | 基础架构：一条SQL查询语句是如何执行的》%}\n&emsp;&emsp;    {% post_link 02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的 《02 | 日志系统：一条SQL更新语句是如何执行的》%}\n&emsp;&emsp;    {% post_link 03-MySQL实战45讲-事务隔离：为什么你改了我还看不见 《03-事务隔离：为什么你改了我还看不见》%}","source":"_posts/MySQL汇总.md","raw":"---\ntitle: MySQL汇总\ndate: 9999-12-31\ncategories: \n    - MySQL\ntags:\n    - MySQL\n---\n\n<br/>\n\n&zwj;{% post_link MySQL索引 《MySQL索引》%}\n{% post_link MySQL锁 《MySQL锁》%}\n\n<hr/>\n\n<br/>\n### 《MySQL实战45讲》\n&emsp;&emsp;    {% post_link 01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的 《01 | 基础架构：一条SQL查询语句是如何执行的》%}\n&emsp;&emsp;    {% post_link 02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的 《02 | 日志系统：一条SQL更新语句是如何执行的》%}\n&emsp;&emsp;    {% post_link 03-MySQL实战45讲-事务隔离：为什么你改了我还看不见 《03-事务隔离：为什么你改了我还看不见》%}","slug":"MySQL汇总","published":1,"updated":"2021-06-30T02:33:24.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswu006lr5p7b9lu9pqj","content":"<br>\n\n<p>‍<a href=\"/2019/06/12/mysql-suo-yin/\" title=\"《MySQL索引》\">《MySQL索引》</a></p>\n<a href=\"/2019/06/06/mysql-suo/\" title=\"《MySQL锁》\">《MySQL锁》</a>\n\n<hr>\n\n<br>\n### 《MySQL实战45讲》\n      <a href=\"/2019/06/03/01-mysql-shi-zhan-45-jiang-ji-chu-jia-gou-yi-tiao-sql-cha-xun-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《01 | 基础架构：一条SQL查询语句是如何执行的》\">《01 | 基础架构：一条SQL查询语句是如何执行的》</a>\n      <a href=\"/2019/06/03/02-mysql-shi-zhan-45-jiang-ri-zhi-xi-tong-yi-tiao-sql-geng-xin-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《02 | 日志系统：一条SQL更新语句是如何执行的》\">《02 | 日志系统：一条SQL更新语句是如何执行的》</a>\n      <a href=\"/2019/06/03/03-mysql-shi-zhan-45-jiang-shi-wu-ge-chi-wei-shi-me-ni-gai-liao-wo-huan-kan-bu-jian/\" title=\"《03-事务隔离：为什么你改了我还看不见》\">《03-事务隔离：为什么你改了我还看不见》</a>","site":{"data":{}},"excerpt":"","more":"<br/>\n\n<p>&zwj;<a href=\"/2019/06/12/mysql-suo-yin/\" title=\"《MySQL索引》\">《MySQL索引》</a></p>\n<a href=\"/2019/06/06/mysql-suo/\" title=\"《MySQL锁》\">《MySQL锁》</a>\n\n<hr/>\n\n<br/>\n### 《MySQL实战45讲》\n&emsp;&emsp;    <a href=\"/2019/06/03/01-mysql-shi-zhan-45-jiang-ji-chu-jia-gou-yi-tiao-sql-cha-xun-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《01 | 基础架构：一条SQL查询语句是如何执行的》\">《01 | 基础架构：一条SQL查询语句是如何执行的》</a>\n&emsp;&emsp;    <a href=\"/2019/06/03/02-mysql-shi-zhan-45-jiang-ri-zhi-xi-tong-yi-tiao-sql-geng-xin-yu-ju-shi-ru-he-zhi-xing-de/\" title=\"《02 | 日志系统：一条SQL更新语句是如何执行的》\">《02 | 日志系统：一条SQL更新语句是如何执行的》</a>\n&emsp;&emsp;    <a href=\"/2019/06/03/03-mysql-shi-zhan-45-jiang-shi-wu-ge-chi-wei-shi-me-ni-gai-liao-wo-huan-kan-bu-jian/\" title=\"《03-事务隔离：为什么你改了我还看不见》\">《03-事务隔离：为什么你改了我还看不见》</a>"},{"title":"MongoDB设计与实现","date":"2018-12-26T02:13:46.000Z","_content":"","source":"_posts/MongoDB设计与实现.md","raw":"---\ntitle: MongoDB设计与实现\ndate: 2018-12-26 10:13:46\ntags:\n---\n","slug":"MongoDB设计与实现","published":1,"updated":"2021-06-30T02:33:24.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswv006nr5p7byz9e79v","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"MySQL索引","date":"2019-06-11T16:00:00.000Z","_content":"\n数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;—————————— 《维基百科》\n\n索引是存储引擎用于快速找到记录的一种数据结构\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;—————————— 《高性能MySQL》\n\n\n\n<!-- more -->\n<br/>\n### \n\n<br/>\n\n### 原理\n\n---\n\n<br/>\n\n**参考**\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》","source":"_posts/MySQL索引.md","raw":"---\ntitle: MySQL索引\ndate: 2019-06-12\ncategories: \n    - MySQL\ntags:\n    - MySQL\n---\n\n数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;—————————— 《维基百科》\n\n索引是存储引擎用于快速找到记录的一种数据结构\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;—————————— 《高性能MySQL》\n\n\n\n<!-- more -->\n<br/>\n### \n\n<br/>\n\n### 原理\n\n---\n\n<br/>\n\n**参考**\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》","slug":"MySQL索引","published":1,"updated":"2021-06-30T02:33:24.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsww006sr5p728t62h09","content":"<p>数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据\n                                —————————— 《维基百科》</p>\n<p>索引是存储引擎用于快速找到记录的一种数据结构\n                                —————————— 《高性能MySQL》</p>\n<span id=\"more\"></span>\n<br>\n### \n\n<br>\n\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><hr>\n<br>\n\n<p><strong>参考</strong>\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》</p>\n","site":{"data":{}},"excerpt":"<p>数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据\n                                —————————— 《维基百科》</p>\n<p>索引是存储引擎用于快速找到记录的一种数据结构\n                                —————————— 《高性能MySQL》</p>","more":"<br/>\n### \n\n<br/>\n\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><hr>\n<br/>\n\n<p><strong>参考</strong>\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》</p>"},{"title":"MySQL锁","date":"2019-06-06T09:56:32.000Z","_content":"\n\n\n<!-- more -->\n\n---\n\n\n## InnoDB\n\n### 共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）\nInnoDB实现了两种类型的行级锁：\n- `共享锁（shared (S) lock）`：允许持有锁的事务读取一行\n- `排它锁（exclusive (X) lock）`：允许持有锁的事务更新或删除行\n\n用一张经典的矩阵表格继续说明共享锁和排他锁的互斥关系：\n\n | S | X\n-|---|---\nS | 兼容 | 冲突\nX | 冲突 | 冲突\n\n- 如果一个事务对某一行数据加了S锁，另一个事务还可以对相应的行加S锁，但是不能对相应的行加X锁。\n- 如果一个事务对某一行数据加了X锁，另一个事务既不能对相应的行加S锁也不能加X锁。\n\n\n<br/>\n### 意向锁\n\n\n\n | X | IX | S | IS\n-|---|----|---|---\nX | 冲突 | 冲突 | 冲突 | 冲突\nIX | 冲突 | 兼容 | 冲突 | 兼容\nS | 冲突 | 冲突 | 兼容 | 兼容\nIS | 冲突 | 兼容 | 兼容 | 兼容\n\n\n<br/>\n### Record Locks\n\n\n\n<br/>\n### Gap Locks\n\n\n\n<br/>\n### Next-Key Locks\n\n\n\n<br/>\n### AUTO-INC Locks\n\n\n\n### 加锁语句\n- `select ... from`: InnoDB引擎采用多版本并发控制（MVCC）的方式实现了非阻塞读，所以对于普通的select读语句，InnoDB并不会加锁[【备注1】](#备注1)\n- `select ... from lock in share mode`: \n- `select ... from for update`: \n- `update ... where ...`: \n\n\n\n\n---\n\n<br/>\n### 备注\n<span id=\"备注1\">**【备注1】**: xxxx sffs</span>\n\n\n\n---\n\n<br/>\n\n**参考**\n[MySQL innodb-locking](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html)\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》","source":"_posts/MySQL锁.md","raw":"---\ntitle: MySQL锁\ndate: 2019-06-06 17:56:32\ncategories:\n    - SQL\n    - MySQL\ntags:\n    - SQL\n    - MySQL\n---\n\n\n\n<!-- more -->\n\n---\n\n\n## InnoDB\n\n### 共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）\nInnoDB实现了两种类型的行级锁：\n- `共享锁（shared (S) lock）`：允许持有锁的事务读取一行\n- `排它锁（exclusive (X) lock）`：允许持有锁的事务更新或删除行\n\n用一张经典的矩阵表格继续说明共享锁和排他锁的互斥关系：\n\n | S | X\n-|---|---\nS | 兼容 | 冲突\nX | 冲突 | 冲突\n\n- 如果一个事务对某一行数据加了S锁，另一个事务还可以对相应的行加S锁，但是不能对相应的行加X锁。\n- 如果一个事务对某一行数据加了X锁，另一个事务既不能对相应的行加S锁也不能加X锁。\n\n\n<br/>\n### 意向锁\n\n\n\n | X | IX | S | IS\n-|---|----|---|---\nX | 冲突 | 冲突 | 冲突 | 冲突\nIX | 冲突 | 兼容 | 冲突 | 兼容\nS | 冲突 | 冲突 | 兼容 | 兼容\nIS | 冲突 | 兼容 | 兼容 | 兼容\n\n\n<br/>\n### Record Locks\n\n\n\n<br/>\n### Gap Locks\n\n\n\n<br/>\n### Next-Key Locks\n\n\n\n<br/>\n### AUTO-INC Locks\n\n\n\n### 加锁语句\n- `select ... from`: InnoDB引擎采用多版本并发控制（MVCC）的方式实现了非阻塞读，所以对于普通的select读语句，InnoDB并不会加锁[【备注1】](#备注1)\n- `select ... from lock in share mode`: \n- `select ... from for update`: \n- `update ... where ...`: \n\n\n\n\n---\n\n<br/>\n### 备注\n<span id=\"备注1\">**【备注1】**: xxxx sffs</span>\n\n\n\n---\n\n<br/>\n\n**参考**\n[MySQL innodb-locking](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html)\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》","slug":"MySQL锁","published":1,"updated":"2021-06-30T02:33:24.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswx006vr5p7087xefv6","content":"<span id=\"more\"></span>\n\n<hr>\n<h2 id=\"InnoDB\"><a href=\"#InnoDB\" class=\"headerlink\" title=\"InnoDB\"></a>InnoDB</h2><h3 id=\"共享锁（shared-S-lock）和-排它锁（exclusive-X-lock）\"><a href=\"#共享锁（shared-S-lock）和-排它锁（exclusive-X-lock）\" class=\"headerlink\" title=\"共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）\"></a>共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）</h3><p>InnoDB实现了两种类型的行级锁：</p>\n<ul>\n<li><code>共享锁（shared (S) lock）</code>：允许持有锁的事务读取一行</li>\n<li><code>排它锁（exclusive (X) lock）</code>：允许持有锁的事务更新或删除行</li>\n</ul>\n<p>用一张经典的矩阵表格继续说明共享锁和排他锁的互斥关系：</p>\n<p> | S | X\n-|—|—\nS | 兼容 | 冲突\nX | 冲突 | 冲突</p>\n<ul>\n<li>如果一个事务对某一行数据加了S锁，另一个事务还可以对相应的行加S锁，但是不能对相应的行加X锁。</li>\n<li>如果一个事务对某一行数据加了X锁，另一个事务既不能对相应的行加S锁也不能加X锁。</li>\n</ul>\n<br>\n### 意向锁\n\n\n\n<p> | X | IX | S | IS\n-|—|—-|—|—\nX | 冲突 | 冲突 | 冲突 | 冲突\nIX | 冲突 | 兼容 | 冲突 | 兼容\nS | 冲突 | 冲突 | 兼容 | 兼容\nIS | 冲突 | 兼容 | 兼容 | 兼容</p>\n<br>\n### Record Locks\n\n\n\n<br>\n### Gap Locks\n\n\n\n<br>\n### Next-Key Locks\n\n\n\n<br>\n### AUTO-INC Locks\n\n\n\n<h3 id=\"加锁语句\"><a href=\"#加锁语句\" class=\"headerlink\" title=\"加锁语句\"></a>加锁语句</h3><ul>\n<li><code>select ... from</code>: InnoDB引擎采用多版本并发控制（MVCC）的方式实现了非阻塞读，所以对于普通的select读语句，InnoDB并不会加锁<a href=\"#%E5%A4%87%E6%B3%A81\">【备注1】</a></li>\n<li><code>select ... from lock in share mode</code>: </li>\n<li><code>select ... from for update</code>: </li>\n<li><code>update ... where ...</code>: </li>\n</ul>\n<hr>\n<br>\n### 备注\n<span id=\"备注1\">**【备注1】**: xxxx sffs</span>\n\n\n\n<hr>\n<br>\n\n<p><strong>参考</strong>\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html\">MySQL innodb-locking</a>\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<h2 id=\"InnoDB\"><a href=\"#InnoDB\" class=\"headerlink\" title=\"InnoDB\"></a>InnoDB</h2><h3 id=\"共享锁（shared-S-lock）和-排它锁（exclusive-X-lock）\"><a href=\"#共享锁（shared-S-lock）和-排它锁（exclusive-X-lock）\" class=\"headerlink\" title=\"共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）\"></a>共享锁（shared (S) lock）和 排它锁（exclusive (X) lock）</h3><p>InnoDB实现了两种类型的行级锁：</p>\n<ul>\n<li><code>共享锁（shared (S) lock）</code>：允许持有锁的事务读取一行</li>\n<li><code>排它锁（exclusive (X) lock）</code>：允许持有锁的事务更新或删除行</li>\n</ul>\n<p>用一张经典的矩阵表格继续说明共享锁和排他锁的互斥关系：</p>\n<p> | S | X\n-|—|—\nS | 兼容 | 冲突\nX | 冲突 | 冲突</p>\n<ul>\n<li>如果一个事务对某一行数据加了S锁，另一个事务还可以对相应的行加S锁，但是不能对相应的行加X锁。</li>\n<li>如果一个事务对某一行数据加了X锁，另一个事务既不能对相应的行加S锁也不能加X锁。</li>\n</ul>\n<br/>\n### 意向锁\n\n\n\n<p> | X | IX | S | IS\n-|—|—-|—|—\nX | 冲突 | 冲突 | 冲突 | 冲突\nIX | 冲突 | 兼容 | 冲突 | 兼容\nS | 冲突 | 冲突 | 兼容 | 兼容\nIS | 冲突 | 兼容 | 兼容 | 兼容</p>\n<br/>\n### Record Locks\n\n\n\n<br/>\n### Gap Locks\n\n\n\n<br/>\n### Next-Key Locks\n\n\n\n<br/>\n### AUTO-INC Locks\n\n\n\n<h3 id=\"加锁语句\"><a href=\"#加锁语句\" class=\"headerlink\" title=\"加锁语句\"></a>加锁语句</h3><ul>\n<li><code>select ... from</code>: InnoDB引擎采用多版本并发控制（MVCC）的方式实现了非阻塞读，所以对于普通的select读语句，InnoDB并不会加锁<a href=\"#%E5%A4%87%E6%B3%A81\">【备注1】</a></li>\n<li><code>select ... from lock in share mode</code>: </li>\n<li><code>select ... from for update</code>: </li>\n<li><code>update ... where ...</code>: </li>\n</ul>\n<hr>\n<br/>\n### 备注\n<span id=\"备注1\">**【备注1】**: xxxx sffs</span>\n\n\n\n<hr>\n<br/>\n\n<p><strong>参考</strong>\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html\">MySQL innodb-locking</a>\n《高性能MySQL》\n《MySQL技术内幕——InnoDB存储引擎》</p>"},{"title":"Oracle转EDB总结","date":"2019-08-15T15:26:31.000Z","_content":"\n\n## 数据类型\n### character datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### number datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### long and raw datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### datetime datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### large object datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### rowid datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### ANSI supported datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### any types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### XML types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### spatial types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### media types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n### Other datatypes\n\n\n<br/>\n## 方法\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>   \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n\n\n<br/>\n## DDL\n\n### FUNCTION\n\n<br/>\n### MATERIALIZED VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n#### ALTER\n- 物理属性、字段属性等无关信息去掉\n\n#### DROP\n- 物理属性、字段属性等无关信息去掉\n\n<br/>\n### TABLE\nCREATE\n- 物理属性、字段属性等无关信息去掉\n\nALTER\n- 物理属性、字段属性等无关信息去掉\n\nDROP\n- 物理属性、字段属性等无关信息去掉\n\n### TYPE\n\n### TYPE BODY\n\n### PROCEDURE\n\n### TRIGGER\n\n### VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n#### ALTER\n#### DROP\n\n<br/>\n## DML\n### SELECT\n\n### INSERT\n\n### DELETE\n\n### UPDATE\n\n\n\n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [EDB官网文档](https://www.enterprisedb.com/edb-docs/d/edb-postgres-advanced-server/user-guides/database-compatibility-for-oracle-developers-guide/11/toc.html)","source":"_posts/Oracle转EDB总结.md","raw":"---\ntitle: Oracle转EDB总结\ndate: 2019-08-15 23:26:31\ncategories: \n    - SQL转换\ntags:\n    - SQL转换\n---\n\n\n## 数据类型\n### character datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### number datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### long and raw datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### datetime datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### large object datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### rowid datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### ANSI supported datatypes\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### any types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### XML types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n<br/>\n### spatial types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n<br/>\n### media types\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n### Other datatypes\n\n\n<br/>\n## 方法\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>   \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n{% endraw %}\n\n\n\n\n<br/>\n## DDL\n\n### FUNCTION\n\n<br/>\n### MATERIALIZED VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n#### ALTER\n- 物理属性、字段属性等无关信息去掉\n\n#### DROP\n- 物理属性、字段属性等无关信息去掉\n\n<br/>\n### TABLE\nCREATE\n- 物理属性、字段属性等无关信息去掉\n\nALTER\n- 物理属性、字段属性等无关信息去掉\n\nDROP\n- 物理属性、字段属性等无关信息去掉\n\n### TYPE\n\n### TYPE BODY\n\n### PROCEDURE\n\n### TRIGGER\n\n### VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n#### ALTER\n#### DROP\n\n<br/>\n## DML\n### SELECT\n\n### INSERT\n\n### DELETE\n\n### UPDATE\n\n\n\n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [EDB官网文档](https://www.enterprisedb.com/edb-docs/d/edb-postgres-advanced-server/user-guides/database-compatibility-for-oracle-developers-guide/11/toc.html)","slug":"Oracle转EDB总结","published":1,"updated":"2021-06-30T02:33:24.718Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswy0070r5p7979ggwup","content":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"character-datatypes\"><a href=\"#character-datatypes\" class=\"headerlink\" title=\"character datatypes\"></a>character datatypes</h3>\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br>\n### number datatypes\n\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br>\n### long and raw datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br>\n### datetime datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br>\n### large object datatypes\n\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br>\n### rowid datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br>\n### ANSI supported datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br>\n### any types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br>\n### XML types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br>\n### spatial types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br>\n### media types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<h3 id=\"Other-datatypes\"><a href=\"#Other-datatypes\" class=\"headerlink\" title=\"Other datatypes\"></a>Other datatypes</h3><br>\n## 方法\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>   \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n\n\n<br>\n## DDL\n\n<h3 id=\"FUNCTION\"><a href=\"#FUNCTION\" class=\"headerlink\" title=\"FUNCTION\"></a>FUNCTION</h3><br>\n### MATERIALIZED VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n<h4 id=\"ALTER\"><a href=\"#ALTER\" class=\"headerlink\" title=\"ALTER\"></a>ALTER</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h4 id=\"DROP\"><a href=\"#DROP\" class=\"headerlink\" title=\"DROP\"></a>DROP</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<br>\n### TABLE\nCREATE\n- 物理属性、字段属性等无关信息去掉\n\n<p>ALTER</p>\n<ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<p>DROP</p>\n<ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h3 id=\"TYPE\"><a href=\"#TYPE\" class=\"headerlink\" title=\"TYPE\"></a>TYPE</h3><h3 id=\"TYPE-BODY\"><a href=\"#TYPE-BODY\" class=\"headerlink\" title=\"TYPE BODY\"></a>TYPE BODY</h3><h3 id=\"PROCEDURE\"><a href=\"#PROCEDURE\" class=\"headerlink\" title=\"PROCEDURE\"></a>PROCEDURE</h3><h3 id=\"TRIGGER\"><a href=\"#TRIGGER\" class=\"headerlink\" title=\"TRIGGER\"></a>TRIGGER</h3><h3 id=\"VIEW\"><a href=\"#VIEW\" class=\"headerlink\" title=\"VIEW\"></a>VIEW</h3><h4 id=\"CREATE\"><a href=\"#CREATE\" class=\"headerlink\" title=\"CREATE\"></a>CREATE</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h4 id=\"ALTER-1\"><a href=\"#ALTER-1\" class=\"headerlink\" title=\"ALTER\"></a>ALTER</h4><h4 id=\"DROP-1\"><a href=\"#DROP-1\" class=\"headerlink\" title=\"DROP\"></a>DROP</h4><br>\n## DML\n### SELECT\n\n<h3 id=\"INSERT\"><a href=\"#INSERT\" class=\"headerlink\" title=\"INSERT\"></a>INSERT</h3><h3 id=\"DELETE\"><a href=\"#DELETE\" class=\"headerlink\" title=\"DELETE\"></a>DELETE</h3><h3 id=\"UPDATE\"><a href=\"#UPDATE\" class=\"headerlink\" title=\"UPDATE\"></a>UPDATE</h3><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://www.enterprisedb.com/edb-docs/d/edb-postgres-advanced-server/user-guides/database-compatibility-for-oracle-developers-guide/11/toc.html\">EDB官网文档</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"character-datatypes\"><a href=\"#character-datatypes\" class=\"headerlink\" title=\"character datatypes\"></a>character datatypes</h3>\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br/>\n### number datatypes\n\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br/>\n### long and raw datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br/>\n### datetime datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br/>\n### large object datatypes\n\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br/>\n### rowid datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br/>\n### ANSI supported datatypes\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br/>\n### any types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br/>\n### XML types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<br/>\n### spatial types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n<br/>\n### media types\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n<h3 id=\"Other-datatypes\"><a href=\"#Other-datatypes\" class=\"headerlink\" title=\"Other datatypes\"></a>Other datatypes</h3><br/>\n## 方法\n\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>   \n    <tbody>\n<!--CHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">CHAR [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--VARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">VARCHAR2 [(size [BYTE | CHAR]) ]</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n            <td style=\"text-align:center\">VARCHAR2</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">VARCHAR2(size [BYTE | CHAR])</td>\n            <td style=\"text-align:center\">VARCHAR2(size)</td>\n        </tr>\n<!--NCHAR -->\n        <tr>\n            <td style=\"text-align:center\" rowspan=\"2\">NCHAR [ (size) ]</td>\n            <td style=\"text-align:center\">NCHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">NCHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n<!--NVARCHAR2 -->\n        <tr>\n            <td style=\"text-align:center\">NVARCHAR2 (size)</td>\n            <td style=\"text-align:center\">NVARCHAR2(size)</td>\n            <td style=\"text-align:center\">VARCHAR(size)</td>\n        </tr>\n    </tbody>\n</table>\n\n\n\n\n\n<br/>\n## DDL\n\n<h3 id=\"FUNCTION\"><a href=\"#FUNCTION\" class=\"headerlink\" title=\"FUNCTION\"></a>FUNCTION</h3><br/>\n### MATERIALIZED VIEW\n#### CREATE\n- 物理属性、字段属性等无关信息去掉\n\n<h4 id=\"ALTER\"><a href=\"#ALTER\" class=\"headerlink\" title=\"ALTER\"></a>ALTER</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h4 id=\"DROP\"><a href=\"#DROP\" class=\"headerlink\" title=\"DROP\"></a>DROP</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<br/>\n### TABLE\nCREATE\n- 物理属性、字段属性等无关信息去掉\n\n<p>ALTER</p>\n<ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<p>DROP</p>\n<ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h3 id=\"TYPE\"><a href=\"#TYPE\" class=\"headerlink\" title=\"TYPE\"></a>TYPE</h3><h3 id=\"TYPE-BODY\"><a href=\"#TYPE-BODY\" class=\"headerlink\" title=\"TYPE BODY\"></a>TYPE BODY</h3><h3 id=\"PROCEDURE\"><a href=\"#PROCEDURE\" class=\"headerlink\" title=\"PROCEDURE\"></a>PROCEDURE</h3><h3 id=\"TRIGGER\"><a href=\"#TRIGGER\" class=\"headerlink\" title=\"TRIGGER\"></a>TRIGGER</h3><h3 id=\"VIEW\"><a href=\"#VIEW\" class=\"headerlink\" title=\"VIEW\"></a>VIEW</h3><h4 id=\"CREATE\"><a href=\"#CREATE\" class=\"headerlink\" title=\"CREATE\"></a>CREATE</h4><ul>\n<li>物理属性、字段属性等无关信息去掉</li>\n</ul>\n<h4 id=\"ALTER-1\"><a href=\"#ALTER-1\" class=\"headerlink\" title=\"ALTER\"></a>ALTER</h4><h4 id=\"DROP-1\"><a href=\"#DROP-1\" class=\"headerlink\" title=\"DROP\"></a>DROP</h4><br/>\n## DML\n### SELECT\n\n<h3 id=\"INSERT\"><a href=\"#INSERT\" class=\"headerlink\" title=\"INSERT\"></a>INSERT</h3><h3 id=\"DELETE\"><a href=\"#DELETE\" class=\"headerlink\" title=\"DELETE\"></a>DELETE</h3><h3 id=\"UPDATE\"><a href=\"#UPDATE\" class=\"headerlink\" title=\"UPDATE\"></a>UPDATE</h3><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://www.enterprisedb.com/edb-docs/d/edb-postgres-advanced-server/user-guides/database-compatibility-for-oracle-developers-guide/11/toc.html\">EDB官网文档</a></li>\n</ul>\n"},{"title":"Oracle转Postgresql总结","date":"2019-08-15T15:26:48.000Z","_content":"\n## 数据类型\nOracle数据类型  Postgresql数据类型\n\n\n## 方法\n\n数字函数：（总共 26）\n\t1、PG 支持 ACOS、ASIN、ATAN、ATAN2、CEIL、COS、FLOOR、ROUND、SIN/TAN/TRUNC ，但是转换的时候，函数中字段 如果是 小数 转换成Char ，不是Number，SQLNumberExpr clone 只赋值了number，其他字段抛弃了 ；看 SelectTableTest_2_ACOS、SelectTableTest_3_ASIN \n\t2、PG 不支持 BITAND(x1, x2) :两个数值型数值在按位进行AND , 可以改为：x1 & x2 看：SelectTableTest_6_BITAND\n\t3、PG 不支持 COSH 反余弦值 ；SINH 反正弦值， TANH 看 ： SelectTableTest_9_COSH、SelectTableTest_19_SINH、SelectTableTest_24_TANH\n\t4、PG 不支持 NANVL(n1,n2) 如果n1是数字就返回n1，否则返回n2，看：SelectTableTest_15_NANVL\n\t5、 PG 不支持  REMAINDER（n1, n2） 四舍六入五取偶； 看：SelectTableTest_17_REMAINDER\n\t6、PG 不支持 SIGN(n1） 取数字n的符号,大于0返回1,小于0返回-1,等于0返回0; 看 ：SelectTableTest_19_SIGN\n\n\n字符函数：（总共28）\n\t1、pg 不支持 NLS_INITCAP, 可以使用 INITCAP 替代；看 ：SelectTableTest_7_NLS_INITCAP\n\t2、pg 不支持 NLS_LOWER , 可以使用 LOWER 替代；看： SelectTableTest_8_NLS_LOWER\n\t3、pg 不支持 NLS_UPPER , 可以使用 UPPER 替代；看： SelectTableTest_10_NLS_UPPER\n\t4、pg 不支持 NLSSORT、NLS_SORT 看： SelectTableTest_9_NLSSORT\n\t5、pg 不支持 SOUNDEX  : 四个字符组成的代码 (SOUNDEX) 以评估两个字符串的相似性 ; 看： SelectTableTest_16_SOUNDEX\n\t6、pg 不支持 NLS_CHARSET_ID  : 字符集对应的 ID ; 看： SelectTableTest_23_NLS_CHARSET_ID\n\t7、pg 不支持 NLS_CHARSET_DECL_LEN  : 声明长度（也就是字符个数） ; 看： SelectTableTest_22_NLS_CHARSET_DECL_LEN \n\t8、pg 不支持 NLS_CHARSET_NAME  : 字符集 ID 对应的字符集名称 ; 看： SelectTableTest_24_NLS_CHARSET_NAME \n\n\n日期时间函数：（总共25）\n\t1、oracle CURRENT_DATE(日期+时间) 转PG CURRENT_DATE（只有日期）, 可以用 SYSDATE 代替 ， 看: SelectTableTest_CURRENT_DATE\n\t2、pg 不支持 DBTIMEZONE  : 数据库时区  ; 看： SelectTableTest_4_DBTIMEZONE\n\t3、pg 不支持 FROM_TZ  : 将一个timstamp和timzone拼成一个timestamp with timezone  ; 看： SelectTableTest_6_FROM_TZ\n\t4、pg 不支持 NEXT_DAY  : 日期开始得到到未来  星期数  的日期  ; 看： SelectTableTest_11_NEXT_DAY\n\t5、pg 不支持 NUMTODSINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_12_NUMTODSINTERVAL\n\t6、pg 不支持 NUMTOYMINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_13_NUMTOYMINTERVAL\n\t7、pg 不支持 SESSIONTIMEZONE  :  会话时区  ; 看： SelectTableTest_15_SESSIONTIMEZONE \n\t8、pg 不支持 TO_TIMESTAMP_TZ  :  时间+时区 字符串 转 时间  ; 看： SelectTableTest_21_TO_TIMESTAMP_TZ \n\t9、pg 不支持 TO_DSINTERVAL  :  字符串转时间  ; 看： SelectTableTest_22_TO_DSINTERVAL\n   10、pg 不支持 TO_YMINTERVAL  :  字符串转 年 和月  ; 看： SelectTableTest_23_TO_YMINTERVAL\n   11、pg 不支持 TZ_OFFSET  :  将时区别名转换为以UTC为标准的OFFSET  ; 看： SelectTableTest_25_TZ_OFFSET  ： https://yq.aliyun.com/articles/61071\n\n\n一般比较功能函数：（总共2）\n\n转换函数：（总共 34）\n\t1、pg 不支持 ASCIISTR  : 字符在ASCII码表中有,则转成ASCII表中的字符, 如果没有,则转成\\xxxx格式,xxxx是UTF-16的编码.  ; 看： SelectTableTest_1_ASCIISTR\n\t2、pg 不支持 BIN_TO_NUM  : 二进制到十进制的转换 ，可以转换： select int4(bit(4) '1010'); ; 看： SelectTableTest_1_ASCIISTR ： https://yq.aliyun.com/articles/61074\n\t3、pg 不支持 CHARTOROWID  : 把包含外部格式的ROWID的CHAR或VARCHAR2数值转换为内部的二进制格式 ; 看： SelectTableTest_4_CHARTOROWID  \n\t4、pg 不支持 COMPOSE   ; 看： SelectTableTest_5_COMPOSE   \n\t5、pg 不支持 DECOMPOSE   ; 看： SelectTableTest_7_DECOMPOSE   \n\t6、pg 不支持 RAWTONHEX  ，     可以：TO_NCHAR(RAWTOHEX(raw))   ; 看： SelectTableTest_12_RAWTONHEX\n\t7、pg 不支持 ROWIDTOCHAR  将ROWID转换为字符串，长度18 ，   看： SelectTableTest_13_ROWIDTOCHAR\n\t8、pg 不支持 ROWIDTONCHAR ，   看： SelectTableTest_14_ROWIDTONCHAR\n\t9、pg 不支持 TO_BINARY_DOUBLE , 可以： 通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_17_TO_BINARY_DOUBLE\n   10、pg 不支持 TO_BINARY_FLOAT , 可以：  通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_18_TO_BINARY_FLOAT\n   11、pg 不支持 TO_CLOB ,可以：  过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_20_TO_CLOB\n   12、pg 支持 TO_DATE， 但是只支持 两个参数，  看：  SelectTableTest_21_TO_DATE\n   13、pg 不支持 TO_LOB ， 通过PPAS语法使用 xxxx::newtype 实现,  看：  SelectTableTest_23_TO_LOB\n   14、pg 不支持 TO_MULTI_BYTE ： 将字符串转换为双字节表示 ，   看：  SelectTableTest_24_TO_MULTI_BYTE\n   15、pg 不支持 TO_NCHAR  ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_25_TO_NCHAR\n   16、pg 不支持 TO_NCLOB   将字符串转换为NCLOB类型 ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_26_TO_NCLOB\n   17、pg 不支持 TO_SINGLE_BYTE  全角字符转换为半角的字符 ； 看：  SelectTableTest_29_TO_SINGLE_BYTE\n   18、pg 不支持 TRANSLATE_USING  将字符串转换为规定的字符集 ；  看：  SelectTableTest_33_TRANSLATE_USING\n   19、pg 不支持 UNISTR    将字符串转换为AL16UTF16或 UTF8字符 ；  看： SelectTableTest_34_UNISTR\n\n\nNULL 相关函数：(总共 5)\n\t1、pg 不支持 LNNVL 用于某个语句的where子句中的条件，如果条件为true就返回false；如果条件为UNKNOWN或者false就返回true  ， 看： SelectTableTest_2_LNNVL\n\t2、PG 不支持 NVL2（x, n1, n2） 如果X是空值，返回n2， 否则返回n1 ， pg 可以用 case : SELECT case WHEN null = null then  'Not Applicable' else '1' end  ， 看： SelectTableTest_5_NVL2\n\t\n\n聚合函数：(总共 36)\n\t1、pg 不支持 COLLECT  转换为一个嵌套表 ， 看：  SelectTableTest_2_COLLECT\n\t2、pg 不支持 CUME_DIST  ； 看：  SelectTableTest_7_CUME_DIST\n\t3、pg 不支持 DENSE_RANK  ； 看：  SelectTableTest_8_DENSE_RANK\n\t4、pg 不支持 GROUP_ID  消除GROUP BY子句返回的重复记录 ， 且  parse 错误； 看： SelectTableTest_10_GROUP_ID\n\t5、pg 不支持 GROUPING  区分常规行与合计(总计)行 ； 看：  SelectTableTest_11_GROUPING\n\t6、pg 不支持 GROUPING_ID 返回GROUPING位向量的十进制值 ； 看： SelectTableTest_12_GROUPING_ID\n\t7、pg 不支持 MEDIAN  中位数； 看： SelectTableTest_15_MEDIAN\n\n\t8、pg 不支持 PERCENTILE_CONT  ， 看： SelectTableTest_17_PERCENTILE_CONT\n\t9、pg 不支持 PERCENTILE_DISC  ， 看： SelectTableTest_18_PERCENTILE_DISC\n   10、pg 不支持 PERCENT_RANK  ， 看： SelectTableTest_19_PERCENT_RANK\n   11、pg 不支持 RANK  ， 看： SelectTableTest_20_RANK\n\n   12、pg 不支持 统计二项测试 BINOMIAL_TEST  ； SelectTableTest_21_STATS_BINOMIAL_TEST\n   13、pg 不支持 分析两个变量 STATS_CROSSTAB ； SelectTableTest_22_STATS_CROSSTAB\n   14、pg 不支持 STATS_F_TEST          SelectTableTest_23_STATS_F_TEST\n   15、pg 不支持 STATS_MODE            SelectTableTest_24_STATS_KS_TEST\n   16、pg 不支持 STATS_MODE            SelectTableTest_25_STATS_MODE\n   17、pg 不支持 STATS_MW_TEST         SelectTableTest_26_STATS_MW_TEST\n   18、pg 不支持 STATS_ONE_WAY_ANOVA\t  SelectTableTest_27_STATS_ONE_WAY_ANOVA\n   19、pg 不支持 STATS_T_TEST  \t\t  SelectTableTest_28_STATS_T_TEST\n   20、pg 不支持 STATS_WSR_TEST  \t\t  SelectTableTest_29_STATS_WSR_TEST\n\n\n## create table\n安装自带UUID，不是需要手动安装：select rds_manage_extension('create','uuid-ossp'); / CREATE EXTENSION \"uuid-ossp\";\n\n\n## Select\nSELECT:\n\t1、 分页：minus、intersect 、Union、Union all 与分页结合 的查询； LIMIT XX OFFSET XX\n\t2、 WMSYS.WM_CONCAT、WM_CONCAT、listagg -> STRING_AGG\n\t3、 ^= -> !=\n\t4、子查询 加上别名，多个子查询同样加上不同的别名\n\t5、rowid 不支持\n\t6、UTL_RAW.CAST_TO_RAW 不支持\n\t7、update 不能有别名 \n\t8、采样： sample ()、sample block () 、sample block () seed() :  https://github.com/digoal/blog/blob/master/201706/20170602_02.md\n\t9、select sequence_name.nextval   --> select nextval('testseq_id_seq')\n\t10、connect by ：  fix\n\t11、 oracle（+）转 左连接、右连接\n\t12、limit union /limit union all 处理 -> (xx limit ) union / union all xxxx\n\t\n\t13、update/delete  有 rownum -> with 处理 ： https://yq.aliyun.com/articles/59451   没有处理\n\n\t14、select count(*) xx order by xx  处理：count sql 不能有 order by\n\t15、or SELECT DISTINCT, ORDER BY expressions must appear in select list LINE ，fix\n\t16、\n\t17、\n    \n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [Postgresql官网文档](https://www.postgresql.org/docs/devel/)\n","source":"_posts/Oracle转Postgresql总结.md","raw":"---\ntitle: Oracle转Postgresql总结\ndate: 2019-08-15 23:26:48\ncategories: \n    - SQL转换\ntags:\n    - SQL转换\n---\n\n## 数据类型\nOracle数据类型  Postgresql数据类型\n\n\n## 方法\n\n数字函数：（总共 26）\n\t1、PG 支持 ACOS、ASIN、ATAN、ATAN2、CEIL、COS、FLOOR、ROUND、SIN/TAN/TRUNC ，但是转换的时候，函数中字段 如果是 小数 转换成Char ，不是Number，SQLNumberExpr clone 只赋值了number，其他字段抛弃了 ；看 SelectTableTest_2_ACOS、SelectTableTest_3_ASIN \n\t2、PG 不支持 BITAND(x1, x2) :两个数值型数值在按位进行AND , 可以改为：x1 & x2 看：SelectTableTest_6_BITAND\n\t3、PG 不支持 COSH 反余弦值 ；SINH 反正弦值， TANH 看 ： SelectTableTest_9_COSH、SelectTableTest_19_SINH、SelectTableTest_24_TANH\n\t4、PG 不支持 NANVL(n1,n2) 如果n1是数字就返回n1，否则返回n2，看：SelectTableTest_15_NANVL\n\t5、 PG 不支持  REMAINDER（n1, n2） 四舍六入五取偶； 看：SelectTableTest_17_REMAINDER\n\t6、PG 不支持 SIGN(n1） 取数字n的符号,大于0返回1,小于0返回-1,等于0返回0; 看 ：SelectTableTest_19_SIGN\n\n\n字符函数：（总共28）\n\t1、pg 不支持 NLS_INITCAP, 可以使用 INITCAP 替代；看 ：SelectTableTest_7_NLS_INITCAP\n\t2、pg 不支持 NLS_LOWER , 可以使用 LOWER 替代；看： SelectTableTest_8_NLS_LOWER\n\t3、pg 不支持 NLS_UPPER , 可以使用 UPPER 替代；看： SelectTableTest_10_NLS_UPPER\n\t4、pg 不支持 NLSSORT、NLS_SORT 看： SelectTableTest_9_NLSSORT\n\t5、pg 不支持 SOUNDEX  : 四个字符组成的代码 (SOUNDEX) 以评估两个字符串的相似性 ; 看： SelectTableTest_16_SOUNDEX\n\t6、pg 不支持 NLS_CHARSET_ID  : 字符集对应的 ID ; 看： SelectTableTest_23_NLS_CHARSET_ID\n\t7、pg 不支持 NLS_CHARSET_DECL_LEN  : 声明长度（也就是字符个数） ; 看： SelectTableTest_22_NLS_CHARSET_DECL_LEN \n\t8、pg 不支持 NLS_CHARSET_NAME  : 字符集 ID 对应的字符集名称 ; 看： SelectTableTest_24_NLS_CHARSET_NAME \n\n\n日期时间函数：（总共25）\n\t1、oracle CURRENT_DATE(日期+时间) 转PG CURRENT_DATE（只有日期）, 可以用 SYSDATE 代替 ， 看: SelectTableTest_CURRENT_DATE\n\t2、pg 不支持 DBTIMEZONE  : 数据库时区  ; 看： SelectTableTest_4_DBTIMEZONE\n\t3、pg 不支持 FROM_TZ  : 将一个timstamp和timzone拼成一个timestamp with timezone  ; 看： SelectTableTest_6_FROM_TZ\n\t4、pg 不支持 NEXT_DAY  : 日期开始得到到未来  星期数  的日期  ; 看： SelectTableTest_11_NEXT_DAY\n\t5、pg 不支持 NUMTODSINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_12_NUMTODSINTERVAL\n\t6、pg 不支持 NUMTOYMINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_13_NUMTOYMINTERVAL\n\t7、pg 不支持 SESSIONTIMEZONE  :  会话时区  ; 看： SelectTableTest_15_SESSIONTIMEZONE \n\t8、pg 不支持 TO_TIMESTAMP_TZ  :  时间+时区 字符串 转 时间  ; 看： SelectTableTest_21_TO_TIMESTAMP_TZ \n\t9、pg 不支持 TO_DSINTERVAL  :  字符串转时间  ; 看： SelectTableTest_22_TO_DSINTERVAL\n   10、pg 不支持 TO_YMINTERVAL  :  字符串转 年 和月  ; 看： SelectTableTest_23_TO_YMINTERVAL\n   11、pg 不支持 TZ_OFFSET  :  将时区别名转换为以UTC为标准的OFFSET  ; 看： SelectTableTest_25_TZ_OFFSET  ： https://yq.aliyun.com/articles/61071\n\n\n一般比较功能函数：（总共2）\n\n转换函数：（总共 34）\n\t1、pg 不支持 ASCIISTR  : 字符在ASCII码表中有,则转成ASCII表中的字符, 如果没有,则转成\\xxxx格式,xxxx是UTF-16的编码.  ; 看： SelectTableTest_1_ASCIISTR\n\t2、pg 不支持 BIN_TO_NUM  : 二进制到十进制的转换 ，可以转换： select int4(bit(4) '1010'); ; 看： SelectTableTest_1_ASCIISTR ： https://yq.aliyun.com/articles/61074\n\t3、pg 不支持 CHARTOROWID  : 把包含外部格式的ROWID的CHAR或VARCHAR2数值转换为内部的二进制格式 ; 看： SelectTableTest_4_CHARTOROWID  \n\t4、pg 不支持 COMPOSE   ; 看： SelectTableTest_5_COMPOSE   \n\t5、pg 不支持 DECOMPOSE   ; 看： SelectTableTest_7_DECOMPOSE   \n\t6、pg 不支持 RAWTONHEX  ，     可以：TO_NCHAR(RAWTOHEX(raw))   ; 看： SelectTableTest_12_RAWTONHEX\n\t7、pg 不支持 ROWIDTOCHAR  将ROWID转换为字符串，长度18 ，   看： SelectTableTest_13_ROWIDTOCHAR\n\t8、pg 不支持 ROWIDTONCHAR ，   看： SelectTableTest_14_ROWIDTONCHAR\n\t9、pg 不支持 TO_BINARY_DOUBLE , 可以： 通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_17_TO_BINARY_DOUBLE\n   10、pg 不支持 TO_BINARY_FLOAT , 可以：  通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_18_TO_BINARY_FLOAT\n   11、pg 不支持 TO_CLOB ,可以：  过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_20_TO_CLOB\n   12、pg 支持 TO_DATE， 但是只支持 两个参数，  看：  SelectTableTest_21_TO_DATE\n   13、pg 不支持 TO_LOB ， 通过PPAS语法使用 xxxx::newtype 实现,  看：  SelectTableTest_23_TO_LOB\n   14、pg 不支持 TO_MULTI_BYTE ： 将字符串转换为双字节表示 ，   看：  SelectTableTest_24_TO_MULTI_BYTE\n   15、pg 不支持 TO_NCHAR  ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_25_TO_NCHAR\n   16、pg 不支持 TO_NCLOB   将字符串转换为NCLOB类型 ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_26_TO_NCLOB\n   17、pg 不支持 TO_SINGLE_BYTE  全角字符转换为半角的字符 ； 看：  SelectTableTest_29_TO_SINGLE_BYTE\n   18、pg 不支持 TRANSLATE_USING  将字符串转换为规定的字符集 ；  看：  SelectTableTest_33_TRANSLATE_USING\n   19、pg 不支持 UNISTR    将字符串转换为AL16UTF16或 UTF8字符 ；  看： SelectTableTest_34_UNISTR\n\n\nNULL 相关函数：(总共 5)\n\t1、pg 不支持 LNNVL 用于某个语句的where子句中的条件，如果条件为true就返回false；如果条件为UNKNOWN或者false就返回true  ， 看： SelectTableTest_2_LNNVL\n\t2、PG 不支持 NVL2（x, n1, n2） 如果X是空值，返回n2， 否则返回n1 ， pg 可以用 case : SELECT case WHEN null = null then  'Not Applicable' else '1' end  ， 看： SelectTableTest_5_NVL2\n\t\n\n聚合函数：(总共 36)\n\t1、pg 不支持 COLLECT  转换为一个嵌套表 ， 看：  SelectTableTest_2_COLLECT\n\t2、pg 不支持 CUME_DIST  ； 看：  SelectTableTest_7_CUME_DIST\n\t3、pg 不支持 DENSE_RANK  ； 看：  SelectTableTest_8_DENSE_RANK\n\t4、pg 不支持 GROUP_ID  消除GROUP BY子句返回的重复记录 ， 且  parse 错误； 看： SelectTableTest_10_GROUP_ID\n\t5、pg 不支持 GROUPING  区分常规行与合计(总计)行 ； 看：  SelectTableTest_11_GROUPING\n\t6、pg 不支持 GROUPING_ID 返回GROUPING位向量的十进制值 ； 看： SelectTableTest_12_GROUPING_ID\n\t7、pg 不支持 MEDIAN  中位数； 看： SelectTableTest_15_MEDIAN\n\n\t8、pg 不支持 PERCENTILE_CONT  ， 看： SelectTableTest_17_PERCENTILE_CONT\n\t9、pg 不支持 PERCENTILE_DISC  ， 看： SelectTableTest_18_PERCENTILE_DISC\n   10、pg 不支持 PERCENT_RANK  ， 看： SelectTableTest_19_PERCENT_RANK\n   11、pg 不支持 RANK  ， 看： SelectTableTest_20_RANK\n\n   12、pg 不支持 统计二项测试 BINOMIAL_TEST  ； SelectTableTest_21_STATS_BINOMIAL_TEST\n   13、pg 不支持 分析两个变量 STATS_CROSSTAB ； SelectTableTest_22_STATS_CROSSTAB\n   14、pg 不支持 STATS_F_TEST          SelectTableTest_23_STATS_F_TEST\n   15、pg 不支持 STATS_MODE            SelectTableTest_24_STATS_KS_TEST\n   16、pg 不支持 STATS_MODE            SelectTableTest_25_STATS_MODE\n   17、pg 不支持 STATS_MW_TEST         SelectTableTest_26_STATS_MW_TEST\n   18、pg 不支持 STATS_ONE_WAY_ANOVA\t  SelectTableTest_27_STATS_ONE_WAY_ANOVA\n   19、pg 不支持 STATS_T_TEST  \t\t  SelectTableTest_28_STATS_T_TEST\n   20、pg 不支持 STATS_WSR_TEST  \t\t  SelectTableTest_29_STATS_WSR_TEST\n\n\n## create table\n安装自带UUID，不是需要手动安装：select rds_manage_extension('create','uuid-ossp'); / CREATE EXTENSION \"uuid-ossp\";\n\n\n## Select\nSELECT:\n\t1、 分页：minus、intersect 、Union、Union all 与分页结合 的查询； LIMIT XX OFFSET XX\n\t2、 WMSYS.WM_CONCAT、WM_CONCAT、listagg -> STRING_AGG\n\t3、 ^= -> !=\n\t4、子查询 加上别名，多个子查询同样加上不同的别名\n\t5、rowid 不支持\n\t6、UTL_RAW.CAST_TO_RAW 不支持\n\t7、update 不能有别名 \n\t8、采样： sample ()、sample block () 、sample block () seed() :  https://github.com/digoal/blog/blob/master/201706/20170602_02.md\n\t9、select sequence_name.nextval   --> select nextval('testseq_id_seq')\n\t10、connect by ：  fix\n\t11、 oracle（+）转 左连接、右连接\n\t12、limit union /limit union all 处理 -> (xx limit ) union / union all xxxx\n\t\n\t13、update/delete  有 rownum -> with 处理 ： https://yq.aliyun.com/articles/59451   没有处理\n\n\t14、select count(*) xx order by xx  处理：count sql 不能有 order by\n\t15、or SELECT DISTINCT, ORDER BY expressions must appear in select list LINE ，fix\n\t16、\n\t17、\n    \n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [Postgresql官网文档](https://www.postgresql.org/docs/devel/)\n","slug":"Oracle转Postgresql总结","published":1,"updated":"2021-06-30T02:33:24.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswy0073r5p7chmifdr2","content":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>Oracle数据类型  Postgresql数据类型</p>\n<h2 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h2><p>数字函数：（总共 26）\n    1、PG 支持 ACOS、ASIN、ATAN、ATAN2、CEIL、COS、FLOOR、ROUND、SIN/TAN/TRUNC ，但是转换的时候，函数中字段 如果是 小数 转换成Char ，不是Number，SQLNumberExpr clone 只赋值了number，其他字段抛弃了 ；看 SelectTableTest_2_ACOS、SelectTableTest_3_ASIN \n    2、PG 不支持 BITAND(x1, x2) :两个数值型数值在按位进行AND , 可以改为：x1 &amp; x2 看：SelectTableTest_6_BITAND\n    3、PG 不支持 COSH 反余弦值 ；SINH 反正弦值， TANH 看 ： SelectTableTest_9_COSH、SelectTableTest_19_SINH、SelectTableTest_24_TANH\n    4、PG 不支持 NANVL(n1,n2) 如果n1是数字就返回n1，否则返回n2，看：SelectTableTest_15_NANVL\n    5、 PG 不支持  REMAINDER（n1, n2） 四舍六入五取偶； 看：SelectTableTest_17_REMAINDER\n    6、PG 不支持 SIGN(n1） 取数字n的符号,大于0返回1,小于0返回-1,等于0返回0; 看 ：SelectTableTest_19_SIGN</p>\n<p>字符函数：（总共28）\n    1、pg 不支持 NLS_INITCAP, 可以使用 INITCAP 替代；看 ：SelectTableTest_7_NLS_INITCAP\n    2、pg 不支持 NLS_LOWER , 可以使用 LOWER 替代；看： SelectTableTest_8_NLS_LOWER\n    3、pg 不支持 NLS_UPPER , 可以使用 UPPER 替代；看： SelectTableTest_10_NLS_UPPER\n    4、pg 不支持 NLSSORT、NLS_SORT 看： SelectTableTest_9_NLSSORT\n    5、pg 不支持 SOUNDEX  : 四个字符组成的代码 (SOUNDEX) 以评估两个字符串的相似性 ; 看： SelectTableTest_16_SOUNDEX\n    6、pg 不支持 NLS_CHARSET_ID  : 字符集对应的 ID ; 看： SelectTableTest_23_NLS_CHARSET_ID\n    7、pg 不支持 NLS_CHARSET_DECL_LEN  : 声明长度（也就是字符个数） ; 看： SelectTableTest_22_NLS_CHARSET_DECL_LEN \n    8、pg 不支持 NLS_CHARSET_NAME  : 字符集 ID 对应的字符集名称 ; 看： SelectTableTest_24_NLS_CHARSET_NAME </p>\n<p>日期时间函数：（总共25）\n    1、oracle CURRENT_DATE(日期+时间) 转PG CURRENT_DATE（只有日期）, 可以用 SYSDATE 代替 ， 看: SelectTableTest_CURRENT_DATE\n    2、pg 不支持 DBTIMEZONE  : 数据库时区  ; 看： SelectTableTest_4_DBTIMEZONE\n    3、pg 不支持 FROM_TZ  : 将一个timstamp和timzone拼成一个timestamp with timezone  ; 看： SelectTableTest_6_FROM_TZ\n    4、pg 不支持 NEXT_DAY  : 日期开始得到到未来  星期数  的日期  ; 看： SelectTableTest_11_NEXT_DAY\n    5、pg 不支持 NUMTODSINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_12_NUMTODSINTERVAL\n    6、pg 不支持 NUMTOYMINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_13_NUMTOYMINTERVAL\n    7、pg 不支持 SESSIONTIMEZONE  :  会话时区  ; 看： SelectTableTest_15_SESSIONTIMEZONE \n    8、pg 不支持 TO_TIMESTAMP_TZ  :  时间+时区 字符串 转 时间  ; 看： SelectTableTest_21_TO_TIMESTAMP_TZ \n    9、pg 不支持 TO_DSINTERVAL  :  字符串转时间  ; 看： SelectTableTest_22_TO_DSINTERVAL\n   10、pg 不支持 TO_YMINTERVAL  :  字符串转 年 和月  ; 看： SelectTableTest_23_TO_YMINTERVAL\n   11、pg 不支持 TZ_OFFSET  :  将时区别名转换为以UTC为标准的OFFSET  ; 看： SelectTableTest_25_TZ_OFFSET  ： <a href=\"https://yq.aliyun.com/articles/61071\">https://yq.aliyun.com/articles/61071</a></p>\n<p>一般比较功能函数：（总共2）</p>\n<p>转换函数：（总共 34）\n    1、pg 不支持 ASCIISTR  : 字符在ASCII码表中有,则转成ASCII表中的字符, 如果没有,则转成\\xxxx格式,xxxx是UTF-16的编码.  ; 看： SelectTableTest_1_ASCIISTR\n    2、pg 不支持 BIN_TO_NUM  : 二进制到十进制的转换 ，可以转换： select int4(bit(4) ‘1010’); ; 看： SelectTableTest_1_ASCIISTR ： <a href=\"https://yq.aliyun.com/articles/61074\">https://yq.aliyun.com/articles/61074</a>\n    3、pg 不支持 CHARTOROWID  : 把包含外部格式的ROWID的CHAR或VARCHAR2数值转换为内部的二进制格式 ; 看： SelectTableTest_4_CHARTOROWID<br>    4、pg 不支持 COMPOSE   ; 看： SelectTableTest_5_COMPOSE<br>    5、pg 不支持 DECOMPOSE   ; 看： SelectTableTest_7_DECOMPOSE<br>    6、pg 不支持 RAWTONHEX  ，     可以：TO_NCHAR(RAWTOHEX(raw))   ; 看： SelectTableTest_12_RAWTONHEX\n    7、pg 不支持 ROWIDTOCHAR  将ROWID转换为字符串，长度18 ，   看： SelectTableTest_13_ROWIDTOCHAR\n    8、pg 不支持 ROWIDTONCHAR ，   看： SelectTableTest_14_ROWIDTONCHAR\n    9、pg 不支持 TO_BINARY_DOUBLE , 可以： 通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_17_TO_BINARY_DOUBLE\n   10、pg 不支持 TO_BINARY_FLOAT , 可以：  通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_18_TO_BINARY_FLOAT\n   11、pg 不支持 TO_CLOB ,可以：  过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_20_TO_CLOB\n   12、pg 支持 TO_DATE， 但是只支持 两个参数，  看：  SelectTableTest_21_TO_DATE\n   13、pg 不支持 TO_LOB ， 通过PPAS语法使用 xxxx::newtype 实现,  看：  SelectTableTest_23_TO_LOB\n   14、pg 不支持 TO_MULTI_BYTE ： 将字符串转换为双字节表示 ，   看：  SelectTableTest_24_TO_MULTI_BYTE\n   15、pg 不支持 TO_NCHAR  ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_25_TO_NCHAR\n   16、pg 不支持 TO_NCLOB   将字符串转换为NCLOB类型 ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_26_TO_NCLOB\n   17、pg 不支持 TO_SINGLE_BYTE  全角字符转换为半角的字符 ； 看：  SelectTableTest_29_TO_SINGLE_BYTE\n   18、pg 不支持 TRANSLATE_USING  将字符串转换为规定的字符集 ；  看：  SelectTableTest_33_TRANSLATE_USING\n   19、pg 不支持 UNISTR    将字符串转换为AL16UTF16或 UTF8字符 ；  看： SelectTableTest_34_UNISTR</p>\n<p>NULL 相关函数：(总共 5)\n    1、pg 不支持 LNNVL 用于某个语句的where子句中的条件，如果条件为true就返回false；如果条件为UNKNOWN或者false就返回true  ， 看： SelectTableTest_2_LNNVL\n    2、PG 不支持 NVL2（x, n1, n2） 如果X是空值，返回n2， 否则返回n1 ， pg 可以用 case : SELECT case WHEN null = null then  ‘Not Applicable’ else ‘1’ end  ， 看： SelectTableTest_5_NVL2</p>\n<p>聚合函数：(总共 36)\n    1、pg 不支持 COLLECT  转换为一个嵌套表 ， 看：  SelectTableTest_2_COLLECT\n    2、pg 不支持 CUME_DIST  ； 看：  SelectTableTest_7_CUME_DIST\n    3、pg 不支持 DENSE_RANK  ； 看：  SelectTableTest_8_DENSE_RANK\n    4、pg 不支持 GROUP_ID  消除GROUP BY子句返回的重复记录 ， 且  parse 错误； 看： SelectTableTest_10_GROUP_ID\n    5、pg 不支持 GROUPING  区分常规行与合计(总计)行 ； 看：  SelectTableTest_11_GROUPING\n    6、pg 不支持 GROUPING_ID 返回GROUPING位向量的十进制值 ； 看： SelectTableTest_12_GROUPING_ID\n    7、pg 不支持 MEDIAN  中位数； 看： SelectTableTest_15_MEDIAN</p>\n<pre><code>8、pg 不支持 PERCENTILE_CONT  ， 看： SelectTableTest_17_PERCENTILE_CONT\n9、pg 不支持 PERCENTILE_DISC  ， 看： SelectTableTest_18_PERCENTILE_DISC\n</code></pre>\n<p>   10、pg 不支持 PERCENT_RANK  ， 看： SelectTableTest_19_PERCENT_RANK\n   11、pg 不支持 RANK  ， 看： SelectTableTest_20_RANK</p>\n<p>   12、pg 不支持 统计二项测试 BINOMIAL_TEST  ； SelectTableTest_21_STATS_BINOMIAL_TEST\n   13、pg 不支持 分析两个变量 STATS_CROSSTAB ； SelectTableTest_22_STATS_CROSSTAB\n   14、pg 不支持 STATS_F_TEST          SelectTableTest_23_STATS_F_TEST\n   15、pg 不支持 STATS_MODE            SelectTableTest_24_STATS_KS_TEST\n   16、pg 不支持 STATS_MODE            SelectTableTest_25_STATS_MODE\n   17、pg 不支持 STATS_MW_TEST         SelectTableTest_26_STATS_MW_TEST\n   18、pg 不支持 STATS_ONE_WAY_ANOVA      SelectTableTest_27_STATS_ONE_WAY_ANOVA\n   19、pg 不支持 STATS_T_TEST            SelectTableTest_28_STATS_T_TEST\n   20、pg 不支持 STATS_WSR_TEST            SelectTableTest_29_STATS_WSR_TEST</p>\n<h2 id=\"create-table\"><a href=\"#create-table\" class=\"headerlink\" title=\"create table\"></a>create table</h2><p>安装自带UUID，不是需要手动安装：select rds_manage_extension(‘create’,’uuid-ossp’); / CREATE EXTENSION “uuid-ossp”;</p>\n<h2 id=\"Select\"><a href=\"#Select\" class=\"headerlink\" title=\"Select\"></a>Select</h2><p>SELECT:\n    1、 分页：minus、intersect 、Union、Union all 与分页结合 的查询； LIMIT XX OFFSET XX\n    2、 WMSYS.WM_CONCAT、WM_CONCAT、listagg -&gt; STRING_AGG\n    3、 ^= -&gt; !=\n    4、子查询 加上别名，多个子查询同样加上不同的别名\n    5、rowid 不支持\n    6、UTL_RAW.CAST_TO_RAW 不支持\n    7、update 不能有别名 \n    8、采样： sample ()、sample block () 、sample block () seed() :  <a href=\"https://github.com/digoal/blog/blob/master/201706/20170602_02.md\">https://github.com/digoal/blog/blob/master/201706/20170602_02.md</a>\n    9、select sequence_name.nextval   –&gt; select nextval(‘testseq_id_seq’)\n    10、connect by ：  fix\n    11、 oracle（+）转 左连接、右连接\n    12、limit union /limit union all 处理 -&gt; (xx limit ) union / union all xxxx</p>\n<pre><code>13、update/delete  有 rownum -&gt; with 处理 ： https://yq.aliyun.com/articles/59451   没有处理\n\n14、select count(*) xx order by xx  处理：count sql 不能有 order by\n15、or SELECT DISTINCT, ORDER BY expressions must appear in select list LINE ，fix\n16、\n17、\n</code></pre>\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://www.postgresql.org/docs/devel/\">Postgresql官网文档</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p>Oracle数据类型  Postgresql数据类型</p>\n<h2 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h2><p>数字函数：（总共 26）\n    1、PG 支持 ACOS、ASIN、ATAN、ATAN2、CEIL、COS、FLOOR、ROUND、SIN/TAN/TRUNC ，但是转换的时候，函数中字段 如果是 小数 转换成Char ，不是Number，SQLNumberExpr clone 只赋值了number，其他字段抛弃了 ；看 SelectTableTest_2_ACOS、SelectTableTest_3_ASIN \n    2、PG 不支持 BITAND(x1, x2) :两个数值型数值在按位进行AND , 可以改为：x1 &amp; x2 看：SelectTableTest_6_BITAND\n    3、PG 不支持 COSH 反余弦值 ；SINH 反正弦值， TANH 看 ： SelectTableTest_9_COSH、SelectTableTest_19_SINH、SelectTableTest_24_TANH\n    4、PG 不支持 NANVL(n1,n2) 如果n1是数字就返回n1，否则返回n2，看：SelectTableTest_15_NANVL\n    5、 PG 不支持  REMAINDER（n1, n2） 四舍六入五取偶； 看：SelectTableTest_17_REMAINDER\n    6、PG 不支持 SIGN(n1） 取数字n的符号,大于0返回1,小于0返回-1,等于0返回0; 看 ：SelectTableTest_19_SIGN</p>\n<p>字符函数：（总共28）\n    1、pg 不支持 NLS_INITCAP, 可以使用 INITCAP 替代；看 ：SelectTableTest_7_NLS_INITCAP\n    2、pg 不支持 NLS_LOWER , 可以使用 LOWER 替代；看： SelectTableTest_8_NLS_LOWER\n    3、pg 不支持 NLS_UPPER , 可以使用 UPPER 替代；看： SelectTableTest_10_NLS_UPPER\n    4、pg 不支持 NLSSORT、NLS_SORT 看： SelectTableTest_9_NLSSORT\n    5、pg 不支持 SOUNDEX  : 四个字符组成的代码 (SOUNDEX) 以评估两个字符串的相似性 ; 看： SelectTableTest_16_SOUNDEX\n    6、pg 不支持 NLS_CHARSET_ID  : 字符集对应的 ID ; 看： SelectTableTest_23_NLS_CHARSET_ID\n    7、pg 不支持 NLS_CHARSET_DECL_LEN  : 声明长度（也就是字符个数） ; 看： SelectTableTest_22_NLS_CHARSET_DECL_LEN \n    8、pg 不支持 NLS_CHARSET_NAME  : 字符集 ID 对应的字符集名称 ; 看： SelectTableTest_24_NLS_CHARSET_NAME </p>\n<p>日期时间函数：（总共25）\n    1、oracle CURRENT_DATE(日期+时间) 转PG CURRENT_DATE（只有日期）, 可以用 SYSDATE 代替 ， 看: SelectTableTest_CURRENT_DATE\n    2、pg 不支持 DBTIMEZONE  : 数据库时区  ; 看： SelectTableTest_4_DBTIMEZONE\n    3、pg 不支持 FROM_TZ  : 将一个timstamp和timzone拼成一个timestamp with timezone  ; 看： SelectTableTest_6_FROM_TZ\n    4、pg 不支持 NEXT_DAY  : 日期开始得到到未来  星期数  的日期  ; 看： SelectTableTest_11_NEXT_DAY\n    5、pg 不支持 NUMTODSINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_12_NUMTODSINTERVAL\n    6、pg 不支持 NUMTOYMINTERVAL  :  把数字转换为时间 ；  且 parser 异常  ; 看： SelectTableTest_13_NUMTOYMINTERVAL\n    7、pg 不支持 SESSIONTIMEZONE  :  会话时区  ; 看： SelectTableTest_15_SESSIONTIMEZONE \n    8、pg 不支持 TO_TIMESTAMP_TZ  :  时间+时区 字符串 转 时间  ; 看： SelectTableTest_21_TO_TIMESTAMP_TZ \n    9、pg 不支持 TO_DSINTERVAL  :  字符串转时间  ; 看： SelectTableTest_22_TO_DSINTERVAL\n   10、pg 不支持 TO_YMINTERVAL  :  字符串转 年 和月  ; 看： SelectTableTest_23_TO_YMINTERVAL\n   11、pg 不支持 TZ_OFFSET  :  将时区别名转换为以UTC为标准的OFFSET  ; 看： SelectTableTest_25_TZ_OFFSET  ： <a href=\"https://yq.aliyun.com/articles/61071\">https://yq.aliyun.com/articles/61071</a></p>\n<p>一般比较功能函数：（总共2）</p>\n<p>转换函数：（总共 34）\n    1、pg 不支持 ASCIISTR  : 字符在ASCII码表中有,则转成ASCII表中的字符, 如果没有,则转成\\xxxx格式,xxxx是UTF-16的编码.  ; 看： SelectTableTest_1_ASCIISTR\n    2、pg 不支持 BIN_TO_NUM  : 二进制到十进制的转换 ，可以转换： select int4(bit(4) ‘1010’); ; 看： SelectTableTest_1_ASCIISTR ： <a href=\"https://yq.aliyun.com/articles/61074\">https://yq.aliyun.com/articles/61074</a>\n    3、pg 不支持 CHARTOROWID  : 把包含外部格式的ROWID的CHAR或VARCHAR2数值转换为内部的二进制格式 ; 看： SelectTableTest_4_CHARTOROWID<br>    4、pg 不支持 COMPOSE   ; 看： SelectTableTest_5_COMPOSE<br>    5、pg 不支持 DECOMPOSE   ; 看： SelectTableTest_7_DECOMPOSE<br>    6、pg 不支持 RAWTONHEX  ，     可以：TO_NCHAR(RAWTOHEX(raw))   ; 看： SelectTableTest_12_RAWTONHEX\n    7、pg 不支持 ROWIDTOCHAR  将ROWID转换为字符串，长度18 ，   看： SelectTableTest_13_ROWIDTOCHAR\n    8、pg 不支持 ROWIDTONCHAR ，   看： SelectTableTest_14_ROWIDTONCHAR\n    9、pg 不支持 TO_BINARY_DOUBLE , 可以： 通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_17_TO_BINARY_DOUBLE\n   10、pg 不支持 TO_BINARY_FLOAT , 可以：  通过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_18_TO_BINARY_FLOAT\n   11、pg 不支持 TO_CLOB ,可以：  过PPAS语法使用 xxxx::newtype 实现  看： SelectTableTest_20_TO_CLOB\n   12、pg 支持 TO_DATE， 但是只支持 两个参数，  看：  SelectTableTest_21_TO_DATE\n   13、pg 不支持 TO_LOB ， 通过PPAS语法使用 xxxx::newtype 实现,  看：  SelectTableTest_23_TO_LOB\n   14、pg 不支持 TO_MULTI_BYTE ： 将字符串转换为双字节表示 ，   看：  SelectTableTest_24_TO_MULTI_BYTE\n   15、pg 不支持 TO_NCHAR  ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_25_TO_NCHAR\n   16、pg 不支持 TO_NCLOB   将字符串转换为NCLOB类型 ； 可以： 通过PPAS语法使用 xxxx::newtype 实现 ；  看： SelectTableTest_26_TO_NCLOB\n   17、pg 不支持 TO_SINGLE_BYTE  全角字符转换为半角的字符 ； 看：  SelectTableTest_29_TO_SINGLE_BYTE\n   18、pg 不支持 TRANSLATE_USING  将字符串转换为规定的字符集 ；  看：  SelectTableTest_33_TRANSLATE_USING\n   19、pg 不支持 UNISTR    将字符串转换为AL16UTF16或 UTF8字符 ；  看： SelectTableTest_34_UNISTR</p>\n<p>NULL 相关函数：(总共 5)\n    1、pg 不支持 LNNVL 用于某个语句的where子句中的条件，如果条件为true就返回false；如果条件为UNKNOWN或者false就返回true  ， 看： SelectTableTest_2_LNNVL\n    2、PG 不支持 NVL2（x, n1, n2） 如果X是空值，返回n2， 否则返回n1 ， pg 可以用 case : SELECT case WHEN null = null then  ‘Not Applicable’ else ‘1’ end  ， 看： SelectTableTest_5_NVL2</p>\n<p>聚合函数：(总共 36)\n    1、pg 不支持 COLLECT  转换为一个嵌套表 ， 看：  SelectTableTest_2_COLLECT\n    2、pg 不支持 CUME_DIST  ； 看：  SelectTableTest_7_CUME_DIST\n    3、pg 不支持 DENSE_RANK  ； 看：  SelectTableTest_8_DENSE_RANK\n    4、pg 不支持 GROUP_ID  消除GROUP BY子句返回的重复记录 ， 且  parse 错误； 看： SelectTableTest_10_GROUP_ID\n    5、pg 不支持 GROUPING  区分常规行与合计(总计)行 ； 看：  SelectTableTest_11_GROUPING\n    6、pg 不支持 GROUPING_ID 返回GROUPING位向量的十进制值 ； 看： SelectTableTest_12_GROUPING_ID\n    7、pg 不支持 MEDIAN  中位数； 看： SelectTableTest_15_MEDIAN</p>\n<pre><code>8、pg 不支持 PERCENTILE_CONT  ， 看： SelectTableTest_17_PERCENTILE_CONT\n9、pg 不支持 PERCENTILE_DISC  ， 看： SelectTableTest_18_PERCENTILE_DISC\n</code></pre>\n<p>   10、pg 不支持 PERCENT_RANK  ， 看： SelectTableTest_19_PERCENT_RANK\n   11、pg 不支持 RANK  ， 看： SelectTableTest_20_RANK</p>\n<p>   12、pg 不支持 统计二项测试 BINOMIAL_TEST  ； SelectTableTest_21_STATS_BINOMIAL_TEST\n   13、pg 不支持 分析两个变量 STATS_CROSSTAB ； SelectTableTest_22_STATS_CROSSTAB\n   14、pg 不支持 STATS_F_TEST          SelectTableTest_23_STATS_F_TEST\n   15、pg 不支持 STATS_MODE            SelectTableTest_24_STATS_KS_TEST\n   16、pg 不支持 STATS_MODE            SelectTableTest_25_STATS_MODE\n   17、pg 不支持 STATS_MW_TEST         SelectTableTest_26_STATS_MW_TEST\n   18、pg 不支持 STATS_ONE_WAY_ANOVA      SelectTableTest_27_STATS_ONE_WAY_ANOVA\n   19、pg 不支持 STATS_T_TEST            SelectTableTest_28_STATS_T_TEST\n   20、pg 不支持 STATS_WSR_TEST            SelectTableTest_29_STATS_WSR_TEST</p>\n<h2 id=\"create-table\"><a href=\"#create-table\" class=\"headerlink\" title=\"create table\"></a>create table</h2><p>安装自带UUID，不是需要手动安装：select rds_manage_extension(‘create’,’uuid-ossp’); / CREATE EXTENSION “uuid-ossp”;</p>\n<h2 id=\"Select\"><a href=\"#Select\" class=\"headerlink\" title=\"Select\"></a>Select</h2><p>SELECT:\n    1、 分页：minus、intersect 、Union、Union all 与分页结合 的查询； LIMIT XX OFFSET XX\n    2、 WMSYS.WM_CONCAT、WM_CONCAT、listagg -&gt; STRING_AGG\n    3、 ^= -&gt; !=\n    4、子查询 加上别名，多个子查询同样加上不同的别名\n    5、rowid 不支持\n    6、UTL_RAW.CAST_TO_RAW 不支持\n    7、update 不能有别名 \n    8、采样： sample ()、sample block () 、sample block () seed() :  <a href=\"https://github.com/digoal/blog/blob/master/201706/20170602_02.md\">https://github.com/digoal/blog/blob/master/201706/20170602_02.md</a>\n    9、select sequence_name.nextval   –&gt; select nextval(‘testseq_id_seq’)\n    10、connect by ：  fix\n    11、 oracle（+）转 左连接、右连接\n    12、limit union /limit union all 处理 -&gt; (xx limit ) union / union all xxxx</p>\n<pre><code>13、update/delete  有 rownum -&gt; with 处理 ： https://yq.aliyun.com/articles/59451   没有处理\n\n14、select count(*) xx order by xx  处理：count sql 不能有 order by\n15、or SELECT DISTINCT, ORDER BY expressions must appear in select list LINE ，fix\n16、\n17、\n</code></pre>\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://www.postgresql.org/docs/devel/\">Postgresql官网文档</a></li>\n</ul>\n"},{"title":"PyTorch教程","date":"2018-11-23T07:45:02.000Z","_content":"\nPyTorch是一个开源的Python机器学习库，基于Torch，应用于人工智能领域，如自然语言处理。 它最初由Facebook的人工智能研究团队开发，并且被用于Uber的概率编程软件\"Pyro\"。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n## \n\n## \n\n\n\n<br/>\n\n---\n参考\n[pytorch官网](https://pytorch.org/)\n[pytorch-Github](https://github.com/pytorch/pytorch)\n","source":"_posts/PyTorch教程.md","raw":"---\ntitle: PyTorch教程\ndate: 2018-11-23 15:45:02\ncategories: \n    - PyTorch\ntags:\n    - 机器学习\n    - 深度学习\n    - 深度学习框架\n    - PyTorch\n---\n\nPyTorch是一个开源的Python机器学习库，基于Torch，应用于人工智能领域，如自然语言处理。 它最初由Facebook的人工智能研究团队开发，并且被用于Uber的概率编程软件\"Pyro\"。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n## \n\n## \n\n\n\n<br/>\n\n---\n参考\n[pytorch官网](https://pytorch.org/)\n[pytorch-Github](https://github.com/pytorch/pytorch)\n","slug":"PyTorch教程","published":1,"updated":"2021-06-30T02:33:24.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjswz0077r5p73sxb46tp","content":"<p>PyTorch是一个开源的Python机器学习库，基于Torch，应用于人工智能领域，如自然语言处理。 它最初由Facebook的人工智能研究团队开发，并且被用于Uber的概率编程软件”Pyro”。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><br>\n\n<hr>\n<p>参考\n<a href=\"https://pytorch.org/\">pytorch官网</a>\n<a href=\"https://github.com/pytorch/pytorch\">pytorch-Github</a></p>\n","site":{"data":{}},"excerpt":"<p>PyTorch是一个开源的Python机器学习库，基于Torch，应用于人工智能领域，如自然语言处理。 它最初由Facebook的人工智能研究团队开发，并且被用于Uber的概率编程软件”Pyro”。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><br/>\n\n<hr>\n<p>参考\n<a href=\"https://pytorch.org/\">pytorch官网</a>\n<a href=\"https://github.com/pytorch/pytorch\">pytorch-Github</a></p>"},{"title":"Redis安装","date":"2018-12-06T01:19:51.000Z","_content":"\n## MAC环境安装\n### 下载\n下载地址：http://www.redis.cn/download.html\n\n<br/>\n### 安装\n```bash\n# 进入下载目录 & 解压\n$ sudo tar -zxzf redis-xxx.tar.gz\n```\n\n<!-- more -->\n\n\n```bash\n# make test\n$ sudo make test\n\n[exception]: Executing test client: couldn't execute \"src/redis-benchmark\": no such file or directory.\ncouldn't execute \"src/redis-benchmark\": no such file or directory\n    while executing\n\"exec src/redis-benchmark -p $R_port(0) -n 10000000 -r 1000 incr __rand_int__ > /dev/null &\"\n    (\"uplevel\" body line 31)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0                   ; # Do no...\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0          ...\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {tags {\"psync2\"}} {\nstart_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug mess...\"\n    (file \"tests/integration/psync2-reg.tcl\" line 7)\n    invoked from within\n\"source $path\"\n    (procedure \"execute_tests\" line 4)\n    invoked from within\n\"execute_tests $data\"\n    (procedure \"test_client_main\" line 10)\n    invoked from within\n\"test_client_main $::test_server_port \"\nKilling still running Redis server 48649\nKilling still running Redis server 48648\nKilling still running Redis server 48663\nKilling still running Redis server 48661\nKilling still running Redis server 48660\nKilling still running Redis server 48856\nKilling still running Redis server 48884\nKilling still running Redis server 48894\nI/O error reading reply\n    while executing\n\"$r bzpopmax $k 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            $r zadd $k [randomInt 10000] $v\n        } {\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        } {\n     ...\"\n    (procedure \"bg_block_op\" line 30)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nI/O error reading reply\n    while executing\n\"$r bzpopmax $k 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            $r zadd $k [randomInt 10000] $v\n        } {\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        } {\n     ...\"\n    (procedure \"bg_block_op\" line 30)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nI/O error reading reply\n    while executing\n\"$r blpop $k $k2 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            randpath {\n                $r rpush $k $v\n            } {\n                $r lpush $k $v\n            }\n        } {\n            ...\"\n    (procedure \"bg_block_op\" line 12)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nKilling still running Redis server 48948\nKilling still running Redis server 48956\nKilling still running Redis server 48969\nKilling still running Redis server 48975\nKilling still running Redis server 49228\nKilling still running Redis server 49238\nKilling still running Redis server 49251\nKilling still running Redis server 49263\nKilling still running Redis server 49278\nKilling still running Redis server 49295\nKilling still running Redis server 49469\nKilling still running Redis server 49482\nKilling still running Redis server 49501\nKilling still running Redis server 49509\nKilling still running Redis server 49520\nKilling still running Redis server 49535\nKilling still running Redis server 49540\nKilling still running Redis server 49563\nKilling still running Redis server 49566\nKilling still running Redis server 49578\nKilling still running Redis server 49587\nKilling still running Redis server 49648\nKilling still running Redis server 49660\nmake[1]: *** [test] Error 1\nmake: *** [test] Error 2\n```\n\n\n```bash\n# install（上面报错不影响安装）\n$ sudo make install\n\nNSTALL redis-sentinel\n    CC redis-cli.o\n    LINK redis-cli\n    CC redis-benchmark.o\n    LINK redis-benchmark\n    INSTALL redis-check-rdb\n\nHint: It's a good idea to run 'make test' ;)\n\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n```\n\n\n### 启动\n\n** 在`Library` 目录\b创建相应的`redis-xxx`目录 ** \n```bash\n$ cd /Library\n$ sudo mkdir redis-xxx\n```\n\n** 在`redis-xxx`目录下建立`bin`、`conf`、`data`和`log`目录 **\n\n```bash\n$ sudo mkdir bin\n$ sudo mkdir conf\n$ sudo mkdir data\n$ sudo mkdir log\n```\n\n** 把`make install`之后的`src`目录下的文件 : `mkreleasehdr.sh` `redis-benchmark` `redis-check-rdb` `redis-cli` `redis-server` 拷贝到上面 `bin` 目录 **\n```\ncp mkreleasehdr.sh /Library/redis-xxx/bin\ncp redis-check-rdb /Library/redis-xxx/bin\ncp redis-cli /Library/redis-xxx/bin\ncp redis-server /Library/redis-xxx/bin\n```\n\n\n```\n$ ./redis-server ../conf/redis.conf\n\n$ ./redis-cli\n\n```\n\n### 配置\n\n","source":"_posts/Redis安装.md","raw":"---\ntitle: Redis安装\ndate: 2018-12-06 09:19:51\ncategories: \n    - Redis\ntags:\n    - NoSQL\n    - Redis\n---\n\n## MAC环境安装\n### 下载\n下载地址：http://www.redis.cn/download.html\n\n<br/>\n### 安装\n```bash\n# 进入下载目录 & 解压\n$ sudo tar -zxzf redis-xxx.tar.gz\n```\n\n<!-- more -->\n\n\n```bash\n# make test\n$ sudo make test\n\n[exception]: Executing test client: couldn't execute \"src/redis-benchmark\": no such file or directory.\ncouldn't execute \"src/redis-benchmark\": no such file or directory\n    while executing\n\"exec src/redis-benchmark -p $R_port(0) -n 10000000 -r 1000 incr __rand_int__ > /dev/null &\"\n    (\"uplevel\" body line 31)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0                   ; # Do no...\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0          ...\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {tags {\"psync2\"}} {\nstart_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug mess...\"\n    (file \"tests/integration/psync2-reg.tcl\" line 7)\n    invoked from within\n\"source $path\"\n    (procedure \"execute_tests\" line 4)\n    invoked from within\n\"execute_tests $data\"\n    (procedure \"test_client_main\" line 10)\n    invoked from within\n\"test_client_main $::test_server_port \"\nKilling still running Redis server 48649\nKilling still running Redis server 48648\nKilling still running Redis server 48663\nKilling still running Redis server 48661\nKilling still running Redis server 48660\nKilling still running Redis server 48856\nKilling still running Redis server 48884\nKilling still running Redis server 48894\nI/O error reading reply\n    while executing\n\"$r bzpopmax $k 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            $r zadd $k [randomInt 10000] $v\n        } {\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        } {\n     ...\"\n    (procedure \"bg_block_op\" line 30)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nI/O error reading reply\n    while executing\n\"$r bzpopmax $k 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            $r zadd $k [randomInt 10000] $v\n        } {\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        } {\n     ...\"\n    (procedure \"bg_block_op\" line 30)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nI/O error reading reply\n    while executing\n\"$r blpop $k $k2 2\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 [lindex $args $path]\"\n    (procedure \"randpath\" line 3)\n    invoked from within\n\"randpath {\n            randpath {\n                $r rpush $k $v\n            } {\n                $r lpush $k $v\n            }\n        } {\n            ...\"\n    (procedure \"bg_block_op\" line 12)\n    invoked from within\n\"bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]\"\n    (file \"tests/helpers/bg_block_op.tcl\" line 52)\nKilling still running Redis server 48948\nKilling still running Redis server 48956\nKilling still running Redis server 48969\nKilling still running Redis server 48975\nKilling still running Redis server 49228\nKilling still running Redis server 49238\nKilling still running Redis server 49251\nKilling still running Redis server 49263\nKilling still running Redis server 49278\nKilling still running Redis server 49295\nKilling still running Redis server 49469\nKilling still running Redis server 49482\nKilling still running Redis server 49501\nKilling still running Redis server 49509\nKilling still running Redis server 49520\nKilling still running Redis server 49535\nKilling still running Redis server 49540\nKilling still running Redis server 49563\nKilling still running Redis server 49566\nKilling still running Redis server 49578\nKilling still running Redis server 49587\nKilling still running Redis server 49648\nKilling still running Redis server 49660\nmake[1]: *** [test] Error 1\nmake: *** [test] Error 2\n```\n\n\n```bash\n# install（上面报错不影响安装）\n$ sudo make install\n\nNSTALL redis-sentinel\n    CC redis-cli.o\n    LINK redis-cli\n    CC redis-benchmark.o\n    LINK redis-benchmark\n    INSTALL redis-check-rdb\n\nHint: It's a good idea to run 'make test' ;)\n\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n```\n\n\n### 启动\n\n** 在`Library` 目录\b创建相应的`redis-xxx`目录 ** \n```bash\n$ cd /Library\n$ sudo mkdir redis-xxx\n```\n\n** 在`redis-xxx`目录下建立`bin`、`conf`、`data`和`log`目录 **\n\n```bash\n$ sudo mkdir bin\n$ sudo mkdir conf\n$ sudo mkdir data\n$ sudo mkdir log\n```\n\n** 把`make install`之后的`src`目录下的文件 : `mkreleasehdr.sh` `redis-benchmark` `redis-check-rdb` `redis-cli` `redis-server` 拷贝到上面 `bin` 目录 **\n```\ncp mkreleasehdr.sh /Library/redis-xxx/bin\ncp redis-check-rdb /Library/redis-xxx/bin\ncp redis-cli /Library/redis-xxx/bin\ncp redis-server /Library/redis-xxx/bin\n```\n\n\n```\n$ ./redis-server ../conf/redis.conf\n\n$ ./redis-cli\n\n```\n\n### 配置\n\n","slug":"Redis安装","published":1,"updated":"2021-06-30T02:33:24.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx0007br5p70y8aey5q","content":"<h2 id=\"MAC环境安装\"><a href=\"#MAC环境安装\" class=\"headerlink\" title=\"MAC环境安装\"></a>MAC环境安装</h2><h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><p>下载地址：<a href=\"http://www.redis.cn/download.html\">http://www.redis.cn/download.html</a></p>\n<br>\n### 安装\n```bash\n# 进入下载目录 &amp; 解压\n$ sudo tar -zxzf redis-xxx.tar.gz\n```\n\n<span id=\"more\"></span>\n\n\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># make test</span>\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">test</span>\n\n<span class=\"token punctuation\">[</span>exception<span class=\"token punctuation\">]</span>: Executing <span class=\"token function\">test</span> client: couldn<span class=\"token string\">'t execute \"src/redis-benchmark\": no such file or directory.\ncouldn'</span>t execute <span class=\"token string\">\"src/redis-benchmark\"</span><span class=\"token keyword\">:</span> no such <span class=\"token function\">file</span> or directory\n    <span class=\"token keyword\">while</span> executing\n<span class=\"token string\">\"exec src/redis-benchmark -p <span class=\"token variable\">$R_port</span>(0) -n 10000000 -r 1000 incr __rand_int__ > /dev/null &amp;\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 31<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 <span class=\"token variable\">$code</span> \"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"start_server\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"start_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0                   ; # Do no...\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 2<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 <span class=\"token variable\">$code</span> \"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"start_server\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"start_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0          ...\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 2<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 <span class=\"token variable\">$code</span> \"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"start_server\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"start_server {tags {\"</span>psync2<span class=\"token string\">\"}} {\nstart_server {} {\nstart_server {} {\n    # Config\n    set debug_msg 0                 ; # Enable additional debug mess...\"</span>\n    <span class=\"token punctuation\">(</span>file <span class=\"token string\">\"tests/integration/psync2-reg.tcl\"</span> line 7<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"source <span class=\"token variable\">$path</span>\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"execute_tests\"</span> line 4<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"execute_tests <span class=\"token variable\">$data</span>\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"test_client_main\"</span> line 10<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"test_client_main $::test_server_port \"</span>\nKilling still running Redis server 48649\nKilling still running Redis server 48648\nKilling still running Redis server 48663\nKilling still running Redis server 48661\nKilling still running Redis server 48660\nKilling still running Redis server 48856\nKilling still running Redis server 48884\nKilling still running Redis server 48894\nI/O error reading reply\n    <span class=\"token keyword\">while</span> executing\n<span class=\"token string\">\"<span class=\"token variable\">$r</span> bzpopmax <span class=\"token variable\">$k</span> 2\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 2<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 [lindex <span class=\"token variable\">$args</span> <span class=\"token variable\">$path</span>]\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"randpath\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"randpath {\n            <span class=\"token variable\">$r</span> zadd <span class=\"token variable\">$k</span> [randomInt 10000] <span class=\"token variable\">$v</span>\n        } {\n            <span class=\"token variable\">$r</span> zadd <span class=\"token variable\">$k</span> [randomInt 10000] <span class=\"token variable\">$v</span> [randomInt 10000] <span class=\"token variable\">$v2</span>\n        } {\n     ...\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"bg_block_op\"</span> line 30<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"bg_block_op [lindex <span class=\"token variable\">$argv</span> 0] [lindex <span class=\"token variable\">$argv</span> 1] [lindex <span class=\"token variable\">$argv</span> 2] [lindex <span class=\"token variable\">$argv</span> 3]\"</span>\n    <span class=\"token punctuation\">(</span>file <span class=\"token string\">\"tests/helpers/bg_block_op.tcl\"</span> line 52<span class=\"token punctuation\">)</span>\nI/O error reading reply\n    <span class=\"token keyword\">while</span> executing\n<span class=\"token string\">\"<span class=\"token variable\">$r</span> bzpopmax <span class=\"token variable\">$k</span> 2\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 2<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 [lindex <span class=\"token variable\">$args</span> <span class=\"token variable\">$path</span>]\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"randpath\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"randpath {\n            <span class=\"token variable\">$r</span> zadd <span class=\"token variable\">$k</span> [randomInt 10000] <span class=\"token variable\">$v</span>\n        } {\n            <span class=\"token variable\">$r</span> zadd <span class=\"token variable\">$k</span> [randomInt 10000] <span class=\"token variable\">$v</span> [randomInt 10000] <span class=\"token variable\">$v2</span>\n        } {\n     ...\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"bg_block_op\"</span> line 30<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"bg_block_op [lindex <span class=\"token variable\">$argv</span> 0] [lindex <span class=\"token variable\">$argv</span> 1] [lindex <span class=\"token variable\">$argv</span> 2] [lindex <span class=\"token variable\">$argv</span> 3]\"</span>\n    <span class=\"token punctuation\">(</span>file <span class=\"token string\">\"tests/helpers/bg_block_op.tcl\"</span> line 52<span class=\"token punctuation\">)</span>\nI/O error reading reply\n    <span class=\"token keyword\">while</span> executing\n<span class=\"token string\">\"<span class=\"token variable\">$r</span> blpop <span class=\"token variable\">$k</span> <span class=\"token variable\">$k2</span> 2\"</span>\n    <span class=\"token punctuation\">(</span><span class=\"token string\">\"uplevel\"</span> body line 2<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"uplevel 1 [lindex <span class=\"token variable\">$args</span> <span class=\"token variable\">$path</span>]\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"randpath\"</span> line 3<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"randpath {\n            randpath {\n                <span class=\"token variable\">$r</span> rpush <span class=\"token variable\">$k</span> <span class=\"token variable\">$v</span>\n            } {\n                <span class=\"token variable\">$r</span> lpush <span class=\"token variable\">$k</span> <span class=\"token variable\">$v</span>\n            }\n        } {\n            ...\"</span>\n    <span class=\"token punctuation\">(</span>procedure <span class=\"token string\">\"bg_block_op\"</span> line 12<span class=\"token punctuation\">)</span>\n    invoked from within\n<span class=\"token string\">\"bg_block_op [lindex <span class=\"token variable\">$argv</span> 0] [lindex <span class=\"token variable\">$argv</span> 1] [lindex <span class=\"token variable\">$argv</span> 2] [lindex <span class=\"token variable\">$argv</span> 3]\"</span>\n    <span class=\"token punctuation\">(</span>file <span class=\"token string\">\"tests/helpers/bg_block_op.tcl\"</span> line 52<span class=\"token punctuation\">)</span>\nKilling still running Redis server 48948\nKilling still running Redis server 48956\nKilling still running Redis server 48969\nKilling still running Redis server 48975\nKilling still running Redis server 49228\nKilling still running Redis server 49238\nKilling still running Redis server 49251\nKilling still running Redis server 49263\nKilling still running Redis server 49278\nKilling still running Redis server 49295\nKilling still running Redis server 49469\nKilling still running Redis server 49482\nKilling still running Redis server 49501\nKilling still running Redis server 49509\nKilling still running Redis server 49520\nKilling still running Redis server 49535\nKilling still running Redis server 49540\nKilling still running Redis server 49563\nKilling still running Redis server 49566\nKilling still running Redis server 49578\nKilling still running Redis server 49587\nKilling still running Redis server 49648\nKilling still running Redis server 49660\nmake<span class=\"token punctuation\">[</span>1<span class=\"token punctuation\">]</span>: *** <span class=\"token punctuation\">[</span>test<span class=\"token punctuation\">]</span> Error 1\nmake: *** <span class=\"token punctuation\">[</span>test<span class=\"token punctuation\">]</span> Error 2\n</code></pre>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># install（上面报错不影响安装）</span>\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span>\n\nNSTALL redis-sentinel\n    CC redis-cli.o\n    LINK redis-cli\n    CC redis-benchmark.o\n    LINK redis-benchmark\n    INSTALL redis-check-rdb\n\nHint: It<span class=\"token string\">'s a good idea to run '</span><span class=\"token function\">make</span> test' <span class=\"token punctuation\">;</span><span class=\"token punctuation\">)</span>\n\n    INSTALL <span class=\"token function\">install</span>\n    INSTALL <span class=\"token function\">install</span>\n    INSTALL <span class=\"token function\">install</span>\n    INSTALL <span class=\"token function\">install</span>\n    INSTALL <span class=\"token function\">install</span>\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><p>** 在<code>Library</code> 目录\b创建相应的<code>redis-xxx</code>目录 ** </p>\n<pre class=\" language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">cd</span> /Library\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> redis-xxx\n</code></pre>\n<p>** 在<code>redis-xxx</code>目录下建立<code>bin</code>、<code>conf</code>、<code>data</code>和<code>log</code>目录 **</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> bin\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> conf\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> data\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">mkdir</span> log\n</code></pre>\n<p>** 把<code>make install</code>之后的<code>src</code>目录下的文件 : <code>mkreleasehdr.sh</code> <code>redis-benchmark</code> <code>redis-check-rdb</code> <code>redis-cli</code> <code>redis-server</code> 拷贝到上面 <code>bin</code> 目录 **</p>\n<pre><code>cp mkreleasehdr.sh /Library/redis-xxx/bin\ncp redis-check-rdb /Library/redis-xxx/bin\ncp redis-cli /Library/redis-xxx/bin\ncp redis-server /Library/redis-xxx/bin\n</code></pre>\n<pre><code>$ ./redis-server ../conf/redis.conf\n\n$ ./redis-cli\n</code></pre>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3>","site":{"data":{}},"excerpt":"<h2 id=\"MAC环境安装\"><a href=\"#MAC环境安装\" class=\"headerlink\" title=\"MAC环境安装\"></a>MAC环境安装</h2><h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><p>下载地址：<a href=\"http://www.redis.cn/download.html\">http://www.redis.cn/download.html</a></p>\n<br>\n### 安装\n```bash\n# 进入下载目录 &amp; 解压\n$ sudo tar -zxzf redis-xxx.tar.gz\n```","more":"<pre><code class=\"bash\"># make test\n$ sudo make test\n\n[exception]: Executing test client: couldn&#39;t execute &quot;src/redis-benchmark&quot;: no such file or directory.\ncouldn&#39;t execute &quot;src/redis-benchmark&quot;: no such file or directory\n    while executing\n&quot;exec src/redis-benchmark -p $R_port(0) -n 10000000 -r 1000 incr __rand_int__ &gt; /dev/null &amp;&quot;\n    (&quot;uplevel&quot; body line 31)\n    invoked from within\n&quot;uplevel 1 $code &quot;\n    (procedure &quot;start_server&quot; line 3)\n    invoked from within\n&quot;start_server &#123;&#125; &#123;\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0                   ; # Do no...&quot;\n    (&quot;uplevel&quot; body line 2)\n    invoked from within\n&quot;uplevel 1 $code &quot;\n    (procedure &quot;start_server&quot; line 3)\n    invoked from within\n&quot;start_server &#123;&#125; &#123;\nstart_server &#123;&#125; &#123;\n    # Config\n    set debug_msg 0                 ; # Enable additional debug messages\n\n    set no_exit 0          ...&quot;\n    (&quot;uplevel&quot; body line 2)\n    invoked from within\n&quot;uplevel 1 $code &quot;\n    (procedure &quot;start_server&quot; line 3)\n    invoked from within\n&quot;start_server &#123;tags &#123;&quot;psync2&quot;&#125;&#125; &#123;\nstart_server &#123;&#125; &#123;\nstart_server &#123;&#125; &#123;\n    # Config\n    set debug_msg 0                 ; # Enable additional debug mess...&quot;\n    (file &quot;tests/integration/psync2-reg.tcl&quot; line 7)\n    invoked from within\n&quot;source $path&quot;\n    (procedure &quot;execute_tests&quot; line 4)\n    invoked from within\n&quot;execute_tests $data&quot;\n    (procedure &quot;test_client_main&quot; line 10)\n    invoked from within\n&quot;test_client_main $::test_server_port &quot;\nKilling still running Redis server 48649\nKilling still running Redis server 48648\nKilling still running Redis server 48663\nKilling still running Redis server 48661\nKilling still running Redis server 48660\nKilling still running Redis server 48856\nKilling still running Redis server 48884\nKilling still running Redis server 48894\nI/O error reading reply\n    while executing\n&quot;$r bzpopmax $k 2&quot;\n    (&quot;uplevel&quot; body line 2)\n    invoked from within\n&quot;uplevel 1 [lindex $args $path]&quot;\n    (procedure &quot;randpath&quot; line 3)\n    invoked from within\n&quot;randpath &#123;\n            $r zadd $k [randomInt 10000] $v\n        &#125; &#123;\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        &#125; &#123;\n     ...&quot;\n    (procedure &quot;bg_block_op&quot; line 30)\n    invoked from within\n&quot;bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]&quot;\n    (file &quot;tests/helpers/bg_block_op.tcl&quot; line 52)\nI/O error reading reply\n    while executing\n&quot;$r bzpopmax $k 2&quot;\n    (&quot;uplevel&quot; body line 2)\n    invoked from within\n&quot;uplevel 1 [lindex $args $path]&quot;\n    (procedure &quot;randpath&quot; line 3)\n    invoked from within\n&quot;randpath &#123;\n            $r zadd $k [randomInt 10000] $v\n        &#125; &#123;\n            $r zadd $k [randomInt 10000] $v [randomInt 10000] $v2\n        &#125; &#123;\n     ...&quot;\n    (procedure &quot;bg_block_op&quot; line 30)\n    invoked from within\n&quot;bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]&quot;\n    (file &quot;tests/helpers/bg_block_op.tcl&quot; line 52)\nI/O error reading reply\n    while executing\n&quot;$r blpop $k $k2 2&quot;\n    (&quot;uplevel&quot; body line 2)\n    invoked from within\n&quot;uplevel 1 [lindex $args $path]&quot;\n    (procedure &quot;randpath&quot; line 3)\n    invoked from within\n&quot;randpath &#123;\n            randpath &#123;\n                $r rpush $k $v\n            &#125; &#123;\n                $r lpush $k $v\n            &#125;\n        &#125; &#123;\n            ...&quot;\n    (procedure &quot;bg_block_op&quot; line 12)\n    invoked from within\n&quot;bg_block_op [lindex $argv 0] [lindex $argv 1] [lindex $argv 2] [lindex $argv 3]&quot;\n    (file &quot;tests/helpers/bg_block_op.tcl&quot; line 52)\nKilling still running Redis server 48948\nKilling still running Redis server 48956\nKilling still running Redis server 48969\nKilling still running Redis server 48975\nKilling still running Redis server 49228\nKilling still running Redis server 49238\nKilling still running Redis server 49251\nKilling still running Redis server 49263\nKilling still running Redis server 49278\nKilling still running Redis server 49295\nKilling still running Redis server 49469\nKilling still running Redis server 49482\nKilling still running Redis server 49501\nKilling still running Redis server 49509\nKilling still running Redis server 49520\nKilling still running Redis server 49535\nKilling still running Redis server 49540\nKilling still running Redis server 49563\nKilling still running Redis server 49566\nKilling still running Redis server 49578\nKilling still running Redis server 49587\nKilling still running Redis server 49648\nKilling still running Redis server 49660\nmake[1]: *** [test] Error 1\nmake: *** [test] Error 2\n</code></pre>\n<pre><code class=\"bash\"># install（上面报错不影响安装）\n$ sudo make install\n\nNSTALL redis-sentinel\n    CC redis-cli.o\n    LINK redis-cli\n    CC redis-benchmark.o\n    LINK redis-benchmark\n    INSTALL redis-check-rdb\n\nHint: It&#39;s a good idea to run &#39;make test&#39; ;)\n\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n    INSTALL install\n</code></pre>\n<h3 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h3><p>** 在<code>Library</code> 目录\b创建相应的<code>redis-xxx</code>目录 ** </p>\n<pre><code class=\"bash\">$ cd /Library\n$ sudo mkdir redis-xxx\n</code></pre>\n<p>** 在<code>redis-xxx</code>目录下建立<code>bin</code>、<code>conf</code>、<code>data</code>和<code>log</code>目录 **</p>\n<pre><code class=\"bash\">$ sudo mkdir bin\n$ sudo mkdir conf\n$ sudo mkdir data\n$ sudo mkdir log\n</code></pre>\n<p>** 把<code>make install</code>之后的<code>src</code>目录下的文件 : <code>mkreleasehdr.sh</code> <code>redis-benchmark</code> <code>redis-check-rdb</code> <code>redis-cli</code> <code>redis-server</code> 拷贝到上面 <code>bin</code> 目录 **</p>\n<pre><code>cp mkreleasehdr.sh /Library/redis-xxx/bin\ncp redis-check-rdb /Library/redis-xxx/bin\ncp redis-cli /Library/redis-xxx/bin\ncp redis-server /Library/redis-xxx/bin\n</code></pre>\n<pre><code>$ ./redis-server ../conf/redis.conf\n\n$ ./redis-cli\n</code></pre>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3>"},{"title":"Redis开发规范","date":"2018-12-06T12:09:48.000Z","_content":"\n## 阿里云Redis开发规范\n\n### 一、键值设计\n\n#### 1. key名设计\n##### (1)【建议】: 可读性和可管理性\n以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id\n```\nugc:video:1\n```\n\n<!-- more -->\n\n##### (2)【建议】：简洁性\n保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：\n```\nuser:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。\n```\n\n##### (3)【强制】：不要包含特殊字符\n** 反例：** 包含`空格`、`换行`、`单双引号`以及其他`转义字符`\n\n<br/>\n#### 2. value设计\n##### (1)【强制】：拒绝bigkey(防止网卡流量、慢查询)\n`string`类型控制在10KB以内，`hash`、`list`、`set`、`zset`元素个数不要超过`5000`。\n\n** 反例：** `一个包含200万个元素的list。`\n\n非字符串的bigkey，不要使用del删除，使用`hscan`、`sscan`、`zscan`方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，[#查找方法](#2-【推荐】：big-key搜索)和[#删除方法](#五、附录：删除bigkey)\n\n##### (2)【推荐】：选择适合的数据类型。\n例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)\n\n** 反例：**\n```bash\nset user:1:name tom\nset user:1:age 19\nset user:1:favor football\n```\n\n** 正例: **\n```bash\nhmset user:1 name tom age 19 favor football\n```\n\n<br/>\n##### 3.【推荐】：控制key的生命周期，redis不是垃圾桶。\n建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。\n\n\n<br/>\n### 二、命令使用\n#### 1.【推荐】 O(N)命令关注N的数量\n例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。\n\n#### 2.【推荐】：禁用命令\n禁止线上使用`keys`、`flushall`、`flushdb`等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。\n\n#### 3.【推荐】合理使用select\nredis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。\n\n#### 4.【推荐】使用批量操作提高效率\n原生命令：例如`mget`、`mset`。\n非原生命令：可以使用`pipeline`提高效率。\n但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。\n\n** 注意两者不同：**\n\n> 1. 原生是原子操作，pipeline是非原子操作。\n> 2. pipeline可以打包不同的命令，原生做不到\n> 3. pipeline需要客户端和服务端同时支持。\n\n#### 5.【建议】Redis事务功能较弱，不建议过多使用\nRedis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)\n\n#### 6.【建议】Redis集群版本在使用Lua上有特殊要求：\n\n1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，\"-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array\\r\\n\"\n\n2.所有key，必须在1个slot上，否则直接返回error, \"-ERR eval/evalsha command keys must in same slot\\r\\n\"\n\n#### 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\n\n<br/>\n### 三、客户端使用\n#### 1.【推荐】\n避免多个应用使用一个Redis实例\n\n正例：不相干的业务拆分，公共数据做服务化。\n\n#### 2.【推荐】\n使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：\n\n执行命令如下：\n```java\nJedis jedis = null;\ntry {\n    jedis = jedisPool.getResource();\n    //具体的命令\n    jedis.executeCommand();\n} catch (Exception e) {\n    logger.error(\"op key {} error: \" + e.getMessage(), key, e);\n} finally {\n    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。\n    if (jedis != null) jedis.close();\n}\n```\n\n下面是JedisPool优化方法的文章:\n\n[Jedis常见异常汇总](https://yq.aliyun.com/articles/236384)\n[JedisPool资源池优化](https://yq.aliyun.com/articles/236383)\n\n\n#### 3.【建议】\n高并发下建议客户端添加熔断功能(例如netflix hystrix)\n\n#### 4.【推荐】\n设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）\n\n#### 5.【建议】\n根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。\n\n默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。\n\n其他策略如下：\n> `allkeys-lru`：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。\n> `allkeys-random`：随机删除所有键，直到腾出足够空间为止。\n> `volatile-random`: 随机删除过期键，直到腾出足够空间为止。\n> `volatile-ttl`：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。\n> `noeviction`：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息\"(error) OOM command not allowed when used memory\"，此时Redis只响应读操作。\n\n<br/>\n### 四、相关工具\n#### 1.【推荐】：数据同步\nredis间数据同步可以使用：redis-port\n\n#### 2.【推荐】：big key搜索\n[redis大key搜索工具](https://yq.aliyun.com/articles/117042)\n\n#### 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)\n[facebook的redis-faina](https://github.com/facebookarchive/redis-faina)\n\n<br/>\n### 五、附录：删除bigkey\n\n> 1. 下面操作可以使用pipeline加速。 2. redis 4.0已经支持key的异步删除，欢迎使用。\n\n#### 1. Hash删除: hscan + hdel\n```java\npublic void delBigHash(String host, int port, String password, String bigHashKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<Entry<String, String>> scanResult = jedis.hscan(bigHashKey, cursor, scanParams);\n        List<Entry<String, String>> entryList = scanResult.getResult(); \n        if (entryList != null && !entryList.isEmpty()) {\n            for (Entry<String, String> entry : entryList) {\n                jedis.hdel(bigHashKey, entry.getKey()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigHashKey); \n}\n```\n\n<br/>\n#### 2. List删除: ltrim\n```java\npublic void delBigList(String host, int port, String password, String bigListKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    long llen = jedis.llen(bigListKey);\n    int counter = 0; int left = 100;\n    while (counter < llen) {\n        //每次从左侧截掉100个 \n        jedis.ltrim(bigListKey, left, llen); counter += left; \n    }\n    //最终删除key \n    jedis.del(bigListKey); \n}\n```\n\n<br/>\n#### 3. Set删除: sscan + srem\n```java\npublic void delBigSet(String host, int port, String password, String bigSetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<String> scanResult = jedis.sscan(bigSetKey, cursor, scanParams); \n        List<String> memberList = scanResult.getResult(); \n        if (memberList != null && !memberList.isEmpty()) { \n            for (String member : memberList) { \n                jedis.srem(bigSetKey, member); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigSetKey); \n}\n```\n\n<br/>\n#### 4. SortedSet删除: zscan + zrem\n```java\npublic void delBigZset(String host, int port, String password, String bigZsetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); \n        List<Tuple> tupleList = scanResult.getResult(); \n        if (tupleList != null && !tupleList.isEmpty()) { \n            for (Tuple tuple : tupleList) { \n                jedis.zrem(bigZsetKey, tuple.getElement()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigZsetKey); \n}\n```\n\n\n\n<br/>\n\n---\n参考\nhttps://yq.aliyun.com/articles/531067","source":"_posts/Redis开发规范.md","raw":"---\ntitle: Redis开发规范\ndate: 2018-12-06 20:09:48\ncategories: \n    - Redis\ntags:\n    - NoSQL\n    - Redis\n---\n\n## 阿里云Redis开发规范\n\n### 一、键值设计\n\n#### 1. key名设计\n##### (1)【建议】: 可读性和可管理性\n以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id\n```\nugc:video:1\n```\n\n<!-- more -->\n\n##### (2)【建议】：简洁性\n保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：\n```\nuser:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。\n```\n\n##### (3)【强制】：不要包含特殊字符\n** 反例：** 包含`空格`、`换行`、`单双引号`以及其他`转义字符`\n\n<br/>\n#### 2. value设计\n##### (1)【强制】：拒绝bigkey(防止网卡流量、慢查询)\n`string`类型控制在10KB以内，`hash`、`list`、`set`、`zset`元素个数不要超过`5000`。\n\n** 反例：** `一个包含200万个元素的list。`\n\n非字符串的bigkey，不要使用del删除，使用`hscan`、`sscan`、`zscan`方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，[#查找方法](#2-【推荐】：big-key搜索)和[#删除方法](#五、附录：删除bigkey)\n\n##### (2)【推荐】：选择适合的数据类型。\n例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)\n\n** 反例：**\n```bash\nset user:1:name tom\nset user:1:age 19\nset user:1:favor football\n```\n\n** 正例: **\n```bash\nhmset user:1 name tom age 19 favor football\n```\n\n<br/>\n##### 3.【推荐】：控制key的生命周期，redis不是垃圾桶。\n建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。\n\n\n<br/>\n### 二、命令使用\n#### 1.【推荐】 O(N)命令关注N的数量\n例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。\n\n#### 2.【推荐】：禁用命令\n禁止线上使用`keys`、`flushall`、`flushdb`等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。\n\n#### 3.【推荐】合理使用select\nredis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。\n\n#### 4.【推荐】使用批量操作提高效率\n原生命令：例如`mget`、`mset`。\n非原生命令：可以使用`pipeline`提高效率。\n但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。\n\n** 注意两者不同：**\n\n> 1. 原生是原子操作，pipeline是非原子操作。\n> 2. pipeline可以打包不同的命令，原生做不到\n> 3. pipeline需要客户端和服务端同时支持。\n\n#### 5.【建议】Redis事务功能较弱，不建议过多使用\nRedis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)\n\n#### 6.【建议】Redis集群版本在使用Lua上有特殊要求：\n\n1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，\"-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array\\r\\n\"\n\n2.所有key，必须在1个slot上，否则直接返回error, \"-ERR eval/evalsha command keys must in same slot\\r\\n\"\n\n#### 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\n\n<br/>\n### 三、客户端使用\n#### 1.【推荐】\n避免多个应用使用一个Redis实例\n\n正例：不相干的业务拆分，公共数据做服务化。\n\n#### 2.【推荐】\n使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：\n\n执行命令如下：\n```java\nJedis jedis = null;\ntry {\n    jedis = jedisPool.getResource();\n    //具体的命令\n    jedis.executeCommand();\n} catch (Exception e) {\n    logger.error(\"op key {} error: \" + e.getMessage(), key, e);\n} finally {\n    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。\n    if (jedis != null) jedis.close();\n}\n```\n\n下面是JedisPool优化方法的文章:\n\n[Jedis常见异常汇总](https://yq.aliyun.com/articles/236384)\n[JedisPool资源池优化](https://yq.aliyun.com/articles/236383)\n\n\n#### 3.【建议】\n高并发下建议客户端添加熔断功能(例如netflix hystrix)\n\n#### 4.【推荐】\n设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）\n\n#### 5.【建议】\n根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。\n\n默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。\n\n其他策略如下：\n> `allkeys-lru`：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。\n> `allkeys-random`：随机删除所有键，直到腾出足够空间为止。\n> `volatile-random`: 随机删除过期键，直到腾出足够空间为止。\n> `volatile-ttl`：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。\n> `noeviction`：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息\"(error) OOM command not allowed when used memory\"，此时Redis只响应读操作。\n\n<br/>\n### 四、相关工具\n#### 1.【推荐】：数据同步\nredis间数据同步可以使用：redis-port\n\n#### 2.【推荐】：big key搜索\n[redis大key搜索工具](https://yq.aliyun.com/articles/117042)\n\n#### 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)\n[facebook的redis-faina](https://github.com/facebookarchive/redis-faina)\n\n<br/>\n### 五、附录：删除bigkey\n\n> 1. 下面操作可以使用pipeline加速。 2. redis 4.0已经支持key的异步删除，欢迎使用。\n\n#### 1. Hash删除: hscan + hdel\n```java\npublic void delBigHash(String host, int port, String password, String bigHashKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<Entry<String, String>> scanResult = jedis.hscan(bigHashKey, cursor, scanParams);\n        List<Entry<String, String>> entryList = scanResult.getResult(); \n        if (entryList != null && !entryList.isEmpty()) {\n            for (Entry<String, String> entry : entryList) {\n                jedis.hdel(bigHashKey, entry.getKey()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigHashKey); \n}\n```\n\n<br/>\n#### 2. List删除: ltrim\n```java\npublic void delBigList(String host, int port, String password, String bigListKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    long llen = jedis.llen(bigListKey);\n    int counter = 0; int left = 100;\n    while (counter < llen) {\n        //每次从左侧截掉100个 \n        jedis.ltrim(bigListKey, left, llen); counter += left; \n    }\n    //最终删除key \n    jedis.del(bigListKey); \n}\n```\n\n<br/>\n#### 3. Set删除: sscan + srem\n```java\npublic void delBigSet(String host, int port, String password, String bigSetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<String> scanResult = jedis.sscan(bigSetKey, cursor, scanParams); \n        List<String> memberList = scanResult.getResult(); \n        if (memberList != null && !memberList.isEmpty()) { \n            for (String member : memberList) { \n                jedis.srem(bigSetKey, member); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigSetKey); \n}\n```\n\n<br/>\n#### 4. SortedSet删除: zscan + zrem\n```java\npublic void delBigZset(String host, int port, String password, String bigZsetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); \n        List<Tuple> tupleList = scanResult.getResult(); \n        if (tupleList != null && !tupleList.isEmpty()) { \n            for (Tuple tuple : tupleList) { \n                jedis.zrem(bigZsetKey, tuple.getElement()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigZsetKey); \n}\n```\n\n\n\n<br/>\n\n---\n参考\nhttps://yq.aliyun.com/articles/531067","slug":"Redis开发规范","published":1,"updated":"2021-06-30T02:33:24.720Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx1007er5p72tcnf6sr","content":"<h2 id=\"阿里云Redis开发规范\"><a href=\"#阿里云Redis开发规范\" class=\"headerlink\" title=\"阿里云Redis开发规范\"></a>阿里云Redis开发规范</h2><h3 id=\"一、键值设计\"><a href=\"#一、键值设计\" class=\"headerlink\" title=\"一、键值设计\"></a>一、键值设计</h3><h4 id=\"1-key名设计\"><a href=\"#1-key名设计\" class=\"headerlink\" title=\"1. key名设计\"></a>1. key名设计</h4><h5 id=\"1-【建议】-可读性和可管理性\"><a href=\"#1-【建议】-可读性和可管理性\" class=\"headerlink\" title=\"(1)【建议】: 可读性和可管理性\"></a>(1)【建议】: 可读性和可管理性</h5><p>以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id</p>\n<pre><code>ugc:video:1\n</code></pre>\n<span id=\"more\"></span>\n\n<h5 id=\"2-【建议】：简洁性\"><a href=\"#2-【建议】：简洁性\" class=\"headerlink\" title=\"(2)【建议】：简洁性\"></a>(2)【建议】：简洁性</h5><p>保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：</p>\n<pre><code>user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。\n</code></pre>\n<h5 id=\"3-【强制】：不要包含特殊字符\"><a href=\"#3-【强制】：不要包含特殊字符\" class=\"headerlink\" title=\"(3)【强制】：不要包含特殊字符\"></a>(3)【强制】：不要包含特殊字符</h5><p>** 反例：** 包含<code>空格</code>、<code>换行</code>、<code>单双引号</code>以及其他<code>转义字符</code></p>\n<br>\n#### 2. value设计\n##### (1)【强制】：拒绝bigkey(防止网卡流量、慢查询)\n`string`类型控制在10KB以内，`hash`、`list`、`set`、`zset`元素个数不要超过`5000`。\n\n<p>** 反例：** <code>一个包含200万个元素的list。</code></p>\n<p>非字符串的bigkey，不要使用del删除，使用<code>hscan</code>、<code>sscan</code>、<code>zscan</code>方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，<a href=\"#2-%E3%80%90%E6%8E%A8%E8%8D%90%E3%80%91%EF%BC%9Abig-key%E6%90%9C%E7%B4%A2\">#查找方法</a>和<a href=\"#%E4%BA%94%E3%80%81%E9%99%84%E5%BD%95%EF%BC%9A%E5%88%A0%E9%99%A4bigkey\">#删除方法</a></p>\n<h5 id=\"2-【推荐】：选择适合的数据类型。\"><a href=\"#2-【推荐】：选择适合的数据类型。\" class=\"headerlink\" title=\"(2)【推荐】：选择适合的数据类型。\"></a>(2)【推荐】：选择适合的数据类型。</h5><p>例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)</p>\n<p>** 反例：**</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token keyword\">set</span> user:1:name tom\n<span class=\"token keyword\">set</span> user:1:age 19\n<span class=\"token keyword\">set</span> user:1:favor football\n</code></pre>\n<p>** 正例: **</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">hmset user:1 name tom age 19 favor football\n</code></pre>\n<br>\n##### 3.【推荐】：控制key的生命周期，redis不是垃圾桶。\n建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。\n\n\n<br>\n### 二、命令使用\n#### 1.【推荐】 O(N)命令关注N的数量\n例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。\n\n<h4 id=\"2-【推荐】：禁用命令\"><a href=\"#2-【推荐】：禁用命令\" class=\"headerlink\" title=\"2.【推荐】：禁用命令\"></a>2.【推荐】：禁用命令</h4><p>禁止线上使用<code>keys</code>、<code>flushall</code>、<code>flushdb</code>等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。</p>\n<h4 id=\"3-【推荐】合理使用select\"><a href=\"#3-【推荐】合理使用select\" class=\"headerlink\" title=\"3.【推荐】合理使用select\"></a>3.【推荐】合理使用select</h4><p>redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。</p>\n<h4 id=\"4-【推荐】使用批量操作提高效率\"><a href=\"#4-【推荐】使用批量操作提高效率\" class=\"headerlink\" title=\"4.【推荐】使用批量操作提高效率\"></a>4.【推荐】使用批量操作提高效率</h4><p>原生命令：例如<code>mget</code>、<code>mset</code>。\n非原生命令：可以使用<code>pipeline</code>提高效率。\n但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。</p>\n<p>** 注意两者不同：**</p>\n<blockquote>\n<ol>\n<li>原生是原子操作，pipeline是非原子操作。</li>\n<li>pipeline可以打包不同的命令，原生做不到</li>\n<li>pipeline需要客户端和服务端同时支持。</li>\n</ol>\n</blockquote>\n<h4 id=\"5-【建议】Redis事务功能较弱，不建议过多使用\"><a href=\"#5-【建议】Redis事务功能较弱，不建议过多使用\" class=\"headerlink\" title=\"5.【建议】Redis事务功能较弱，不建议过多使用\"></a>5.【建议】Redis事务功能较弱，不建议过多使用</h4><p>Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)</p>\n<h4 id=\"6-【建议】Redis集群版本在使用Lua上有特殊要求：\"><a href=\"#6-【建议】Redis集群版本在使用Lua上有特殊要求：\" class=\"headerlink\" title=\"6.【建议】Redis集群版本在使用Lua上有特殊要求：\"></a>6.【建议】Redis集群版本在使用Lua上有特殊要求：</h4><p>1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array\\r\\n”</p>\n<p>2.所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot\\r\\n”</p>\n<h4 id=\"7-【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\"><a href=\"#7-【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\" class=\"headerlink\" title=\"7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\"></a>7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。</h4><br>\n### 三、客户端使用\n#### 1.【推荐】\n避免多个应用使用一个Redis实例\n\n<p>正例：不相干的业务拆分，公共数据做服务化。</p>\n<h4 id=\"2-【推荐】\"><a href=\"#2-【推荐】\" class=\"headerlink\" title=\"2.【推荐】\"></a>2.【推荐】</h4><p>使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：</p>\n<p>执行命令如下：</p>\n<pre class=\" language-java\"><code class=\"language-java\">Jedis jedis <span class=\"token operator\">=</span> null<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n    jedis <span class=\"token operator\">=</span> jedisPool<span class=\"token punctuation\">.</span><span class=\"token function\">getResource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">//具体的命令</span>\n    jedis<span class=\"token punctuation\">.</span><span class=\"token function\">executeCommand</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    logger<span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"op key {} error: \"</span> <span class=\"token operator\">+</span> e<span class=\"token punctuation\">.</span><span class=\"token function\">getMessage</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">,</span> e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>jedis <span class=\"token operator\">!=</span> null<span class=\"token punctuation\">)</span> jedis<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>下面是JedisPool优化方法的文章:</p>\n<p><a href=\"https://yq.aliyun.com/articles/236384\">Jedis常见异常汇总</a>\n<a href=\"https://yq.aliyun.com/articles/236383\">JedisPool资源池优化</a></p>\n<h4 id=\"3-【建议】\"><a href=\"#3-【建议】\" class=\"headerlink\" title=\"3.【建议】\"></a>3.【建议】</h4><p>高并发下建议客户端添加熔断功能(例如netflix hystrix)</p>\n<h4 id=\"4-【推荐】\"><a href=\"#4-【推荐】\" class=\"headerlink\" title=\"4.【推荐】\"></a>4.【推荐】</h4><p>设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）</p>\n<h4 id=\"5-【建议】\"><a href=\"#5-【建议】\" class=\"headerlink\" title=\"5.【建议】\"></a>5.【建议】</h4><p>根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。</p>\n<p>默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。</p>\n<p>其他策略如下：</p>\n<blockquote>\n<p><code>allkeys-lru</code>：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。\n<code>allkeys-random</code>：随机删除所有键，直到腾出足够空间为止。\n<code>volatile-random</code>: 随机删除过期键，直到腾出足够空间为止。\n<code>volatile-ttl</code>：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。\n<code>noeviction</code>：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。</p>\n</blockquote>\n<br>\n### 四、相关工具\n#### 1.【推荐】：数据同步\nredis间数据同步可以使用：redis-port\n\n<h4 id=\"2-【推荐】：big-key搜索\"><a href=\"#2-【推荐】：big-key搜索\" class=\"headerlink\" title=\"2.【推荐】：big key搜索\"></a>2.【推荐】：big key搜索</h4><p><a href=\"https://yq.aliyun.com/articles/117042\">redis大key搜索工具</a></p>\n<h4 id=\"3-【推荐】：热点key寻找-内部实现使用monitor，所以建议短时间使用\"><a href=\"#3-【推荐】：热点key寻找-内部实现使用monitor，所以建议短时间使用\" class=\"headerlink\" title=\"3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)\"></a>3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)</h4><p><a href=\"https://github.com/facebookarchive/redis-faina\">facebook的redis-faina</a></p>\n<br>\n### 五、附录：删除bigkey\n\n<blockquote>\n<ol>\n<li>下面操作可以使用pipeline加速。 2. redis 4.0已经支持key的异步删除，欢迎使用。</li>\n</ol>\n</blockquote>\n<h4 id=\"1-Hash删除-hscan-hdel\"><a href=\"#1-Hash删除-hscan-hdel\" class=\"headerlink\" title=\"1. Hash删除: hscan + hdel\"></a>1. Hash删除: hscan + hdel</h4><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">delBigHash</span><span class=\"token punctuation\">(</span>String host<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> port<span class=\"token punctuation\">,</span> String password<span class=\"token punctuation\">,</span> String bigHashKey<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span> \n    Jedis jedis <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Jedis</span><span class=\"token punctuation\">(</span>host<span class=\"token punctuation\">,</span> port<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>password <span class=\"token operator\">!=</span> null <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>password<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        jedis<span class=\"token punctuation\">.</span><span class=\"token function\">auth</span><span class=\"token punctuation\">(</span>password<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n    ScanParams scanParams <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ScanParams</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    String cursor <span class=\"token operator\">=</span> <span class=\"token string\">\"0\"</span><span class=\"token punctuation\">;</span> \n    <span class=\"token keyword\">do</span> <span class=\"token punctuation\">{</span> \n        ScanResult<span class=\"token operator\">&lt;</span>Entry<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">>></span> scanResult <span class=\"token operator\">=</span> jedis<span class=\"token punctuation\">.</span><span class=\"token function\">hscan</span><span class=\"token punctuation\">(</span>bigHashKey<span class=\"token punctuation\">,</span> cursor<span class=\"token punctuation\">,</span> scanParams<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        List<span class=\"token operator\">&lt;</span>Entry<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">>></span> entryList <span class=\"token operator\">=</span> scanResult<span class=\"token punctuation\">.</span><span class=\"token function\">getResult</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>entryList <span class=\"token operator\">!=</span> null <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span>entryList<span class=\"token punctuation\">.</span><span class=\"token function\">isEmpty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Entry<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> String<span class=\"token operator\">></span> entry <span class=\"token operator\">:</span> entryList<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                jedis<span class=\"token punctuation\">.</span><span class=\"token function\">hdel</span><span class=\"token punctuation\">(</span>bigHashKey<span class=\"token punctuation\">,</span> entry<span class=\"token punctuation\">.</span><span class=\"token function\">getKey</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n            <span class=\"token punctuation\">}</span> \n        <span class=\"token punctuation\">}</span> \n        cursor <span class=\"token operator\">=</span> scanResult<span class=\"token punctuation\">.</span><span class=\"token function\">getStringCursor</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token string\">\"0\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>cursor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token comment\" spellcheck=\"true\">//删除bigkey </span>\n    jedis<span class=\"token punctuation\">.</span><span class=\"token function\">del</span><span class=\"token punctuation\">(</span>bigHashKey<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n</code></pre>\n<br>\n#### 2. List删除: ltrim\n```java\npublic void delBigList(String host, int port, String password, String bigListKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null &amp;&amp; !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    long llen = jedis.llen(bigListKey);\n    int counter = 0; int left = 100;\n    while (counter &lt; llen) {\n        //每次从左侧截掉100个 \n        jedis.ltrim(bigListKey, left, llen); counter += left; \n    }\n    //最终删除key \n    jedis.del(bigListKey); \n}\n```\n\n<br>\n#### 3. Set删除: sscan + srem\n```java\npublic void delBigSet(String host, int port, String password, String bigSetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null &amp;&amp; !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<string> scanResult = jedis.sscan(bigSetKey, cursor, scanParams); \n        List<string> memberList = scanResult.getResult(); \n        if (memberList != null &amp;&amp; !memberList.isEmpty()) { \n            for (String member : memberList) { \n                jedis.srem(bigSetKey, member); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigSetKey); \n}\n```\n\n<br>\n#### 4. SortedSet删除: zscan + zrem\n```java\npublic void delBigZset(String host, int port, String password, String bigZsetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null &amp;&amp; !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<tuple> scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); \n        List<tuple> tupleList = scanResult.getResult(); \n        if (tupleList != null &amp;&amp; !tupleList.isEmpty()) { \n            for (Tuple tuple : tupleList) { \n                jedis.zrem(bigZsetKey, tuple.getElement()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigZsetKey); \n}\n```\n\n\n\n<br>\n\n<hr>\n<p>参考\n<a href=\"https://yq.aliyun.com/articles/531067\">https://yq.aliyun.com/articles/531067</a></p>\n</tuple></tuple></string></string>","site":{"data":{}},"excerpt":"<h2 id=\"阿里云Redis开发规范\"><a href=\"#阿里云Redis开发规范\" class=\"headerlink\" title=\"阿里云Redis开发规范\"></a>阿里云Redis开发规范</h2><h3 id=\"一、键值设计\"><a href=\"#一、键值设计\" class=\"headerlink\" title=\"一、键值设计\"></a>一、键值设计</h3><h4 id=\"1-key名设计\"><a href=\"#1-key名设计\" class=\"headerlink\" title=\"1. key名设计\"></a>1. key名设计</h4><h5 id=\"1-【建议】-可读性和可管理性\"><a href=\"#1-【建议】-可读性和可管理性\" class=\"headerlink\" title=\"(1)【建议】: 可读性和可管理性\"></a>(1)【建议】: 可读性和可管理性</h5><p>以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id</p>\n<pre><code>ugc:video:1\n</code></pre>","more":"<h5 id=\"2-【建议】：简洁性\"><a href=\"#2-【建议】：简洁性\" class=\"headerlink\" title=\"(2)【建议】：简洁性\"></a>(2)【建议】：简洁性</h5><p>保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：</p>\n<pre><code>user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。\n</code></pre>\n<h5 id=\"3-【强制】：不要包含特殊字符\"><a href=\"#3-【强制】：不要包含特殊字符\" class=\"headerlink\" title=\"(3)【强制】：不要包含特殊字符\"></a>(3)【强制】：不要包含特殊字符</h5><p>** 反例：** 包含<code>空格</code>、<code>换行</code>、<code>单双引号</code>以及其他<code>转义字符</code></p>\n<br/>\n#### 2. value设计\n##### (1)【强制】：拒绝bigkey(防止网卡流量、慢查询)\n`string`类型控制在10KB以内，`hash`、`list`、`set`、`zset`元素个数不要超过`5000`。\n\n<p>** 反例：** <code>一个包含200万个元素的list。</code></p>\n<p>非字符串的bigkey，不要使用del删除，使用<code>hscan</code>、<code>sscan</code>、<code>zscan</code>方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，<a href=\"#2-%E3%80%90%E6%8E%A8%E8%8D%90%E3%80%91%EF%BC%9Abig-key%E6%90%9C%E7%B4%A2\">#查找方法</a>和<a href=\"#%E4%BA%94%E3%80%81%E9%99%84%E5%BD%95%EF%BC%9A%E5%88%A0%E9%99%A4bigkey\">#删除方法</a></p>\n<h5 id=\"2-【推荐】：选择适合的数据类型。\"><a href=\"#2-【推荐】：选择适合的数据类型。\" class=\"headerlink\" title=\"(2)【推荐】：选择适合的数据类型。\"></a>(2)【推荐】：选择适合的数据类型。</h5><p>例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)</p>\n<p>** 反例：**</p>\n<pre><code class=\"bash\">set user:1:name tom\nset user:1:age 19\nset user:1:favor football\n</code></pre>\n<p>** 正例: **</p>\n<pre><code class=\"bash\">hmset user:1 name tom age 19 favor football\n</code></pre>\n<br/>\n##### 3.【推荐】：控制key的生命周期，redis不是垃圾桶。\n建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。\n\n\n<br/>\n### 二、命令使用\n#### 1.【推荐】 O(N)命令关注N的数量\n例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。\n\n<h4 id=\"2-【推荐】：禁用命令\"><a href=\"#2-【推荐】：禁用命令\" class=\"headerlink\" title=\"2.【推荐】：禁用命令\"></a>2.【推荐】：禁用命令</h4><p>禁止线上使用<code>keys</code>、<code>flushall</code>、<code>flushdb</code>等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。</p>\n<h4 id=\"3-【推荐】合理使用select\"><a href=\"#3-【推荐】合理使用select\" class=\"headerlink\" title=\"3.【推荐】合理使用select\"></a>3.【推荐】合理使用select</h4><p>redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。</p>\n<h4 id=\"4-【推荐】使用批量操作提高效率\"><a href=\"#4-【推荐】使用批量操作提高效率\" class=\"headerlink\" title=\"4.【推荐】使用批量操作提高效率\"></a>4.【推荐】使用批量操作提高效率</h4><p>原生命令：例如<code>mget</code>、<code>mset</code>。\n非原生命令：可以使用<code>pipeline</code>提高效率。\n但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。</p>\n<p>** 注意两者不同：**</p>\n<blockquote>\n<ol>\n<li>原生是原子操作，pipeline是非原子操作。</li>\n<li>pipeline可以打包不同的命令，原生做不到</li>\n<li>pipeline需要客户端和服务端同时支持。</li>\n</ol>\n</blockquote>\n<h4 id=\"5-【建议】Redis事务功能较弱，不建议过多使用\"><a href=\"#5-【建议】Redis事务功能较弱，不建议过多使用\" class=\"headerlink\" title=\"5.【建议】Redis事务功能较弱，不建议过多使用\"></a>5.【建议】Redis事务功能较弱，不建议过多使用</h4><p>Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决)</p>\n<h4 id=\"6-【建议】Redis集群版本在使用Lua上有特殊要求：\"><a href=\"#6-【建议】Redis集群版本在使用Lua上有特殊要求：\" class=\"headerlink\" title=\"6.【建议】Redis集群版本在使用Lua上有特殊要求：\"></a>6.【建议】Redis集群版本在使用Lua上有特殊要求：</h4><p>1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array\\r\\n”</p>\n<p>2.所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot\\r\\n”</p>\n<h4 id=\"7-【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\"><a href=\"#7-【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\" class=\"headerlink\" title=\"7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。\"></a>7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。</h4><br/>\n### 三、客户端使用\n#### 1.【推荐】\n避免多个应用使用一个Redis实例\n\n<p>正例：不相干的业务拆分，公共数据做服务化。</p>\n<h4 id=\"2-【推荐】\"><a href=\"#2-【推荐】\" class=\"headerlink\" title=\"2.【推荐】\"></a>2.【推荐】</h4><p>使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式：</p>\n<p>执行命令如下：</p>\n<pre><code class=\"java\">Jedis jedis = null;\ntry &#123;\n    jedis = jedisPool.getResource();\n    //具体的命令\n    jedis.executeCommand();\n&#125; catch (Exception e) &#123;\n    logger.error(&quot;op key &#123;&#125; error: &quot; + e.getMessage(), key, e);\n&#125; finally &#123;\n    //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。\n    if (jedis != null) jedis.close();\n&#125;\n</code></pre>\n<p>下面是JedisPool优化方法的文章:</p>\n<p><a href=\"https://yq.aliyun.com/articles/236384\">Jedis常见异常汇总</a>\n<a href=\"https://yq.aliyun.com/articles/236383\">JedisPool资源池优化</a></p>\n<h4 id=\"3-【建议】\"><a href=\"#3-【建议】\" class=\"headerlink\" title=\"3.【建议】\"></a>3.【建议】</h4><p>高并发下建议客户端添加熔断功能(例如netflix hystrix)</p>\n<h4 id=\"4-【推荐】\"><a href=\"#4-【推荐】\" class=\"headerlink\" title=\"4.【推荐】\"></a>4.【推荐】</h4><p>设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持）</p>\n<h4 id=\"5-【建议】\"><a href=\"#5-【建议】\" class=\"headerlink\" title=\"5.【建议】\"></a>5.【建议】</h4><p>根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。</p>\n<p>默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。</p>\n<p>其他策略如下：</p>\n<blockquote>\n<p><code>allkeys-lru</code>：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。\n<code>allkeys-random</code>：随机删除所有键，直到腾出足够空间为止。\n<code>volatile-random</code>: 随机删除过期键，直到腾出足够空间为止。\n<code>volatile-ttl</code>：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。\n<code>noeviction</code>：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。</p>\n</blockquote>\n<br/>\n### 四、相关工具\n#### 1.【推荐】：数据同步\nredis间数据同步可以使用：redis-port\n\n<h4 id=\"2-【推荐】：big-key搜索\"><a href=\"#2-【推荐】：big-key搜索\" class=\"headerlink\" title=\"2.【推荐】：big key搜索\"></a>2.【推荐】：big key搜索</h4><p><a href=\"https://yq.aliyun.com/articles/117042\">redis大key搜索工具</a></p>\n<h4 id=\"3-【推荐】：热点key寻找-内部实现使用monitor，所以建议短时间使用\"><a href=\"#3-【推荐】：热点key寻找-内部实现使用monitor，所以建议短时间使用\" class=\"headerlink\" title=\"3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)\"></a>3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)</h4><p><a href=\"https://github.com/facebookarchive/redis-faina\">facebook的redis-faina</a></p>\n<br/>\n### 五、附录：删除bigkey\n\n<blockquote>\n<ol>\n<li>下面操作可以使用pipeline加速。 2. redis 4.0已经支持key的异步删除，欢迎使用。</li>\n</ol>\n</blockquote>\n<h4 id=\"1-Hash删除-hscan-hdel\"><a href=\"#1-Hash删除-hscan-hdel\" class=\"headerlink\" title=\"1. Hash删除: hscan + hdel\"></a>1. Hash删除: hscan + hdel</h4><pre><code class=\"java\">public void delBigHash(String host, int port, String password, String bigHashKey) &#123; \n    Jedis jedis = new Jedis(host, port); \n    if (password != null &amp;&amp; !&quot;&quot;.equals(password)) &#123;\n        jedis.auth(password); \n    &#125; \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = &quot;0&quot;; \n    do &#123; \n        ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams);\n        List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); \n        if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123;\n            for (Entry&lt;String, String&gt; entry : entryList) &#123;\n                jedis.hdel(bigHashKey, entry.getKey()); \n            &#125; \n        &#125; \n        cursor = scanResult.getStringCursor(); \n    &#125; while (!&quot;0&quot;.equals(cursor)); \n    //删除bigkey \n    jedis.del(bigHashKey); \n&#125;\n</code></pre>\n<br/>\n#### 2. List删除: ltrim\n```java\npublic void delBigList(String host, int port, String password, String bigListKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) {\n        jedis.auth(password); \n    } \n    long llen = jedis.llen(bigListKey);\n    int counter = 0; int left = 100;\n    while (counter < llen) {\n        //每次从左侧截掉100个 \n        jedis.ltrim(bigListKey, left, llen); counter += left; \n    }\n    //最终删除key \n    jedis.del(bigListKey); \n}\n```\n\n<br/>\n#### 3. Set删除: sscan + srem\n```java\npublic void delBigSet(String host, int port, String password, String bigSetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<String> scanResult = jedis.sscan(bigSetKey, cursor, scanParams); \n        List<String> memberList = scanResult.getResult(); \n        if (memberList != null && !memberList.isEmpty()) { \n            for (String member : memberList) { \n                jedis.srem(bigSetKey, member); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigSetKey); \n}\n```\n\n<br/>\n#### 4. SortedSet删除: zscan + zrem\n```java\npublic void delBigZset(String host, int port, String password, String bigZsetKey) { \n    Jedis jedis = new Jedis(host, port); \n    if (password != null && !\"\".equals(password)) { \n        jedis.auth(password); \n    } \n    ScanParams scanParams = new ScanParams().count(100); \n    String cursor = \"0\"; \n    do { \n        ScanResult<Tuple> scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); \n        List<Tuple> tupleList = scanResult.getResult(); \n        if (tupleList != null && !tupleList.isEmpty()) { \n            for (Tuple tuple : tupleList) { \n                jedis.zrem(bigZsetKey, tuple.getElement()); \n            } \n        } \n        cursor = scanResult.getStringCursor(); \n    } while (!\"0\".equals(cursor)); \n    //删除bigkey \n    jedis.del(bigZsetKey); \n}\n```\n\n\n\n<br/>\n\n<hr>\n<p>参考\n<a href=\"https://yq.aliyun.com/articles/531067\">https://yq.aliyun.com/articles/531067</a></p>"},{"title":"Oracle转MySQL总结","date":"2019-08-15T15:26:56.000Z","_content":"\n\n## 数据类型\n\n### character datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--   -->    \n        <tr>\n            <td style=\"text-align:center\" rowspan=3>CHAR [ (size [ BYTE | CHAR ]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n        <tr>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n        </tr>\n<!--   -->  \n    </tbody>\n</table>\n{% endraw %}\n\n\n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [MySQL官网文档](https://dev.mysql.com/doc/refman/8.0/en/)","source":"_posts/Oracle转MySQL总结.md","raw":"---\ntitle: Oracle转MySQL总结\ndate: 2019-08-15 23:26:56\ncategories: \n    - SQL转换\ntags:\n    - SQL转换\n---\n\n\n## 数据类型\n\n### character datatypes\n\n{% raw %}\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--   -->    \n        <tr>\n            <td style=\"text-align:center\" rowspan=3>CHAR [ (size [ BYTE | CHAR ]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n        <tr>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n        </tr>\n<!--   -->  \n    </tbody>\n</table>\n{% endraw %}\n\n\n---\n参考\n- http://www.sqlines.com/oracle-to-postgresql\n- [Oracle官网文档](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html)\n- [MySQL官网文档](https://dev.mysql.com/doc/refman/8.0/en/)","slug":"Oracle转MySQL总结","published":1,"updated":"2021-06-30T02:33:24.719Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx1007ir5p7clh4dp4s","content":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"character-datatypes\"><a href=\"#character-datatypes\" class=\"headerlink\" title=\"character datatypes\"></a>character datatypes</h3>\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--   -->    \n        <tr>\n            <td style=\"text-align:center\" rowspan=\"3\">CHAR [ (size [ BYTE | CHAR ]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n        <tr>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n        </tr>\n<!--   -->  \n    </tbody>\n</table>\n\n\n\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://dev.mysql.com/doc/refman/8.0/en/\">MySQL官网文档</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><h3 id=\"character-datatypes\"><a href=\"#character-datatypes\" class=\"headerlink\" title=\"character datatypes\"></a>character datatypes</h3>\n<table>\n    <thead>\n        <tr>\n            <th style=\"text-align:center\" colspan=\"2\">Oracle数据类型</th>\n            <th style=\"text-align:center\">EDB数据类型</th>\n        </tr>\n    </thead>    \n    <tbody>\n<!--   -->    \n        <tr>\n            <td style=\"text-align:center\" rowspan=3>CHAR [ (size [ BYTE | CHAR ]) ]</td>\n            <td style=\"text-align:center\">CHAR</td>\n            <td style=\"text-align:center\">CHAR</td>\n        </tr>\n         <tr>\n            <td style=\"text-align:center\">CHAR(size)</td>\n            <td style=\"text-align:center\">CHAR(size)</td>\n        </tr>\n        <tr>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n            <td style=\"text-align:center\">CHAR[256, )</td>\n        </tr>\n<!--   -->  \n    </tbody>\n</table>\n\n\n\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"http://www.sqlines.com/oracle-to-postgresql\">http://www.sqlines.com/oracle-to-postgresql</a></li>\n<li><a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/index.html\">Oracle官网文档</a></li>\n<li><a href=\"https://dev.mysql.com/doc/refman/8.0/en/\">MySQL官网文档</a></li>\n</ul>\n"},{"title":"Redis教程","date":"2018-12-05T02:59:05.000Z","_content":"\n\nRedis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 `字符串（strings）`， `散列（hashes）`， `列表（lists）`， `集合（sets）`， `有序集合（sorted sets）` 与范围查询， `bitmaps`， `hyperloglogs` 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。\n\n\n<!-- more -->\n---\n\n<br/>\n\n如果自己本地没有安装Redis，可以使用在线Reids。\nRedis 在线测试：http://try.redis.io/\n\n<br/>\n### 数据类型\nRedis支持五种数据类型：`string`（字符串）、`list`（列表）、`hash`（哈希）、`set`（集合）及`zset`(sorted set：有序集合)。\n\n\n** 1、String（字符串） **\n```\nredis> SET mykey \"Hello\"\n\"OK\"\nredis> GET mykey\n\"Hello\"\n```\n\n\n** 2、List（列表）** \n```bash\nredis> LPUSH mylist \"world\"\n(integer) 1\nredis> LPUSH mylist \"hello\"\n(integer) 2\nredis> LRANGE mylist 0 -1\n1) \"hello\"\n2) \"world\"\n```\n\n列表的最大长度为`2^32 - 1`个元素(`4294967295`，每个列表可容纳超过`40亿`个元素)\n\n** 3、Hash（哈希）**\n```bash\nredis> HMSET myhash field1 \"Hello\" field2 \"World\"\n\"OK\"\nredis> HGET myhash field1\n\"Hello\"\nredis> HGET myhash field2\n\"World\"\n```\n\n\n** 4、Set（集合）**\n```bash\nredis> SADD myset \"Hello\"\n(integer) 1\nredis> SADD myset \"World\"\n(integer) 1\nredis> SADD myset \"World\"\n(integer) 0\nredis> SMEMBERS myset\n1) \"World\"\n2) \"Hello\"\n```\n\n** 5、ZSET(sorted set：有序集合)**\n```bash\nredis> ZADD myzset 1 \"one\"\n(integer) 1\nredis> ZADD myzset 1 \"uno\"\n(integer) 1\nredis> ZADD myzset 2 \"two\" 3 \"three\"\n(integer) 2\nredis> ZRANGE myzset 0 -1 WITHSCORES\n1) \"one\"\n2) \"1\"\n3) \"uno\"\n4) \"1\"\n5) \"two\"\n6) \"2\"\n7) \"three\"\n8) \"3\"\n```\n\n\n### 命令\b汇总\n\n\n\n### 事物\n\n\n\n### 发布/订阅\n\n![]()\n![]()\n\n\n\n\n\n\n\n<br/>\n\n---\n参考\nRedis官网：https://redis.io\nhttps://redisbook.readthedocs.io/en/latest/feature/pubsub.html","source":"_posts/Redis教程.md","raw":"---\ntitle: Redis教程\ndate: 2018-12-05 10:59:05\ncategories: \n    - Redis\ntags:\n    - NoSQL\n    - Redis\n---\n\n\nRedis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 `字符串（strings）`， `散列（hashes）`， `列表（lists）`， `集合（sets）`， `有序集合（sorted sets）` 与范围查询， `bitmaps`， `hyperloglogs` 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。\n\n\n<!-- more -->\n---\n\n<br/>\n\n如果自己本地没有安装Redis，可以使用在线Reids。\nRedis 在线测试：http://try.redis.io/\n\n<br/>\n### 数据类型\nRedis支持五种数据类型：`string`（字符串）、`list`（列表）、`hash`（哈希）、`set`（集合）及`zset`(sorted set：有序集合)。\n\n\n** 1、String（字符串） **\n```\nredis> SET mykey \"Hello\"\n\"OK\"\nredis> GET mykey\n\"Hello\"\n```\n\n\n** 2、List（列表）** \n```bash\nredis> LPUSH mylist \"world\"\n(integer) 1\nredis> LPUSH mylist \"hello\"\n(integer) 2\nredis> LRANGE mylist 0 -1\n1) \"hello\"\n2) \"world\"\n```\n\n列表的最大长度为`2^32 - 1`个元素(`4294967295`，每个列表可容纳超过`40亿`个元素)\n\n** 3、Hash（哈希）**\n```bash\nredis> HMSET myhash field1 \"Hello\" field2 \"World\"\n\"OK\"\nredis> HGET myhash field1\n\"Hello\"\nredis> HGET myhash field2\n\"World\"\n```\n\n\n** 4、Set（集合）**\n```bash\nredis> SADD myset \"Hello\"\n(integer) 1\nredis> SADD myset \"World\"\n(integer) 1\nredis> SADD myset \"World\"\n(integer) 0\nredis> SMEMBERS myset\n1) \"World\"\n2) \"Hello\"\n```\n\n** 5、ZSET(sorted set：有序集合)**\n```bash\nredis> ZADD myzset 1 \"one\"\n(integer) 1\nredis> ZADD myzset 1 \"uno\"\n(integer) 1\nredis> ZADD myzset 2 \"two\" 3 \"three\"\n(integer) 2\nredis> ZRANGE myzset 0 -1 WITHSCORES\n1) \"one\"\n2) \"1\"\n3) \"uno\"\n4) \"1\"\n5) \"two\"\n6) \"2\"\n7) \"three\"\n8) \"3\"\n```\n\n\n### 命令\b汇总\n\n\n\n### 事物\n\n\n\n### 发布/订阅\n\n![]()\n![]()\n\n\n\n\n\n\n\n<br/>\n\n---\n参考\nRedis官网：https://redis.io\nhttps://redisbook.readthedocs.io/en/latest/feature/pubsub.html","slug":"Redis教程","published":1,"updated":"2021-06-30T02:33:24.720Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx2007lr5p7ah6900gb","content":"<p>Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 <code>字符串（strings）</code>， <code>散列（hashes）</code>， <code>列表（lists）</code>， <code>集合（sets）</code>， <code>有序集合（sorted sets）</code> 与范围查询， <code>bitmaps</code>， <code>hyperloglogs</code> 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。</p>\n<span id=\"more\"></span>\n<hr>\n<br>\n\n<p>如果自己本地没有安装Redis，可以使用在线Reids。\nRedis 在线测试：<a href=\"http://try.redis.io/\">http://try.redis.io/</a></p>\n<br>\n### 数据类型\nRedis支持五种数据类型：`string`（字符串）、`list`（列表）、`hash`（哈希）、`set`（集合）及`zset`(sorted set：有序集合)。\n\n\n<p>** 1、String（字符串） **</p>\n<pre><code>redis&gt; SET mykey \"Hello\"\n\"OK\"\nredis&gt; GET mykey\n\"Hello\"\n</code></pre>\n<p>** 2、List（列表）** </p>\n<pre class=\" language-bash\"><code class=\"language-bash\">redis<span class=\"token operator\">></span> LPUSH mylist <span class=\"token string\">\"world\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 1\nredis<span class=\"token operator\">></span> LPUSH mylist <span class=\"token string\">\"hello\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 2\nredis<span class=\"token operator\">></span> LRANGE mylist 0 -1\n1<span class=\"token punctuation\">)</span> <span class=\"token string\">\"hello\"</span>\n2<span class=\"token punctuation\">)</span> <span class=\"token string\">\"world\"</span>\n</code></pre>\n<p>列表的最大长度为<code>2^32 - 1</code>个元素(<code>4294967295</code>，每个列表可容纳超过<code>40亿</code>个元素)</p>\n<p>** 3、Hash（哈希）**</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">redis<span class=\"token operator\">></span> HMSET myhash field1 <span class=\"token string\">\"Hello\"</span> field2 <span class=\"token string\">\"World\"</span>\n<span class=\"token string\">\"OK\"</span>\nredis<span class=\"token operator\">></span> HGET myhash field1\n<span class=\"token string\">\"Hello\"</span>\nredis<span class=\"token operator\">></span> HGET myhash field2\n<span class=\"token string\">\"World\"</span>\n</code></pre>\n<p>** 4、Set（集合）**</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">redis<span class=\"token operator\">></span> SADD myset <span class=\"token string\">\"Hello\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 1\nredis<span class=\"token operator\">></span> SADD myset <span class=\"token string\">\"World\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 1\nredis<span class=\"token operator\">></span> SADD myset <span class=\"token string\">\"World\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 0\nredis<span class=\"token operator\">></span> SMEMBERS myset\n1<span class=\"token punctuation\">)</span> <span class=\"token string\">\"World\"</span>\n2<span class=\"token punctuation\">)</span> <span class=\"token string\">\"Hello\"</span>\n</code></pre>\n<p>** 5、ZSET(sorted set：有序集合)**</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">redis<span class=\"token operator\">></span> ZADD myzset 1 <span class=\"token string\">\"one\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 1\nredis<span class=\"token operator\">></span> ZADD myzset 1 <span class=\"token string\">\"uno\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 1\nredis<span class=\"token operator\">></span> ZADD myzset 2 <span class=\"token string\">\"two\"</span> 3 <span class=\"token string\">\"three\"</span>\n<span class=\"token punctuation\">(</span>integer<span class=\"token punctuation\">)</span> 2\nredis<span class=\"token operator\">></span> ZRANGE myzset 0 -1 WITHSCORES\n1<span class=\"token punctuation\">)</span> <span class=\"token string\">\"one\"</span>\n2<span class=\"token punctuation\">)</span> <span class=\"token string\">\"1\"</span>\n3<span class=\"token punctuation\">)</span> <span class=\"token string\">\"uno\"</span>\n4<span class=\"token punctuation\">)</span> <span class=\"token string\">\"1\"</span>\n5<span class=\"token punctuation\">)</span> <span class=\"token string\">\"two\"</span>\n6<span class=\"token punctuation\">)</span> <span class=\"token string\">\"2\"</span>\n7<span class=\"token punctuation\">)</span> <span class=\"token string\">\"three\"</span>\n8<span class=\"token punctuation\">)</span> <span class=\"token string\">\"3\"</span>\n</code></pre>\n<h3 id=\"命令汇总\"><a href=\"#命令汇总\" class=\"headerlink\" title=\"命令\b汇总\"></a>命令\b汇总</h3><h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><h3 id=\"发布-订阅\"><a href=\"#发布-订阅\" class=\"headerlink\" title=\"发布/订阅\"></a>发布/订阅</h3><p><img src=\"\">\n<img src=\"\"></p>\n<br>\n\n<hr>\n<p>参考\nRedis官网：<a href=\"https://redis.io/\">https://redis.io</a>\n<a href=\"https://redisbook.readthedocs.io/en/latest/feature/pubsub.html\">https://redisbook.readthedocs.io/en/latest/feature/pubsub.html</a></p>\n","site":{"data":{}},"excerpt":"<p>Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 <code>字符串（strings）</code>， <code>散列（hashes）</code>， <code>列表（lists）</code>， <code>集合（sets）</code>， <code>有序集合（sorted sets）</code> 与范围查询， <code>bitmaps</code>， <code>hyperloglogs</code> 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。</p>","more":"<hr>\n<br/>\n\n<p>如果自己本地没有安装Redis，可以使用在线Reids。\nRedis 在线测试：<a href=\"http://try.redis.io/\">http://try.redis.io/</a></p>\n<br/>\n### 数据类型\nRedis支持五种数据类型：`string`（字符串）、`list`（列表）、`hash`（哈希）、`set`（集合）及`zset`(sorted set：有序集合)。\n\n\n<p>** 1、String（字符串） **</p>\n<pre><code>redis&gt; SET mykey &quot;Hello&quot;\n&quot;OK&quot;\nredis&gt; GET mykey\n&quot;Hello&quot;\n</code></pre>\n<p>** 2、List（列表）** </p>\n<pre><code class=\"bash\">redis&gt; LPUSH mylist &quot;world&quot;\n(integer) 1\nredis&gt; LPUSH mylist &quot;hello&quot;\n(integer) 2\nredis&gt; LRANGE mylist 0 -1\n1) &quot;hello&quot;\n2) &quot;world&quot;\n</code></pre>\n<p>列表的最大长度为<code>2^32 - 1</code>个元素(<code>4294967295</code>，每个列表可容纳超过<code>40亿</code>个元素)</p>\n<p>** 3、Hash（哈希）**</p>\n<pre><code class=\"bash\">redis&gt; HMSET myhash field1 &quot;Hello&quot; field2 &quot;World&quot;\n&quot;OK&quot;\nredis&gt; HGET myhash field1\n&quot;Hello&quot;\nredis&gt; HGET myhash field2\n&quot;World&quot;\n</code></pre>\n<p>** 4、Set（集合）**</p>\n<pre><code class=\"bash\">redis&gt; SADD myset &quot;Hello&quot;\n(integer) 1\nredis&gt; SADD myset &quot;World&quot;\n(integer) 1\nredis&gt; SADD myset &quot;World&quot;\n(integer) 0\nredis&gt; SMEMBERS myset\n1) &quot;World&quot;\n2) &quot;Hello&quot;\n</code></pre>\n<p>** 5、ZSET(sorted set：有序集合)**</p>\n<pre><code class=\"bash\">redis&gt; ZADD myzset 1 &quot;one&quot;\n(integer) 1\nredis&gt; ZADD myzset 1 &quot;uno&quot;\n(integer) 1\nredis&gt; ZADD myzset 2 &quot;two&quot; 3 &quot;three&quot;\n(integer) 2\nredis&gt; ZRANGE myzset 0 -1 WITHSCORES\n1) &quot;one&quot;\n2) &quot;1&quot;\n3) &quot;uno&quot;\n4) &quot;1&quot;\n5) &quot;two&quot;\n6) &quot;2&quot;\n7) &quot;three&quot;\n8) &quot;3&quot;\n</code></pre>\n<h3 id=\"命令汇总\"><a href=\"#命令汇总\" class=\"headerlink\" title=\"命令\b汇总\"></a>命令\b汇总</h3><h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><h3 id=\"发布-订阅\"><a href=\"#发布-订阅\" class=\"headerlink\" title=\"发布/订阅\"></a>发布/订阅</h3><p><img src=\"\">\n<img src=\"\"></p>\n<br/>\n\n<hr>\n<p>参考\nRedis官网：<a href=\"https://redis.io/\">https://redis.io</a>\n<a href=\"https://redisbook.readthedocs.io/en/latest/feature/pubsub.html\">https://redisbook.readthedocs.io/en/latest/feature/pubsub.html</a></p>"},{"title":"Redis设计与实现","date":"2018-12-06T02:19:30.000Z","_content":"\n\n## 数据结构\n\n`Redis`键值对都是`对象(object)`组成，理解对象所使用的数据结构，你更加好理解和使用`Redis`\n\n下面剖析对象所使用的`数据结构`：`简单动态字符串` `链表` `字典` `跳跃表` `整数集合` `压缩列表` 6种数据结构\n\n<!-- more -->\n\n<br/>\n### 简单动态字符串(simple dynamic string, SDS)\n\n#### 源码解析\n```c\nstruct sdshdr {\n\n    // 记录 buf 数组中已使用字节的数量\n    // 等于 SDS 所保存字符串的长度\n    int len;\n\n    // 记录 buf 数组中未使用字节的数量\n    int free;\n\n    // 字节数组，用于保存字符串\n    char buf[];\n};\n```\n\n- `free` 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。\n- `len` 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。\n- `buf` 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 'R' 、 'e' 、 'd' 、 'i' 、 's' 五个字符， 而最后一个字节则保存了空字符 '\\0' 。\n\n![](graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png)\n\n\n#### `SDS`比`C`字符串区别\n\n| C 字符串\t| SDS | \n| :--------: | :-----: |\n| 获取字符串长度的复杂度为 O(N)  | 获取字符串长度的复杂度为 O(1) |\n| API 是不安全的，可能会造成缓冲区溢出 |\tAPI 是安全的，不会造成缓冲区溢出|\n| 修改字符串长度 N 次必然需要执行 N 次内存重分配 | 修改字符串长度 N 次最多需要执行 N 次内存重分配 |\n| 只能保存文本数据 | 可以保存文本或者二进制数据 |\n| 可以使用所有 <string.h> 库中的函数 |\t可以使用一部分 <string.h> 库中的函数|\n\n\n<br/>\n### 链表(Linked List)\n#### 源码解析\n```c\n\ntypedef struct listNode {\n\n    // 前置节点\n    struct listNode *prev;\n\n    // 后置节点\n    struct listNode *next;\n\n    // 节点的值\n    void *value;\n\n} listNode;\n\ntypedef struct list {\n\n    // 表头节点\n    listNode *head;\n\n    // 表尾节点\n    listNode *tail;\n\n    // 链表所包含的节点数量\n    unsigned long len;\n\n    // 节点值复制函数\n    void *(*dup)(void *ptr);\n\n    // 节点值释放函数\n    void (*free)(void *ptr);\n\n    // 节点值对比函数\n    int (*match)(void *ptr, void *key);\n\n} list;\n\n```\n\n![](graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png)\n![](graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png)\n\n\n** 特性总结 **\n> `双端：` 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。\n> `无环：` 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。\n> `带表头指针和表尾指针：` 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。\n> `带链表长度计数器：` 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。\n> `多态：` 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。\n\n\n\n<br/>\n### 字典(Dict)\n#### 源码解析\n```c\ntypedef struct dictht {\n\n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n\n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n} dictht;\n\ntypedef struct dictEntry {\n\n    // 键\n    void *key;\n\n    // 值\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n    } v;\n\n    // 指向下个哈希表节点，形成链表\n    struct dictEntry *next;\n\n} dictEntry;\n```\n\n![](graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png)\n\n\n<br/>\n### 跳跃表(Skip List)\n#### 源码解析\n```c\ntypedef struct zskiplistNode {\n\n    // 后退指针\n    struct zskiplistNode *backward;\n\n    // 分值\n    double score;\n\n    // 成员对象\n    robj *obj;\n\n    // 层\n    struct zskiplistLevel {\n\n        // 前进指针\n        struct zskiplistNode *forward;\n\n        // 跨度\n        unsigned int span;\n\n    } level[];\n\n} zskiplistNode;\n```\n\n![](graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png)\n\n\n<br/>\n### 整数集合(Int Set)\n#### 源码解析\n```c\ntypedef struct intset {\n\n    // 编码方式\n    uint32_t encoding;\n\n    // 集合包含的元素数量\n    uint32_t length;\n\n    // 保存元素的数组\n    int8_t contents[];\n\n} intset;\n```\n\n![](graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f)\n\n\n<br/>\n### 压缩列表(Zip List)\n#### 源码解析\n```c\n\n```\n\n\n## 过期（Expires）\n\n<!-- more -->\n\n\n## LRU\n\n** 1、需要设置最大内存限制，如：**\n```bash\nmaxmemory 100mb\n```\n\n** 2、选择策略 **\n```bash\nmaxmemory-policy noeviction\n```\n\n\n<br/>\n### Redis淘汰机制(Eviction policies)\n\n`noeviction`: 默认策略，不淘汰，如果内存已满，添加数据报错。 \n`allkeys-lru`: 在所有键中，选取最近最少使用的数据抛弃。\n`volatile-lru`: 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。\n`allkeys-random`: 在所有键中，随机抛弃。\n`volatile-random`: 在设置了过期时间的所有键，随机抛弃。\n`volatile-ttl`: 在设置了过期时间的所有键，抛弃存活时间最短的数据。\n\n\n\n\n![LRU Comparison](lru_comparison.png)\n\n\n\n<br/>\n\n---\n参考\nRedis官网：https://redis.io\n《Redis设计与实现》：http://redisbook.com/","source":"_posts/Redis设计与实现.md","raw":"---\ntitle: Redis设计与实现\ndate: 2018-12-06 10:19:30\ncategories: \n    - Redis\ntags:\n    - NoSQL\n    - Redis\n---\n\n\n## 数据结构\n\n`Redis`键值对都是`对象(object)`组成，理解对象所使用的数据结构，你更加好理解和使用`Redis`\n\n下面剖析对象所使用的`数据结构`：`简单动态字符串` `链表` `字典` `跳跃表` `整数集合` `压缩列表` 6种数据结构\n\n<!-- more -->\n\n<br/>\n### 简单动态字符串(simple dynamic string, SDS)\n\n#### 源码解析\n```c\nstruct sdshdr {\n\n    // 记录 buf 数组中已使用字节的数量\n    // 等于 SDS 所保存字符串的长度\n    int len;\n\n    // 记录 buf 数组中未使用字节的数量\n    int free;\n\n    // 字节数组，用于保存字符串\n    char buf[];\n};\n```\n\n- `free` 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。\n- `len` 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。\n- `buf` 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 'R' 、 'e' 、 'd' 、 'i' 、 's' 五个字符， 而最后一个字节则保存了空字符 '\\0' 。\n\n![](graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png)\n\n\n#### `SDS`比`C`字符串区别\n\n| C 字符串\t| SDS | \n| :--------: | :-----: |\n| 获取字符串长度的复杂度为 O(N)  | 获取字符串长度的复杂度为 O(1) |\n| API 是不安全的，可能会造成缓冲区溢出 |\tAPI 是安全的，不会造成缓冲区溢出|\n| 修改字符串长度 N 次必然需要执行 N 次内存重分配 | 修改字符串长度 N 次最多需要执行 N 次内存重分配 |\n| 只能保存文本数据 | 可以保存文本或者二进制数据 |\n| 可以使用所有 <string.h> 库中的函数 |\t可以使用一部分 <string.h> 库中的函数|\n\n\n<br/>\n### 链表(Linked List)\n#### 源码解析\n```c\n\ntypedef struct listNode {\n\n    // 前置节点\n    struct listNode *prev;\n\n    // 后置节点\n    struct listNode *next;\n\n    // 节点的值\n    void *value;\n\n} listNode;\n\ntypedef struct list {\n\n    // 表头节点\n    listNode *head;\n\n    // 表尾节点\n    listNode *tail;\n\n    // 链表所包含的节点数量\n    unsigned long len;\n\n    // 节点值复制函数\n    void *(*dup)(void *ptr);\n\n    // 节点值释放函数\n    void (*free)(void *ptr);\n\n    // 节点值对比函数\n    int (*match)(void *ptr, void *key);\n\n} list;\n\n```\n\n![](graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png)\n![](graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png)\n\n\n** 特性总结 **\n> `双端：` 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。\n> `无环：` 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。\n> `带表头指针和表尾指针：` 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。\n> `带链表长度计数器：` 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。\n> `多态：` 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。\n\n\n\n<br/>\n### 字典(Dict)\n#### 源码解析\n```c\ntypedef struct dictht {\n\n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n\n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n} dictht;\n\ntypedef struct dictEntry {\n\n    // 键\n    void *key;\n\n    // 值\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n    } v;\n\n    // 指向下个哈希表节点，形成链表\n    struct dictEntry *next;\n\n} dictEntry;\n```\n\n![](graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png)\n\n\n<br/>\n### 跳跃表(Skip List)\n#### 源码解析\n```c\ntypedef struct zskiplistNode {\n\n    // 后退指针\n    struct zskiplistNode *backward;\n\n    // 分值\n    double score;\n\n    // 成员对象\n    robj *obj;\n\n    // 层\n    struct zskiplistLevel {\n\n        // 前进指针\n        struct zskiplistNode *forward;\n\n        // 跨度\n        unsigned int span;\n\n    } level[];\n\n} zskiplistNode;\n```\n\n![](graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png)\n\n\n<br/>\n### 整数集合(Int Set)\n#### 源码解析\n```c\ntypedef struct intset {\n\n    // 编码方式\n    uint32_t encoding;\n\n    // 集合包含的元素数量\n    uint32_t length;\n\n    // 保存元素的数组\n    int8_t contents[];\n\n} intset;\n```\n\n![](graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f)\n\n\n<br/>\n### 压缩列表(Zip List)\n#### 源码解析\n```c\n\n```\n\n\n## 过期（Expires）\n\n<!-- more -->\n\n\n## LRU\n\n** 1、需要设置最大内存限制，如：**\n```bash\nmaxmemory 100mb\n```\n\n** 2、选择策略 **\n```bash\nmaxmemory-policy noeviction\n```\n\n\n<br/>\n### Redis淘汰机制(Eviction policies)\n\n`noeviction`: 默认策略，不淘汰，如果内存已满，添加数据报错。 \n`allkeys-lru`: 在所有键中，选取最近最少使用的数据抛弃。\n`volatile-lru`: 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。\n`allkeys-random`: 在所有键中，随机抛弃。\n`volatile-random`: 在设置了过期时间的所有键，随机抛弃。\n`volatile-ttl`: 在设置了过期时间的所有键，抛弃存活时间最短的数据。\n\n\n\n\n![LRU Comparison](lru_comparison.png)\n\n\n\n<br/>\n\n---\n参考\nRedis官网：https://redis.io\n《Redis设计与实现》：http://redisbook.com/","slug":"Redis设计与实现","published":1,"updated":"2021-06-30T02:33:24.720Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx3007pr5p786ki9ze0","content":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><p><code>Redis</code>键值对都是<code>对象(object)</code>组成，理解对象所使用的数据结构，你更加好理解和使用<code>Redis</code></p>\n<p>下面剖析对象所使用的<code>数据结构</code>：<code>简单动态字符串</code> <code>链表</code> <code>字典</code> <code>跳跃表</code> <code>整数集合</code> <code>压缩列表</code> 6种数据结构</p>\n<span id=\"more\"></span>\n\n<br>\n### 简单动态字符串(simple dynamic string, SDS)\n\n<h4 id=\"源码解析\"><a href=\"#源码解析\" class=\"headerlink\" title=\"源码解析\"></a>源码解析</h4><pre class=\" language-c\"><code class=\"language-c\"><span class=\"token keyword\">struct</span> sdshdr <span class=\"token punctuation\">{</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 记录 buf 数组中已使用字节的数量</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 等于 SDS 所保存字符串的长度</span>\n    <span class=\"token keyword\">int</span> len<span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 记录 buf 数组中未使用字节的数量</span>\n    <span class=\"token keyword\">int</span> free<span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\" spellcheck=\"true\">// 字节数组，用于保存字符串</span>\n    <span class=\"token keyword\">char</span> buf<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n</code></pre>\n<ul>\n<li><code>free</code> 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。</li>\n<li><code>len</code> 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。</li>\n<li><code>buf</code> 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 ‘R’ 、 ‘e’ 、 ‘d’ 、 ‘i’ 、 ‘s’ 五个字符， 而最后一个字节则保存了空字符 ‘\\0’ 。</li>\n</ul>\n<p><img src=\"graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png\"></p>\n<h4 id=\"SDS比C字符串区别\"><a href=\"#SDS比C字符串区别\" class=\"headerlink\" title=\"SDS比C字符串区别\"></a><code>SDS</code>比<code>C</code>字符串区别</h4><table>\n<thead>\n<tr>\n<th align=\"center\">C 字符串</th>\n<th align=\"center\">SDS</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">获取字符串长度的复杂度为 O(N)</td>\n<td align=\"center\">获取字符串长度的复杂度为 O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">API 是不安全的，可能会造成缓冲区溢出</td>\n<td align=\"center\">API 是安全的，不会造成缓冲区溢出</td>\n</tr>\n<tr>\n<td align=\"center\">修改字符串长度 N 次必然需要执行 N 次内存重分配</td>\n<td align=\"center\">修改字符串长度 N 次最多需要执行 N 次内存重分配</td>\n</tr>\n<tr>\n<td align=\"center\">只能保存文本数据</td>\n<td align=\"center\">可以保存文本或者二进制数据</td>\n</tr>\n<tr>\n<td align=\"center\">可以使用所有 &lt;string.h&gt; 库中的函数</td>\n<td align=\"center\">可以使用一部分 &lt;string.h&gt; 库中的函数</td>\n</tr>\n</tbody></table>\n<br>\n### 链表(Linked List)\n#### 源码解析\n```c\n\n<p>typedef struct listNode {</p>\n<pre><code>// 前置节点\nstruct listNode *prev;\n\n// 后置节点\nstruct listNode *next;\n\n// 节点的值\nvoid *value;\n</code></pre>\n<p>} listNode;</p>\n<p>typedef struct list {</p>\n<pre><code>// 表头节点\nlistNode *head;\n\n// 表尾节点\nlistNode *tail;\n\n// 链表所包含的节点数量\nunsigned long len;\n\n// 节点值复制函数\nvoid *(*dup)(void *ptr);\n\n// 节点值释放函数\nvoid (*free)(void *ptr);\n\n// 节点值对比函数\nint (*match)(void *ptr, void *key);\n</code></pre>\n<p>} list;</p>\n<pre><code>\n![](graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png)\n![](graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png)\n\n\n** 特性总结 **\n&gt; `双端：` 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。\n&gt; `无环：` 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。\n&gt; `带表头指针和表尾指针：` 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。\n&gt; `带链表长度计数器：` 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。\n&gt; `多态：` 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。\n\n\n\n&lt;br/&gt;\n### 字典(Dict)\n#### 源码解析\n```c\ntypedef struct dictht {\n\n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n\n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n} dictht;\n\ntypedef struct dictEntry {\n\n    // 键\n    void *key;\n\n    // 值\n    union {\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n    } v;\n\n    // 指向下个哈希表节点，形成链表\n    struct dictEntry *next;\n\n} dictEntry;\n</code></pre>\n<p><img src=\"graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png\"></p>\n<br>\n### 跳跃表(Skip List)\n#### 源码解析\n```c\ntypedef struct zskiplistNode {\n\n<pre><code>// 后退指针\nstruct zskiplistNode *backward;\n\n// 分值\ndouble score;\n\n// 成员对象\nrobj *obj;\n\n// 层\nstruct zskiplistLevel {\n\n    // 前进指针\n    struct zskiplistNode *forward;\n\n    // 跨度\n    unsigned int span;\n\n} level[];\n</code></pre>\n<p>} zskiplistNode;</p>\n<pre><code>\n![](graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png)\n\n\n&lt;br/&gt;\n### 整数集合(Int Set)\n#### 源码解析\n```c\ntypedef struct intset {\n\n    // 编码方式\n    uint32_t encoding;\n\n    // 集合包含的元素数量\n    uint32_t length;\n\n    // 保存元素的数组\n    int8_t contents[];\n\n} intset;\n</code></pre>\n<p><img src=\"graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f\"></p>\n<br>\n### 压缩列表(Zip List)\n#### 源码解析\n```c\n\n<pre><code>\n\n## 过期（Expires）\n\n&lt;!-- more --&gt;\n\n\n## LRU\n\n** 1、需要设置最大内存限制，如：**\n```bash\nmaxmemory 100mb\n</code></pre>\n<p>** 2、选择策略 **</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">maxmemory-policy noeviction\n</code></pre>\n<br>\n### Redis淘汰机制(Eviction policies)\n\n<p><code>noeviction</code>: 默认策略，不淘汰，如果内存已满，添加数据报错。 \n<code>allkeys-lru</code>: 在所有键中，选取最近最少使用的数据抛弃。\n<code>volatile-lru</code>: 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。\n<code>allkeys-random</code>: 在所有键中，随机抛弃。\n<code>volatile-random</code>: 在设置了过期时间的所有键，随机抛弃。\n<code>volatile-ttl</code>: 在设置了过期时间的所有键，抛弃存活时间最短的数据。</p>\n<p><img src=\"lru_comparison.png\" alt=\"LRU Comparison\"></p>\n<br>\n\n<hr>\n<p>参考\nRedis官网：<a href=\"https://redis.io/\">https://redis.io</a>\n《Redis设计与实现》：<a href=\"http://redisbook.com/\">http://redisbook.com/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><p><code>Redis</code>键值对都是<code>对象(object)</code>组成，理解对象所使用的数据结构，你更加好理解和使用<code>Redis</code></p>\n<p>下面剖析对象所使用的<code>数据结构</code>：<code>简单动态字符串</code> <code>链表</code> <code>字典</code> <code>跳跃表</code> <code>整数集合</code> <code>压缩列表</code> 6种数据结构</p>","more":"<br/>\n### 简单动态字符串(simple dynamic string, SDS)\n\n<h4 id=\"源码解析\"><a href=\"#源码解析\" class=\"headerlink\" title=\"源码解析\"></a>源码解析</h4><pre><code class=\"c\">struct sdshdr &#123;\n\n    // 记录 buf 数组中已使用字节的数量\n    // 等于 SDS 所保存字符串的长度\n    int len;\n\n    // 记录 buf 数组中未使用字节的数量\n    int free;\n\n    // 字节数组，用于保存字符串\n    char buf[];\n&#125;;\n</code></pre>\n<ul>\n<li><code>free</code> 属性的值为 0 ， 表示这个 SDS 没有分配任何未使用空间。</li>\n<li><code>len</code> 属性的值为 5 ， 表示这个 SDS 保存了一个五字节长的字符串。</li>\n<li><code>buf</code> 属性是一个 char 类型的数组， 数组的前五个字节分别保存了 ‘R’ 、 ‘e’ 、 ‘d’ 、 ‘i’ 、 ‘s’ 五个字符， 而最后一个字节则保存了空字符 ‘\\0’ 。</li>\n</ul>\n<p><img src=\"graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png\"></p>\n<h4 id=\"SDS比C字符串区别\"><a href=\"#SDS比C字符串区别\" class=\"headerlink\" title=\"SDS比C字符串区别\"></a><code>SDS</code>比<code>C</code>字符串区别</h4><table>\n<thead>\n<tr>\n<th align=\"center\">C 字符串</th>\n<th align=\"center\">SDS</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">获取字符串长度的复杂度为 O(N)</td>\n<td align=\"center\">获取字符串长度的复杂度为 O(1)</td>\n</tr>\n<tr>\n<td align=\"center\">API 是不安全的，可能会造成缓冲区溢出</td>\n<td align=\"center\">API 是安全的，不会造成缓冲区溢出</td>\n</tr>\n<tr>\n<td align=\"center\">修改字符串长度 N 次必然需要执行 N 次内存重分配</td>\n<td align=\"center\">修改字符串长度 N 次最多需要执行 N 次内存重分配</td>\n</tr>\n<tr>\n<td align=\"center\">只能保存文本数据</td>\n<td align=\"center\">可以保存文本或者二进制数据</td>\n</tr>\n<tr>\n<td align=\"center\">可以使用所有 &lt;string.h&gt; 库中的函数</td>\n<td align=\"center\">可以使用一部分 &lt;string.h&gt; 库中的函数</td>\n</tr>\n</tbody></table>\n<br/>\n### 链表(Linked List)\n#### 源码解析\n```c\n\n<p>typedef struct listNode {</p>\n<pre><code>// 前置节点\nstruct listNode *prev;\n\n// 后置节点\nstruct listNode *next;\n\n// 节点的值\nvoid *value;\n</code></pre>\n<p>} listNode;</p>\n<p>typedef struct list {</p>\n<pre><code>// 表头节点\nlistNode *head;\n\n// 表尾节点\nlistNode *tail;\n\n// 链表所包含的节点数量\nunsigned long len;\n\n// 节点值复制函数\nvoid *(*dup)(void *ptr);\n\n// 节点值释放函数\nvoid (*free)(void *ptr);\n\n// 节点值对比函数\nint (*match)(void *ptr, void *key);\n</code></pre>\n<p>} list;</p>\n<pre><code>\n![](graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png)\n![](graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png)\n\n\n** 特性总结 **\n&gt; `双端：` 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。\n&gt; `无环：` 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。\n&gt; `带表头指针和表尾指针：` 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。\n&gt; `带链表长度计数器：` 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。\n&gt; `多态：` 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。\n\n\n\n&lt;br/&gt;\n### 字典(Dict)\n#### 源码解析\n```c\ntypedef struct dictht &#123;\n\n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n\n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n&#125; dictht;\n\ntypedef struct dictEntry &#123;\n\n    // 键\n    void *key;\n\n    // 值\n    union &#123;\n        void *val;\n        uint64_t u64;\n        int64_t s64;\n    &#125; v;\n\n    // 指向下个哈希表节点，形成链表\n    struct dictEntry *next;\n\n&#125; dictEntry;\n</code></pre>\n<p><img src=\"graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png\"></p>\n<br/>\n### 跳跃表(Skip List)\n#### 源码解析\n```c\ntypedef struct zskiplistNode {\n\n<pre><code>// 后退指针\nstruct zskiplistNode *backward;\n\n// 分值\ndouble score;\n\n// 成员对象\nrobj *obj;\n\n// 层\nstruct zskiplistLevel &#123;\n\n    // 前进指针\n    struct zskiplistNode *forward;\n\n    // 跨度\n    unsigned int span;\n\n&#125; level[];\n</code></pre>\n<p>} zskiplistNode;</p>\n<pre><code>\n![](graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png)\n\n\n&lt;br/&gt;\n### 整数集合(Int Set)\n#### 源码解析\n```c\ntypedef struct intset &#123;\n\n    // 编码方式\n    uint32_t encoding;\n\n    // 集合包含的元素数量\n    uint32_t length;\n\n    // 保存元素的数组\n    int8_t contents[];\n\n&#125; intset;\n</code></pre>\n<p><img src=\"graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f\"></p>\n<br/>\n### 压缩列表(Zip List)\n#### 源码解析\n```c\n\n<pre><code>\n\n## 过期（Expires）\n\n&lt;!-- more --&gt;\n\n\n## LRU\n\n** 1、需要设置最大内存限制，如：**\n```bash\nmaxmemory 100mb\n</code></pre>\n<p>** 2、选择策略 **</p>\n<pre><code class=\"bash\">maxmemory-policy noeviction\n</code></pre>\n<br/>\n### Redis淘汰机制(Eviction policies)\n\n<p><code>noeviction</code>: 默认策略，不淘汰，如果内存已满，添加数据报错。 \n<code>allkeys-lru</code>: 在所有键中，选取最近最少使用的数据抛弃。\n<code>volatile-lru</code>: 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。\n<code>allkeys-random</code>: 在所有键中，随机抛弃。\n<code>volatile-random</code>: 在设置了过期时间的所有键，随机抛弃。\n<code>volatile-ttl</code>: 在设置了过期时间的所有键，抛弃存活时间最短的数据。</p>\n<p><img src=\"lru_comparison.png\" alt=\"LRU Comparison\"></p>\n<br/>\n\n<hr>\n<p>参考\nRedis官网：<a href=\"https://redis.io/\">https://redis.io</a>\n《Redis设计与实现》：<a href=\"http://redisbook.com/\">http://redisbook.com/</a></p>"},{"title":"SQL运算符优先级","date":"2019-06-21T08:34:56.000Z","_content":"\n\n### MySQL\n\n级别 | 运算符\n---|----\n1   |   INTERVAL\n2   |   BINARY, COLLATE\n3   |   !\n4   |   - (unary minus), ~ (unary bit inversion)\n5   |   ^\n6   |   *, /, DIV, %, MOD\n7   |   -, +\n8   |   <<, >>\n9   |   &\n10  |   &#124;  \n11  |   = (comparison), <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP, IN\n12  |   BETWEEN, CASE, WHEN, THEN, ELSE\n13  |   NOT\n14  |   AND, &&\n15  |   XOR\n16  |   OR, &#124;&#124;\n17  |   = (assignment), :=\n\n\n<br/>\n### Oracle\n级别   |   运算符  |   Purpose\n------|-------|--------\n1   |   +, - (as unary operators), PRIOR, CONNECT_BY_ROOT, COLLATE  |   Identity, negation, location in hierarchy\n2   |   *, /    |   Multiplication, division\n3   |   +, - (as binary operators), &#124;&#124;  |   Addition, subtraction, concatenation    \n4   |   =, !=, <, >, <=, >= |   comparison\n5   |   IS [NOT] NULL, LIKE, [NOT] BETWEEN, [NOT] IN, EXISTS, IS OF type    |   comparison\n6   |   NOT |   exponentiation, logical negation\n7   |   AND |   conjunction\n8   |   OR  |   disjunction\n\n<br/>\n### PostgreSQL\n级别    |   Operator/Element    |   Associativity   |   Description\n-------|------------------------|------------------|---------\n1   |   .   |   left    |   table/column name separator\n2   |   ::  |   left    |   PostgreSQL-style typecast\n3   |   [ ]\t|   left\t|   array element selection\n4   |   + -\t|   right\t|   unary plus, unary minus\n5   |   ^   |   left\t|   exponentiation\n6   |   * / %   |\tleft\t|   multiplication, division, modulo\n7   |   + - |   left\t|   addition, subtraction\n8   |   (any other operator)\t|   left\t|   all other native and user-defined operators\n9   |   BETWEEN IN LIKE ILIKE SIMILAR\t \t|   |   range containment, set membership, string matching\n10  |   < > = <= >= <>\t \t|   |   comparison operators\n11  |   IS ISNULL NOTNULL   |   |   IS TRUE, IS FALSE, IS NULL, IS DISTINCT FROM, etc\n12  |   NOT\t|   right\t|   logical negation\n13  |   AND\t|   left\t|   logical conjunction\n14  |   OR\t|   left\t|   logical disjunction\n\n<br/>\n### Transact-SQL\n级别 | 运算符\n---|----\n1 | ~（位非）\n2 | *（乘）、/（除）、%（取模）\n3 | +（正）、-（负）、+（加）、+（串联）、-（减）、&（位与）、^（位异或）、&#124;（位或）\n4 | =、>、<、>=、<=、<>、!=、!>、!<（比较运算符）\n5 | NOT\n6 | 和\n7 | ALL、ANY、BETWEEN、IN、LIKE、OR、SOME\n8 | =（赋值）\n\n---\n参考\n[MySQL运算符优先级](https://dev.mysql.com/doc/refman/8.0/en/operator-precedence.html)\n[Oracle运算符优先级1](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Operators.html)\n[Oracle运算符优先级2](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Conditions.html)\n[PostgreSQL运算符优先级](https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-PRECEDENCE)\n[Transact-SQL运算符优先级](https://docs.microsoft.com/zh-cn/sql/t-sql/language-elements/operator-precedence-transact-sql?view=sql-server-ver15)\n","source":"_posts/SQL运算符优先级.md","raw":"---\ntitle: SQL运算符优先级\ndate: 2019-06-21 16:34:56\ncategories: \n    - SQL\ntags:\n    - SQL\n---\n\n\n### MySQL\n\n级别 | 运算符\n---|----\n1   |   INTERVAL\n2   |   BINARY, COLLATE\n3   |   !\n4   |   - (unary minus), ~ (unary bit inversion)\n5   |   ^\n6   |   *, /, DIV, %, MOD\n7   |   -, +\n8   |   <<, >>\n9   |   &\n10  |   &#124;  \n11  |   = (comparison), <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP, IN\n12  |   BETWEEN, CASE, WHEN, THEN, ELSE\n13  |   NOT\n14  |   AND, &&\n15  |   XOR\n16  |   OR, &#124;&#124;\n17  |   = (assignment), :=\n\n\n<br/>\n### Oracle\n级别   |   运算符  |   Purpose\n------|-------|--------\n1   |   +, - (as unary operators), PRIOR, CONNECT_BY_ROOT, COLLATE  |   Identity, negation, location in hierarchy\n2   |   *, /    |   Multiplication, division\n3   |   +, - (as binary operators), &#124;&#124;  |   Addition, subtraction, concatenation    \n4   |   =, !=, <, >, <=, >= |   comparison\n5   |   IS [NOT] NULL, LIKE, [NOT] BETWEEN, [NOT] IN, EXISTS, IS OF type    |   comparison\n6   |   NOT |   exponentiation, logical negation\n7   |   AND |   conjunction\n8   |   OR  |   disjunction\n\n<br/>\n### PostgreSQL\n级别    |   Operator/Element    |   Associativity   |   Description\n-------|------------------------|------------------|---------\n1   |   .   |   left    |   table/column name separator\n2   |   ::  |   left    |   PostgreSQL-style typecast\n3   |   [ ]\t|   left\t|   array element selection\n4   |   + -\t|   right\t|   unary plus, unary minus\n5   |   ^   |   left\t|   exponentiation\n6   |   * / %   |\tleft\t|   multiplication, division, modulo\n7   |   + - |   left\t|   addition, subtraction\n8   |   (any other operator)\t|   left\t|   all other native and user-defined operators\n9   |   BETWEEN IN LIKE ILIKE SIMILAR\t \t|   |   range containment, set membership, string matching\n10  |   < > = <= >= <>\t \t|   |   comparison operators\n11  |   IS ISNULL NOTNULL   |   |   IS TRUE, IS FALSE, IS NULL, IS DISTINCT FROM, etc\n12  |   NOT\t|   right\t|   logical negation\n13  |   AND\t|   left\t|   logical conjunction\n14  |   OR\t|   left\t|   logical disjunction\n\n<br/>\n### Transact-SQL\n级别 | 运算符\n---|----\n1 | ~（位非）\n2 | *（乘）、/（除）、%（取模）\n3 | +（正）、-（负）、+（加）、+（串联）、-（减）、&（位与）、^（位异或）、&#124;（位或）\n4 | =、>、<、>=、<=、<>、!=、!>、!<（比较运算符）\n5 | NOT\n6 | 和\n7 | ALL、ANY、BETWEEN、IN、LIKE、OR、SOME\n8 | =（赋值）\n\n---\n参考\n[MySQL运算符优先级](https://dev.mysql.com/doc/refman/8.0/en/operator-precedence.html)\n[Oracle运算符优先级1](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Operators.html)\n[Oracle运算符优先级2](https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Conditions.html)\n[PostgreSQL运算符优先级](https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-PRECEDENCE)\n[Transact-SQL运算符优先级](https://docs.microsoft.com/zh-cn/sql/t-sql/language-elements/operator-precedence-transact-sql?view=sql-server-ver15)\n","slug":"SQL运算符优先级","published":1,"updated":"2021-06-30T02:33:24.729Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx4007sr5p71vphdbcw","content":"<h3 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h3><table>\n<thead>\n<tr>\n<th>级别</th>\n<th>运算符</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>INTERVAL</td>\n</tr>\n<tr>\n<td>2</td>\n<td>BINARY, COLLATE</td>\n</tr>\n<tr>\n<td>3</td>\n<td>!</td>\n</tr>\n<tr>\n<td>4</td>\n<td>- (unary minus), ~ (unary bit inversion)</td>\n</tr>\n<tr>\n<td>5</td>\n<td>^</td>\n</tr>\n<tr>\n<td>6</td>\n<td>*, /, DIV, %, MOD</td>\n</tr>\n<tr>\n<td>7</td>\n<td>-, +</td>\n</tr>\n<tr>\n<td>8</td>\n<td>&lt;&lt;, &gt;&gt;</td>\n</tr>\n<tr>\n<td>9</td>\n<td>&amp;</td>\n</tr>\n<tr>\n<td>10</td>\n<td>|</td>\n</tr>\n<tr>\n<td>11</td>\n<td>= (comparison), &lt;=&gt;, &gt;=, &gt;, &lt;=, &lt;, &lt;&gt;, !=, IS, LIKE, REGEXP, IN</td>\n</tr>\n<tr>\n<td>12</td>\n<td>BETWEEN, CASE, WHEN, THEN, ELSE</td>\n</tr>\n<tr>\n<td>13</td>\n<td>NOT</td>\n</tr>\n<tr>\n<td>14</td>\n<td>AND, &amp;&amp;</td>\n</tr>\n<tr>\n<td>15</td>\n<td>XOR</td>\n</tr>\n<tr>\n<td>16</td>\n<td>OR, ||</td>\n</tr>\n<tr>\n<td>17</td>\n<td>= (assignment), :=</td>\n</tr>\n</tbody></table>\n<br>\n### Oracle\n级别   |   运算符  |   Purpose\n------|-------|--------\n1   |   +, - (as unary operators), PRIOR, CONNECT_BY_ROOT, COLLATE  |   Identity, negation, location in hierarchy\n2   |   *, /    |   Multiplication, division\n3   |   +, - (as binary operators), ||  |   Addition, subtraction, concatenation    \n4   |   =, !=, &lt;, &gt;, &lt;=, &gt;= |   comparison\n5   |   IS [NOT] NULL, LIKE, [NOT] BETWEEN, [NOT] IN, EXISTS, IS OF type    |   comparison\n6   |   NOT |   exponentiation, logical negation\n7   |   AND |   conjunction\n8   |   OR  |   disjunction\n\n<br>\n### PostgreSQL\n级别    |   Operator/Element    |   Associativity   |   Description\n-------|------------------------|------------------|---------\n1   |   .   |   left    |   table/column name separator\n2   |   ::  |   left    |   PostgreSQL-style typecast\n3   |   [ ]    |   left    |   array element selection\n4   |   + -    |   right    |   unary plus, unary minus\n5   |   ^   |   left    |   exponentiation\n6   |   * / %   |    left    |   multiplication, division, modulo\n7   |   + - |   left    |   addition, subtraction\n8   |   (any other operator)    |   left    |   all other native and user-defined operators\n9   |   BETWEEN IN LIKE ILIKE SIMILAR         |   |   range containment, set membership, string matching\n10  |   &lt; &gt; = &lt;= &gt;= &lt;&gt;         |   |   comparison operators\n11  |   IS ISNULL NOTNULL   |   |   IS TRUE, IS FALSE, IS NULL, IS DISTINCT FROM, etc\n12  |   NOT    |   right    |   logical negation\n13  |   AND    |   left    |   logical conjunction\n14  |   OR    |   left    |   logical disjunction\n\n<br>\n### Transact-SQL\n级别 | 运算符\n---|----\n1 | ~（位非）\n2 | *（乘）、/（除）、%（取模）\n3 | +（正）、-（负）、+（加）、+（串联）、-（减）、&amp;（位与）、^（位异或）、|（位或）\n4 | =、&gt;、&lt;、&gt;=、&lt;=、&lt;&gt;、!=、!&gt;、!&lt;（比较运算符）\n5 | NOT\n6 | 和\n7 | ALL、ANY、BETWEEN、IN、LIKE、OR、SOME\n8 | =（赋值）\n\n<hr>\n<p>参考\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/operator-precedence.html\">MySQL运算符优先级</a>\n<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Operators.html\">Oracle运算符优先级1</a>\n<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Conditions.html\">Oracle运算符优先级2</a>\n<a href=\"https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-PRECEDENCE\">PostgreSQL运算符优先级</a>\n<a href=\"https://docs.microsoft.com/zh-cn/sql/t-sql/language-elements/operator-precedence-transact-sql?view=sql-server-ver15\">Transact-SQL运算符优先级</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h3><table>\n<thead>\n<tr>\n<th>级别</th>\n<th>运算符</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>INTERVAL</td>\n</tr>\n<tr>\n<td>2</td>\n<td>BINARY, COLLATE</td>\n</tr>\n<tr>\n<td>3</td>\n<td>!</td>\n</tr>\n<tr>\n<td>4</td>\n<td>- (unary minus), ~ (unary bit inversion)</td>\n</tr>\n<tr>\n<td>5</td>\n<td>^</td>\n</tr>\n<tr>\n<td>6</td>\n<td>*, /, DIV, %, MOD</td>\n</tr>\n<tr>\n<td>7</td>\n<td>-, +</td>\n</tr>\n<tr>\n<td>8</td>\n<td>&lt;&lt;, &gt;&gt;</td>\n</tr>\n<tr>\n<td>9</td>\n<td>&amp;</td>\n</tr>\n<tr>\n<td>10</td>\n<td>&#124;</td>\n</tr>\n<tr>\n<td>11</td>\n<td>= (comparison), &lt;=&gt;, &gt;=, &gt;, &lt;=, &lt;, &lt;&gt;, !=, IS, LIKE, REGEXP, IN</td>\n</tr>\n<tr>\n<td>12</td>\n<td>BETWEEN, CASE, WHEN, THEN, ELSE</td>\n</tr>\n<tr>\n<td>13</td>\n<td>NOT</td>\n</tr>\n<tr>\n<td>14</td>\n<td>AND, &amp;&amp;</td>\n</tr>\n<tr>\n<td>15</td>\n<td>XOR</td>\n</tr>\n<tr>\n<td>16</td>\n<td>OR, &#124;&#124;</td>\n</tr>\n<tr>\n<td>17</td>\n<td>= (assignment), :=</td>\n</tr>\n</tbody></table>\n<br/>\n### Oracle\n级别   |   运算符  |   Purpose\n------|-------|--------\n1   |   +, - (as unary operators), PRIOR, CONNECT_BY_ROOT, COLLATE  |   Identity, negation, location in hierarchy\n2   |   *, /    |   Multiplication, division\n3   |   +, - (as binary operators), &#124;&#124;  |   Addition, subtraction, concatenation    \n4   |   =, !=, <, >, <=, >= |   comparison\n5   |   IS [NOT] NULL, LIKE, [NOT] BETWEEN, [NOT] IN, EXISTS, IS OF type    |   comparison\n6   |   NOT |   exponentiation, logical negation\n7   |   AND |   conjunction\n8   |   OR  |   disjunction\n\n<br/>\n### PostgreSQL\n级别    |   Operator/Element    |   Associativity   |   Description\n-------|------------------------|------------------|---------\n1   |   .   |   left    |   table/column name separator\n2   |   ::  |   left    |   PostgreSQL-style typecast\n3   |   [ ]    |   left    |   array element selection\n4   |   + -    |   right    |   unary plus, unary minus\n5   |   ^   |   left    |   exponentiation\n6   |   * / %   |    left    |   multiplication, division, modulo\n7   |   + - |   left    |   addition, subtraction\n8   |   (any other operator)    |   left    |   all other native and user-defined operators\n9   |   BETWEEN IN LIKE ILIKE SIMILAR         |   |   range containment, set membership, string matching\n10  |   < > = <= >= <>         |   |   comparison operators\n11  |   IS ISNULL NOTNULL   |   |   IS TRUE, IS FALSE, IS NULL, IS DISTINCT FROM, etc\n12  |   NOT    |   right    |   logical negation\n13  |   AND    |   left    |   logical conjunction\n14  |   OR    |   left    |   logical disjunction\n\n<br/>\n### Transact-SQL\n级别 | 运算符\n---|----\n1 | ~（位非）\n2 | *（乘）、/（除）、%（取模）\n3 | +（正）、-（负）、+（加）、+（串联）、-（减）、&（位与）、^（位异或）、&#124;（位或）\n4 | =、>、<、>=、<=、<>、!=、!>、!<（比较运算符）\n5 | NOT\n6 | 和\n7 | ALL、ANY、BETWEEN、IN、LIKE、OR、SOME\n8 | =（赋值）\n\n<hr>\n<p>参考\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/operator-precedence.html\">MySQL运算符优先级</a>\n<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Operators.html\">Oracle运算符优先级1</a>\n<a href=\"https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/About-SQL-Conditions.html\">Oracle运算符优先级2</a>\n<a href=\"https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-PRECEDENCE\">PostgreSQL运算符优先级</a>\n<a href=\"https://docs.microsoft.com/zh-cn/sql/t-sql/language-elements/operator-precedence-transact-sql?view=sql-server-ver15\">Transact-SQL运算符优先级</a></p>\n"},{"title":"SpringBoot应用启动原理分析","date":"2017-06-01T00:01:01.000Z","_content":"\n\nidea：\n\n```java\n├── BOOT-INF\n│   ├── classes\n│   │   ├── application.properties\n│   │   └── com\n│   │       └── example\n│   │           └── demo\n│   │               └── DemoApplication.class\n│   └── lib\n│       ├── classmate-1.3.4.jar\n│       ├── hibernate-validator-6.0.13.Final.jar\n│       ├── ...\n├── META-INF\n│   ├── MANIFEST.MF\n│   └── maven\n│       └── com.example\n│           └── demo\n│               ├── pom.properties\n│               └── pom.xml\n└── org\n    └── springframework\n        └── boot\n            └── loader\n                ├── ExecutableArchiveLauncher.class\n                ├── JarLauncher.class\n                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration.class\n                ├── LaunchedURLClassLoader.class\n                ├── Launcher.class\n                ├── MainMethodRunner.class\n                ├── PropertiesLauncher$1.class\n                ├── PropertiesLauncher$ArchiveEntryFilter.class\n                ├── PropertiesLauncher$PrefixMatchingArchiveFilter.class\n                ├── PropertiesLauncher.class\n                ├── WarLauncher.class\n                ├── archive\n                │   ├── Archive$Entry.class\n                │   ├── Archive$EntryFilter.class\n                │   ├── Archive.class\n                │   ├── ExplodedArchive$1.class\n                │   ├── ExplodedArchive$FileEntry.class\n                │   ├── ExplodedArchive$FileEntryIterator$EntryComparator.class\n                │   ├── ExplodedArchive$FileEntryIterator.class\n                │   ├── ExplodedArchive.class\n                │   ├── JarFileArchive$EntryIterator.class\n                │   ├── JarFileArchive$JarFileEntry.class\n                │   └── JarFileArchive.class\n                ├── data\n                │   ├── RandomAccessData.class\n                │   ├── RandomAccessDataFile$1.class\n                │   ├── RandomAccessDataFile$DataInputStream.class\n                │   ├── RandomAccessDataFile$FileAccess.class\n                │   └── RandomAccessDataFile.class\n                ├── jar\n                │   ├── AsciiBytes.class\n                │   ├── Bytes.class\n                │   ├── CentralDirectoryEndRecord.class\n                │   ├── CentralDirectoryFileHeader.class\n                │   ├── CentralDirectoryParser.class\n                │   ├── CentralDirectoryVisitor.class\n                │   ├── FileHeader.class\n                │   ├── Handler.class\n                │   ├── JarEntry.class\n                │   ├── JarEntryFilter.class\n                │   ├── JarFile$1.class\n                │   ├── JarFile$2.class\n                │   ├── JarFile$JarFileType.class\n                │   ├── JarFile.class\n                │   ├── JarFileEntries$1.class\n                │   ├── JarFileEntries$EntryIterator.class\n                │   ├── JarFileEntries.class\n                │   ├── JarURLConnection$1.class\n                │   ├── JarURLConnection$JarEntryName.class\n                │   ├── JarURLConnection.class\n                │   ├── StringSequence.class\n                │   └── ZipInflaterInputStream.class\n                └── util\n                    └── SystemPropertyUtils.class\n```","source":"_posts/SpringBoot应用启动原理分析.md","raw":"---\ntitle: SpringBoot应用启动原理分析\ndate: 2017-06-01 08:01:01\ncategories:\n    - SpringBoot\ntags:\n    - SpringBoot\n---\n\n\nidea：\n\n```java\n├── BOOT-INF\n│   ├── classes\n│   │   ├── application.properties\n│   │   └── com\n│   │       └── example\n│   │           └── demo\n│   │               └── DemoApplication.class\n│   └── lib\n│       ├── classmate-1.3.4.jar\n│       ├── hibernate-validator-6.0.13.Final.jar\n│       ├── ...\n├── META-INF\n│   ├── MANIFEST.MF\n│   └── maven\n│       └── com.example\n│           └── demo\n│               ├── pom.properties\n│               └── pom.xml\n└── org\n    └── springframework\n        └── boot\n            └── loader\n                ├── ExecutableArchiveLauncher.class\n                ├── JarLauncher.class\n                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration.class\n                ├── LaunchedURLClassLoader.class\n                ├── Launcher.class\n                ├── MainMethodRunner.class\n                ├── PropertiesLauncher$1.class\n                ├── PropertiesLauncher$ArchiveEntryFilter.class\n                ├── PropertiesLauncher$PrefixMatchingArchiveFilter.class\n                ├── PropertiesLauncher.class\n                ├── WarLauncher.class\n                ├── archive\n                │   ├── Archive$Entry.class\n                │   ├── Archive$EntryFilter.class\n                │   ├── Archive.class\n                │   ├── ExplodedArchive$1.class\n                │   ├── ExplodedArchive$FileEntry.class\n                │   ├── ExplodedArchive$FileEntryIterator$EntryComparator.class\n                │   ├── ExplodedArchive$FileEntryIterator.class\n                │   ├── ExplodedArchive.class\n                │   ├── JarFileArchive$EntryIterator.class\n                │   ├── JarFileArchive$JarFileEntry.class\n                │   └── JarFileArchive.class\n                ├── data\n                │   ├── RandomAccessData.class\n                │   ├── RandomAccessDataFile$1.class\n                │   ├── RandomAccessDataFile$DataInputStream.class\n                │   ├── RandomAccessDataFile$FileAccess.class\n                │   └── RandomAccessDataFile.class\n                ├── jar\n                │   ├── AsciiBytes.class\n                │   ├── Bytes.class\n                │   ├── CentralDirectoryEndRecord.class\n                │   ├── CentralDirectoryFileHeader.class\n                │   ├── CentralDirectoryParser.class\n                │   ├── CentralDirectoryVisitor.class\n                │   ├── FileHeader.class\n                │   ├── Handler.class\n                │   ├── JarEntry.class\n                │   ├── JarEntryFilter.class\n                │   ├── JarFile$1.class\n                │   ├── JarFile$2.class\n                │   ├── JarFile$JarFileType.class\n                │   ├── JarFile.class\n                │   ├── JarFileEntries$1.class\n                │   ├── JarFileEntries$EntryIterator.class\n                │   ├── JarFileEntries.class\n                │   ├── JarURLConnection$1.class\n                │   ├── JarURLConnection$JarEntryName.class\n                │   ├── JarURLConnection.class\n                │   ├── StringSequence.class\n                │   └── ZipInflaterInputStream.class\n                └── util\n                    └── SystemPropertyUtils.class\n```","slug":"SpringBoot应用启动原理分析","published":1,"updated":"2021-06-30T02:33:24.729Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx5007xr5p7eukkctak","content":"<p>idea：</p>\n<pre class=\" language-java\"><code class=\"language-java\">├── BOOT<span class=\"token operator\">-</span>INF\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── classes\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── application<span class=\"token punctuation\">.</span>properties\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── com\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>     └── example\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>         └── demo\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>             └── DemoApplication<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── lib\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>     ├── classmate<span class=\"token operator\">-</span><span class=\"token number\">1.3</span><span class=\"token punctuation\">.</span><span class=\"token number\">4</span><span class=\"token punctuation\">.</span>jar\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>     ├── hibernate<span class=\"token operator\">-</span>validator<span class=\"token operator\">-</span><span class=\"token number\">6.0</span><span class=\"token punctuation\">.</span><span class=\"token number\">13</span><span class=\"token punctuation\">.</span>Final<span class=\"token punctuation\">.</span>jar\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>     ├── <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n├── META<span class=\"token operator\">-</span>INF\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── MANIFEST<span class=\"token punctuation\">.</span>MF\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── maven\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>     └── com<span class=\"token punctuation\">.</span>example\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>         └── demo\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>             ├── pom<span class=\"token punctuation\">.</span>properties\n│<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span>             └── pom<span class=\"token punctuation\">.</span>xml\n└── org\n    └── springframework\n        └── boot\n            └── loader\n                ├── ExecutableArchiveLauncher<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── JarLauncher<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── LaunchedURLClassLoader<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── Launcher<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── MainMethodRunner<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── PropertiesLauncher$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── PropertiesLauncher$ArchiveEntryFilter<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── PropertiesLauncher$PrefixMatchingArchiveFilter<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── PropertiesLauncher<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── WarLauncher<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── archive\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── Archive$Entry<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── Archive$EntryFilter<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── Archive<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── ExplodedArchive$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── ExplodedArchive$FileEntry<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── ExplodedArchive$FileEntryIterator$EntryComparator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── ExplodedArchive$FileEntryIterator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── ExplodedArchive<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFileArchive$EntryIterator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFileArchive$JarFileEntry<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── JarFileArchive<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── data\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── RandomAccessData<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── RandomAccessDataFile$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── RandomAccessDataFile$DataInputStream<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── RandomAccessDataFile$FileAccess<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── RandomAccessDataFile<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                ├── jar\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── AsciiBytes<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── Bytes<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── CentralDirectoryEndRecord<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── CentralDirectoryFileHeader<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── CentralDirectoryParser<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── CentralDirectoryVisitor<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── FileHeader<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── Handler<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarEntry<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarEntryFilter<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFile$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFile$<span class=\"token number\">2</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFile$JarFileType<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFile<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFileEntries$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFileEntries$EntryIterator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarFileEntries<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarURLConnection$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarURLConnection$JarEntryName<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── JarURLConnection<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> ├── StringSequence<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                │<span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span><span class=\"token operator\">&amp;</span>nbsp<span class=\"token punctuation\">;</span> └── ZipInflaterInputStream<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n                └── util\n                    └── SystemPropertyUtils<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span>\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>idea：</p>\n<pre><code class=\"java\">├── BOOT-INF\n│   ├── classes\n│   │   ├── application.properties\n│   │   └── com\n│   │       └── example\n│   │           └── demo\n│   │               └── DemoApplication.class\n│   └── lib\n│       ├── classmate-1.3.4.jar\n│       ├── hibernate-validator-6.0.13.Final.jar\n│       ├── ...\n├── META-INF\n│   ├── MANIFEST.MF\n│   └── maven\n│       └── com.example\n│           └── demo\n│               ├── pom.properties\n│               └── pom.xml\n└── org\n    └── springframework\n        └── boot\n            └── loader\n                ├── ExecutableArchiveLauncher.class\n                ├── JarLauncher.class\n                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration.class\n                ├── LaunchedURLClassLoader.class\n                ├── Launcher.class\n                ├── MainMethodRunner.class\n                ├── PropertiesLauncher$1.class\n                ├── PropertiesLauncher$ArchiveEntryFilter.class\n                ├── PropertiesLauncher$PrefixMatchingArchiveFilter.class\n                ├── PropertiesLauncher.class\n                ├── WarLauncher.class\n                ├── archive\n                │   ├── Archive$Entry.class\n                │   ├── Archive$EntryFilter.class\n                │   ├── Archive.class\n                │   ├── ExplodedArchive$1.class\n                │   ├── ExplodedArchive$FileEntry.class\n                │   ├── ExplodedArchive$FileEntryIterator$EntryComparator.class\n                │   ├── ExplodedArchive$FileEntryIterator.class\n                │   ├── ExplodedArchive.class\n                │   ├── JarFileArchive$EntryIterator.class\n                │   ├── JarFileArchive$JarFileEntry.class\n                │   └── JarFileArchive.class\n                ├── data\n                │   ├── RandomAccessData.class\n                │   ├── RandomAccessDataFile$1.class\n                │   ├── RandomAccessDataFile$DataInputStream.class\n                │   ├── RandomAccessDataFile$FileAccess.class\n                │   └── RandomAccessDataFile.class\n                ├── jar\n                │   ├── AsciiBytes.class\n                │   ├── Bytes.class\n                │   ├── CentralDirectoryEndRecord.class\n                │   ├── CentralDirectoryFileHeader.class\n                │   ├── CentralDirectoryParser.class\n                │   ├── CentralDirectoryVisitor.class\n                │   ├── FileHeader.class\n                │   ├── Handler.class\n                │   ├── JarEntry.class\n                │   ├── JarEntryFilter.class\n                │   ├── JarFile$1.class\n                │   ├── JarFile$2.class\n                │   ├── JarFile$JarFileType.class\n                │   ├── JarFile.class\n                │   ├── JarFileEntries$1.class\n                │   ├── JarFileEntries$EntryIterator.class\n                │   ├── JarFileEntries.class\n                │   ├── JarURLConnection$1.class\n                │   ├── JarURLConnection$JarEntryName.class\n                │   ├── JarURLConnection.class\n                │   ├── StringSequence.class\n                │   └── ZipInflaterInputStream.class\n                └── util\n                    └── SystemPropertyUtils.class\n</code></pre>\n"},{"title":"SpringBoot集成Elasticsearch","date":"2019-01-17T03:17:49.000Z","_content":"\n\n\n---\n\n原本是采用 transportClient 来写的，但是一个是官方说明在5.x以后的版本就不怎么支持了，二是因为实际环境上使用了加密，无法通过 transportclient 的方式进行查询了，所以综合了一下采用了 High-level-rest-client 的方式。同时在使用 High-level-rest-client 的方式创建 client 的时候务必注意版本的情况，我这里使用的是5.6版本的，不同版本之间创建 client 的方式的差别还是比较大的。\n\n\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch -->\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>${org.elasticsearch.version}</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.elasticsearch.client/transport -->\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>transport</artifactId>\n    <version>${org.elasticsearch.version}</version>\n</dependency>\n```\n\n\n## 问题：\n\n### 问题详情\n```\n2019-01-17 15:47:56.134  WARN 45208 --- [ent_boss][T#10]] o.e.transport.netty4.Netty4Transport     : exception caught on transport layer [NettyTcpChannel{localAddress=/127.0.0.1:54984, remoteAddress=/127.0.0.1:9200}], closing connection\n\nio.netty.handler.codec.DecoderException: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167) [netty-handler-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:822) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]\nCaused by: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n\tat org.elasticsearch.transport.TcpTransport.validateMessageHeader(TcpTransport.java:1072) ~[elasticsearch-6.5.4.jar:6.5.4]\n\tat org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoder.decode(Netty4SizeHeaderFrameDecoder.java:36) ~[transport-netty4-client-6.5.4.jar:6.5.4]\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\t... 20 common frames omitted\n```\n### 解决方案\n\n\n---\n参考","source":"_posts/SpringBoot集成Elasticsearch.md","raw":"---\ntitle: SpringBoot集成Elasticsearch\ndate: 2019-01-17 11:17:49\ncategories: \n    - Elasticsearch\ntags:\n    - 全文搜索\n    - SpringBoot\n    - Elasticsearch\n---\n\n\n\n---\n\n原本是采用 transportClient 来写的，但是一个是官方说明在5.x以后的版本就不怎么支持了，二是因为实际环境上使用了加密，无法通过 transportclient 的方式进行查询了，所以综合了一下采用了 High-level-rest-client 的方式。同时在使用 High-level-rest-client 的方式创建 client 的时候务必注意版本的情况，我这里使用的是5.6版本的，不同版本之间创建 client 的方式的差别还是比较大的。\n\n\n\n```xml\n<!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch -->\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>${org.elasticsearch.version}</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.elasticsearch.client/transport -->\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>transport</artifactId>\n    <version>${org.elasticsearch.version}</version>\n</dependency>\n```\n\n\n## 问题：\n\n### 问题详情\n```\n2019-01-17 15:47:56.134  WARN 45208 --- [ent_boss][T#10]] o.e.transport.netty4.Netty4Transport     : exception caught on transport layer [NettyTcpChannel{localAddress=/127.0.0.1:54984, remoteAddress=/127.0.0.1:9200}], closing connection\n\nio.netty.handler.codec.DecoderException: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167) [netty-handler-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:822) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n\tat java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]\nCaused by: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n\tat org.elasticsearch.transport.TcpTransport.validateMessageHeader(TcpTransport.java:1072) ~[elasticsearch-6.5.4.jar:6.5.4]\n\tat org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoder.decode(Netty4SizeHeaderFrameDecoder.java:36) ~[transport-netty4-client-6.5.4.jar:6.5.4]\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\tat io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n\t... 20 common frames omitted\n```\n### 解决方案\n\n\n---\n参考","slug":"SpringBoot集成Elasticsearch","published":1,"updated":"2021-06-30T02:33:24.729Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx50080r5p7hlxw8x8g","content":"<hr>\n<p>原本是采用 transportClient 来写的，但是一个是官方说明在5.x以后的版本就不怎么支持了，二是因为实际环境上使用了加密，无法通过 transportclient 的方式进行查询了，所以综合了一下采用了 High-level-rest-client 的方式。同时在使用 High-level-rest-client 的方式创建 client 的时候务必注意版本的情况，我这里使用的是5.6版本的，不同版本之间创建 client 的方式的差别还是比较大的。</p>\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.elasticsearch<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>elasticsearch<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>${org.elasticsearch.version}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch.client/transport --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.elasticsearch.client<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>transport<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>${org.elasticsearch.version}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<h2 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h2><h3 id=\"问题详情\"><a href=\"#问题详情\" class=\"headerlink\" title=\"问题详情\"></a>问题详情</h3><pre><code>2019-01-17 15:47:56.134  WARN 45208 --- [ent_boss][T#10]] o.e.transport.netty4.Netty4Transport     : exception caught on transport layer [NettyTcpChannel{localAddress=/127.0.0.1:54984, remoteAddress=/127.0.0.1:9200}], closing connection\n\nio.netty.handler.codec.DecoderException: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n    at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167) [netty-handler-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:822) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]\nCaused by: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n    at org.elasticsearch.transport.TcpTransport.validateMessageHeader(TcpTransport.java:1072) ~[elasticsearch-6.5.4.jar:6.5.4]\n    at org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoder.decode(Netty4SizeHeaderFrameDecoder.java:36) ~[transport-netty4-client-6.5.4.jar:6.5.4]\n    at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    ... 20 common frames omitted\n</code></pre>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>原本是采用 transportClient 来写的，但是一个是官方说明在5.x以后的版本就不怎么支持了，二是因为实际环境上使用了加密，无法通过 transportclient 的方式进行查询了，所以综合了一下采用了 High-level-rest-client 的方式。同时在使用 High-level-rest-client 的方式创建 client 的时候务必注意版本的情况，我这里使用的是5.6版本的，不同版本之间创建 client 的方式的差别还是比较大的。</p>\n<pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;\n    &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;\n    &lt;version&gt;$&#123;org.elasticsearch.version&#125;&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch.client/transport --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;\n    &lt;artifactId&gt;transport&lt;/artifactId&gt;\n    &lt;version&gt;$&#123;org.elasticsearch.version&#125;&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h2 id=\"问题：\"><a href=\"#问题：\" class=\"headerlink\" title=\"问题：\"></a>问题：</h2><h3 id=\"问题详情\"><a href=\"#问题详情\" class=\"headerlink\" title=\"问题详情\"></a>问题详情</h3><pre><code>2019-01-17 15:47:56.134  WARN 45208 --- [ent_boss][T#10]] o.e.transport.netty4.Netty4Transport     : exception caught on transport layer [NettyTcpChannel&#123;localAddress=/127.0.0.1:54984, remoteAddress=/127.0.0.1:9200&#125;], closing connection\n\nio.netty.handler.codec.DecoderException: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n    at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:472) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:405) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:372) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:355) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.logging.LoggingHandler.channelInactive(LoggingHandler.java:167) [netty-handler-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:224) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1429) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:245) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:231) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:947) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:822) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:404) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:462) [netty-transport-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897) [netty-common-4.1.30.Final.jar:4.1.30.Final]\n    at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]\nCaused by: java.io.StreamCorruptedException: invalid internal transport message format, got (48,54,54,50)\n    at org.elasticsearch.transport.TcpTransport.validateMessageHeader(TcpTransport.java:1072) ~[elasticsearch-6.5.4.jar:6.5.4]\n    at org.elasticsearch.transport.netty4.Netty4SizeHeaderFrameDecoder.decode(Netty4SizeHeaderFrameDecoder.java:36) ~[transport-netty4-client-6.5.4.jar:6.5.4]\n    at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:502) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:441) ~[netty-codec-4.1.30.Final.jar:4.1.30.Final]\n    ... 20 common frames omitted\n</code></pre>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><hr>\n<p>参考</p>\n"},{"title":"SQL词法分析器问题总结","date":"2019-07-18T03:04:07.000Z","_content":"\n\n## 运算符优先级\n左递归 转换成 右递归\n```\nE: T (+、-) T (+、-) T ...\nT: X (*、/、mod) X\n```\n\n## +、-\n+、- 后面是数字\n需要判断前面`Token`\n\n## Literal\n字符需要贪婪匹配算法拿到 字符串\n\n## \n\n\n","source":"_posts/SQL词法分析器问题总结.md","raw":"---\ntitle: SQL词法分析器问题总结\ndate: 2019-07-18 11:04:07\ncategories: \n    - 词法分析\ntags:\n    - 词法分析\n---\n\n\n## 运算符优先级\n左递归 转换成 右递归\n```\nE: T (+、-) T (+、-) T ...\nT: X (*、/、mod) X\n```\n\n## +、-\n+、- 后面是数字\n需要判断前面`Token`\n\n## Literal\n字符需要贪婪匹配算法拿到 字符串\n\n## \n\n\n","slug":"SQL词法分析器问题总结","published":1,"updated":"2021-06-30T02:33:24.728Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx60084r5p75fej1rp9","content":"<h2 id=\"运算符优先级\"><a href=\"#运算符优先级\" class=\"headerlink\" title=\"运算符优先级\"></a>运算符优先级</h2><p>左递归 转换成 右递归</p>\n<pre><code>E: T (+、-) T (+、-) T ...\nT: X (*、/、mod) X\n</code></pre>\n<h2 id=\"、\"><a href=\"#、\" class=\"headerlink\" title=\"+、-\"></a>+、-</h2><p>+、- 后面是数字\n需要判断前面<code>Token</code></p>\n<h2 id=\"Literal\"><a href=\"#Literal\" class=\"headerlink\" title=\"Literal\"></a>Literal</h2><p>字符需要贪婪匹配算法拿到 字符串</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"运算符优先级\"><a href=\"#运算符优先级\" class=\"headerlink\" title=\"运算符优先级\"></a>运算符优先级</h2><p>左递归 转换成 右递归</p>\n<pre><code>E: T (+、-) T (+、-) T ...\nT: X (*、/、mod) X\n</code></pre>\n<h2 id=\"、\"><a href=\"#、\" class=\"headerlink\" title=\"+、-\"></a>+、-</h2><p>+、- 后面是数字\n需要判断前面<code>Token</code></p>\n<h2 id=\"Literal\"><a href=\"#Literal\" class=\"headerlink\" title=\"Literal\"></a>Literal</h2><p>字符需要贪婪匹配算法拿到 字符串</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"title":"ZooKeeper安装","date":"2019-01-09T10:27:23.000Z","_content":"\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《百度百科》\n<!-- more -->\n\n\n## 下载\n\n下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/\n\n## 安装\n\n```\n$ cd /Library\n$ tar -zxf zookeeper-3.4.13.tar.gz\n$ cd zookeeper-3.4.13\n$ mkdir data\n```\n\n### 配置\n```\ntickTime = 2000\ndataDir = /Library/zookeeper-3.4.13/data\nclientPort = 2181\ninitLimit = 5\nsyncLimit = 2\n```\n\n### 单机\n\n### 集群\n\n\n\n---\n\n\n\n\n---\n参考\n官网：https://zookeeper.apache.org/\nGithub：\n","source":"_posts/ZooKeeper安装.md","raw":"---\ntitle: ZooKeeper安装\ndate: 2019-01-09 18:27:23\ncategories: \n    - ZooKeeper\ntags:\n    - ZooKeeper\n---\n\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《百度百科》\n<!-- more -->\n\n\n## 下载\n\n下载地址：https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/\n\n## 安装\n\n```\n$ cd /Library\n$ tar -zxf zookeeper-3.4.13.tar.gz\n$ cd zookeeper-3.4.13\n$ mkdir data\n```\n\n### 配置\n```\ntickTime = 2000\ndataDir = /Library/zookeeper-3.4.13/data\nclientPort = 2181\ninitLimit = 5\nsyncLimit = 2\n```\n\n### 单机\n\n### 集群\n\n\n\n---\n\n\n\n\n---\n参考\n官网：https://zookeeper.apache.org/\nGithub：\n","slug":"ZooKeeper安装","published":1,"updated":"2021-06-30T02:33:24.729Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx70088r5p75ys04q1e","content":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《百度百科》</p>\n<span id=\"more\"></span>\n\n\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/\">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><pre><code>$ cd /Library\n$ tar -zxf zookeeper-3.4.13.tar.gz\n$ cd zookeeper-3.4.13\n$ mkdir data\n</code></pre>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><pre><code>tickTime = 2000\ndataDir = /Library/zookeeper-3.4.13/data\nclientPort = 2181\ninitLimit = 5\nsyncLimit = 2\n</code></pre>\n<h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><hr>\n<hr>\n<p>参考\n官网：<a href=\"https://zookeeper.apache.org/\">https://zookeeper.apache.org/</a>\nGithub：</p>\n","site":{"data":{}},"excerpt":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《百度百科》</p>","more":"<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><p>下载地址：<a href=\"https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/\">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/</a></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><pre><code>$ cd /Library\n$ tar -zxf zookeeper-3.4.13.tar.gz\n$ cd zookeeper-3.4.13\n$ mkdir data\n</code></pre>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><pre><code>tickTime = 2000\ndataDir = /Library/zookeeper-3.4.13/data\nclientPort = 2181\ninitLimit = 5\nsyncLimit = 2\n</code></pre>\n<h3 id=\"单机\"><a href=\"#单机\" class=\"headerlink\" title=\"单机\"></a>单机</h3><h3 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h3><hr>\n<hr>\n<p>参考\n官网：<a href=\"https://zookeeper.apache.org/\">https://zookeeper.apache.org/</a>\nGithub：</p>"},{"title":"iTerm2","date":"2012-07-15T02:00:00.000Z","_content":"\n> 摘要：记录汇总iTerm2配置、使用，方便后续查阅使用\n\niTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能。\n\n官网：https://www.iterm2.com/index.html\n\n![iTerm2](logo2x.jpg)\n\n---\n\n\n## 下载&安装\n下载地址：https://iterm2.com/downloads.html\n把`iTerm`移动到应用程序中\n\n## 配置\n- 设置`iTerm2`为默认终端\n![设置iTerm2为默认终端](Setting_Default_Term.png)\n点击【`iTerm2` - `Make iTerm2 Default Term`】\n\n- 设置 `Status Bar`\n![Status Bar配置](Status_bar.jpg)\n点击【`iTerm2` - `Preferences` - `Profiles` - `Session` - `configure Status Bar`】 移到`Active Components`, 也可以移出\n\n- 设置`Theme` & `Status bar location`\n![Theme设置](Appearance.jpg)\n点击【`iTerm2` - `Preferences` - `Appearance`】配置自己喜欢的`Theme` & `Status bar location`\n\n- 设置颜色\n![config](1543213263217.jpg)\n\n## 高级功能\n### Zsh\n\n一般终端默认的`Shell`都是`Bash`，但是`Zsh`的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等非常强大的功能。\n\n查看当前终端使用`Shell`类型\n```bash\necho $SHELL\n```\n\n查看当前系统有多少种`Shell`类型\n```bash\ncat /etc/shells\n```\n\n**Zsh安装&切换**\n- 先查看是否安装\n```bash\nzsh --version\n```\n\n- 安装（推荐）\n```bash\nbrew install zsh\n```\n- 更新\n```bash\nbrew upgrade zsh\n```\n\n- 切换zsh\n```bash\n# Recent Mac OS versions\nchsh -s /usr/local/bin/zsh\n# Mac OS High Sierra and before\nchsh -s /bin/zsh\n```\n\n\n### Oh My Zsh\n`Oh My Zsh`是一个令人愉快的开源社区驱动工具，用于管理您的 `Zsh` 配置。 它捆绑了数以千计的有用功能、助手、插件、主题和一些让人惊奇的东西：https://ohmyz.sh/\n\n#### 1、安装\n\nhttps://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\n\n安装有多种方式，随意用那种\n\n- curl 安装方式（推荐）\n```bash\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n```\n- wget 安装方式\n```bash\nsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"\n```\n\n- fetch 安装方式\n```bash\nsh -c \"$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n#### 2、配置\n\n##### 主题\n`Oh My Zsh` 默认自带了一些默认主题，存放在 `~/.oh-my-zsh/themes` 目录中。我们可以查看这些主题\n```bash\ncd ~/.oh-my-zsh/themes\nll\n```\n\n> `Oh My Zsh`的 GitHub Wiki 页面提供了主题列表：https://github.com/robbyrussell/oh-my-zsh/wiki/themes\n\n- 打开配置\n```bash\nsudo vim ~/.zshrc\n```\n- 配置主题：选择一个你喜欢的，我这里设置随机\n```bash\nZSH_THEME=\"random\"\n```\n- 修改生效\n```bash\nsource ~/.zshrc\n```\n\n##### 插件\n\n`Oh My Zsh`的 GitHub Wiki 页面提供了插件列表：https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins\n\n- 查看当前默认安装的插件\n```bash\ncat ~/.oh-my-zsh/plugins\n```\n- 查看当前安装的自定义插件\n```bash\ncat ~/.oh-my-zsh/custom/plugins\n```\n\n- 打开配置\n```bash\nsudo vim ~/.zshrc\n```\n\n- **git**：提供了许多别名和一些有用的功能\n```bash\nplugins=(git)\n```\n这个是装好`Oh My Zsh`就默认已经开启的，可以查看所有的`git`命令`alias`\n```bash\ncat ~/.oh-my-zsh/plugins/git/git.plugin.zsh\n```\n> git plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git\n\n\n- **自动提示**\n```bash\n# 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n```\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    zsh-autosuggestions\n)\n```\n> Zsh自动提示 plugins: https://github.com/zsh-users/zsh-autosuggestions\n\n- **高亮**\n```bash\n# 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n```\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    zsh-syntax-highlighting\n)\n```\n> Zsh高亮 plugins: https://github.com/zsh-users/zsh-syntax-highlighting\n\n\n- **vscode**\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    vscode\n)\n```\n这个是装好`Oh My Zsh`就默认安装了`vscode plugins`，只需要配置\n> vscode plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode\n\n- **sublime**\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    sublime\n)\n```\n这个是装好`Oh My Zsh`就默认安装了`sublime plugins`，只需要配置\n> sublime plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime\n\n\n\n#### 3、卸载\n如果想卸载 `Oh My Zsh`,执行下面命令\n```bash\nuninstall_oh_my_zsh\n```\n\n\n### Powerline 字体\n`Zsh`有些字体乱码，主题需要 `Powerline` 字体，Github：https://github.com/powerline/fonts\n- **1、安装**\n```bash\n# clone\ngit clone https://github.com/powerline/fonts.git --depth=1\n# install\ncd fonts\n./install.sh\n# clean-up a bit\ncd ..\nrm -rf fonts\n```\n- **2、配置**\n![配置](1543202719106.jpg)\n\n\n\n---\n## 参考\n- iterm2-官网：https://www.iterm2.com/index.html\n- oh-my-zsh：https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH","source":"_posts/iTerm2.md","raw":"---\ntitle: iTerm2\ndate: 2012-07-15 10:00:00\ncategories: \n    - [Mac]\n    - [iTerm2]\ntags:\n    - Mac\n    - Iterm2\n---\n\n> 摘要：记录汇总iTerm2配置、使用，方便后续查阅使用\n\niTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能。\n\n官网：https://www.iterm2.com/index.html\n\n![iTerm2](logo2x.jpg)\n\n---\n\n\n## 下载&安装\n下载地址：https://iterm2.com/downloads.html\n把`iTerm`移动到应用程序中\n\n## 配置\n- 设置`iTerm2`为默认终端\n![设置iTerm2为默认终端](Setting_Default_Term.png)\n点击【`iTerm2` - `Make iTerm2 Default Term`】\n\n- 设置 `Status Bar`\n![Status Bar配置](Status_bar.jpg)\n点击【`iTerm2` - `Preferences` - `Profiles` - `Session` - `configure Status Bar`】 移到`Active Components`, 也可以移出\n\n- 设置`Theme` & `Status bar location`\n![Theme设置](Appearance.jpg)\n点击【`iTerm2` - `Preferences` - `Appearance`】配置自己喜欢的`Theme` & `Status bar location`\n\n- 设置颜色\n![config](1543213263217.jpg)\n\n## 高级功能\n### Zsh\n\n一般终端默认的`Shell`都是`Bash`，但是`Zsh`的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等非常强大的功能。\n\n查看当前终端使用`Shell`类型\n```bash\necho $SHELL\n```\n\n查看当前系统有多少种`Shell`类型\n```bash\ncat /etc/shells\n```\n\n**Zsh安装&切换**\n- 先查看是否安装\n```bash\nzsh --version\n```\n\n- 安装（推荐）\n```bash\nbrew install zsh\n```\n- 更新\n```bash\nbrew upgrade zsh\n```\n\n- 切换zsh\n```bash\n# Recent Mac OS versions\nchsh -s /usr/local/bin/zsh\n# Mac OS High Sierra and before\nchsh -s /bin/zsh\n```\n\n\n### Oh My Zsh\n`Oh My Zsh`是一个令人愉快的开源社区驱动工具，用于管理您的 `Zsh` 配置。 它捆绑了数以千计的有用功能、助手、插件、主题和一些让人惊奇的东西：https://ohmyz.sh/\n\n#### 1、安装\n\nhttps://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\n\n安装有多种方式，随意用那种\n\n- curl 安装方式（推荐）\n```bash\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n```\n- wget 安装方式\n```bash\nsh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\"\n```\n\n- fetch 安装方式\n```bash\nsh -c \"$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\n#### 2、配置\n\n##### 主题\n`Oh My Zsh` 默认自带了一些默认主题，存放在 `~/.oh-my-zsh/themes` 目录中。我们可以查看这些主题\n```bash\ncd ~/.oh-my-zsh/themes\nll\n```\n\n> `Oh My Zsh`的 GitHub Wiki 页面提供了主题列表：https://github.com/robbyrussell/oh-my-zsh/wiki/themes\n\n- 打开配置\n```bash\nsudo vim ~/.zshrc\n```\n- 配置主题：选择一个你喜欢的，我这里设置随机\n```bash\nZSH_THEME=\"random\"\n```\n- 修改生效\n```bash\nsource ~/.zshrc\n```\n\n##### 插件\n\n`Oh My Zsh`的 GitHub Wiki 页面提供了插件列表：https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins\n\n- 查看当前默认安装的插件\n```bash\ncat ~/.oh-my-zsh/plugins\n```\n- 查看当前安装的自定义插件\n```bash\ncat ~/.oh-my-zsh/custom/plugins\n```\n\n- 打开配置\n```bash\nsudo vim ~/.zshrc\n```\n\n- **git**：提供了许多别名和一些有用的功能\n```bash\nplugins=(git)\n```\n这个是装好`Oh My Zsh`就默认已经开启的，可以查看所有的`git`命令`alias`\n```bash\ncat ~/.oh-my-zsh/plugins/git/git.plugin.zsh\n```\n> git plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git\n\n\n- **自动提示**\n```bash\n# 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n```\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    zsh-autosuggestions\n)\n```\n> Zsh自动提示 plugins: https://github.com/zsh-users/zsh-autosuggestions\n\n- **高亮**\n```bash\n# 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n```\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    zsh-syntax-highlighting\n)\n```\n> Zsh高亮 plugins: https://github.com/zsh-users/zsh-syntax-highlighting\n\n\n- **vscode**\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    vscode\n)\n```\n这个是装好`Oh My Zsh`就默认安装了`vscode plugins`，只需要配置\n> vscode plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode\n\n- **sublime**\n```bash\n# 插件配置\nplugins=( \n    # other plugins...\n    sublime\n)\n```\n这个是装好`Oh My Zsh`就默认安装了`sublime plugins`，只需要配置\n> sublime plugins: https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime\n\n\n\n#### 3、卸载\n如果想卸载 `Oh My Zsh`,执行下面命令\n```bash\nuninstall_oh_my_zsh\n```\n\n\n### Powerline 字体\n`Zsh`有些字体乱码，主题需要 `Powerline` 字体，Github：https://github.com/powerline/fonts\n- **1、安装**\n```bash\n# clone\ngit clone https://github.com/powerline/fonts.git --depth=1\n# install\ncd fonts\n./install.sh\n# clean-up a bit\ncd ..\nrm -rf fonts\n```\n- **2、配置**\n![配置](1543202719106.jpg)\n\n\n\n---\n## 参考\n- iterm2-官网：https://www.iterm2.com/index.html\n- oh-my-zsh：https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH","slug":"iTerm2","published":1,"updated":"2021-07-18T03:35:49.985Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsx8008cr5p7285l76as","content":"<blockquote>\n<p>摘要：记录汇总iTerm2配置、使用，方便后续查阅使用</p>\n</blockquote>\n<p>iTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能。</p>\n<p>官网：<a href=\"https://www.iterm2.com/index.html\">https://www.iterm2.com/index.html</a></p>\n<p><img src=\"logo2x.jpg\" alt=\"iTerm2\"></p>\n<hr>\n<h2 id=\"下载-amp-安装\"><a href=\"#下载-amp-安装\" class=\"headerlink\" title=\"下载&amp;安装\"></a>下载&amp;安装</h2><p>下载地址：<a href=\"https://iterm2.com/downloads.html\">https://iterm2.com/downloads.html</a>\n把<code>iTerm</code>移动到应用程序中</p>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><ul>\n<li><p>设置<code>iTerm2</code>为默认终端\n<img src=\"Setting_Default_Term.png\" alt=\"设置iTerm2为默认终端\">\n点击【<code>iTerm2</code> - <code>Make iTerm2 Default Term</code>】</p>\n</li>\n<li><p>设置 <code>Status Bar</code>\n<img src=\"Status_bar.jpg\" alt=\"Status Bar配置\">\n点击【<code>iTerm2</code> - <code>Preferences</code> - <code>Profiles</code> - <code>Session</code> - <code>configure Status Bar</code>】 移到<code>Active Components</code>, 也可以移出</p>\n</li>\n<li><p>设置<code>Theme</code> &amp; <code>Status bar location</code>\n<img src=\"Appearance.jpg\" alt=\"Theme设置\">\n点击【<code>iTerm2</code> - <code>Preferences</code> - <code>Appearance</code>】配置自己喜欢的<code>Theme</code> &amp; <code>Status bar location</code></p>\n</li>\n<li><p>设置颜色\n<img src=\"1543213263217.jpg\" alt=\"config\"></p>\n</li>\n</ul>\n<h2 id=\"高级功能\"><a href=\"#高级功能\" class=\"headerlink\" title=\"高级功能\"></a>高级功能</h2><h3 id=\"Zsh\"><a href=\"#Zsh\" class=\"headerlink\" title=\"Zsh\"></a>Zsh</h3><p>一般终端默认的<code>Shell</code>都是<code>Bash</code>，但是<code>Zsh</code>的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等非常强大的功能。</p>\n<p>查看当前终端使用<code>Shell</code>类型</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token keyword\">echo</span> <span class=\"token variable\">$SHELL</span>\n</code></pre>\n<p>查看当前系统有多少种<code>Shell</code>类型</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> /etc/shells\n</code></pre>\n<p><strong>Zsh安装&amp;切换</strong></p>\n<ul>\n<li><p>先查看是否安装</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">zsh --version\n</code></pre>\n</li>\n<li><p>安装（推荐）</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> zsh\n</code></pre>\n</li>\n<li><p>更新</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew upgrade zsh\n</code></pre>\n</li>\n<li><p>切换zsh</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># Recent Mac OS versions</span>\nchsh -s /usr/local/bin/zsh\n<span class=\"token comment\" spellcheck=\"true\"># Mac OS High Sierra and before</span>\nchsh -s /bin/zsh\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Oh-My-Zsh\"><a href=\"#Oh-My-Zsh\" class=\"headerlink\" title=\"Oh My Zsh\"></a>Oh My Zsh</h3><p><code>Oh My Zsh</code>是一个令人愉快的开源社区驱动工具，用于管理您的 <code>Zsh</code> 配置。 它捆绑了数以千计的有用功能、助手、插件、主题和一些让人惊奇的东西：<a href=\"https://ohmyz.sh/\">https://ohmyz.sh/</a></p>\n<h4 id=\"1、安装\"><a href=\"#1、安装\" class=\"headerlink\" title=\"1、安装\"></a>1、安装</h4><p><a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\">https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH</a></p>\n<p>安装有多种方式，随意用那种</p>\n<ul>\n<li><p>curl 安装方式（推荐）</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">sh -c <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span>curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh<span class=\"token variable\">)</span></span>\"</span>\n</code></pre>\n</li>\n<li><p>wget 安装方式</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">sh -c <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">wget</span> https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -<span class=\"token variable\">)</span></span>\"</span>\n</code></pre>\n</li>\n<li><p>fetch 安装方式</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">sh -c <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span>fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh<span class=\"token variable\">)</span></span>\"</span>\n</code></pre>\n</li>\n</ul>\n<h4 id=\"2、配置\"><a href=\"#2、配置\" class=\"headerlink\" title=\"2、配置\"></a>2、配置</h4><h5 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h5><p><code>Oh My Zsh</code> 默认自带了一些默认主题，存放在 <code>~/.oh-my-zsh/themes</code> 目录中。我们可以查看这些主题</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cd</span> ~/.oh-my-zsh/themes\nll\n</code></pre>\n<blockquote>\n<p><code>Oh My Zsh</code>的 GitHub Wiki 页面提供了主题列表：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/themes\">https://github.com/robbyrussell/oh-my-zsh/wiki/themes</a></p>\n</blockquote>\n<ul>\n<li>打开配置<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> vim ~/.zshrc\n</code></pre>\n</li>\n<li>配置主题：选择一个你喜欢的，我这里设置随机<pre class=\" language-bash\"><code class=\"language-bash\">ZSH_THEME<span class=\"token operator\">=</span><span class=\"token string\">\"random\"</span>\n</code></pre>\n</li>\n<li>修改生效<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">source</span> ~/.zshrc\n</code></pre>\n</li>\n</ul>\n<h5 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h5><p><code>Oh My Zsh</code>的 GitHub Wiki 页面提供了插件列表：<a href=\"https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins\">https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins</a></p>\n<ul>\n<li><p>查看当前默认安装的插件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> ~/.oh-my-zsh/plugins\n</code></pre>\n</li>\n<li><p>查看当前安装的自定义插件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> ~/.oh-my-zsh/custom/plugins\n</code></pre>\n</li>\n<li><p>打开配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> vim ~/.zshrc\n</code></pre>\n</li>\n<li><p><strong>git</strong>：提供了许多别名和一些有用的功能</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">plugins<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>git<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认已经开启的，可以查看所有的<code>git</code>命令<code>alias</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> ~/.oh-my-zsh/plugins/git/git.plugin.zsh\n</code></pre>\n<blockquote>\n<p>git plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git</a></p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li><p><strong>自动提示</strong></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 安装插件(安装在自定义插件目录下面)</span>\n<span class=\"token function\">git</span> clone https://github.com/zsh-users/zsh-autosuggestions <span class=\"token variable\">${ZSH_CUSTOM:-~/.oh-my-zsh/custom}</span>/plugins/zsh-autosuggestions\n</code></pre>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 插件配置</span>\nplugins<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span> \n  <span class=\"token comment\" spellcheck=\"true\"># other plugins...</span>\n  zsh-autosuggestions\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<blockquote>\n<p>Zsh自动提示 plugins: <a href=\"https://github.com/zsh-users/zsh-autosuggestions\">https://github.com/zsh-users/zsh-autosuggestions</a></p>\n</blockquote>\n</li>\n<li><p><strong>高亮</strong></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 安装插件(安装在自定义插件目录下面)</span>\n<span class=\"token function\">git</span> clone https://github.com/zsh-users/zsh-syntax-highlighting.git <span class=\"token variable\">${ZSH_CUSTOM:-~/.oh-my-zsh/custom}</span>/plugins/zsh-syntax-highlighting\n</code></pre>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 插件配置</span>\nplugins<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span> \n  <span class=\"token comment\" spellcheck=\"true\"># other plugins...</span>\n  zsh-syntax-highlighting\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<blockquote>\n<p>Zsh高亮 plugins: <a href=\"https://github.com/zsh-users/zsh-syntax-highlighting\">https://github.com/zsh-users/zsh-syntax-highlighting</a></p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li><p><strong>vscode</strong></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 插件配置</span>\nplugins<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span> \n  <span class=\"token comment\" spellcheck=\"true\"># other plugins...</span>\n  vscode\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认安装了<code>vscode plugins</code>，只需要配置</p>\n<blockquote>\n<p>vscode plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode</a></p>\n</blockquote>\n</li>\n<li><p><strong>sublime</strong></p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 插件配置</span>\nplugins<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span> \n  <span class=\"token comment\" spellcheck=\"true\"># other plugins...</span>\n  sublime\n<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认安装了<code>sublime plugins</code>，只需要配置</p>\n<blockquote>\n<p>sublime plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime</a></p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"3、卸载\"><a href=\"#3、卸载\" class=\"headerlink\" title=\"3、卸载\"></a>3、卸载</h4><p>如果想卸载 <code>Oh My Zsh</code>,执行下面命令</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">uninstall_oh_my_zsh\n</code></pre>\n<h3 id=\"Powerline-字体\"><a href=\"#Powerline-字体\" class=\"headerlink\" title=\"Powerline 字体\"></a>Powerline 字体</h3><p><code>Zsh</code>有些字体乱码，主题需要 <code>Powerline</code> 字体，Github：<a href=\"https://github.com/powerline/fonts\">https://github.com/powerline/fonts</a></p>\n<ul>\n<li><strong>1、安装</strong><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># clone</span>\n<span class=\"token function\">git</span> clone https://github.com/powerline/fonts.git --depth<span class=\"token operator\">=</span>1\n<span class=\"token comment\" spellcheck=\"true\"># install</span>\n<span class=\"token function\">cd</span> fonts\n./install.sh\n<span class=\"token comment\" spellcheck=\"true\"># clean-up a bit</span>\n<span class=\"token function\">cd</span> <span class=\"token punctuation\">..</span>\n<span class=\"token function\">rm</span> -rf fonts\n</code></pre>\n</li>\n<li><strong>2、配置</strong>\n<img src=\"1543202719106.jpg\" alt=\"配置\"></li>\n</ul>\n<hr>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>iterm2-官网：<a href=\"https://www.iterm2.com/index.html\">https://www.iterm2.com/index.html</a></li>\n<li>oh-my-zsh：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\">https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：记录汇总iTerm2配置、使用，方便后续查阅使用</p>\n</blockquote>\n<p>iTerm2 是 Terminal 的替代品，也是 iTerm 的继承者。 它适用于装有 macOS 10.14 或更新版本的 Mac。 iTerm2 将终端带入现代，具有您从未想过的功能。</p>\n<p>官网：<a href=\"https://www.iterm2.com/index.html\">https://www.iterm2.com/index.html</a></p>\n<p><img src=\"logo2x.jpg\" alt=\"iTerm2\"></p>\n<hr>\n<h2 id=\"下载-amp-安装\"><a href=\"#下载-amp-安装\" class=\"headerlink\" title=\"下载&amp;安装\"></a>下载&amp;安装</h2><p>下载地址：<a href=\"https://iterm2.com/downloads.html\">https://iterm2.com/downloads.html</a>\n把<code>iTerm</code>移动到应用程序中</p>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><ul>\n<li><p>设置<code>iTerm2</code>为默认终端\n<img src=\"Setting_Default_Term.png\" alt=\"设置iTerm2为默认终端\">\n点击【<code>iTerm2</code> - <code>Make iTerm2 Default Term</code>】</p>\n</li>\n<li><p>设置 <code>Status Bar</code>\n<img src=\"Status_bar.jpg\" alt=\"Status Bar配置\">\n点击【<code>iTerm2</code> - <code>Preferences</code> - <code>Profiles</code> - <code>Session</code> - <code>configure Status Bar</code>】 移到<code>Active Components</code>, 也可以移出</p>\n</li>\n<li><p>设置<code>Theme</code> &amp; <code>Status bar location</code>\n<img src=\"Appearance.jpg\" alt=\"Theme设置\">\n点击【<code>iTerm2</code> - <code>Preferences</code> - <code>Appearance</code>】配置自己喜欢的<code>Theme</code> &amp; <code>Status bar location</code></p>\n</li>\n<li><p>设置颜色\n<img src=\"1543213263217.jpg\" alt=\"config\"></p>\n</li>\n</ul>\n<h2 id=\"高级功能\"><a href=\"#高级功能\" class=\"headerlink\" title=\"高级功能\"></a>高级功能</h2><h3 id=\"Zsh\"><a href=\"#Zsh\" class=\"headerlink\" title=\"Zsh\"></a>Zsh</h3><p>一般终端默认的<code>Shell</code>都是<code>Bash</code>，但是<code>Zsh</code>的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等非常强大的功能。</p>\n<p>查看当前终端使用<code>Shell</code>类型</p>\n<pre><code class=\"bash\">echo $SHELL\n</code></pre>\n<p>查看当前系统有多少种<code>Shell</code>类型</p>\n<pre><code class=\"bash\">cat /etc/shells\n</code></pre>\n<p><strong>Zsh安装&amp;切换</strong></p>\n<ul>\n<li><p>先查看是否安装</p>\n<pre><code class=\"bash\">zsh --version\n</code></pre>\n</li>\n<li><p>安装（推荐）</p>\n<pre><code class=\"bash\">brew install zsh\n</code></pre>\n</li>\n<li><p>更新</p>\n<pre><code class=\"bash\">brew upgrade zsh\n</code></pre>\n</li>\n<li><p>切换zsh</p>\n<pre><code class=\"bash\"># Recent Mac OS versions\nchsh -s /usr/local/bin/zsh\n# Mac OS High Sierra and before\nchsh -s /bin/zsh\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Oh-My-Zsh\"><a href=\"#Oh-My-Zsh\" class=\"headerlink\" title=\"Oh My Zsh\"></a>Oh My Zsh</h3><p><code>Oh My Zsh</code>是一个令人愉快的开源社区驱动工具，用于管理您的 <code>Zsh</code> 配置。 它捆绑了数以千计的有用功能、助手、插件、主题和一些让人惊奇的东西：<a href=\"https://ohmyz.sh/\">https://ohmyz.sh/</a></p>\n<h4 id=\"1、安装\"><a href=\"#1、安装\" class=\"headerlink\" title=\"1、安装\"></a>1、安装</h4><p><a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\">https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH</a></p>\n<p>安装有多种方式，随意用那种</p>\n<ul>\n<li><p>curl 安装方式（推荐）</p>\n<pre><code class=\"bash\">sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;\n</code></pre>\n</li>\n<li><p>wget 安装方式</p>\n<pre><code class=\"bash\">sh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot;\n</code></pre>\n</li>\n<li><p>fetch 安装方式</p>\n<pre><code class=\"bash\">sh -c &quot;$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;\n</code></pre>\n</li>\n</ul>\n<h4 id=\"2、配置\"><a href=\"#2、配置\" class=\"headerlink\" title=\"2、配置\"></a>2、配置</h4><h5 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h5><p><code>Oh My Zsh</code> 默认自带了一些默认主题，存放在 <code>~/.oh-my-zsh/themes</code> 目录中。我们可以查看这些主题</p>\n<pre><code class=\"bash\">cd ~/.oh-my-zsh/themes\nll\n</code></pre>\n<blockquote>\n<p><code>Oh My Zsh</code>的 GitHub Wiki 页面提供了主题列表：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/themes\">https://github.com/robbyrussell/oh-my-zsh/wiki/themes</a></p>\n</blockquote>\n<ul>\n<li>打开配置<pre><code class=\"bash\">sudo vim ~/.zshrc\n</code></pre>\n</li>\n<li>配置主题：选择一个你喜欢的，我这里设置随机<pre><code class=\"bash\">ZSH_THEME=&quot;random&quot;\n</code></pre>\n</li>\n<li>修改生效<pre><code class=\"bash\">source ~/.zshrc\n</code></pre>\n</li>\n</ul>\n<h5 id=\"插件\"><a href=\"#插件\" class=\"headerlink\" title=\"插件\"></a>插件</h5><p><code>Oh My Zsh</code>的 GitHub Wiki 页面提供了插件列表：<a href=\"https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins\">https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins</a></p>\n<ul>\n<li><p>查看当前默认安装的插件</p>\n<pre><code class=\"bash\">cat ~/.oh-my-zsh/plugins\n</code></pre>\n</li>\n<li><p>查看当前安装的自定义插件</p>\n<pre><code class=\"bash\">cat ~/.oh-my-zsh/custom/plugins\n</code></pre>\n</li>\n<li><p>打开配置</p>\n<pre><code class=\"bash\">sudo vim ~/.zshrc\n</code></pre>\n</li>\n<li><p><strong>git</strong>：提供了许多别名和一些有用的功能</p>\n<pre><code class=\"bash\">plugins=(git)\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认已经开启的，可以查看所有的<code>git</code>命令<code>alias</code></p>\n<pre><code class=\"bash\">cat ~/.oh-my-zsh/plugins/git/git.plugin.zsh\n</code></pre>\n<blockquote>\n<p>git plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git</a></p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li><p><strong>自动提示</strong></p>\n<pre><code class=\"bash\"># 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions\n</code></pre>\n<pre><code class=\"bash\"># 插件配置\nplugins=( \n  # other plugins...\n  zsh-autosuggestions\n)\n</code></pre>\n<blockquote>\n<p>Zsh自动提示 plugins: <a href=\"https://github.com/zsh-users/zsh-autosuggestions\">https://github.com/zsh-users/zsh-autosuggestions</a></p>\n</blockquote>\n</li>\n<li><p><strong>高亮</strong></p>\n<pre><code class=\"bash\"># 安装插件(安装在自定义插件目录下面)\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting\n</code></pre>\n<pre><code class=\"bash\"># 插件配置\nplugins=( \n  # other plugins...\n  zsh-syntax-highlighting\n)\n</code></pre>\n<blockquote>\n<p>Zsh高亮 plugins: <a href=\"https://github.com/zsh-users/zsh-syntax-highlighting\">https://github.com/zsh-users/zsh-syntax-highlighting</a></p>\n</blockquote>\n</li>\n</ul>\n<ul>\n<li><p><strong>vscode</strong></p>\n<pre><code class=\"bash\"># 插件配置\nplugins=( \n  # other plugins...\n  vscode\n)\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认安装了<code>vscode plugins</code>，只需要配置</p>\n<blockquote>\n<p>vscode plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode</a></p>\n</blockquote>\n</li>\n<li><p><strong>sublime</strong></p>\n<pre><code class=\"bash\"># 插件配置\nplugins=( \n  # other plugins...\n  sublime\n)\n</code></pre>\n<p>这个是装好<code>Oh My Zsh</code>就默认安装了<code>sublime plugins</code>，只需要配置</p>\n<blockquote>\n<p>sublime plugins: <a href=\"https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime\">https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sublime</a></p>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"3、卸载\"><a href=\"#3、卸载\" class=\"headerlink\" title=\"3、卸载\"></a>3、卸载</h4><p>如果想卸载 <code>Oh My Zsh</code>,执行下面命令</p>\n<pre><code class=\"bash\">uninstall_oh_my_zsh\n</code></pre>\n<h3 id=\"Powerline-字体\"><a href=\"#Powerline-字体\" class=\"headerlink\" title=\"Powerline 字体\"></a>Powerline 字体</h3><p><code>Zsh</code>有些字体乱码，主题需要 <code>Powerline</code> 字体，Github：<a href=\"https://github.com/powerline/fonts\">https://github.com/powerline/fonts</a></p>\n<ul>\n<li><strong>1、安装</strong><pre><code class=\"bash\"># clone\ngit clone https://github.com/powerline/fonts.git --depth=1\n# install\ncd fonts\n./install.sh\n# clean-up a bit\ncd ..\nrm -rf fonts\n</code></pre>\n</li>\n<li><strong>2、配置</strong>\n<img src=\"1543202719106.jpg\" alt=\"配置\"></li>\n</ul>\n<hr>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>iterm2-官网：<a href=\"https://www.iterm2.com/index.html\">https://www.iterm2.com/index.html</a></li>\n<li>oh-my-zsh：<a href=\"https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH\">https://github.com/robbyrussell/oh-my-zsh/wiki/Installing-ZSH</a></li>\n</ul>\n"},{"title":"Mac 使用rz、sz 远程上传、下载文件","date":"2015-08-30T02:00:00.000Z","_content":"\n> 摘要：记录`lrzsz`配置、使用，方便后续使用查阅\n\n`lrzsz`是一款在linux里可代替ftp上传和下载的程序。通过它来使用rz，sz\n\n## 安装\n\n- 检查是否安装\n```bash\nrz --version\nsz --version\n```\n\n- 安装\n```bash\nbrew install lrzsz\n```\n\n\n## 与iTerm2结合\n\n- 安装automatic zmoderm\n```bash\n# 切换到 /usr/local/bin 目录\ncd /usr/local/bin\n## 如果没有安装 wget：brew install wget\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-send-zmodem.sh\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-recv-zmodem.sh\n# 授权\nchmod +x /usr/local/bin/iterm2-send-zmodem.sh\nchmod +x /usr/local/bin/iterm2-recv-zmodem.sh\n```\n\n- 配置iTerm2 trigger\n\n`iTerm2` --> `Profiles` --> `Open Profiles` --> `Edit Profiles`--> `Advanced` --> `Edit Trigger`\n\n```bash\nRegular expression      　　Action      　　　　　　　Parameters\n\n\\*\\*B0100　　　　　　　　Run Silent Coprocess　　/usr/local/bin/iterm2-send-zmodem.sh\n\\*\\*B00000000000000　  Run Silent Coprocess　　/usr/local/bin/iterm2-recv-zmodem.sh\n```\n\n![配置图片](122150034707951.png)\n\n\n> 最后 iTerm2 重启","source":"_posts/lrzsz.md","raw":"---\ntitle: Mac 使用rz、sz 远程上传、下载文件\ndate: 2015-08-30 10:00\ncategories: \n    - [Mac]\n    - [rz]\n    - [sz]\ntags:\n    - Mac\n    - rz\n    - sz\n---\n\n> 摘要：记录`lrzsz`配置、使用，方便后续使用查阅\n\n`lrzsz`是一款在linux里可代替ftp上传和下载的程序。通过它来使用rz，sz\n\n## 安装\n\n- 检查是否安装\n```bash\nrz --version\nsz --version\n```\n\n- 安装\n```bash\nbrew install lrzsz\n```\n\n\n## 与iTerm2结合\n\n- 安装automatic zmoderm\n```bash\n# 切换到 /usr/local/bin 目录\ncd /usr/local/bin\n## 如果没有安装 wget：brew install wget\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-send-zmodem.sh\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-recv-zmodem.sh\n# 授权\nchmod +x /usr/local/bin/iterm2-send-zmodem.sh\nchmod +x /usr/local/bin/iterm2-recv-zmodem.sh\n```\n\n- 配置iTerm2 trigger\n\n`iTerm2` --> `Profiles` --> `Open Profiles` --> `Edit Profiles`--> `Advanced` --> `Edit Trigger`\n\n```bash\nRegular expression      　　Action      　　　　　　　Parameters\n\n\\*\\*B0100　　　　　　　　Run Silent Coprocess　　/usr/local/bin/iterm2-send-zmodem.sh\n\\*\\*B00000000000000　  Run Silent Coprocess　　/usr/local/bin/iterm2-recv-zmodem.sh\n```\n\n![配置图片](122150034707951.png)\n\n\n> 最后 iTerm2 重启","slug":"lrzsz","published":1,"updated":"2022-03-10T02:30:42.006Z","_id":"ckr8tjsx9008gr5p7ebje7rg5","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>摘要：记录<code>lrzsz</code>配置、使用，方便后续使用查阅</p>\n</blockquote>\n<p><code>lrzsz</code>是一款在linux里可代替ftp上传和下载的程序。通过它来使用rz，sz</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><ul>\n<li><p>检查是否安装</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">rz --version\nsz --version\n</code></pre>\n</li>\n<li><p>安装</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> lrzsz\n</code></pre>\n</li>\n</ul>\n<h2 id=\"与iTerm2结合\"><a href=\"#与iTerm2结合\" class=\"headerlink\" title=\"与iTerm2结合\"></a>与iTerm2结合</h2><ul>\n<li><p>安装automatic zmoderm</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 切换到 /usr/local/bin 目录</span>\n<span class=\"token function\">cd</span> /usr/local/bin\n<span class=\"token comment\" spellcheck=\"true\">## 如果没有安装 wget：brew install wget</span>\n<span class=\"token function\">wget</span> https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-send-zmodem.sh\n<span class=\"token function\">wget</span> https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-recv-zmodem.sh\n<span class=\"token comment\" spellcheck=\"true\"># 授权</span>\n<span class=\"token function\">chmod</span> +x /usr/local/bin/iterm2-send-zmodem.sh\n<span class=\"token function\">chmod</span> +x /usr/local/bin/iterm2-recv-zmodem.sh\n</code></pre>\n</li>\n<li><p>配置iTerm2 trigger</p>\n</li>\n</ul>\n<p><code>iTerm2</code> –&gt; <code>Profiles</code> –&gt; <code>Open Profiles</code> –&gt; <code>Edit Profiles</code>–&gt; <code>Advanced</code> –&gt; <code>Edit Trigger</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">Regular expression      　　Action      　　　　　　　Parameters\n\n\\*\\*B0100　　　　　　　　Run Silent Coprocess　　/usr/local/bin/iterm2-send-zmodem.sh\n\\*\\*B00000000000000　  Run Silent Coprocess　　/usr/local/bin/iterm2-recv-zmodem.sh\n</code></pre>\n<p><img src=\"122150034707951.png\" alt=\"配置图片\"></p>\n<blockquote>\n<p>最后 iTerm2 重启</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：记录<code>lrzsz</code>配置、使用，方便后续使用查阅</p>\n</blockquote>\n<p><code>lrzsz</code>是一款在linux里可代替ftp上传和下载的程序。通过它来使用rz，sz</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><ul>\n<li><p>检查是否安装</p>\n<pre><code class=\"bash\">rz --version\nsz --version\n</code></pre>\n</li>\n<li><p>安装</p>\n<pre><code class=\"bash\">brew install lrzsz\n</code></pre>\n</li>\n</ul>\n<h2 id=\"与iTerm2结合\"><a href=\"#与iTerm2结合\" class=\"headerlink\" title=\"与iTerm2结合\"></a>与iTerm2结合</h2><ul>\n<li><p>安装automatic zmoderm</p>\n<pre><code class=\"bash\"># 切换到 /usr/local/bin 目录\ncd /usr/local/bin\n## 如果没有安装 wget：brew install wget\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-send-zmodem.sh\nwget https://raw.githubusercontent.com/Gumihoy/iterm2-zmodem/master/iterm2-recv-zmodem.sh\n# 授权\nchmod +x /usr/local/bin/iterm2-send-zmodem.sh\nchmod +x /usr/local/bin/iterm2-recv-zmodem.sh\n</code></pre>\n</li>\n<li><p>配置iTerm2 trigger</p>\n</li>\n</ul>\n<p><code>iTerm2</code> –&gt; <code>Profiles</code> –&gt; <code>Open Profiles</code> –&gt; <code>Edit Profiles</code>–&gt; <code>Advanced</code> –&gt; <code>Edit Trigger</code></p>\n<pre><code class=\"bash\">Regular expression      　　Action      　　　　　　　Parameters\n\n\\*\\*B0100　　　　　　　　Run Silent Coprocess　　/usr/local/bin/iterm2-send-zmodem.sh\n\\*\\*B00000000000000　  Run Silent Coprocess　　/usr/local/bin/iterm2-recv-zmodem.sh\n</code></pre>\n<p><img src=\"122150034707951.png\" alt=\"配置图片\"></p>\n<blockquote>\n<p>最后 iTerm2 重启</p>\n</blockquote>\n"},{"title":"python教程","date":"2018-11-24T11:16:00.000Z","_content":"\nPython（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/），是一种动态的、面向对象的脚本语言。\n\n目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的，因为现在Python正在朝着3.x版本进化，本文基于python3\b。\n\n<!-- more -->\n---\n\n<br/>\n## 安装\n\n官网下载地址：https://www.python.org/downloads/\n\n#### MAC\n\n\n\n```bash\n# 先查看是否安装，如果显示版本号 表明已经安装: \npython3 --version\n```\n\n\n- 安装程序\n上面地址下载，双击运行并安装\n- 命令安装\n```\nbrew install python3\n```\n\n\n\n<br/>\n## 语法\n\n\n\n### \n\n\n<br/>\n\n---\n参考\n[官网](https://www.python.org/)","source":"_posts/python教程.md","raw":"---\ntitle: python教程\ndate: 2018-11-24 19:16:00\ncategories: \n    - Python\ntags:\n    - Python\n---\n\nPython（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/），是一种动态的、面向对象的脚本语言。\n\n目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的，因为现在Python正在朝着3.x版本进化，本文基于python3\b。\n\n<!-- more -->\n---\n\n<br/>\n## 安装\n\n官网下载地址：https://www.python.org/downloads/\n\n#### MAC\n\n\n\n```bash\n# 先查看是否安装，如果显示版本号 表明已经安装: \npython3 --version\n```\n\n\n- 安装程序\n上面地址下载，双击运行并安装\n- 命令安装\n```\nbrew install python3\n```\n\n\n\n<br/>\n## 语法\n\n\n\n### \n\n\n<br/>\n\n---\n参考\n[官网](https://www.python.org/)","slug":"python教程","published":1,"updated":"2021-06-30T02:33:24.771Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxa008kr5p70rz4hve7","content":"<p>Python（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/），是一种动态的、面向对象的脚本语言。</p>\n<p>目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的，因为现在Python正在朝着3.x版本进化，本文基于python3\b。</p>\n<span id=\"more\"></span>\n<hr>\n<br>\n## 安装\n\n<p>官网下载地址：<a href=\"https://www.python.org/downloads/\">https://www.python.org/downloads/</a></p>\n<h4 id=\"MAC\"><a href=\"#MAC\" class=\"headerlink\" title=\"MAC\"></a>MAC</h4><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 先查看是否安装，如果显示版本号 表明已经安装: </span>\npython3 --version\n</code></pre>\n<ul>\n<li>安装程序\n上面地址下载，双击运行并安装</li>\n<li>命令安装<pre><code>brew install python3\n</code></pre>\n</li>\n</ul>\n<br>\n## 语法\n\n\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><br>\n\n<hr>\n<p>参考\n<a href=\"https://www.python.org/\">官网</a></p>\n","site":{"data":{}},"excerpt":"<p>Python（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/），是一种动态的、面向对象的脚本语言。</p>\n<p>目前，Python有两个版本，一个是2.x版，一个是3.x版，这两个版本是不兼容的，因为现在Python正在朝着3.x版本进化，本文基于python3\b。</p>","more":"<hr>\n<br/>\n## 安装\n\n<p>官网下载地址：<a href=\"https://www.python.org/downloads/\">https://www.python.org/downloads/</a></p>\n<h4 id=\"MAC\"><a href=\"#MAC\" class=\"headerlink\" title=\"MAC\"></a>MAC</h4><pre><code class=\"bash\"># 先查看是否安装，如果显示版本号 表明已经安装: \npython3 --version\n</code></pre>\n<ul>\n<li>安装程序\n上面地址下载，双击运行并安装</li>\n<li>命令安装<pre><code>brew install python3\n</code></pre>\n</li>\n</ul>\n<br/>\n## 语法\n\n\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><br/>\n\n<hr>\n<p>参考\n<a href=\"https://www.python.org/\">官网</a></p>"},{"title":"tensorflow教程","date":"2018-11-22T09:42:36.000Z","_content":"\nTensorFlow™ 是一个开放源代码软件库，用于进行高性能数值计算。借助其灵活的架构，用户可以轻松地将计算工作部署到多种平台（CPU、GPU、TPU）和设备（桌面设备、服务器集群、移动设备、边缘设备等）。\nTensorFlow™ 最初是由 Google Brain 团队（隶属于 Google 的 AI 部门）中的研究人员和工程师开发的，可为机器学习和深度学习提供强力支持，并且其灵活的数值计算核心广泛应用于许多其他科学领域。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《tensorflow.google.cn》\n\n<!-- more -->\n\n\n![tensors_flowing](tensors_flowing.gif)\n<br/>\n\n## 安装\n官网：https://tensorflow.google.cn/install/\n\n现在tensorflow在以下系统进行测试和支持：\n- Ubuntu 16.04 or later\n- Windows 7 or later\n- macOS 10.12.6 (Sierra) or later (no GPU support)\n- Raspbian 9.0 or later\n\ntensorflow有多种安装方式:\n- [Pip 安装](https://tensorflow.google.cn/install/pip)\n- [Docker 安装](https://tensorflow.google.cn/install/docker)\n- [从源代码安装](https://tensorflow.google.cn/install/source)\n\n\n本教程使用 pip 在MAC系统的安装方式：https://tensorflow.google.cn/install/pip\n\n<br/>\n### MacOS\n** 1、安装python、pip、virtualenv **\n\n`要求 Python 3.4, 3.5, or 3.6`\n\n```bash\npython3 --version\npip3 --version\nvirtualenv --version\n```\n\n```bash\n# 升级pip\nsudo python3 -m pip install -U pip\n\n# 安装virtualenv\nsudo pip3 install -U virtualenv  # system-wide install\n```\n\n** 2、安装 tensorflow（CPU 版） **\n`Tensorflow 已经不再支持 mac 的 GPU 版了`\n```\n# python 3+ 的用户:\n$ pip3 install --upgrade tensorflow\n\n# 删除tensorflow原有的版本\n$ pip3 uninstall tensorflow\n```\n\n** 3、验证Tensorflow是否安装成功 **\n在python编译器运行下面代码：\n```\nimport tensorflow as tf\nprint(tf.__version__)\n```\n\n\n<br/>\n## 教程\n\n\n\n\n\n<br/>\n\n---\n参考\n[tensorflow官网](https://tensorflow.google.cn/)\n[tensorflow官网例子](https://www.tensorflow.org/tutorials/)\nhttp://www.tensorfly.cn/tfdoc/get_started/introduction.html\nhttps://morvanzhou.github.io/tutorials/machine-learning/tensorflow\n","source":"_posts/tensorflow教程.md","raw":"---\ntitle: tensorflow教程\ndate: 2018-11-22 17:42:36\ncategories: \n    - Tensorflow\ntags:\n    - 机器学习\n    - 深度学习\n    - 深度学习框架\n    - Tensorflow\n---\n\nTensorFlow™ 是一个开放源代码软件库，用于进行高性能数值计算。借助其灵活的架构，用户可以轻松地将计算工作部署到多种平台（CPU、GPU、TPU）和设备（桌面设备、服务器集群、移动设备、边缘设备等）。\nTensorFlow™ 最初是由 Google Brain 团队（隶属于 Google 的 AI 部门）中的研究人员和工程师开发的，可为机器学习和深度学习提供强力支持，并且其灵活的数值计算核心广泛应用于许多其他科学领域。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《tensorflow.google.cn》\n\n<!-- more -->\n\n\n![tensors_flowing](tensors_flowing.gif)\n<br/>\n\n## 安装\n官网：https://tensorflow.google.cn/install/\n\n现在tensorflow在以下系统进行测试和支持：\n- Ubuntu 16.04 or later\n- Windows 7 or later\n- macOS 10.12.6 (Sierra) or later (no GPU support)\n- Raspbian 9.0 or later\n\ntensorflow有多种安装方式:\n- [Pip 安装](https://tensorflow.google.cn/install/pip)\n- [Docker 安装](https://tensorflow.google.cn/install/docker)\n- [从源代码安装](https://tensorflow.google.cn/install/source)\n\n\n本教程使用 pip 在MAC系统的安装方式：https://tensorflow.google.cn/install/pip\n\n<br/>\n### MacOS\n** 1、安装python、pip、virtualenv **\n\n`要求 Python 3.4, 3.5, or 3.6`\n\n```bash\npython3 --version\npip3 --version\nvirtualenv --version\n```\n\n```bash\n# 升级pip\nsudo python3 -m pip install -U pip\n\n# 安装virtualenv\nsudo pip3 install -U virtualenv  # system-wide install\n```\n\n** 2、安装 tensorflow（CPU 版） **\n`Tensorflow 已经不再支持 mac 的 GPU 版了`\n```\n# python 3+ 的用户:\n$ pip3 install --upgrade tensorflow\n\n# 删除tensorflow原有的版本\n$ pip3 uninstall tensorflow\n```\n\n** 3、验证Tensorflow是否安装成功 **\n在python编译器运行下面代码：\n```\nimport tensorflow as tf\nprint(tf.__version__)\n```\n\n\n<br/>\n## 教程\n\n\n\n\n\n<br/>\n\n---\n参考\n[tensorflow官网](https://tensorflow.google.cn/)\n[tensorflow官网例子](https://www.tensorflow.org/tutorials/)\nhttp://www.tensorfly.cn/tfdoc/get_started/introduction.html\nhttps://morvanzhou.github.io/tutorials/machine-learning/tensorflow\n","slug":"tensorflow教程","published":1,"updated":"2021-06-30T02:33:24.771Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxb008or5p7c9g737hs","content":"<p>TensorFlow™ 是一个开放源代码软件库，用于进行高性能数值计算。借助其灵活的架构，用户可以轻松地将计算工作部署到多种平台（CPU、GPU、TPU）和设备（桌面设备、服务器集群、移动设备、边缘设备等）。\nTensorFlow™ 最初是由 Google Brain 团队（隶属于 Google 的 AI 部门）中的研究人员和工程师开发的，可为机器学习和深度学习提供强力支持，并且其灵活的数值计算核心广泛应用于许多其他科学领域。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《tensorflow.google.cn》</p>\n<span id=\"more\"></span>\n\n\n<p><img src=\"tensors_flowing.gif\" alt=\"tensors_flowing\">\n<br></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>官网：<a href=\"https://tensorflow.google.cn/install/\">https://tensorflow.google.cn/install/</a></p>\n<p>现在tensorflow在以下系统进行测试和支持：</p>\n<ul>\n<li>Ubuntu 16.04 or later</li>\n<li>Windows 7 or later</li>\n<li>macOS 10.12.6 (Sierra) or later (no GPU support)</li>\n<li>Raspbian 9.0 or later</li>\n</ul>\n<p>tensorflow有多种安装方式:</p>\n<ul>\n<li><a href=\"https://tensorflow.google.cn/install/pip\">Pip 安装</a></li>\n<li><a href=\"https://tensorflow.google.cn/install/docker\">Docker 安装</a></li>\n<li><a href=\"https://tensorflow.google.cn/install/source\">从源代码安装</a></li>\n</ul>\n<p>本教程使用 pip 在MAC系统的安装方式：<a href=\"https://tensorflow.google.cn/install/pip\">https://tensorflow.google.cn/install/pip</a></p>\n<br>\n### MacOS\n** 1、安装python、pip、virtualenv **\n\n<p><code>要求 Python 3.4, 3.5, or 3.6</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">python3 --version\npip3 --version\nvirtualenv --version\n</code></pre>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 升级pip</span>\n<span class=\"token function\">sudo</span> python3 -m pip <span class=\"token function\">install</span> -U pip\n\n<span class=\"token comment\" spellcheck=\"true\"># 安装virtualenv</span>\n<span class=\"token function\">sudo</span> pip3 <span class=\"token function\">install</span> -U virtualenv  <span class=\"token comment\" spellcheck=\"true\"># system-wide install</span>\n</code></pre>\n<p>** 2、安装 tensorflow（CPU 版） **\n<code>Tensorflow 已经不再支持 mac 的 GPU 版了</code></p>\n<pre><code># python 3+ 的用户:\n$ pip3 install --upgrade tensorflow\n\n# 删除tensorflow原有的版本\n$ pip3 uninstall tensorflow\n</code></pre>\n<p>** 3、验证Tensorflow是否安装成功 **\n在python编译器运行下面代码：</p>\n<pre><code>import tensorflow as tf\nprint(tf.__version__)\n</code></pre>\n<br>\n## 教程\n\n\n\n\n\n<br>\n\n<hr>\n<p>参考\n<a href=\"https://tensorflow.google.cn/\">tensorflow官网</a>\n<a href=\"https://www.tensorflow.org/tutorials/\">tensorflow官网例子</a>\n<a href=\"http://www.tensorfly.cn/tfdoc/get_started/introduction.html\">http://www.tensorfly.cn/tfdoc/get_started/introduction.html</a>\n<a href=\"https://morvanzhou.github.io/tutorials/machine-learning/tensorflow\">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow</a></p>\n","site":{"data":{}},"excerpt":"<p>TensorFlow™ 是一个开放源代码软件库，用于进行高性能数值计算。借助其灵活的架构，用户可以轻松地将计算工作部署到多种平台（CPU、GPU、TPU）和设备（桌面设备、服务器集群、移动设备、边缘设备等）。\nTensorFlow™ 最初是由 Google Brain 团队（隶属于 Google 的 AI 部门）中的研究人员和工程师开发的，可为机器学习和深度学习提供强力支持，并且其灵活的数值计算核心广泛应用于许多其他科学领域。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《tensorflow.google.cn》</p>","more":"<p><img src=\"tensors_flowing.gif\" alt=\"tensors_flowing\">\n<br/></p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>官网：<a href=\"https://tensorflow.google.cn/install/\">https://tensorflow.google.cn/install/</a></p>\n<p>现在tensorflow在以下系统进行测试和支持：</p>\n<ul>\n<li>Ubuntu 16.04 or later</li>\n<li>Windows 7 or later</li>\n<li>macOS 10.12.6 (Sierra) or later (no GPU support)</li>\n<li>Raspbian 9.0 or later</li>\n</ul>\n<p>tensorflow有多种安装方式:</p>\n<ul>\n<li><a href=\"https://tensorflow.google.cn/install/pip\">Pip 安装</a></li>\n<li><a href=\"https://tensorflow.google.cn/install/docker\">Docker 安装</a></li>\n<li><a href=\"https://tensorflow.google.cn/install/source\">从源代码安装</a></li>\n</ul>\n<p>本教程使用 pip 在MAC系统的安装方式：<a href=\"https://tensorflow.google.cn/install/pip\">https://tensorflow.google.cn/install/pip</a></p>\n<br/>\n### MacOS\n** 1、安装python、pip、virtualenv **\n\n<p><code>要求 Python 3.4, 3.5, or 3.6</code></p>\n<pre><code class=\"bash\">python3 --version\npip3 --version\nvirtualenv --version\n</code></pre>\n<pre><code class=\"bash\"># 升级pip\nsudo python3 -m pip install -U pip\n\n# 安装virtualenv\nsudo pip3 install -U virtualenv  # system-wide install\n</code></pre>\n<p>** 2、安装 tensorflow（CPU 版） **\n<code>Tensorflow 已经不再支持 mac 的 GPU 版了</code></p>\n<pre><code># python 3+ 的用户:\n$ pip3 install --upgrade tensorflow\n\n# 删除tensorflow原有的版本\n$ pip3 uninstall tensorflow\n</code></pre>\n<p>** 3、验证Tensorflow是否安装成功 **\n在python编译器运行下面代码：</p>\n<pre><code>import tensorflow as tf\nprint(tf.__version__)\n</code></pre>\n<br/>\n## 教程\n\n\n\n\n\n<br/>\n\n<hr>\n<p>参考\n<a href=\"https://tensorflow.google.cn/\">tensorflow官网</a>\n<a href=\"https://www.tensorflow.org/tutorials/\">tensorflow官网例子</a>\n<a href=\"http://www.tensorfly.cn/tfdoc/get_started/introduction.html\">http://www.tensorfly.cn/tfdoc/get_started/introduction.html</a>\n<a href=\"https://morvanzhou.github.io/tutorials/machine-learning/tensorflow\">https://morvanzhou.github.io/tutorials/machine-learning/tensorflow</a></p>"},{"title":"thrift教程","date":"2018-11-23T09:32:06.000Z","_content":"\n Apache Thrift 采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《thrift.apache.org》\n<!-- more -->\n\n---\n\n<br/>\n### 介绍\nThrift通过IDL（Interface Definition Language，接口定义语言）来定义RPC（Remote Procedure Call，远程过程调用）的接口和数据类型，然后通过thrift编译器生成不同语言的代码，并由生成的代码负责RPC协议层和传输层的实现。\n\n\n![thrift-layers](thrift-layers.png)\n\n<br/>\n### 安装\n现下载：https://thrift.apache.org/download\n官网安装：https://thrift.apache.org/docs/install/\n\n<br/>\n#### 快速安装\n\n```bash\n# 安装命令\nbrew install thrift\n# 卸载命令\nbrew uninstall thrift\n```\n\n<br/>\n#### 源安装\n\n** 1、Install Boost **\nBoost 下载地址：https://www.boost.org/\n```bash\n./bootstrap.sh\nsudo ./b2 threading=multi address-model=64 variant=release stage install\n```\n\n** 2、Install libevent **\nlibevent 下载地址：http://libevent.org/\n```bash\n./configure --prefix=/usr/local\nmake\nsudo make install\n```\n\n** 3、Building Apache Thrift **\n```bash\n./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/local\n```\n\n\n<br/>\n### 使用\n\n1、pom文件导入thrift依赖\n```xml\n<!-- https://mvnrepository.com/artifact/org.apache.thrift/libthrift -->\n<dependency>\n    <groupId>org.apache.thrift</groupId>\n    <artifactId>libthrift</artifactId>\n    <version>0.11.0</version>\n    <type>pom</type>\n</dependency>\n```\n\n\n```java\n\n```\n\n\n\n\n\n<br/>\n### 源码分析\n\n\n\n\n\n\n<br/>\n\n---\n参考\n[thrift官网](https://thrift.apache.org/)\n[thrift-Github](https://github.com/apache/thrift)\nhttps://www.kancloud.cn/digest/thrift/","source":"_posts/thrift教程.md","raw":"---\ntitle: thrift教程\ndate: 2018-11-23 17:32:06\ncategories:\n    - Thrift\ntags:\n    - RPC\n    - Thrift\n---\n\n Apache Thrift 采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《thrift.apache.org》\n<!-- more -->\n\n---\n\n<br/>\n### 介绍\nThrift通过IDL（Interface Definition Language，接口定义语言）来定义RPC（Remote Procedure Call，远程过程调用）的接口和数据类型，然后通过thrift编译器生成不同语言的代码，并由生成的代码负责RPC协议层和传输层的实现。\n\n\n![thrift-layers](thrift-layers.png)\n\n<br/>\n### 安装\n现下载：https://thrift.apache.org/download\n官网安装：https://thrift.apache.org/docs/install/\n\n<br/>\n#### 快速安装\n\n```bash\n# 安装命令\nbrew install thrift\n# 卸载命令\nbrew uninstall thrift\n```\n\n<br/>\n#### 源安装\n\n** 1、Install Boost **\nBoost 下载地址：https://www.boost.org/\n```bash\n./bootstrap.sh\nsudo ./b2 threading=multi address-model=64 variant=release stage install\n```\n\n** 2、Install libevent **\nlibevent 下载地址：http://libevent.org/\n```bash\n./configure --prefix=/usr/local\nmake\nsudo make install\n```\n\n** 3、Building Apache Thrift **\n```bash\n./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/local\n```\n\n\n<br/>\n### 使用\n\n1、pom文件导入thrift依赖\n```xml\n<!-- https://mvnrepository.com/artifact/org.apache.thrift/libthrift -->\n<dependency>\n    <groupId>org.apache.thrift</groupId>\n    <artifactId>libthrift</artifactId>\n    <version>0.11.0</version>\n    <type>pom</type>\n</dependency>\n```\n\n\n```java\n\n```\n\n\n\n\n\n<br/>\n### 源码分析\n\n\n\n\n\n\n<br/>\n\n---\n参考\n[thrift官网](https://thrift.apache.org/)\n[thrift-Github](https://github.com/apache/thrift)\nhttps://www.kancloud.cn/digest/thrift/","slug":"thrift教程","published":1,"updated":"2021-06-30T02:33:24.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxc008sr5p7a5w8erud","content":"<p> Apache Thrift 采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《thrift.apache.org》</p>\n<span id=\"more\"></span>\n\n<hr>\n<br>\n### 介绍\nThrift通过IDL（Interface Definition Language，接口定义语言）来定义RPC（Remote Procedure Call，远程过程调用）的接口和数据类型，然后通过thrift编译器生成不同语言的代码，并由生成的代码负责RPC协议层和传输层的实现。\n\n\n<p><img src=\"thrift-layers.png\" alt=\"thrift-layers\"></p>\n<br>\n### 安装\n现下载：https://thrift.apache.org/download\n官网安装：https://thrift.apache.org/docs/install/\n\n<br>\n#### 快速安装\n\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># 安装命令</span>\nbrew <span class=\"token function\">install</span> thrift\n<span class=\"token comment\" spellcheck=\"true\"># 卸载命令</span>\nbrew uninstall thrift\n</code></pre>\n<br>\n#### 源安装\n\n<p>** 1、Install Boost **\nBoost 下载地址：<a href=\"https://www.boost.org/\">https://www.boost.org/</a></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">./bootstrap.sh\n<span class=\"token function\">sudo</span> ./b2 threading<span class=\"token operator\">=</span>multi address-model<span class=\"token operator\">=</span>64 variant<span class=\"token operator\">=</span>release stage <span class=\"token function\">install</span>\n</code></pre>\n<p>** 2、Install libevent **\nlibevent 下载地址：<a href=\"http://libevent.org/\">http://libevent.org/</a></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">./configure --prefix<span class=\"token operator\">=</span>/usr/local\n<span class=\"token function\">make</span>\n<span class=\"token function\">sudo</span> <span class=\"token function\">make</span> <span class=\"token function\">install</span>\n</code></pre>\n<p>** 3、Building Apache Thrift **</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">./configure --prefix<span class=\"token operator\">=</span>/usr/local/ --with-boost<span class=\"token operator\">=</span>/usr/local --with-libevent<span class=\"token operator\">=</span>/usr/local\n</code></pre>\n<br>\n### 使用\n\n<p>1、pom文件导入thrift依赖</p>\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token comment\" spellcheck=\"true\">&lt;!-- https://mvnrepository.com/artifact/org.apache.thrift/libthrift --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.thrift<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>libthrift<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>0.11.0<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>type</span><span class=\"token punctuation\">></span></span>pom<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>type</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<pre class=\" language-java\"><code class=\"language-java\">\n</code></pre>\n<br>\n### 源码分析\n\n\n\n\n\n\n<br>\n\n<hr>\n<p>参考\n<a href=\"https://thrift.apache.org/\">thrift官网</a>\n<a href=\"https://github.com/apache/thrift\">thrift-Github</a>\n<a href=\"https://www.kancloud.cn/digest/thrift/\">https://www.kancloud.cn/digest/thrift/</a></p>\n","site":{"data":{}},"excerpt":"<p> Apache Thrift 采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，对于高并发、大数据量和多语言的环境更有优势</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《thrift.apache.org》</p>","more":"<hr>\n<br/>\n### 介绍\nThrift通过IDL（Interface Definition Language，接口定义语言）来定义RPC（Remote Procedure Call，远程过程调用）的接口和数据类型，然后通过thrift编译器生成不同语言的代码，并由生成的代码负责RPC协议层和传输层的实现。\n\n\n<p><img src=\"thrift-layers.png\" alt=\"thrift-layers\"></p>\n<br/>\n### 安装\n现下载：https://thrift.apache.org/download\n官网安装：https://thrift.apache.org/docs/install/\n\n<br/>\n#### 快速安装\n\n<pre><code class=\"bash\"># 安装命令\nbrew install thrift\n# 卸载命令\nbrew uninstall thrift\n</code></pre>\n<br/>\n#### 源安装\n\n<p>** 1、Install Boost **\nBoost 下载地址：<a href=\"https://www.boost.org/\">https://www.boost.org/</a></p>\n<pre><code class=\"bash\">./bootstrap.sh\nsudo ./b2 threading=multi address-model=64 variant=release stage install\n</code></pre>\n<p>** 2、Install libevent **\nlibevent 下载地址：<a href=\"http://libevent.org/\">http://libevent.org/</a></p>\n<pre><code class=\"bash\">./configure --prefix=/usr/local\nmake\nsudo make install\n</code></pre>\n<p>** 3、Building Apache Thrift **</p>\n<pre><code class=\"bash\">./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/local\n</code></pre>\n<br/>\n### 使用\n\n<p>1、pom文件导入thrift依赖</p>\n<pre><code class=\"xml\">&lt;!-- https://mvnrepository.com/artifact/org.apache.thrift/libthrift --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt;\n    &lt;artifactId&gt;libthrift&lt;/artifactId&gt;\n    &lt;version&gt;0.11.0&lt;/version&gt;\n    &lt;type&gt;pom&lt;/type&gt;\n&lt;/dependency&gt;\n</code></pre>\n<pre><code class=\"java\">\n</code></pre>\n<br/>\n### 源码分析\n\n\n\n\n\n\n<br/>\n\n<hr>\n<p>参考\n<a href=\"https://thrift.apache.org/\">thrift官网</a>\n<a href=\"https://github.com/apache/thrift\">thrift-Github</a>\n<a href=\"https://www.kancloud.cn/digest/thrift/\">https://www.kancloud.cn/digest/thrift/</a></p>"},{"title":"中文分词","date":"2018-12-03T11:31:35.000Z","_content":"\n\n","source":"_posts/中文分词.md","raw":"---\ntitle: 中文分词\ndate: 2018-12-03 19:31:35\ncategories: \n    - 机器学习\n    - 自然语言处理\ntags:\n    - 机器学习\n    - 自然语言处理\n    - 中文分词\n    - 深度学习\n---\n\n\n","slug":"中文分词","published":1,"updated":"2021-06-30T02:33:24.776Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxd008wr5p7eal03hao","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"交叉熵","date":"2018-11-10T00:01:01.000Z","_content":"\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n### 公式\n\n$$H(p,q)=- \\sum_{x} p(x) \\log q(x)$$\n\n<br/>\n\n---\n参考\n\n[wikipedia-交叉熵](https://en.wikipedia.org/wiki/Cross_entropy)\n[baike-交叉熵](https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E7%86%B5)\n","source":"_posts/交叉熵.md","raw":"---\ntitle: 交叉熵\ndate: 2018-11-10 08:01:01\ncategories: \n    - 信息论\ntags:\n    - 算法\n    - 机器学习\n    - 信息论\n    - 信息熵\n---\n\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n### 公式\n\n$$H(p,q)=- \\sum_{x} p(x) \\log q(x)$$\n\n<br/>\n\n---\n参考\n\n[wikipedia-交叉熵](https://en.wikipedia.org/wiki/Cross_entropy)\n[baike-交叉熵](https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E7%86%B5)\n","slug":"交叉熵","published":1,"updated":"2021-06-30T02:33:24.776Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxe008zr5p79so8em2y","content":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$H(p,q)=- \\sum_{x} p(x) \\log q(x)$$</p>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Cross_entropy\">wikipedia-交叉熵</a>\n<a href=\"https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E7%86%B5\">baike-交叉熵</a></p>\n","site":{"data":{}},"excerpt":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$H(p,q)=- \\sum_{x} p(x) \\log q(x)$$</p>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Cross_entropy\">wikipedia-交叉熵</a>\n<a href=\"https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E7%86%B5\">baike-交叉熵</a></p>"},{"title":"人工神经网络","date":"2018-12-01T06:52:06.000Z","_content":"\n`人工神经网络`（英语：Artificial Neural Network，ANN），简称`神经网络`（Neural Network，NN）或`类神经网络`，在机器学习和认知科学领域，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。\n神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种`自适应系统`，通俗的讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n---\n\n<br/>\n\n`神经网络`是由具有`适应性`的`神经元`组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的`交互反应`\n\n\n<br/>\n## 神经元\n神经网络最基本的成分是`神经元`模型\n\n![M-P神经元模型](1543648111947.jpg)\n\n\n\n\n<br/>\n## 组成\n\n<br/>\n### 激励函数\n\n#### 阶跃函数（sgn）\n$$\nsgn(x)= \\begin{cases} 1 & x \\geq 0 \\\\\\ 0 & x \\lt 0 \\end{cases}\n$$\n\n#### Sigmoid函数（sigmoid）\n$$\nsigmoid(x) = \\frac{1}{1+e^{-x}}\n$$\n\n#### tanh函数（tanh）\n$$\ntanh(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n$$\n\n#### Relu函数（Relu）\n$$\nrelu(x)= \\begin{cases} 1 & x \\geq 0 \\\\\\ 0 & x \\lt 0 \\end{cases}\n$$\n\n\n\n<br/>\n## 分类\n\n### 依学习策略\n- 监督式学习网络（Supervised Learning Network）为主\n- 无监督式学习网络（Unsupervised Learning Network）\n- 混合式学习网络（Hybrid Learning Network）\n- 联想式学习网络（Associate Learning Network）\n- 最适化学习网络（Optimization Application Network）\n\n### 依网络架构\n- 前馈神经网络（Feed Forward Network）\n- 递归神经网络（Recurrent Network）\n- 强化式架构（Reinforcement Network）\n\n\n\n\n\n\n\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","source":"_posts/人工神经网络.md","raw":"---\ntitle: 人工神经网络\ndate: 2018-12-01 14:52:06\ncategories: \n    - 神经网络\ntags:\n    - 人工智能\n    - 神经网络\n---\n\n`人工神经网络`（英语：Artificial Neural Network，ANN），简称`神经网络`（Neural Network，NN）或`类神经网络`，在机器学习和认知科学领域，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。\n神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种`自适应系统`，通俗的讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n---\n\n<br/>\n\n`神经网络`是由具有`适应性`的`神经元`组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的`交互反应`\n\n\n<br/>\n## 神经元\n神经网络最基本的成分是`神经元`模型\n\n![M-P神经元模型](1543648111947.jpg)\n\n\n\n\n<br/>\n## 组成\n\n<br/>\n### 激励函数\n\n#### 阶跃函数（sgn）\n$$\nsgn(x)= \\begin{cases} 1 & x \\geq 0 \\\\\\ 0 & x \\lt 0 \\end{cases}\n$$\n\n#### Sigmoid函数（sigmoid）\n$$\nsigmoid(x) = \\frac{1}{1+e^{-x}}\n$$\n\n#### tanh函数（tanh）\n$$\ntanh(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n$$\n\n#### Relu函数（Relu）\n$$\nrelu(x)= \\begin{cases} 1 & x \\geq 0 \\\\\\ 0 & x \\lt 0 \\end{cases}\n$$\n\n\n\n<br/>\n## 分类\n\n### 依学习策略\n- 监督式学习网络（Supervised Learning Network）为主\n- 无监督式学习网络（Unsupervised Learning Network）\n- 混合式学习网络（Hybrid Learning Network）\n- 联想式学习网络（Associate Learning Network）\n- 最适化学习网络（Optimization Application Network）\n\n### 依网络架构\n- 前馈神经网络（Feed Forward Network）\n- 递归神经网络（Recurrent Network）\n- 强化式架构（Reinforcement Network）\n\n\n\n\n\n\n\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","slug":"人工神经网络","published":1,"updated":"2021-06-30T02:33:24.777Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxf0093r5p7993h9ekq","content":"<p><code>人工神经网络</code>（英语：Artificial Neural Network，ANN），简称<code>神经网络</code>（Neural Network，NN）或<code>类神经网络</code>，在机器学习和认知科学领域，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。\n神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种<code>自适应系统</code>，通俗的讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n<hr>\n<br>\n\n<p><code>神经网络</code>是由具有<code>适应性</code>的<code>神经元</code>组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的<code>交互反应</code></p>\n<br>\n## 神经元\n神经网络最基本的成分是`神经元`模型\n\n<p><img src=\"1543648111947.jpg\" alt=\"M-P神经元模型\"></p>\n<br>\n## 组成\n\n<br>\n### 激励函数\n\n<h4 id=\"阶跃函数（sgn）\"><a href=\"#阶跃函数（sgn）\" class=\"headerlink\" title=\"阶跃函数（sgn）\"></a>阶跃函数（sgn）</h4><p>$$\nsgn(x)= \\begin{cases} 1 &amp; x \\geq 0 \\\\ 0 &amp; x \\lt 0 \\end{cases}\n$$</p>\n<h4 id=\"Sigmoid函数（sigmoid）\"><a href=\"#Sigmoid函数（sigmoid）\" class=\"headerlink\" title=\"Sigmoid函数（sigmoid）\"></a>Sigmoid函数（sigmoid）</h4><p>$$\nsigmoid(x) = \\frac{1}{1+e^{-x}}\n$$</p>\n<h4 id=\"tanh函数（tanh）\"><a href=\"#tanh函数（tanh）\" class=\"headerlink\" title=\"tanh函数（tanh）\"></a>tanh函数（tanh）</h4><p>$$\ntanh(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n$$</p>\n<h4 id=\"Relu函数（Relu）\"><a href=\"#Relu函数（Relu）\" class=\"headerlink\" title=\"Relu函数（Relu）\"></a>Relu函数（Relu）</h4><p>$$\nrelu(x)= \\begin{cases} 1 &amp; x \\geq 0 \\\\ 0 &amp; x \\lt 0 \\end{cases}\n$$</p>\n<br>\n## 分类\n\n<h3 id=\"依学习策略\"><a href=\"#依学习策略\" class=\"headerlink\" title=\"依学习策略\"></a>依学习策略</h3><ul>\n<li>监督式学习网络（Supervised Learning Network）为主</li>\n<li>无监督式学习网络（Unsupervised Learning Network）</li>\n<li>混合式学习网络（Hybrid Learning Network）</li>\n<li>联想式学习网络（Associate Learning Network）</li>\n<li>最适化学习网络（Optimization Application Network）</li>\n</ul>\n<h3 id=\"依网络架构\"><a href=\"#依网络架构\" class=\"headerlink\" title=\"依网络架构\"></a>依网络架构</h3><ul>\n<li>前馈神经网络（Feed Forward Network）</li>\n<li>递归神经网络（Recurrent Network）</li>\n<li>强化式架构（Reinforcement Network）</li>\n</ul>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>\n","site":{"data":{}},"excerpt":"<p><code>人工神经网络</code>（英语：Artificial Neural Network，ANN），简称<code>神经网络</code>（Neural Network，NN）或<code>类神经网络</code>，在机器学习和认知科学领域，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。\n神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种<code>自适应系统</code>，通俗的讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<hr>\n<br/>\n\n<p><code>神经网络</code>是由具有<code>适应性</code>的<code>神经元</code>组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的<code>交互反应</code></p>\n<br/>\n## 神经元\n神经网络最基本的成分是`神经元`模型\n\n<p><img src=\"1543648111947.jpg\" alt=\"M-P神经元模型\"></p>\n<br/>\n## 组成\n\n<br/>\n### 激励函数\n\n<h4 id=\"阶跃函数（sgn）\"><a href=\"#阶跃函数（sgn）\" class=\"headerlink\" title=\"阶跃函数（sgn）\"></a>阶跃函数（sgn）</h4><p>$$\nsgn(x)= \\begin{cases} 1 &amp; x \\geq 0 \\\\ 0 &amp; x \\lt 0 \\end{cases}\n$$</p>\n<h4 id=\"Sigmoid函数（sigmoid）\"><a href=\"#Sigmoid函数（sigmoid）\" class=\"headerlink\" title=\"Sigmoid函数（sigmoid）\"></a>Sigmoid函数（sigmoid）</h4><p>$$\nsigmoid(x) = \\frac{1}{1+e^{-x}}\n$$</p>\n<h4 id=\"tanh函数（tanh）\"><a href=\"#tanh函数（tanh）\" class=\"headerlink\" title=\"tanh函数（tanh）\"></a>tanh函数（tanh）</h4><p>$$\ntanh(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n$$</p>\n<h4 id=\"Relu函数（Relu）\"><a href=\"#Relu函数（Relu）\" class=\"headerlink\" title=\"Relu函数（Relu）\"></a>Relu函数（Relu）</h4><p>$$\nrelu(x)= \\begin{cases} 1 &amp; x \\geq 0 \\\\ 0 &amp; x \\lt 0 \\end{cases}\n$$</p>\n<br/>\n## 分类\n\n<h3 id=\"依学习策略\"><a href=\"#依学习策略\" class=\"headerlink\" title=\"依学习策略\"></a>依学习策略</h3><ul>\n<li>监督式学习网络（Supervised Learning Network）为主</li>\n<li>无监督式学习网络（Unsupervised Learning Network）</li>\n<li>混合式学习网络（Hybrid Learning Network）</li>\n<li>联想式学习网络（Associate Learning Network）</li>\n<li>最适化学习网络（Optimization Application Network）</li>\n</ul>\n<h3 id=\"依网络架构\"><a href=\"#依网络架构\" class=\"headerlink\" title=\"依网络架构\"></a>依网络架构</h3><ul>\n<li>前馈神经网络（Feed Forward Network）</li>\n<li>递归神经网络（Recurrent Network）</li>\n<li>强化式架构（Reinforcement Network）</li>\n</ul>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>"},{"title":"信息熵","date":"2018-11-10T00:01:01.000Z","_content":"\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大，熵最小是0`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n<br/>\n\n### 公式\n\n$$\nH(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})\n$$\n\n其中，$P(X_{i})$为$X=X_{i}$的概率\n在这里b是对数所使用的底，通常是2、自然常数e或是10。当b = 2，熵的单位是bit；当b = e，熵的单位是nat；而当b = 10，熵的单位是Hart。\n\n<br/>\n### 范例\n\n1、随机投掷一枚硬笔，假设两面不相同且出现正面、反面概率都一样，为$\\frac{1}{2}$。信息熵为：\n\n$$\nH(X)= -\\sum_{i=1}^2 \\frac{1}{2} \\log_2 \\frac{1}{2} = - (\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}) = 1\n$$\n\n但是如果一枚硬币的两面完全相同，信息熵：0\n\n2、\n\n\n<br/>\n### 应用场景\n\n[ID3算法](../ID3算法) [C4.5算法](../C4.5算法)\n\n\n<br/>\n\n--- \n参考\n[wikipedia-信息熵](https://en.wikipedia.org/wiki/Entropy_(information_theory)\n[百度百科-信息熵](https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5)","source":"_posts/信息熵.md","raw":"---\ntitle: 信息熵\ndate: 2018-11-10 08:01:01\ncategories: \n    - 信息论\ntags:\n    - 数学\n    - 算法\n    - 机器学习\n    - 信息论\n    - 信息熵\n---\n\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大，熵最小是0`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n<br/>\n\n### 公式\n\n$$\nH(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})\n$$\n\n其中，$P(X_{i})$为$X=X_{i}$的概率\n在这里b是对数所使用的底，通常是2、自然常数e或是10。当b = 2，熵的单位是bit；当b = e，熵的单位是nat；而当b = 10，熵的单位是Hart。\n\n<br/>\n### 范例\n\n1、随机投掷一枚硬笔，假设两面不相同且出现正面、反面概率都一样，为$\\frac{1}{2}$。信息熵为：\n\n$$\nH(X)= -\\sum_{i=1}^2 \\frac{1}{2} \\log_2 \\frac{1}{2} = - (\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}) = 1\n$$\n\n但是如果一枚硬币的两面完全相同，信息熵：0\n\n2、\n\n\n<br/>\n### 应用场景\n\n[ID3算法](../ID3算法) [C4.5算法](../C4.5算法)\n\n\n<br/>\n\n--- \n参考\n[wikipedia-信息熵](https://en.wikipedia.org/wiki/Entropy_(information_theory)\n[百度百科-信息熵](https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5)","slug":"信息熵","published":1,"updated":"2021-06-30T02:33:24.777Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxg0096r5p772p9a6tl","content":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大，熵最小是0</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<br>\n<br>\n\n<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$\nH(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})\n$$</p>\n<p>其中，$P(X_{i})$为$X=X_{i}$的概率\n在这里b是对数所使用的底，通常是2、自然常数e或是10。当b = 2，熵的单位是bit；当b = e，熵的单位是nat；而当b = 10，熵的单位是Hart。</p>\n<br>\n### 范例\n\n<p>1、随机投掷一枚硬笔，假设两面不相同且出现正面、反面概率都一样，为$\\frac{1}{2}$。信息熵为：</p>\n<p>$$\nH(X)= -\\sum_{i=1}^2 \\frac{1}{2} \\log_2 \\frac{1}{2} = - (\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}) = 1\n$$</p>\n<p>但是如果一枚硬币的两面完全相同，信息熵：0</p>\n<p>2、</p>\n<br>\n### 应用场景\n\n<p><a href=\"../ID3%E7%AE%97%E6%B3%95\">ID3算法</a> <a href=\"../C4.5%E7%AE%97%E6%B3%95\">C4.5算法</a></p>\n<br>\n\n<hr>\n<p>参考\n<a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory\">wikipedia-信息熵</a>\n<a href=\"https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5\">百度百科-信息熵</a></p>\n","site":{"data":{}},"excerpt":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大，熵最小是0</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<br/>\n<br/>\n\n<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$\nH(X)=-\\sum_{i=0} P(X_{i}) \\log_b P(X_{i})\n$$</p>\n<p>其中，$P(X_{i})$为$X=X_{i}$的概率\n在这里b是对数所使用的底，通常是2、自然常数e或是10。当b = 2，熵的单位是bit；当b = e，熵的单位是nat；而当b = 10，熵的单位是Hart。</p>\n<br/>\n### 范例\n\n<p>1、随机投掷一枚硬笔，假设两面不相同且出现正面、反面概率都一样，为$\\frac{1}{2}$。信息熵为：</p>\n<p>$$\nH(X)= -\\sum_{i=1}^2 \\frac{1}{2} \\log_2 \\frac{1}{2} = - (\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}) = 1\n$$</p>\n<p>但是如果一枚硬币的两面完全相同，信息熵：0</p>\n<p>2、</p>\n<br/>\n### 应用场景\n\n<p><a href=\"../ID3%E7%AE%97%E6%B3%95\">ID3算法</a> <a href=\"../C4.5%E7%AE%97%E6%B3%95\">C4.5算法</a></p>\n<br/>\n\n<hr>\n<p>参考\n<a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory\">wikipedia-信息熵</a>\n<a href=\"https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5\">百度百科-信息熵</a></p>"},{"title":"创建SecureRandom过慢问题","date":"2018-12-13T12:14:30.000Z","_content":"\nLinux 环境Tomcat启动项目 创建SecureRandom过慢，报如下警告信息\n```\n o.a.c.util.SessionIdGeneratorBase        : Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [28,420] milliseconds.\n```\n\n这个问题很多人遇到过，tomcat的wiki里面还单独列出来作为加速启动的一个方面：\nhttps://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source\n\n\ntomcat7/tomcat8的session id的生成主要通过`java.security.SecureRandom`生成随机数来实现，随机数算法使用的是`SHA1PRNG`\n\n在sun/oracle的jdk里，这个算法的提供者在底层依赖到操作系统提供的随机数据，在linux上，与之相关的是`/dev/random`和`/dev/urandom` \n** /dev/random **\n```\n在读取时，/dev/random设备会返回小于熵池噪声总数的随机字节。\n/dev/random可生成高随机性的公钥或一次性密码本。\n若熵池空了，对/dev/random的读操作将会被阻塞，直到收集到了足够的环境噪声为止\n```\n\n** /dev/urandom 则是一个非阻塞的发生器 **\n```\ndev/random的一个副本是/dev/urandom （”unlocked”，非阻塞的随机数发生器），它会重复使用熵池中的数据以产生伪随机数据。\n这表示对/dev/urandom的读取操作不会产生阻塞，但其输出的熵可能小于/dev/random的。\n它可以作为生成较低强度密码的伪随机数生成器，不建议用于生成高强度长期密码。\n```\n\n<!-- more -->\n\n** 解决方法：**\n\n采用非阻塞的熵源(entropy source)\n\n```\n系统属性:\n-Djava.security.egd=file:/dev/./urandom\n\n文件修改：$JAVA_HOME/jre/lib/security/java.security\nsecurerandom.source=file:/dev/urandom\n```","source":"_posts/创建SecureRandom过慢问题.md","raw":"---\ntitle: 创建SecureRandom过慢问题\ndate: 2018-12-13 20:14:30\ncategories: \n    - Tomcat\ntags:\n    - Java\n    - Tomcat\n    - Slow\n---\n\nLinux 环境Tomcat启动项目 创建SecureRandom过慢，报如下警告信息\n```\n o.a.c.util.SessionIdGeneratorBase        : Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [28,420] milliseconds.\n```\n\n这个问题很多人遇到过，tomcat的wiki里面还单独列出来作为加速启动的一个方面：\nhttps://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source\n\n\ntomcat7/tomcat8的session id的生成主要通过`java.security.SecureRandom`生成随机数来实现，随机数算法使用的是`SHA1PRNG`\n\n在sun/oracle的jdk里，这个算法的提供者在底层依赖到操作系统提供的随机数据，在linux上，与之相关的是`/dev/random`和`/dev/urandom` \n** /dev/random **\n```\n在读取时，/dev/random设备会返回小于熵池噪声总数的随机字节。\n/dev/random可生成高随机性的公钥或一次性密码本。\n若熵池空了，对/dev/random的读操作将会被阻塞，直到收集到了足够的环境噪声为止\n```\n\n** /dev/urandom 则是一个非阻塞的发生器 **\n```\ndev/random的一个副本是/dev/urandom （”unlocked”，非阻塞的随机数发生器），它会重复使用熵池中的数据以产生伪随机数据。\n这表示对/dev/urandom的读取操作不会产生阻塞，但其输出的熵可能小于/dev/random的。\n它可以作为生成较低强度密码的伪随机数生成器，不建议用于生成高强度长期密码。\n```\n\n<!-- more -->\n\n** 解决方法：**\n\n采用非阻塞的熵源(entropy source)\n\n```\n系统属性:\n-Djava.security.egd=file:/dev/./urandom\n\n文件修改：$JAVA_HOME/jre/lib/security/java.security\nsecurerandom.source=file:/dev/urandom\n```","slug":"创建SecureRandom过慢问题","published":1,"updated":"2021-06-30T02:33:24.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxh0099r5p7b48f4t14","content":"<p>Linux 环境Tomcat启动项目 创建SecureRandom过慢，报如下警告信息</p>\n<pre><code> o.a.c.util.SessionIdGeneratorBase        : Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [28,420] milliseconds.\n</code></pre>\n<p>这个问题很多人遇到过，tomcat的wiki里面还单独列出来作为加速启动的一个方面：\n<a href=\"https://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source\">https://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source</a></p>\n<p>tomcat7/tomcat8的session id的生成主要通过<code>java.security.SecureRandom</code>生成随机数来实现，随机数算法使用的是<code>SHA1PRNG</code></p>\n<p>在sun/oracle的jdk里，这个算法的提供者在底层依赖到操作系统提供的随机数据，在linux上，与之相关的是<code>/dev/random</code>和<code>/dev/urandom</code> \n** /dev/random **</p>\n<pre><code>在读取时，/dev/random设备会返回小于熵池噪声总数的随机字节。\n/dev/random可生成高随机性的公钥或一次性密码本。\n若熵池空了，对/dev/random的读操作将会被阻塞，直到收集到了足够的环境噪声为止\n</code></pre>\n<p>** /dev/urandom 则是一个非阻塞的发生器 **</p>\n<pre><code>dev/random的一个副本是/dev/urandom （”unlocked”，非阻塞的随机数发生器），它会重复使用熵池中的数据以产生伪随机数据。\n这表示对/dev/urandom的读取操作不会产生阻塞，但其输出的熵可能小于/dev/random的。\n它可以作为生成较低强度密码的伪随机数生成器，不建议用于生成高强度长期密码。\n</code></pre>\n<span id=\"more\"></span>\n\n<p>** 解决方法：**</p>\n<p>采用非阻塞的熵源(entropy source)</p>\n<pre><code>系统属性:\n-Djava.security.egd=file:/dev/./urandom\n\n文件修改：$JAVA_HOME/jre/lib/security/java.security\nsecurerandom.source=file:/dev/urandom\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>Linux 环境Tomcat启动项目 创建SecureRandom过慢，报如下警告信息</p>\n<pre><code> o.a.c.util.SessionIdGeneratorBase        : Creation of SecureRandom instance for session ID generation using [SHA1PRNG] took [28,420] milliseconds.\n</code></pre>\n<p>这个问题很多人遇到过，tomcat的wiki里面还单独列出来作为加速启动的一个方面：\n<a href=\"https://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source\">https://wiki.apache.org/tomcat/HowTo/FasterStartUp#Entropy_Source</a></p>\n<p>tomcat7/tomcat8的session id的生成主要通过<code>java.security.SecureRandom</code>生成随机数来实现，随机数算法使用的是<code>SHA1PRNG</code></p>\n<p>在sun/oracle的jdk里，这个算法的提供者在底层依赖到操作系统提供的随机数据，在linux上，与之相关的是<code>/dev/random</code>和<code>/dev/urandom</code> \n** /dev/random **</p>\n<pre><code>在读取时，/dev/random设备会返回小于熵池噪声总数的随机字节。\n/dev/random可生成高随机性的公钥或一次性密码本。\n若熵池空了，对/dev/random的读操作将会被阻塞，直到收集到了足够的环境噪声为止\n</code></pre>\n<p>** /dev/urandom 则是一个非阻塞的发生器 **</p>\n<pre><code>dev/random的一个副本是/dev/urandom （”unlocked”，非阻塞的随机数发生器），它会重复使用熵池中的数据以产生伪随机数据。\n这表示对/dev/urandom的读取操作不会产生阻塞，但其输出的熵可能小于/dev/random的。\n它可以作为生成较低强度密码的伪随机数生成器，不建议用于生成高强度长期密码。\n</code></pre>","more":"<p>** 解决方法：**</p>\n<p>采用非阻塞的熵源(entropy source)</p>\n<pre><code>系统属性:\n-Djava.security.egd=file:/dev/./urandom\n\n文件修改：$JAVA_HOME/jre/lib/security/java.security\nsecurerandom.source=file:/dev/urandom\n</code></pre>"},{"title":"前馈神经网络","date":"2018-12-01T07:20:24.000Z","_content":"\n\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","source":"_posts/前馈神经网络.md","raw":"---\ntitle: 前馈神经网络\ndate: 2018-12-01 15:20:24\ncategories: \n    - 神经网络\ntags:\n    - 人工智能\n    - 神经网络\n---\n\n\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","slug":"前馈神经网络","published":1,"updated":"2021-06-30T02:33:24.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxi009cr5p731p24zc6","content":"<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>\n","site":{"data":{}},"excerpt":"<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>"},{"title":"半朴素贝叶斯算法","date":"2018-11-13T02:41:11.000Z","_content":"\n\n\n\n<!-- more -->","source":"_posts/半朴素贝叶斯算法.md","raw":"---\ntitle: 半朴素贝叶斯算法\ndate: 2018-11-13 10:41:11\ncategories: \n    - 机器学习\ntags: \n    - 算法\n    - 机器学习\n    - 监督学习\n    - 贝叶斯\n---\n\n\n\n\n<!-- more -->","slug":"半朴素贝叶斯算法","published":1,"updated":"2021-06-30T02:33:24.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxl009fr5p7csg49kfd","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"哈希(Hash)函数汇总","date":"2019-06-14T06:00:22.000Z","_content":"\n\n<br/>\n## Fnv\n\n### FNV-1 hash\n```c\n    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n   \t    hash = hash × FNV_prime\n   \t    hash = hash XOR byte_of_data\n    return hash\n```\n\n### FNV-1a hash\n```c\n    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n   \t    hash = hash XOR byte_of_data\n   \t    hash = hash × FNV_prime\n    return hash\n```\n\n### FNV-0 hash (Deprecated)\n```c\n    hash = 0\n    for each byte_of_data to be hashed\n   \t    hash = hash × FNV_prime\n   \t    hash = hash XOR octet_of_data\n    return hash\n```\n\n### FNV parameters\nSize in bits | FNV prime | FNV offset basis\n:-------------:|:-----------:|:-----------------:\n32  |   224 + 28 + 0x93 = <br/>16777619 | 2166136261 = <br/>0x811c9dc5\n64  |   240 + 28 + 0xb3 = <br/>1099511628211 | 14695981039346656037 = <br/>0xcbf29ce484222325\n128 |\t288 + 28 + 0x3b = <br/>309485009821345068724781371   | 144066263297769815596495629667062367629 <br/>= <br/>0x6c62272e07bb014262b821756295c58d\n256 |\t2168 + 28 + 0x63 = <br/>374144419156711147060143317<br/>175368453031918731002211  | 100029257958052580907070968620625704837<br/>092796014241193945225284501741471925557 <br/>= <br/>0xdd268dbcaac550362d98c384c4e576ccc8b153<br/>6847b6bbb31023b4c8caee0535\n512 |\t2344 + 28 + 0x57 = <br/>358359158748448673689190764<br/>890951084499463279557543925<br/>26094039892345713852759 |   965930312949666949800943540071631046609<br/>041874567263789610837432943446265799458<br/>293219771643844981305189220653980578449<br/>5328239340083876191928701583869517785 = <br/>0xb86db0b1171f4416dca1e50f309990acac87d0<br/>59c90000000000000000000d21e948f68a34c192<br/>f62ea79bc942dbe7ce182036415f56e34bac982a<br/>ac4afe9fd9\n1024    |   2680 + 28 + 0x8d = <br/>501645651011311865543459881<br/>103527895503076534540479074<br/>430301752383111205510814745<br/>150915769222029538271616265<br/>187852689524938529229181652<br/>437508374669137180409427187<br/>316048473796672026038921768<br/>4476157468082573 |   14197795064947621068722070641403218320<br/>88062279544193396087847491461758272325<br/>22967323037177221508640965212023555493<br/>65628174669108571814760471015076148029<br/>75596980407732015769245856300321530495<br/>71501574036444603635505054127112859663<br/>61610267868082893823963790439336411086<br/>884584107735010676915 <br/> = <br/>0x0000000000000000 005f7a76758ecc4d 32e56d5a591028b7 4b29fc4223fdada1 <br/>6c3bf34eda3674da 9a21d90000000000 0000000000000000 0000000000000000 <br/>0000000000000000 0000000000000000 0000000000000000 000000000004c6d7 <br/>eb6e73802734510a 555f256cc005ae55 6bde8cc9c6a93b21 aff4b16c71ee90b3\n\n\n### 具体列子\n```java\npublic static long fnv_1a_64(String value) {\n        if (value == null) {\n            return 0;\n        }\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i < value.length(); i++) {\n            char c = value.charAt(i);\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        }\n\n        return hash;\n    }\n\n    public static long fnv_1a_64_lower(String key) {\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i < key.length(); ++i) {\n            char c = key.charAt(i);\n\n            if (c >= 'A' && c <= 'Z') {\n                c = (char) (c + 32);\n            }\n\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        }\n\n        return hash;\n    }\n```\n\n\n## MurmurHash3\n```c++\n//-----------------------------------------------------------------------------\n// MurmurHash3 was written by Austin Appleby, and is placed in the public\n// domain. The author hereby disclaims copyright to this source code.\n\n// Note - The x86 and x64 versions do _not_ produce the same results, as the\n// algorithms are optimized for their respective platforms. You can still\n// compile and run any of them on any platform, but your performance with the\n// non-native version will be less than optimal.\n\n#include \"MurmurHash3.h\"\n\n//-----------------------------------------------------------------------------\n// Platform-specific functions and macros\n\n// Microsoft Visual Studio\n\n#if defined(_MSC_VER)\n\n#define FORCE_INLINE\t__forceinline\n\n#include <stdlib.h>\n\n#define ROTL32(x,y)\t_rotl(x,y)\n#define ROTL64(x,y)\t_rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x)\n\n// Other compilers\n\n#else\t// defined(_MSC_VER)\n\n#define\tFORCE_INLINE inline __attribute__((always_inline))\n\ninline uint32_t rotl32 ( uint32_t x, int8_t r )\n{\n  return (x << r) | (x >> (32 - r));\n}\n\ninline uint64_t rotl64 ( uint64_t x, int8_t r )\n{\n  return (x << r) | (x >> (64 - r));\n}\n\n#define\tROTL32(x,y)\trotl32(x,y)\n#define ROTL64(x,y)\trotl64(x,y)\n\n#define BIG_CONSTANT(x) (x##LLU)\n\n#endif // !defined(_MSC_VER)\n\n//-----------------------------------------------------------------------------\n// Block read - if your platform needs to do endian-swapping or can only\n// handle aligned reads, do the conversion here\n\nFORCE_INLINE uint32_t getblock32 ( const uint32_t * p, int i )\n{\n  return p[i];\n}\n\nFORCE_INLINE uint64_t getblock64 ( const uint64_t * p, int i )\n{\n  return p[i];\n}\n\n//-----------------------------------------------------------------------------\n// Finalization mix - force all bits of a hash block to avalanche\n\nFORCE_INLINE uint32_t fmix32 ( uint32_t h )\n{\n  h ^= h >> 16;\n  h *= 0x85ebca6b;\n  h ^= h >> 13;\n  h *= 0xc2b2ae35;\n  h ^= h >> 16;\n\n  return h;\n}\n\n//----------\n\nFORCE_INLINE uint64_t fmix64 ( uint64_t k )\n{\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xff51afd7ed558ccd);\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xc4ceb9fe1a85ec53);\n  k ^= k >> 33;\n\n  return k;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_32 ( const void * key, int len,\n                          uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 4;\n\n  uint32_t h1 = seed;\n\n  const uint32_t c1 = 0xcc9e2d51;\n  const uint32_t c2 = 0x1b873593;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*4);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i);\n\n    k1 *= c1;\n    k1 = ROTL32(k1,15);\n    k1 *= c2;\n    \n    h1 ^= k1;\n    h1 = ROTL32(h1,13); \n    h1 = h1*5+0xe6546b64;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*4);\n\n  uint32_t k1 = 0;\n\n  switch(len & 3)\n  {\n  case 3: k1 ^= tail[2] << 16;\n  case 2: k1 ^= tail[1] << 8;\n  case 1: k1 ^= tail[0];\n          k1 *= c1; k1 = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len;\n\n  h1 = fmix32(h1);\n\n  *(uint32_t*)out = h1;\n} \n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_128 ( const void * key, const int len,\n                           uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint32_t h1 = seed;\n  uint32_t h2 = seed;\n  uint32_t h3 = seed;\n  uint32_t h4 = seed;\n\n  const uint32_t c1 = 0x239b961b; \n  const uint32_t c2 = 0xab0e9789;\n  const uint32_t c3 = 0x38b34ae5; \n  const uint32_t c4 = 0xa1e38b93;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*16);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i*4+0);\n    uint32_t k2 = getblock32(blocks,i*4+1);\n    uint32_t k3 = getblock32(blocks,i*4+2);\n    uint32_t k4 = getblock32(blocks,i*4+3);\n\n    k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL32(h1,19); h1 += h2; h1 = h1*5+0x561ccd1b;\n\n    k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n    h2 = ROTL32(h2,17); h2 += h3; h2 = h2*5+0x0bcaa747;\n\n    k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n    h3 = ROTL32(h3,15); h3 += h4; h3 = h3*5+0x96cd1c35;\n\n    k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n    h4 = ROTL32(h4,13); h4 += h1; h4 = h4*5+0x32ac3b17;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint32_t k1 = 0;\n  uint32_t k2 = 0;\n  uint32_t k3 = 0;\n  uint32_t k4 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k4 ^= tail[14] << 16;\n  case 14: k4 ^= tail[13] << 8;\n  case 13: k4 ^= tail[12] << 0;\n           k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n  case 12: k3 ^= tail[11] << 24;\n  case 11: k3 ^= tail[10] << 16;\n  case 10: k3 ^= tail[ 9] << 8;\n  case  9: k3 ^= tail[ 8] << 0;\n           k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n  case  8: k2 ^= tail[ 7] << 24;\n  case  7: k2 ^= tail[ 6] << 16;\n  case  6: k2 ^= tail[ 5] << 8;\n  case  5: k2 ^= tail[ 4] << 0;\n           k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n  case  4: k1 ^= tail[ 3] << 24;\n  case  3: k1 ^= tail[ 2] << 16;\n  case  2: k1 ^= tail[ 1] << 8;\n  case  1: k1 ^= tail[ 0] << 0;\n           k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len; h3 ^= len; h4 ^= len;\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  h1 = fmix32(h1);\n  h2 = fmix32(h2);\n  h3 = fmix32(h3);\n  h4 = fmix32(h4);\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  ((uint32_t*)out)[0] = h1;\n  ((uint32_t*)out)[1] = h2;\n  ((uint32_t*)out)[2] = h3;\n  ((uint32_t*)out)[3] = h4;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x64_128 ( const void * key, const int len,\n                           const uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint64_t h1 = seed;\n  uint64_t h2 = seed;\n\n  const uint64_t c1 = BIG_CONSTANT(0x87c37b91114253d5);\n  const uint64_t c2 = BIG_CONSTANT(0x4cf5ad432745937f);\n\n  //----------\n  // body\n\n  const uint64_t * blocks = (const uint64_t *)(data);\n\n  for(int i = 0; i < nblocks; i++)\n  {\n    uint64_t k1 = getblock64(blocks,i*2+0);\n    uint64_t k2 = getblock64(blocks,i*2+1);\n\n    k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL64(h1,27); h1 += h2; h1 = h1*5+0x52dce729;\n\n    k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n    h2 = ROTL64(h2,31); h2 += h1; h2 = h2*5+0x38495ab5;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint64_t k1 = 0;\n  uint64_t k2 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k2 ^= ((uint64_t)tail[14]) << 48;\n  case 14: k2 ^= ((uint64_t)tail[13]) << 40;\n  case 13: k2 ^= ((uint64_t)tail[12]) << 32;\n  case 12: k2 ^= ((uint64_t)tail[11]) << 24;\n  case 11: k2 ^= ((uint64_t)tail[10]) << 16;\n  case 10: k2 ^= ((uint64_t)tail[ 9]) << 8;\n  case  9: k2 ^= ((uint64_t)tail[ 8]) << 0;\n           k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n  case  8: k1 ^= ((uint64_t)tail[ 7]) << 56;\n  case  7: k1 ^= ((uint64_t)tail[ 6]) << 48;\n  case  6: k1 ^= ((uint64_t)tail[ 5]) << 40;\n  case  5: k1 ^= ((uint64_t)tail[ 4]) << 32;\n  case  4: k1 ^= ((uint64_t)tail[ 3]) << 24;\n  case  3: k1 ^= ((uint64_t)tail[ 2]) << 16;\n  case  2: k1 ^= ((uint64_t)tail[ 1]) << 8;\n  case  1: k1 ^= ((uint64_t)tail[ 0]) << 0;\n           k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len;\n\n  h1 += h2;\n  h2 += h1;\n\n  h1 = fmix64(h1);\n  h2 = fmix64(h2);\n\n  h1 += h2;\n  h2 += h1;\n\n  ((uint64_t*)out)[0] = h1;\n  ((uint64_t*)out)[1] = h2;\n}\n\n//-----------------------------------------------------------------------------\n```\n\n\n---\n\n<br/>\n**参考**\n[Fvn Hash Funciton wikipedia](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function)\nhttps://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp","source":"_posts/哈希-Hash-函数汇总.md","raw":"---\ntitle: 哈希(Hash)函数汇总\ndate: 2019-06-14 14:00:22\ncategories: \n    - Algorithm\ntags:\n    - Algorithm\n    - Hash\n---\n\n\n<br/>\n## Fnv\n\n### FNV-1 hash\n```c\n    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n   \t    hash = hash × FNV_prime\n   \t    hash = hash XOR byte_of_data\n    return hash\n```\n\n### FNV-1a hash\n```c\n    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n   \t    hash = hash XOR byte_of_data\n   \t    hash = hash × FNV_prime\n    return hash\n```\n\n### FNV-0 hash (Deprecated)\n```c\n    hash = 0\n    for each byte_of_data to be hashed\n   \t    hash = hash × FNV_prime\n   \t    hash = hash XOR octet_of_data\n    return hash\n```\n\n### FNV parameters\nSize in bits | FNV prime | FNV offset basis\n:-------------:|:-----------:|:-----------------:\n32  |   224 + 28 + 0x93 = <br/>16777619 | 2166136261 = <br/>0x811c9dc5\n64  |   240 + 28 + 0xb3 = <br/>1099511628211 | 14695981039346656037 = <br/>0xcbf29ce484222325\n128 |\t288 + 28 + 0x3b = <br/>309485009821345068724781371   | 144066263297769815596495629667062367629 <br/>= <br/>0x6c62272e07bb014262b821756295c58d\n256 |\t2168 + 28 + 0x63 = <br/>374144419156711147060143317<br/>175368453031918731002211  | 100029257958052580907070968620625704837<br/>092796014241193945225284501741471925557 <br/>= <br/>0xdd268dbcaac550362d98c384c4e576ccc8b153<br/>6847b6bbb31023b4c8caee0535\n512 |\t2344 + 28 + 0x57 = <br/>358359158748448673689190764<br/>890951084499463279557543925<br/>26094039892345713852759 |   965930312949666949800943540071631046609<br/>041874567263789610837432943446265799458<br/>293219771643844981305189220653980578449<br/>5328239340083876191928701583869517785 = <br/>0xb86db0b1171f4416dca1e50f309990acac87d0<br/>59c90000000000000000000d21e948f68a34c192<br/>f62ea79bc942dbe7ce182036415f56e34bac982a<br/>ac4afe9fd9\n1024    |   2680 + 28 + 0x8d = <br/>501645651011311865543459881<br/>103527895503076534540479074<br/>430301752383111205510814745<br/>150915769222029538271616265<br/>187852689524938529229181652<br/>437508374669137180409427187<br/>316048473796672026038921768<br/>4476157468082573 |   14197795064947621068722070641403218320<br/>88062279544193396087847491461758272325<br/>22967323037177221508640965212023555493<br/>65628174669108571814760471015076148029<br/>75596980407732015769245856300321530495<br/>71501574036444603635505054127112859663<br/>61610267868082893823963790439336411086<br/>884584107735010676915 <br/> = <br/>0x0000000000000000 005f7a76758ecc4d 32e56d5a591028b7 4b29fc4223fdada1 <br/>6c3bf34eda3674da 9a21d90000000000 0000000000000000 0000000000000000 <br/>0000000000000000 0000000000000000 0000000000000000 000000000004c6d7 <br/>eb6e73802734510a 555f256cc005ae55 6bde8cc9c6a93b21 aff4b16c71ee90b3\n\n\n### 具体列子\n```java\npublic static long fnv_1a_64(String value) {\n        if (value == null) {\n            return 0;\n        }\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i < value.length(); i++) {\n            char c = value.charAt(i);\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        }\n\n        return hash;\n    }\n\n    public static long fnv_1a_64_lower(String key) {\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i < key.length(); ++i) {\n            char c = key.charAt(i);\n\n            if (c >= 'A' && c <= 'Z') {\n                c = (char) (c + 32);\n            }\n\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        }\n\n        return hash;\n    }\n```\n\n\n## MurmurHash3\n```c++\n//-----------------------------------------------------------------------------\n// MurmurHash3 was written by Austin Appleby, and is placed in the public\n// domain. The author hereby disclaims copyright to this source code.\n\n// Note - The x86 and x64 versions do _not_ produce the same results, as the\n// algorithms are optimized for their respective platforms. You can still\n// compile and run any of them on any platform, but your performance with the\n// non-native version will be less than optimal.\n\n#include \"MurmurHash3.h\"\n\n//-----------------------------------------------------------------------------\n// Platform-specific functions and macros\n\n// Microsoft Visual Studio\n\n#if defined(_MSC_VER)\n\n#define FORCE_INLINE\t__forceinline\n\n#include <stdlib.h>\n\n#define ROTL32(x,y)\t_rotl(x,y)\n#define ROTL64(x,y)\t_rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x)\n\n// Other compilers\n\n#else\t// defined(_MSC_VER)\n\n#define\tFORCE_INLINE inline __attribute__((always_inline))\n\ninline uint32_t rotl32 ( uint32_t x, int8_t r )\n{\n  return (x << r) | (x >> (32 - r));\n}\n\ninline uint64_t rotl64 ( uint64_t x, int8_t r )\n{\n  return (x << r) | (x >> (64 - r));\n}\n\n#define\tROTL32(x,y)\trotl32(x,y)\n#define ROTL64(x,y)\trotl64(x,y)\n\n#define BIG_CONSTANT(x) (x##LLU)\n\n#endif // !defined(_MSC_VER)\n\n//-----------------------------------------------------------------------------\n// Block read - if your platform needs to do endian-swapping or can only\n// handle aligned reads, do the conversion here\n\nFORCE_INLINE uint32_t getblock32 ( const uint32_t * p, int i )\n{\n  return p[i];\n}\n\nFORCE_INLINE uint64_t getblock64 ( const uint64_t * p, int i )\n{\n  return p[i];\n}\n\n//-----------------------------------------------------------------------------\n// Finalization mix - force all bits of a hash block to avalanche\n\nFORCE_INLINE uint32_t fmix32 ( uint32_t h )\n{\n  h ^= h >> 16;\n  h *= 0x85ebca6b;\n  h ^= h >> 13;\n  h *= 0xc2b2ae35;\n  h ^= h >> 16;\n\n  return h;\n}\n\n//----------\n\nFORCE_INLINE uint64_t fmix64 ( uint64_t k )\n{\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xff51afd7ed558ccd);\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xc4ceb9fe1a85ec53);\n  k ^= k >> 33;\n\n  return k;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_32 ( const void * key, int len,\n                          uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 4;\n\n  uint32_t h1 = seed;\n\n  const uint32_t c1 = 0xcc9e2d51;\n  const uint32_t c2 = 0x1b873593;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*4);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i);\n\n    k1 *= c1;\n    k1 = ROTL32(k1,15);\n    k1 *= c2;\n    \n    h1 ^= k1;\n    h1 = ROTL32(h1,13); \n    h1 = h1*5+0xe6546b64;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*4);\n\n  uint32_t k1 = 0;\n\n  switch(len & 3)\n  {\n  case 3: k1 ^= tail[2] << 16;\n  case 2: k1 ^= tail[1] << 8;\n  case 1: k1 ^= tail[0];\n          k1 *= c1; k1 = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len;\n\n  h1 = fmix32(h1);\n\n  *(uint32_t*)out = h1;\n} \n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_128 ( const void * key, const int len,\n                           uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint32_t h1 = seed;\n  uint32_t h2 = seed;\n  uint32_t h3 = seed;\n  uint32_t h4 = seed;\n\n  const uint32_t c1 = 0x239b961b; \n  const uint32_t c2 = 0xab0e9789;\n  const uint32_t c3 = 0x38b34ae5; \n  const uint32_t c4 = 0xa1e38b93;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*16);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i*4+0);\n    uint32_t k2 = getblock32(blocks,i*4+1);\n    uint32_t k3 = getblock32(blocks,i*4+2);\n    uint32_t k4 = getblock32(blocks,i*4+3);\n\n    k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL32(h1,19); h1 += h2; h1 = h1*5+0x561ccd1b;\n\n    k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n    h2 = ROTL32(h2,17); h2 += h3; h2 = h2*5+0x0bcaa747;\n\n    k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n    h3 = ROTL32(h3,15); h3 += h4; h3 = h3*5+0x96cd1c35;\n\n    k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n    h4 = ROTL32(h4,13); h4 += h1; h4 = h4*5+0x32ac3b17;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint32_t k1 = 0;\n  uint32_t k2 = 0;\n  uint32_t k3 = 0;\n  uint32_t k4 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k4 ^= tail[14] << 16;\n  case 14: k4 ^= tail[13] << 8;\n  case 13: k4 ^= tail[12] << 0;\n           k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n  case 12: k3 ^= tail[11] << 24;\n  case 11: k3 ^= tail[10] << 16;\n  case 10: k3 ^= tail[ 9] << 8;\n  case  9: k3 ^= tail[ 8] << 0;\n           k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n  case  8: k2 ^= tail[ 7] << 24;\n  case  7: k2 ^= tail[ 6] << 16;\n  case  6: k2 ^= tail[ 5] << 8;\n  case  5: k2 ^= tail[ 4] << 0;\n           k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n  case  4: k1 ^= tail[ 3] << 24;\n  case  3: k1 ^= tail[ 2] << 16;\n  case  2: k1 ^= tail[ 1] << 8;\n  case  1: k1 ^= tail[ 0] << 0;\n           k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len; h3 ^= len; h4 ^= len;\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  h1 = fmix32(h1);\n  h2 = fmix32(h2);\n  h3 = fmix32(h3);\n  h4 = fmix32(h4);\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  ((uint32_t*)out)[0] = h1;\n  ((uint32_t*)out)[1] = h2;\n  ((uint32_t*)out)[2] = h3;\n  ((uint32_t*)out)[3] = h4;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x64_128 ( const void * key, const int len,\n                           const uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint64_t h1 = seed;\n  uint64_t h2 = seed;\n\n  const uint64_t c1 = BIG_CONSTANT(0x87c37b91114253d5);\n  const uint64_t c2 = BIG_CONSTANT(0x4cf5ad432745937f);\n\n  //----------\n  // body\n\n  const uint64_t * blocks = (const uint64_t *)(data);\n\n  for(int i = 0; i < nblocks; i++)\n  {\n    uint64_t k1 = getblock64(blocks,i*2+0);\n    uint64_t k2 = getblock64(blocks,i*2+1);\n\n    k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL64(h1,27); h1 += h2; h1 = h1*5+0x52dce729;\n\n    k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n    h2 = ROTL64(h2,31); h2 += h1; h2 = h2*5+0x38495ab5;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint64_t k1 = 0;\n  uint64_t k2 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k2 ^= ((uint64_t)tail[14]) << 48;\n  case 14: k2 ^= ((uint64_t)tail[13]) << 40;\n  case 13: k2 ^= ((uint64_t)tail[12]) << 32;\n  case 12: k2 ^= ((uint64_t)tail[11]) << 24;\n  case 11: k2 ^= ((uint64_t)tail[10]) << 16;\n  case 10: k2 ^= ((uint64_t)tail[ 9]) << 8;\n  case  9: k2 ^= ((uint64_t)tail[ 8]) << 0;\n           k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n  case  8: k1 ^= ((uint64_t)tail[ 7]) << 56;\n  case  7: k1 ^= ((uint64_t)tail[ 6]) << 48;\n  case  6: k1 ^= ((uint64_t)tail[ 5]) << 40;\n  case  5: k1 ^= ((uint64_t)tail[ 4]) << 32;\n  case  4: k1 ^= ((uint64_t)tail[ 3]) << 24;\n  case  3: k1 ^= ((uint64_t)tail[ 2]) << 16;\n  case  2: k1 ^= ((uint64_t)tail[ 1]) << 8;\n  case  1: k1 ^= ((uint64_t)tail[ 0]) << 0;\n           k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len;\n\n  h1 += h2;\n  h2 += h1;\n\n  h1 = fmix64(h1);\n  h2 = fmix64(h2);\n\n  h1 += h2;\n  h2 += h1;\n\n  ((uint64_t*)out)[0] = h1;\n  ((uint64_t*)out)[1] = h2;\n}\n\n//-----------------------------------------------------------------------------\n```\n\n\n---\n\n<br/>\n**参考**\n[Fvn Hash Funciton wikipedia](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function)\nhttps://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp","slug":"哈希-Hash-函数汇总","published":1,"updated":"2021-06-30T02:33:24.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxm009jr5p740eedl12","content":"<br>\n## Fnv\n\n<h3 id=\"FNV-1-hash\"><a href=\"#FNV-1-hash\" class=\"headerlink\" title=\"FNV-1 hash\"></a>FNV-1 hash</h3><pre class=\" language-c\"><code class=\"language-c\">    hash <span class=\"token operator\">=</span> FNV_offset_basis\n    <span class=\"token keyword\">for</span> each byte_of_data to be hashed\n           hash <span class=\"token operator\">=</span> hash × FNV_prime\n           hash <span class=\"token operator\">=</span> hash XOR byte_of_data\n    <span class=\"token keyword\">return</span> hash\n</code></pre>\n<h3 id=\"FNV-1a-hash\"><a href=\"#FNV-1a-hash\" class=\"headerlink\" title=\"FNV-1a hash\"></a>FNV-1a hash</h3><pre class=\" language-c\"><code class=\"language-c\">    hash <span class=\"token operator\">=</span> FNV_offset_basis\n    <span class=\"token keyword\">for</span> each byte_of_data to be hashed\n           hash <span class=\"token operator\">=</span> hash XOR byte_of_data\n           hash <span class=\"token operator\">=</span> hash × FNV_prime\n    <span class=\"token keyword\">return</span> hash\n</code></pre>\n<h3 id=\"FNV-0-hash-Deprecated\"><a href=\"#FNV-0-hash-Deprecated\" class=\"headerlink\" title=\"FNV-0 hash (Deprecated)\"></a>FNV-0 hash (Deprecated)</h3><pre class=\" language-c\"><code class=\"language-c\">    hash <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> each byte_of_data to be hashed\n           hash <span class=\"token operator\">=</span> hash × FNV_prime\n           hash <span class=\"token operator\">=</span> hash XOR octet_of_data\n    <span class=\"token keyword\">return</span> hash\n</code></pre>\n<h3 id=\"FNV-parameters\"><a href=\"#FNV-parameters\" class=\"headerlink\" title=\"FNV parameters\"></a>FNV parameters</h3><table>\n<thead>\n<tr>\n<th align=\"center\">Size in bits</th>\n<th align=\"center\">FNV prime</th>\n<th align=\"center\">FNV offset basis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">32</td>\n<td align=\"center\">224 + 28 + 0x93 = <br>16777619</td>\n<td align=\"center\">2166136261 = <br>0x811c9dc5</td>\n</tr>\n<tr>\n<td align=\"center\">64</td>\n<td align=\"center\">240 + 28 + 0xb3 = <br>1099511628211</td>\n<td align=\"center\">14695981039346656037 = <br>0xcbf29ce484222325</td>\n</tr>\n<tr>\n<td align=\"center\">128</td>\n<td align=\"center\">288 + 28 + 0x3b = <br>309485009821345068724781371</td>\n<td align=\"center\">144066263297769815596495629667062367629 <br>= <br>0x6c62272e07bb014262b821756295c58d</td>\n</tr>\n<tr>\n<td align=\"center\">256</td>\n<td align=\"center\">2168 + 28 + 0x63 = <br>374144419156711147060143317<br>175368453031918731002211</td>\n<td align=\"center\">100029257958052580907070968620625704837<br>092796014241193945225284501741471925557 <br>= <br>0xdd268dbcaac550362d98c384c4e576ccc8b153<br>6847b6bbb31023b4c8caee0535</td>\n</tr>\n<tr>\n<td align=\"center\">512</td>\n<td align=\"center\">2344 + 28 + 0x57 = <br>358359158748448673689190764<br>890951084499463279557543925<br>26094039892345713852759</td>\n<td align=\"center\">965930312949666949800943540071631046609<br>041874567263789610837432943446265799458<br>293219771643844981305189220653980578449<br>5328239340083876191928701583869517785 = <br>0xb86db0b1171f4416dca1e50f309990acac87d0<br>59c90000000000000000000d21e948f68a34c192<br>f62ea79bc942dbe7ce182036415f56e34bac982a<br>ac4afe9fd9</td>\n</tr>\n<tr>\n<td align=\"center\">1024</td>\n<td align=\"center\">2680 + 28 + 0x8d = <br>501645651011311865543459881<br>103527895503076534540479074<br>430301752383111205510814745<br>150915769222029538271616265<br>187852689524938529229181652<br>437508374669137180409427187<br>316048473796672026038921768<br>4476157468082573</td>\n<td align=\"center\">14197795064947621068722070641403218320<br>88062279544193396087847491461758272325<br>22967323037177221508640965212023555493<br>65628174669108571814760471015076148029<br>75596980407732015769245856300321530495<br>71501574036444603635505054127112859663<br>61610267868082893823963790439336411086<br>884584107735010676915 <br> = <br>0x0000000000000000 005f7a76758ecc4d 32e56d5a591028b7 4b29fc4223fdada1 <br>6c3bf34eda3674da 9a21d90000000000 0000000000000000 0000000000000000 <br>0000000000000000 0000000000000000 0000000000000000 000000000004c6d7 <br>eb6e73802734510a 555f256cc005ae55 6bde8cc9c6a93b21 aff4b16c71ee90b3</td>\n</tr>\n</tbody></table>\n<h3 id=\"具体列子\"><a href=\"#具体列子\" class=\"headerlink\" title=\"具体列子\"></a>具体列子</h3><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">long</span> <span class=\"token function\">fnv_1a_64</span><span class=\"token punctuation\">(</span>String value<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>value <span class=\"token operator\">==</span> null<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">long</span> hash <span class=\"token operator\">=</span> FNV_1A_64_BASIC<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> value<span class=\"token punctuation\">.</span><span class=\"token function\">length</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">char</span> c <span class=\"token operator\">=</span> value<span class=\"token punctuation\">.</span><span class=\"token function\">charAt</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            hash <span class=\"token operator\">^=</span> c<span class=\"token punctuation\">;</span>\n            hash <span class=\"token operator\">*=</span> FNV_1A_64_PRIME<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> hash<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">long</span> <span class=\"token function\">fnv_1a_64_lower</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">long</span> hash <span class=\"token operator\">=</span> FNV_1A_64_BASIC<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> key<span class=\"token punctuation\">.</span><span class=\"token function\">length</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">char</span> c <span class=\"token operator\">=</span> key<span class=\"token punctuation\">.</span><span class=\"token function\">charAt</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>c <span class=\"token operator\">>=</span> <span class=\"token string\">'A'</span> <span class=\"token operator\">&amp;&amp;</span> c <span class=\"token operator\">&lt;=</span> <span class=\"token string\">'Z'</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                c <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">char</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span>c <span class=\"token operator\">+</span> <span class=\"token number\">32</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n\n            hash <span class=\"token operator\">^=</span> c<span class=\"token punctuation\">;</span>\n            hash <span class=\"token operator\">*=</span> FNV_1A_64_PRIME<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> hash<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre>\n<h2 id=\"MurmurHash3\"><a href=\"#MurmurHash3\" class=\"headerlink\" title=\"MurmurHash3\"></a>MurmurHash3</h2><pre class=\" language-c++\"><code class=\"language-c++\">//-----------------------------------------------------------------------------\n// MurmurHash3 was written by Austin Appleby, and is placed in the public\n// domain. The author hereby disclaims copyright to this source code.\n\n// Note - The x86 and x64 versions do _not_ produce the same results, as the\n// algorithms are optimized for their respective platforms. You can still\n// compile and run any of them on any platform, but your performance with the\n// non-native version will be less than optimal.\n\n#include \"MurmurHash3.h\"\n\n//-----------------------------------------------------------------------------\n// Platform-specific functions and macros\n\n// Microsoft Visual Studio\n\n#if defined(_MSC_VER)\n\n#define FORCE_INLINE    __forceinline\n\n#include <stdlib.h>\n\n#define ROTL32(x,y)    _rotl(x,y)\n#define ROTL64(x,y)    _rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x)\n\n// Other compilers\n\n#else    // defined(_MSC_VER)\n\n#define    FORCE_INLINE inline __attribute__((always_inline))\n\ninline uint32_t rotl32 ( uint32_t x, int8_t r )\n{\n  return (x << r) | (x >> (32 - r));\n}\n\ninline uint64_t rotl64 ( uint64_t x, int8_t r )\n{\n  return (x << r) | (x >> (64 - r));\n}\n\n#define    ROTL32(x,y)    rotl32(x,y)\n#define ROTL64(x,y)    rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x##LLU)\n\n#endif // !defined(_MSC_VER)\n\n//-----------------------------------------------------------------------------\n// Block read - if your platform needs to do endian-swapping or can only\n// handle aligned reads, do the conversion here\n\nFORCE_INLINE uint32_t getblock32 ( const uint32_t * p, int i )\n{\n  return p[i];\n}\n\nFORCE_INLINE uint64_t getblock64 ( const uint64_t * p, int i )\n{\n  return p[i];\n}\n\n//-----------------------------------------------------------------------------\n// Finalization mix - force all bits of a hash block to avalanche\n\nFORCE_INLINE uint32_t fmix32 ( uint32_t h )\n{\n  h ^= h >> 16;\n  h *= 0x85ebca6b;\n  h ^= h >> 13;\n  h *= 0xc2b2ae35;\n  h ^= h >> 16;\n\n  return h;\n}\n\n//----------\n\nFORCE_INLINE uint64_t fmix64 ( uint64_t k )\n{\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xff51afd7ed558ccd);\n  k ^= k >> 33;\n  k *= BIG_CONSTANT(0xc4ceb9fe1a85ec53);\n  k ^= k >> 33;\n\n  return k;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_32 ( const void * key, int len,\n                          uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 4;\n\n  uint32_t h1 = seed;\n\n  const uint32_t c1 = 0xcc9e2d51;\n  const uint32_t c2 = 0x1b873593;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*4);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i);\n\n    k1 *= c1;\n    k1 = ROTL32(k1,15);\n    k1 *= c2;\n    \n    h1 ^= k1;\n    h1 = ROTL32(h1,13); \n    h1 = h1*5+0xe6546b64;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*4);\n\n  uint32_t k1 = 0;\n\n  switch(len & 3)\n  {\n  case 3: k1 ^= tail[2] << 16;\n  case 2: k1 ^= tail[1] << 8;\n  case 1: k1 ^= tail[0];\n          k1 *= c1; k1 = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len;\n\n  h1 = fmix32(h1);\n\n  *(uint32_t*)out = h1;\n} \n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_128 ( const void * key, const int len,\n                           uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint32_t h1 = seed;\n  uint32_t h2 = seed;\n  uint32_t h3 = seed;\n  uint32_t h4 = seed;\n\n  const uint32_t c1 = 0x239b961b; \n  const uint32_t c2 = 0xab0e9789;\n  const uint32_t c3 = 0x38b34ae5; \n  const uint32_t c4 = 0xa1e38b93;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*16);\n\n  for(int i = -nblocks; i; i++)\n  {\n    uint32_t k1 = getblock32(blocks,i*4+0);\n    uint32_t k2 = getblock32(blocks,i*4+1);\n    uint32_t k3 = getblock32(blocks,i*4+2);\n    uint32_t k4 = getblock32(blocks,i*4+3);\n\n    k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL32(h1,19); h1 += h2; h1 = h1*5+0x561ccd1b;\n\n    k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n    h2 = ROTL32(h2,17); h2 += h3; h2 = h2*5+0x0bcaa747;\n\n    k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n    h3 = ROTL32(h3,15); h3 += h4; h3 = h3*5+0x96cd1c35;\n\n    k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n    h4 = ROTL32(h4,13); h4 += h1; h4 = h4*5+0x32ac3b17;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint32_t k1 = 0;\n  uint32_t k2 = 0;\n  uint32_t k3 = 0;\n  uint32_t k4 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k4 ^= tail[14] << 16;\n  case 14: k4 ^= tail[13] << 8;\n  case 13: k4 ^= tail[12] << 0;\n           k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n  case 12: k3 ^= tail[11] << 24;\n  case 11: k3 ^= tail[10] << 16;\n  case 10: k3 ^= tail[ 9] << 8;\n  case  9: k3 ^= tail[ 8] << 0;\n           k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n  case  8: k2 ^= tail[ 7] << 24;\n  case  7: k2 ^= tail[ 6] << 16;\n  case  6: k2 ^= tail[ 5] << 8;\n  case  5: k2 ^= tail[ 4] << 0;\n           k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n  case  4: k1 ^= tail[ 3] << 24;\n  case  3: k1 ^= tail[ 2] << 16;\n  case  2: k1 ^= tail[ 1] << 8;\n  case  1: k1 ^= tail[ 0] << 0;\n           k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len; h3 ^= len; h4 ^= len;\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  h1 = fmix32(h1);\n  h2 = fmix32(h2);\n  h3 = fmix32(h3);\n  h4 = fmix32(h4);\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  ((uint32_t*)out)[0] = h1;\n  ((uint32_t*)out)[1] = h2;\n  ((uint32_t*)out)[2] = h3;\n  ((uint32_t*)out)[3] = h4;\n}\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x64_128 ( const void * key, const int len,\n                           const uint32_t seed, void * out )\n{\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint64_t h1 = seed;\n  uint64_t h2 = seed;\n\n  const uint64_t c1 = BIG_CONSTANT(0x87c37b91114253d5);\n  const uint64_t c2 = BIG_CONSTANT(0x4cf5ad432745937f);\n\n  //----------\n  // body\n\n  const uint64_t * blocks = (const uint64_t *)(data);\n\n  for(int i = 0; i < nblocks; i++)\n  {\n    uint64_t k1 = getblock64(blocks,i*2+0);\n    uint64_t k2 = getblock64(blocks,i*2+1);\n\n    k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL64(h1,27); h1 += h2; h1 = h1*5+0x52dce729;\n\n    k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n    h2 = ROTL64(h2,31); h2 += h1; h2 = h2*5+0x38495ab5;\n  }\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint64_t k1 = 0;\n  uint64_t k2 = 0;\n\n  switch(len & 15)\n  {\n  case 15: k2 ^= ((uint64_t)tail[14]) << 48;\n  case 14: k2 ^= ((uint64_t)tail[13]) << 40;\n  case 13: k2 ^= ((uint64_t)tail[12]) << 32;\n  case 12: k2 ^= ((uint64_t)tail[11]) << 24;\n  case 11: k2 ^= ((uint64_t)tail[10]) << 16;\n  case 10: k2 ^= ((uint64_t)tail[ 9]) << 8;\n  case  9: k2 ^= ((uint64_t)tail[ 8]) << 0;\n           k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n  case  8: k1 ^= ((uint64_t)tail[ 7]) << 56;\n  case  7: k1 ^= ((uint64_t)tail[ 6]) << 48;\n  case  6: k1 ^= ((uint64_t)tail[ 5]) << 40;\n  case  5: k1 ^= ((uint64_t)tail[ 4]) << 32;\n  case  4: k1 ^= ((uint64_t)tail[ 3]) << 24;\n  case  3: k1 ^= ((uint64_t)tail[ 2]) << 16;\n  case  2: k1 ^= ((uint64_t)tail[ 1]) << 8;\n  case  1: k1 ^= ((uint64_t)tail[ 0]) << 0;\n           k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n  };\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len;\n\n  h1 += h2;\n  h2 += h1;\n\n  h1 = fmix64(h1);\n  h2 = fmix64(h2);\n\n  h1 += h2;\n  h2 += h1;\n\n  ((uint64_t*)out)[0] = h1;\n  ((uint64_t*)out)[1] = h2;\n}\n\n//-----------------------------------------------------------------------------\n</code></pre>\n<hr>\n<br>\n**参考**\n[Fvn Hash Funciton wikipedia](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function)\nhttps://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp","site":{"data":{}},"excerpt":"","more":"<br/>\n## Fnv\n\n<h3 id=\"FNV-1-hash\"><a href=\"#FNV-1-hash\" class=\"headerlink\" title=\"FNV-1 hash\"></a>FNV-1 hash</h3><pre><code class=\"c\">    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n           hash = hash × FNV_prime\n           hash = hash XOR byte_of_data\n    return hash\n</code></pre>\n<h3 id=\"FNV-1a-hash\"><a href=\"#FNV-1a-hash\" class=\"headerlink\" title=\"FNV-1a hash\"></a>FNV-1a hash</h3><pre><code class=\"c\">    hash = FNV_offset_basis\n    for each byte_of_data to be hashed\n           hash = hash XOR byte_of_data\n           hash = hash × FNV_prime\n    return hash\n</code></pre>\n<h3 id=\"FNV-0-hash-Deprecated\"><a href=\"#FNV-0-hash-Deprecated\" class=\"headerlink\" title=\"FNV-0 hash (Deprecated)\"></a>FNV-0 hash (Deprecated)</h3><pre><code class=\"c\">    hash = 0\n    for each byte_of_data to be hashed\n           hash = hash × FNV_prime\n           hash = hash XOR octet_of_data\n    return hash\n</code></pre>\n<h3 id=\"FNV-parameters\"><a href=\"#FNV-parameters\" class=\"headerlink\" title=\"FNV parameters\"></a>FNV parameters</h3><table>\n<thead>\n<tr>\n<th align=\"center\">Size in bits</th>\n<th align=\"center\">FNV prime</th>\n<th align=\"center\">FNV offset basis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">32</td>\n<td align=\"center\">224 + 28 + 0x93 = <br/>16777619</td>\n<td align=\"center\">2166136261 = <br/>0x811c9dc5</td>\n</tr>\n<tr>\n<td align=\"center\">64</td>\n<td align=\"center\">240 + 28 + 0xb3 = <br/>1099511628211</td>\n<td align=\"center\">14695981039346656037 = <br/>0xcbf29ce484222325</td>\n</tr>\n<tr>\n<td align=\"center\">128</td>\n<td align=\"center\">288 + 28 + 0x3b = <br/>309485009821345068724781371</td>\n<td align=\"center\">144066263297769815596495629667062367629 <br/>= <br/>0x6c62272e07bb014262b821756295c58d</td>\n</tr>\n<tr>\n<td align=\"center\">256</td>\n<td align=\"center\">2168 + 28 + 0x63 = <br/>374144419156711147060143317<br/>175368453031918731002211</td>\n<td align=\"center\">100029257958052580907070968620625704837<br/>092796014241193945225284501741471925557 <br/>= <br/>0xdd268dbcaac550362d98c384c4e576ccc8b153<br/>6847b6bbb31023b4c8caee0535</td>\n</tr>\n<tr>\n<td align=\"center\">512</td>\n<td align=\"center\">2344 + 28 + 0x57 = <br/>358359158748448673689190764<br/>890951084499463279557543925<br/>26094039892345713852759</td>\n<td align=\"center\">965930312949666949800943540071631046609<br/>041874567263789610837432943446265799458<br/>293219771643844981305189220653980578449<br/>5328239340083876191928701583869517785 = <br/>0xb86db0b1171f4416dca1e50f309990acac87d0<br/>59c90000000000000000000d21e948f68a34c192<br/>f62ea79bc942dbe7ce182036415f56e34bac982a<br/>ac4afe9fd9</td>\n</tr>\n<tr>\n<td align=\"center\">1024</td>\n<td align=\"center\">2680 + 28 + 0x8d = <br/>501645651011311865543459881<br/>103527895503076534540479074<br/>430301752383111205510814745<br/>150915769222029538271616265<br/>187852689524938529229181652<br/>437508374669137180409427187<br/>316048473796672026038921768<br/>4476157468082573</td>\n<td align=\"center\">14197795064947621068722070641403218320<br/>88062279544193396087847491461758272325<br/>22967323037177221508640965212023555493<br/>65628174669108571814760471015076148029<br/>75596980407732015769245856300321530495<br/>71501574036444603635505054127112859663<br/>61610267868082893823963790439336411086<br/>884584107735010676915 <br/> = <br/>0x0000000000000000 005f7a76758ecc4d 32e56d5a591028b7 4b29fc4223fdada1 <br/>6c3bf34eda3674da 9a21d90000000000 0000000000000000 0000000000000000 <br/>0000000000000000 0000000000000000 0000000000000000 000000000004c6d7 <br/>eb6e73802734510a 555f256cc005ae55 6bde8cc9c6a93b21 aff4b16c71ee90b3</td>\n</tr>\n</tbody></table>\n<h3 id=\"具体列子\"><a href=\"#具体列子\" class=\"headerlink\" title=\"具体列子\"></a>具体列子</h3><pre><code class=\"java\">public static long fnv_1a_64(String value) &#123;\n        if (value == null) &#123;\n            return 0;\n        &#125;\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i &lt; value.length(); i++) &#123;\n            char c = value.charAt(i);\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        &#125;\n\n        return hash;\n    &#125;\n\n    public static long fnv_1a_64_lower(String key) &#123;\n        long hash = FNV_1A_64_BASIC;\n        for (int i = 0; i &lt; key.length(); ++i) &#123;\n            char c = key.charAt(i);\n\n            if (c &gt;= &#39;A&#39; &amp;&amp; c &lt;= &#39;Z&#39;) &#123;\n                c = (char) (c + 32);\n            &#125;\n\n            hash ^= c;\n            hash *= FNV_1A_64_PRIME;\n        &#125;\n\n        return hash;\n    &#125;\n</code></pre>\n<h2 id=\"MurmurHash3\"><a href=\"#MurmurHash3\" class=\"headerlink\" title=\"MurmurHash3\"></a>MurmurHash3</h2><pre><code class=\"c++\">//-----------------------------------------------------------------------------\n// MurmurHash3 was written by Austin Appleby, and is placed in the public\n// domain. The author hereby disclaims copyright to this source code.\n\n// Note - The x86 and x64 versions do _not_ produce the same results, as the\n// algorithms are optimized for their respective platforms. You can still\n// compile and run any of them on any platform, but your performance with the\n// non-native version will be less than optimal.\n\n#include &quot;MurmurHash3.h&quot;\n\n//-----------------------------------------------------------------------------\n// Platform-specific functions and macros\n\n// Microsoft Visual Studio\n\n#if defined(_MSC_VER)\n\n#define FORCE_INLINE    __forceinline\n\n#include &lt;stdlib.h&gt;\n\n#define ROTL32(x,y)    _rotl(x,y)\n#define ROTL64(x,y)    _rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x)\n\n// Other compilers\n\n#else    // defined(_MSC_VER)\n\n#define    FORCE_INLINE inline __attribute__((always_inline))\n\ninline uint32_t rotl32 ( uint32_t x, int8_t r )\n&#123;\n  return (x &lt;&lt; r) | (x &gt;&gt; (32 - r));\n&#125;\n\ninline uint64_t rotl64 ( uint64_t x, int8_t r )\n&#123;\n  return (x &lt;&lt; r) | (x &gt;&gt; (64 - r));\n&#125;\n\n#define    ROTL32(x,y)    rotl32(x,y)\n#define ROTL64(x,y)    rotl64(x,y)\n\n#define BIG_CONSTANT(x) (x##LLU)\n\n#endif // !defined(_MSC_VER)\n\n//-----------------------------------------------------------------------------\n// Block read - if your platform needs to do endian-swapping or can only\n// handle aligned reads, do the conversion here\n\nFORCE_INLINE uint32_t getblock32 ( const uint32_t * p, int i )\n&#123;\n  return p[i];\n&#125;\n\nFORCE_INLINE uint64_t getblock64 ( const uint64_t * p, int i )\n&#123;\n  return p[i];\n&#125;\n\n//-----------------------------------------------------------------------------\n// Finalization mix - force all bits of a hash block to avalanche\n\nFORCE_INLINE uint32_t fmix32 ( uint32_t h )\n&#123;\n  h ^= h &gt;&gt; 16;\n  h *= 0x85ebca6b;\n  h ^= h &gt;&gt; 13;\n  h *= 0xc2b2ae35;\n  h ^= h &gt;&gt; 16;\n\n  return h;\n&#125;\n\n//----------\n\nFORCE_INLINE uint64_t fmix64 ( uint64_t k )\n&#123;\n  k ^= k &gt;&gt; 33;\n  k *= BIG_CONSTANT(0xff51afd7ed558ccd);\n  k ^= k &gt;&gt; 33;\n  k *= BIG_CONSTANT(0xc4ceb9fe1a85ec53);\n  k ^= k &gt;&gt; 33;\n\n  return k;\n&#125;\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_32 ( const void * key, int len,\n                          uint32_t seed, void * out )\n&#123;\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 4;\n\n  uint32_t h1 = seed;\n\n  const uint32_t c1 = 0xcc9e2d51;\n  const uint32_t c2 = 0x1b873593;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*4);\n\n  for(int i = -nblocks; i; i++)\n  &#123;\n    uint32_t k1 = getblock32(blocks,i);\n\n    k1 *= c1;\n    k1 = ROTL32(k1,15);\n    k1 *= c2;\n    \n    h1 ^= k1;\n    h1 = ROTL32(h1,13); \n    h1 = h1*5+0xe6546b64;\n  &#125;\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*4);\n\n  uint32_t k1 = 0;\n\n  switch(len &amp; 3)\n  &#123;\n  case 3: k1 ^= tail[2] &lt;&lt; 16;\n  case 2: k1 ^= tail[1] &lt;&lt; 8;\n  case 1: k1 ^= tail[0];\n          k1 *= c1; k1 = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  &#125;;\n\n  //----------\n  // finalization\n\n  h1 ^= len;\n\n  h1 = fmix32(h1);\n\n  *(uint32_t*)out = h1;\n&#125; \n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x86_128 ( const void * key, const int len,\n                           uint32_t seed, void * out )\n&#123;\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint32_t h1 = seed;\n  uint32_t h2 = seed;\n  uint32_t h3 = seed;\n  uint32_t h4 = seed;\n\n  const uint32_t c1 = 0x239b961b; \n  const uint32_t c2 = 0xab0e9789;\n  const uint32_t c3 = 0x38b34ae5; \n  const uint32_t c4 = 0xa1e38b93;\n\n  //----------\n  // body\n\n  const uint32_t * blocks = (const uint32_t *)(data + nblocks*16);\n\n  for(int i = -nblocks; i; i++)\n  &#123;\n    uint32_t k1 = getblock32(blocks,i*4+0);\n    uint32_t k2 = getblock32(blocks,i*4+1);\n    uint32_t k3 = getblock32(blocks,i*4+2);\n    uint32_t k4 = getblock32(blocks,i*4+3);\n\n    k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL32(h1,19); h1 += h2; h1 = h1*5+0x561ccd1b;\n\n    k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n    h2 = ROTL32(h2,17); h2 += h3; h2 = h2*5+0x0bcaa747;\n\n    k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n    h3 = ROTL32(h3,15); h3 += h4; h3 = h3*5+0x96cd1c35;\n\n    k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n    h4 = ROTL32(h4,13); h4 += h1; h4 = h4*5+0x32ac3b17;\n  &#125;\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint32_t k1 = 0;\n  uint32_t k2 = 0;\n  uint32_t k3 = 0;\n  uint32_t k4 = 0;\n\n  switch(len &amp; 15)\n  &#123;\n  case 15: k4 ^= tail[14] &lt;&lt; 16;\n  case 14: k4 ^= tail[13] &lt;&lt; 8;\n  case 13: k4 ^= tail[12] &lt;&lt; 0;\n           k4 *= c4; k4  = ROTL32(k4,18); k4 *= c1; h4 ^= k4;\n\n  case 12: k3 ^= tail[11] &lt;&lt; 24;\n  case 11: k3 ^= tail[10] &lt;&lt; 16;\n  case 10: k3 ^= tail[ 9] &lt;&lt; 8;\n  case  9: k3 ^= tail[ 8] &lt;&lt; 0;\n           k3 *= c3; k3  = ROTL32(k3,17); k3 *= c4; h3 ^= k3;\n\n  case  8: k2 ^= tail[ 7] &lt;&lt; 24;\n  case  7: k2 ^= tail[ 6] &lt;&lt; 16;\n  case  6: k2 ^= tail[ 5] &lt;&lt; 8;\n  case  5: k2 ^= tail[ 4] &lt;&lt; 0;\n           k2 *= c2; k2  = ROTL32(k2,16); k2 *= c3; h2 ^= k2;\n\n  case  4: k1 ^= tail[ 3] &lt;&lt; 24;\n  case  3: k1 ^= tail[ 2] &lt;&lt; 16;\n  case  2: k1 ^= tail[ 1] &lt;&lt; 8;\n  case  1: k1 ^= tail[ 0] &lt;&lt; 0;\n           k1 *= c1; k1  = ROTL32(k1,15); k1 *= c2; h1 ^= k1;\n  &#125;;\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len; h3 ^= len; h4 ^= len;\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  h1 = fmix32(h1);\n  h2 = fmix32(h2);\n  h3 = fmix32(h3);\n  h4 = fmix32(h4);\n\n  h1 += h2; h1 += h3; h1 += h4;\n  h2 += h1; h3 += h1; h4 += h1;\n\n  ((uint32_t*)out)[0] = h1;\n  ((uint32_t*)out)[1] = h2;\n  ((uint32_t*)out)[2] = h3;\n  ((uint32_t*)out)[3] = h4;\n&#125;\n\n//-----------------------------------------------------------------------------\n\nvoid MurmurHash3_x64_128 ( const void * key, const int len,\n                           const uint32_t seed, void * out )\n&#123;\n  const uint8_t * data = (const uint8_t*)key;\n  const int nblocks = len / 16;\n\n  uint64_t h1 = seed;\n  uint64_t h2 = seed;\n\n  const uint64_t c1 = BIG_CONSTANT(0x87c37b91114253d5);\n  const uint64_t c2 = BIG_CONSTANT(0x4cf5ad432745937f);\n\n  //----------\n  // body\n\n  const uint64_t * blocks = (const uint64_t *)(data);\n\n  for(int i = 0; i &lt; nblocks; i++)\n  &#123;\n    uint64_t k1 = getblock64(blocks,i*2+0);\n    uint64_t k2 = getblock64(blocks,i*2+1);\n\n    k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n\n    h1 = ROTL64(h1,27); h1 += h2; h1 = h1*5+0x52dce729;\n\n    k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n    h2 = ROTL64(h2,31); h2 += h1; h2 = h2*5+0x38495ab5;\n  &#125;\n\n  //----------\n  // tail\n\n  const uint8_t * tail = (const uint8_t*)(data + nblocks*16);\n\n  uint64_t k1 = 0;\n  uint64_t k2 = 0;\n\n  switch(len &amp; 15)\n  &#123;\n  case 15: k2 ^= ((uint64_t)tail[14]) &lt;&lt; 48;\n  case 14: k2 ^= ((uint64_t)tail[13]) &lt;&lt; 40;\n  case 13: k2 ^= ((uint64_t)tail[12]) &lt;&lt; 32;\n  case 12: k2 ^= ((uint64_t)tail[11]) &lt;&lt; 24;\n  case 11: k2 ^= ((uint64_t)tail[10]) &lt;&lt; 16;\n  case 10: k2 ^= ((uint64_t)tail[ 9]) &lt;&lt; 8;\n  case  9: k2 ^= ((uint64_t)tail[ 8]) &lt;&lt; 0;\n           k2 *= c2; k2  = ROTL64(k2,33); k2 *= c1; h2 ^= k2;\n\n  case  8: k1 ^= ((uint64_t)tail[ 7]) &lt;&lt; 56;\n  case  7: k1 ^= ((uint64_t)tail[ 6]) &lt;&lt; 48;\n  case  6: k1 ^= ((uint64_t)tail[ 5]) &lt;&lt; 40;\n  case  5: k1 ^= ((uint64_t)tail[ 4]) &lt;&lt; 32;\n  case  4: k1 ^= ((uint64_t)tail[ 3]) &lt;&lt; 24;\n  case  3: k1 ^= ((uint64_t)tail[ 2]) &lt;&lt; 16;\n  case  2: k1 ^= ((uint64_t)tail[ 1]) &lt;&lt; 8;\n  case  1: k1 ^= ((uint64_t)tail[ 0]) &lt;&lt; 0;\n           k1 *= c1; k1  = ROTL64(k1,31); k1 *= c2; h1 ^= k1;\n  &#125;;\n\n  //----------\n  // finalization\n\n  h1 ^= len; h2 ^= len;\n\n  h1 += h2;\n  h2 += h1;\n\n  h1 = fmix64(h1);\n  h2 = fmix64(h2);\n\n  h1 += h2;\n  h2 += h1;\n\n  ((uint64_t*)out)[0] = h1;\n  ((uint64_t*)out)[1] = h2;\n&#125;\n\n//-----------------------------------------------------------------------------\n</code></pre>\n<hr>\n<br/>\n**参考**\n[Fvn Hash Funciton wikipedia](https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function)\nhttps://github.com/aappleby/smhasher/blob/master/src/MurmurHash3.cpp"},{"title":"卷积神经网络(CNN)","date":"2018-12-01T07:22:04.000Z","_content":"\n`卷积神经网络`（Convolutional Neural Network, `CNN`）是一种`前馈神经网络`，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n---\n\n\n\n\n### 应用\n图片识别\n视频识别\n自然语言处理\n围棋\n\n<br/>\n\n---\n参考\n\n","source":"_posts/卷积神经网络.md","raw":"---\ntitle: 卷积神经网络(CNN)\ndate: 2018-12-01 15:22:04\ncategories: \n    - 神经网络\ntags:\n    - 人工智能\n    - 神经网络\n    - 前馈神经网络\n    - 卷积神经网络\n---\n\n`卷积神经网络`（Convolutional Neural Network, `CNN`）是一种`前馈神经网络`，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n---\n\n\n\n\n### 应用\n图片识别\n视频识别\n自然语言处理\n围棋\n\n<br/>\n\n---\n参考\n\n","slug":"卷积神经网络","published":1,"updated":"2021-06-30T02:33:24.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxn009mr5p758j64jdt","content":"<p><code>卷积神经网络</code>（Convolutional Neural Network, <code>CNN</code>）是一种<code>前馈神经网络</code>，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n<hr>\n<h3 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h3><p>图片识别\n视频识别\n自然语言处理\n围棋</p>\n<br>\n\n<hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"<p><code>卷积神经网络</code>（Convolutional Neural Network, <code>CNN</code>）是一种<code>前馈神经网络</code>，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<hr>\n<h3 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h3><p>图片识别\n视频识别\n自然语言处理\n围棋</p>\n<br/>\n\n<hr>\n<p>参考</p>"},{"title":"微积分","date":"2008-09-01T00:01:02.000Z","_content":"\n极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n## 导数\n\n### 基本求导公式\n\n### 导数四则运算\n\n\n## 微分\n\n## 定积分\n\n## 不定积分\n\n\n<br/>\n\n---\n参考\n","source":"_posts/微积分.md","raw":"---\ntitle: 微积分\ndate: 2008-09-01 08:01:02\ncategories:\n    - 数学\ntags:\n    - 数学\n    - 高等数学\n    - 极限\n    - 微积分\n---\n\n极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n## 导数\n\n### 基本求导公式\n\n### 导数四则运算\n\n\n## 微分\n\n## 定积分\n\n## 不定积分\n\n\n<br/>\n\n---\n参考\n","slug":"微积分","published":1,"updated":"2021-06-30T02:33:24.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxo009qr5p79xw43yj0","content":"<p>极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<h2 id=\"导数\"><a href=\"#导数\" class=\"headerlink\" title=\"导数\"></a>导数</h2><h3 id=\"基本求导公式\"><a href=\"#基本求导公式\" class=\"headerlink\" title=\"基本求导公式\"></a>基本求导公式</h3><h3 id=\"导数四则运算\"><a href=\"#导数四则运算\" class=\"headerlink\" title=\"导数四则运算\"></a>导数四则运算</h3><h2 id=\"微分\"><a href=\"#微分\" class=\"headerlink\" title=\"微分\"></a>微分</h2><h2 id=\"定积分\"><a href=\"#定积分\" class=\"headerlink\" title=\"定积分\"></a>定积分</h2><h2 id=\"不定积分\"><a href=\"#不定积分\" class=\"headerlink\" title=\"不定积分\"></a>不定积分</h2><br>\n\n<hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"<p>极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<h2 id=\"导数\"><a href=\"#导数\" class=\"headerlink\" title=\"导数\"></a>导数</h2><h3 id=\"基本求导公式\"><a href=\"#基本求导公式\" class=\"headerlink\" title=\"基本求导公式\"></a>基本求导公式</h3><h3 id=\"导数四则运算\"><a href=\"#导数四则运算\" class=\"headerlink\" title=\"导数四则运算\"></a>导数四则运算</h3><h2 id=\"微分\"><a href=\"#微分\" class=\"headerlink\" title=\"微分\"></a>微分</h2><h2 id=\"定积分\"><a href=\"#定积分\" class=\"headerlink\" title=\"定积分\"></a>定积分</h2><h2 id=\"不定积分\"><a href=\"#不定积分\" class=\"headerlink\" title=\"不定积分\"></a>不定积分</h2><br/>\n\n<hr>\n<p>参考</p>"},{"title":"感知机算法","date":"2018-11-22T07:34:19.000Z","_content":"\n感知器（英语：Perceptron）是Frank Rosenblatt在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种`二元线性分类器`。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n<br/>\n### 定义\n感知器使用特征向量来表示的前馈神经网络，它是一种二元分类器，把矩阵上的输入 $x$（实数值向量）映射到输出值 $f(x)$ 上（一个二元的值）。\n\n$$ f(x)={\\begin{cases}1&{\\text{if }} w\\cdot x+b>0 \\\\\\ 0&{\\text{else}}\\end{cases}}$$\n\n<br/>\n### ss\n\n\n\n<br/>\n\n---\n参考\n李航《统计学习方法》\n周志华《机器学习》\n[wikipedia-感知机](https://en.wikipedia.org/wiki/Perceptron)","source":"_posts/感知机算法.md","raw":"---\ntitle: 感知机算法\ndate: 2018-11-22 15:34:19\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n    - 监督学习\n---\n\n感知器（英语：Perceptron）是Frank Rosenblatt在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种`二元线性分类器`。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n<br/>\n### 定义\n感知器使用特征向量来表示的前馈神经网络，它是一种二元分类器，把矩阵上的输入 $x$（实数值向量）映射到输出值 $f(x)$ 上（一个二元的值）。\n\n$$ f(x)={\\begin{cases}1&{\\text{if }} w\\cdot x+b>0 \\\\\\ 0&{\\text{else}}\\end{cases}}$$\n\n<br/>\n### ss\n\n\n\n<br/>\n\n---\n参考\n李航《统计学习方法》\n周志华《机器学习》\n[wikipedia-感知机](https://en.wikipedia.org/wiki/Perceptron)","slug":"感知机算法","published":1,"updated":"2021-06-30T02:33:24.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxq009ur5p76lpe9g8j","content":"<p>感知器（英语：Perceptron）是Frank Rosenblatt在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种<code>二元线性分类器</code>。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n<br>\n### 定义\n感知器使用特征向量来表示的前馈神经网络，它是一种二元分类器，把矩阵上的输入 $x$（实数值向量）映射到输出值 $f(x)$ 上（一个二元的值）。\n\n<p>$$ f(x)={\\begin{cases}1&amp;{\\text{if }} w\\cdot x+b&gt;0 \\\\ 0&amp;{\\text{else}}\\end{cases}}$$</p>\n<br>\n### ss\n\n\n\n<br>\n\n<hr>\n<p>参考\n李航《统计学习方法》\n周志华《机器学习》\n<a href=\"https://en.wikipedia.org/wiki/Perceptron\">wikipedia-感知机</a></p>\n","site":{"data":{}},"excerpt":"<p>感知器（英语：Perceptron）是Frank Rosenblatt在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种<code>二元线性分类器</code>。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<br/>\n### 定义\n感知器使用特征向量来表示的前馈神经网络，它是一种二元分类器，把矩阵上的输入 $x$（实数值向量）映射到输出值 $f(x)$ 上（一个二元的值）。\n\n<p>$$ f(x)={\\begin{cases}1&amp;{\\text{if }} w\\cdot x+b&gt;0 \\\\ 0&amp;{\\text{else}}\\end{cases}}$$</p>\n<br/>\n### ss\n\n\n\n<br/>\n\n<hr>\n<p>参考\n李航《统计学习方法》\n周志华《机器学习》\n<a href=\"https://en.wikipedia.org/wiki/Perceptron\">wikipedia-感知机</a></p>"},{"title":"协方差","date":"2012-10-01T00:01:04.000Z","_content":"\n在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n\n$$$$\n\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-协方差](https://en.wikipedia.org/wiki/Covariance)","source":"_posts/协方差.md","raw":"---\ntitle: 协方差\ndate: 2012-10-01 08:01:04\ncategories: \n    - 概率与统计\ntags: \n    - 数学\n    - 概率与统计\n    - 方差\n---\n\n在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n\n$$$$\n\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-协方差](https://en.wikipedia.org/wiki/Covariance)","slug":"协方差","published":1,"updated":"2021-06-30T02:33:24.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxr009yr5p7f5ycdc3d","content":"<p>在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<span id=\"more\"></span>\n\n\n<br>\n### 定义\n\n\n<p>$$$$</p>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Covariance\">wikipedia-协方差</a></p>\n","site":{"data":{}},"excerpt":"<p>在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>","more":"<br/>\n### 定义\n\n\n<p>$$$$</p>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Covariance\">wikipedia-协方差</a></p>"},{"title":"排序算法汇总","date":"2018-12-06T12:09:48.000Z","_content":"\n##\n排序算法|平均|最好|最坏|是否稳定\n---|---| --- | --- | ---\n选择排序| - | - | - | -\n冒泡排序| - | - | - | - \n插入排序| - | - | - | -\n梳排序| - | - | - | -\n希尔排序| - | - | - | -\n快速排序| - | - | - | -\n归并排序| - | - | - | -\n堆排序| - | - | - | -\n计数排序| - | - | - | -\n桶排序| - | - | - | -\n二叉树排序| - | - | -| - \n\n## 排序算法\n### 选择排序\n\n### 冒泡排序\n```\n\n```\n\n### 插入排序\n\n### 梳排序\n```java\n/**\n * 梳排序\n * @param a\n * @return\n */\npublic static int[] combSort(int[] a) {\n    int N = a.length;\n    int step = N;\n    int k;\n    // 第一部分\n    while((step /= 1.3) > 1) {\n        for (int i = N-1; i >= step; i--) {\n            k = i -step;\n            if(a[k]>a[i]){\n                // 交换位置\n                exc(a, k, i);\n            }\n        }\n    }\n    // 第二部分：进行冒泡排序\n    a= bubbleSort2(a);\n    return a;\n}\n```\n\n### 希尔排序\n```java\n/**\n * shell排序\n * @param a\n * @return\n */\npublic static int[] shellSort(int[] a){\n    int N = a.length;\n    int h = 1;\n    // 增量序列\n    while(h < N/3){\n        // h = 1,4,13,40,……\n        h = h*3 + 1; \n    }\n\n    while(h>=1){\n        for (int i = h; i < N; i++) {\n            // 进行插入排序，诺a[j]比a[j-h]小，则向前挪动h\n            for (int j = i; j >= h && a[j-h]>a[j]; j -= h) {\n                exc(a, j, j-h);\n            }\n        }\n        h /= 3;\n    }\n    return a;\n}\n```\n\n\n----\n参考\nhttps://www.cnblogs.com/xiaohuiduan/p/11188304.html\n","source":"_posts/排序算法汇总.md","raw":"---\ntitle: 排序算法汇总\ndate: 2018-12-06 20:09:48\ncategories: \n    - 算法\ntags:\n    - 算法\n    - 排序\n---\n\n##\n排序算法|平均|最好|最坏|是否稳定\n---|---| --- | --- | ---\n选择排序| - | - | - | -\n冒泡排序| - | - | - | - \n插入排序| - | - | - | -\n梳排序| - | - | - | -\n希尔排序| - | - | - | -\n快速排序| - | - | - | -\n归并排序| - | - | - | -\n堆排序| - | - | - | -\n计数排序| - | - | - | -\n桶排序| - | - | - | -\n二叉树排序| - | - | -| - \n\n## 排序算法\n### 选择排序\n\n### 冒泡排序\n```\n\n```\n\n### 插入排序\n\n### 梳排序\n```java\n/**\n * 梳排序\n * @param a\n * @return\n */\npublic static int[] combSort(int[] a) {\n    int N = a.length;\n    int step = N;\n    int k;\n    // 第一部分\n    while((step /= 1.3) > 1) {\n        for (int i = N-1; i >= step; i--) {\n            k = i -step;\n            if(a[k]>a[i]){\n                // 交换位置\n                exc(a, k, i);\n            }\n        }\n    }\n    // 第二部分：进行冒泡排序\n    a= bubbleSort2(a);\n    return a;\n}\n```\n\n### 希尔排序\n```java\n/**\n * shell排序\n * @param a\n * @return\n */\npublic static int[] shellSort(int[] a){\n    int N = a.length;\n    int h = 1;\n    // 增量序列\n    while(h < N/3){\n        // h = 1,4,13,40,……\n        h = h*3 + 1; \n    }\n\n    while(h>=1){\n        for (int i = h; i < N; i++) {\n            // 进行插入排序，诺a[j]比a[j-h]小，则向前挪动h\n            for (int j = i; j >= h && a[j-h]>a[j]; j -= h) {\n                exc(a, j, j-h);\n            }\n        }\n        h /= 3;\n    }\n    return a;\n}\n```\n\n\n----\n参考\nhttps://www.cnblogs.com/xiaohuiduan/p/11188304.html\n","slug":"排序算法汇总","published":1,"updated":"2021-06-30T02:33:24.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxs00a1r5p76p0ed87d","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th>排序算法</th>\n<th>平均</th>\n<th>最好</th>\n<th>最坏</th>\n<th>是否稳定</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>选择排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>冒泡排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>梳排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>二叉树排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><h3 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h3><h3 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h3><pre><code>\n</code></pre>\n<h3 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h3><h3 id=\"梳排序\"><a href=\"#梳排序\" class=\"headerlink\" title=\"梳排序\"></a>梳排序</h3><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">/**\n * 梳排序\n * @param a\n * @return\n */</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token function\">combSort</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> a<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> a<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">int</span> step <span class=\"token operator\">=</span> N<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">int</span> k<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 第一部分</span>\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>step <span class=\"token operator\">/=</span> <span class=\"token number\">1.3</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> N<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">>=</span> step<span class=\"token punctuation\">;</span> i<span class=\"token operator\">--</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            k <span class=\"token operator\">=</span> i <span class=\"token operator\">-</span>step<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token operator\">></span>a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n                <span class=\"token comment\" spellcheck=\"true\">// 交换位置</span>\n                <span class=\"token function\">exc</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 第二部分：进行冒泡排序</span>\n    a<span class=\"token operator\">=</span> <span class=\"token function\">bubbleSort2</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> a<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h3 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h3><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">/**\n * shell排序\n * @param a\n * @return\n */</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token function\">shellSort</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> a<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">int</span> h <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\" spellcheck=\"true\">// 增量序列</span>\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span>h <span class=\"token operator\">&lt;</span> N<span class=\"token operator\">/</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n        <span class=\"token comment\" spellcheck=\"true\">// h = 1,4,13,40,……</span>\n        h <span class=\"token operator\">=</span> h<span class=\"token operator\">*</span><span class=\"token number\">3</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span>h<span class=\"token operator\">>=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> h<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token comment\" spellcheck=\"true\">// 进行插入排序，诺a[j]比a[j-h]小，则向前挪动h</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> i<span class=\"token punctuation\">;</span> j <span class=\"token operator\">>=</span> h <span class=\"token operator\">&amp;&amp;</span> a<span class=\"token punctuation\">[</span>j<span class=\"token operator\">-</span>h<span class=\"token punctuation\">]</span><span class=\"token operator\">></span>a<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> j <span class=\"token operator\">-=</span> h<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">exc</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">,</span> j<span class=\"token operator\">-</span>h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        h <span class=\"token operator\">/=</span> <span class=\"token number\">3</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">return</span> a<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<hr>\n<p>参考\n<a href=\"https://www.cnblogs.com/xiaohuiduan/p/11188304.html\">https://www.cnblogs.com/xiaohuiduan/p/11188304.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th>排序算法</th>\n<th>平均</th>\n<th>最好</th>\n<th>最坏</th>\n<th>是否稳定</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>选择排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>冒泡排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>插入排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>梳排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>希尔排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>快速排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>归并排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>堆排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>计数排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>桶排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n<tr>\n<td>二叉树排序</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n<td>-</td>\n</tr>\n</tbody></table>\n<h2 id=\"排序算法\"><a href=\"#排序算法\" class=\"headerlink\" title=\"排序算法\"></a>排序算法</h2><h3 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h3><h3 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h3><pre><code>\n</code></pre>\n<h3 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h3><h3 id=\"梳排序\"><a href=\"#梳排序\" class=\"headerlink\" title=\"梳排序\"></a>梳排序</h3><pre><code class=\"java\">/**\n * 梳排序\n * @param a\n * @return\n */\npublic static int[] combSort(int[] a) &#123;\n    int N = a.length;\n    int step = N;\n    int k;\n    // 第一部分\n    while((step /= 1.3) &gt; 1) &#123;\n        for (int i = N-1; i &gt;= step; i--) &#123;\n            k = i -step;\n            if(a[k]&gt;a[i])&#123;\n                // 交换位置\n                exc(a, k, i);\n            &#125;\n        &#125;\n    &#125;\n    // 第二部分：进行冒泡排序\n    a= bubbleSort2(a);\n    return a;\n&#125;\n</code></pre>\n<h3 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h3><pre><code class=\"java\">/**\n * shell排序\n * @param a\n * @return\n */\npublic static int[] shellSort(int[] a)&#123;\n    int N = a.length;\n    int h = 1;\n    // 增量序列\n    while(h &lt; N/3)&#123;\n        // h = 1,4,13,40,……\n        h = h*3 + 1; \n    &#125;\n\n    while(h&gt;=1)&#123;\n        for (int i = h; i &lt; N; i++) &#123;\n            // 进行插入排序，诺a[j]比a[j-h]小，则向前挪动h\n            for (int j = i; j &gt;= h &amp;&amp; a[j-h]&gt;a[j]; j -= h) &#123;\n                exc(a, j, j-h);\n            &#125;\n        &#125;\n        h /= 3;\n    &#125;\n    return a;\n&#125;\n</code></pre>\n<hr>\n<p>参考\n<a href=\"https://www.cnblogs.com/xiaohuiduan/p/11188304.html\">https://www.cnblogs.com/xiaohuiduan/p/11188304.html</a></p>\n"},{"title":"支持向量机算法","date":"2018-11-09T07:01:41.000Z","_content":"\n\n<!-- more -->\n","source":"_posts/支持向量机.md","raw":"---\ntitle: 支持向量机算法\ndate: 2018-11-09 15:01:41\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 机器学习\n    - 监督学习\n    - SVM\n---\n\n\n<!-- more -->\n","slug":"支持向量机","published":1,"updated":"2021-06-30T02:33:24.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxs00a5r5p7byoig8fx","content":"<span id=\"more\"></span>\n","site":{"data":{}},"excerpt":"","more":""},{"title":"期望值","date":"2012-10-01T00:01:01.000Z","_content":"\n在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n如果X是在概率空间（Ω, F, P）中的随机变量，那么它的期望值E[X]的定义是：\n\n$$E[X]=\\int _{\\Omega }X dP$$\n\n\n- 离散型\n如果X 是离散的随机变量，输出值为x1, x2, ...， 和输出值相应的概率为p1, p2, ...（概率和为1）。\n若级数 $\\sum_{i} p_{i}x_{i}$绝对收敛，那么期望值E[X]是一个无限数列的和。\n$$E[X]=\\sum_{i=1}^{k} x_{i}p_{i} = x_{1}p_{1}+x_{2}p_{2} + \\cdots +x_{k}p_{k}$$\n\n\n- 连续性\n如果 $X$ 是连续的随机变量，存在一个相应的概率密度函数 $f(x)$,\n$$E[X]= \\int_{-\\infty}^{\\infty}xf(x)dx$$\n是针对于连续的随机变量的，与离散随机变量的期望值的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。\n\n<br/>\n### 意义\n数学期望可以用于预测一个随机事件的平均预期情况。\n\n<br/>\n### 范例\n1、掷一枚公平的六面骰子，可知没面概率都是$\\frac{1}{6}$ ，计算如下：\n\n$E(X)= 1\\cdot\\frac{1}{6} + 2\\cdot\\frac{1}{6} + 3\\cdot\\frac{1}{6} + 4\\cdot\\frac{1}{6} + 5\\cdot\\frac{1}{6} + 6\\cdot\\frac{1}{6} = (1+2+3+4+5+6)\\cdot\\frac{1}{6} = 3.5$\n\n> 从上面可知，`均值`是期望的特例：每次概率都是一样\n\n\n<br/>\n### 相关阅读\n\n[方差](../方差) [标准差](../标准差) [协方差](../协方差)\n\n<br/>\n\n---\n参考\n\n[wikipedia-期望值](https://en.wikipedia.org/wiki/Expected_value)","source":"_posts/期望值.md","raw":"---\ntitle: 期望值\ndate: 2012-10-01 08:01:01\ncategories: \n    - 概率与统计\ntags: \n    - 数学\n    - 概率与统计\n    - 期望\n---\n\n在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n如果X是在概率空间（Ω, F, P）中的随机变量，那么它的期望值E[X]的定义是：\n\n$$E[X]=\\int _{\\Omega }X dP$$\n\n\n- 离散型\n如果X 是离散的随机变量，输出值为x1, x2, ...， 和输出值相应的概率为p1, p2, ...（概率和为1）。\n若级数 $\\sum_{i} p_{i}x_{i}$绝对收敛，那么期望值E[X]是一个无限数列的和。\n$$E[X]=\\sum_{i=1}^{k} x_{i}p_{i} = x_{1}p_{1}+x_{2}p_{2} + \\cdots +x_{k}p_{k}$$\n\n\n- 连续性\n如果 $X$ 是连续的随机变量，存在一个相应的概率密度函数 $f(x)$,\n$$E[X]= \\int_{-\\infty}^{\\infty}xf(x)dx$$\n是针对于连续的随机变量的，与离散随机变量的期望值的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。\n\n<br/>\n### 意义\n数学期望可以用于预测一个随机事件的平均预期情况。\n\n<br/>\n### 范例\n1、掷一枚公平的六面骰子，可知没面概率都是$\\frac{1}{6}$ ，计算如下：\n\n$E(X)= 1\\cdot\\frac{1}{6} + 2\\cdot\\frac{1}{6} + 3\\cdot\\frac{1}{6} + 4\\cdot\\frac{1}{6} + 5\\cdot\\frac{1}{6} + 6\\cdot\\frac{1}{6} = (1+2+3+4+5+6)\\cdot\\frac{1}{6} = 3.5$\n\n> 从上面可知，`均值`是期望的特例：每次概率都是一样\n\n\n<br/>\n### 相关阅读\n\n[方差](../方差) [标准差](../标准差) [协方差](../协方差)\n\n<br/>\n\n---\n参考\n\n[wikipedia-期望值](https://en.wikipedia.org/wiki/Expected_value)","slug":"期望值","published":1,"updated":"2021-06-30T02:33:24.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxt00a8r5p7b96c7c8l","content":"<p>在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<span id=\"more\"></span>\n\n\n<br>\n### 定义\n\n<p>如果X是在概率空间（Ω, F, P）中的随机变量，那么它的期望值E[X]的定义是：</p>\n<p>$$E[X]=\\int _{\\Omega }X dP$$</p>\n<ul>\n<li>离散型\n如果X 是离散的随机变量，输出值为x1, x2, …， 和输出值相应的概率为p1, p2, …（概率和为1）。\n若级数 $\\sum_{i} p_{i}x_{i}$绝对收敛，那么期望值E[X]是一个无限数列的和。\n$$E[X]=\\sum_{i=1}^{k} x_{i}p_{i} = x_{1}p_{1}+x_{2}p_{2} + \\cdots +x_{k}p_{k}$$</li>\n</ul>\n<ul>\n<li>连续性\n如果 $X$ 是连续的随机变量，存在一个相应的概率密度函数 $f(x)$,\n$$E[X]= \\int_{-\\infty}^{\\infty}xf(x)dx$$\n是针对于连续的随机变量的，与离散随机变量的期望值的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。</li>\n</ul>\n<br>\n### 意义\n数学期望可以用于预测一个随机事件的平均预期情况。\n\n<br>\n### 范例\n1、掷一枚公平的六面骰子，可知没面概率都是$\\frac{1}{6}$ ，计算如下：\n\n<p>$E(X)= 1\\cdot\\frac{1}{6} + 2\\cdot\\frac{1}{6} + 3\\cdot\\frac{1}{6} + 4\\cdot\\frac{1}{6} + 5\\cdot\\frac{1}{6} + 6\\cdot\\frac{1}{6} = (1+2+3+4+5+6)\\cdot\\frac{1}{6} = 3.5$</p>\n<blockquote>\n<p>从上面可知，<code>均值</code>是期望的特例：每次概率都是一样</p>\n</blockquote>\n<br>\n### 相关阅读\n\n<p><a href=\"../%E6%96%B9%E5%B7%AE\">方差</a> <a href=\"../%E6%A0%87%E5%87%86%E5%B7%AE\">标准差</a> <a href=\"../%E5%8D%8F%E6%96%B9%E5%B7%AE\">协方差</a></p>\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Expected_value\">wikipedia-期望值</a></p>\n","site":{"data":{}},"excerpt":"<p>在概率论和统计学中，一个离散性随机变量的期望值是试验中每次可能的结果乘以其结果概率的总和</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>","more":"<br/>\n### 定义\n\n<p>如果X是在概率空间（Ω, F, P）中的随机变量，那么它的期望值E[X]的定义是：</p>\n<p>$$E[X]=\\int _{\\Omega }X dP$$</p>\n<ul>\n<li>离散型\n如果X 是离散的随机变量，输出值为x1, x2, …， 和输出值相应的概率为p1, p2, …（概率和为1）。\n若级数 $\\sum_{i} p_{i}x_{i}$绝对收敛，那么期望值E[X]是一个无限数列的和。\n$$E[X]=\\sum_{i=1}^{k} x_{i}p_{i} = x_{1}p_{1}+x_{2}p_{2} + \\cdots +x_{k}p_{k}$$</li>\n</ul>\n<ul>\n<li>连续性\n如果 $X$ 是连续的随机变量，存在一个相应的概率密度函数 $f(x)$,\n$$E[X]= \\int_{-\\infty}^{\\infty}xf(x)dx$$\n是针对于连续的随机变量的，与离散随机变量的期望值的算法同出一辙，由于输出值是连续的，所以把求和改成了积分。</li>\n</ul>\n<br/>\n### 意义\n数学期望可以用于预测一个随机事件的平均预期情况。\n\n<br/>\n### 范例\n1、掷一枚公平的六面骰子，可知没面概率都是$\\frac{1}{6}$ ，计算如下：\n\n<p>$E(X)= 1\\cdot\\frac{1}{6} + 2\\cdot\\frac{1}{6} + 3\\cdot\\frac{1}{6} + 4\\cdot\\frac{1}{6} + 5\\cdot\\frac{1}{6} + 6\\cdot\\frac{1}{6} = (1+2+3+4+5+6)\\cdot\\frac{1}{6} = 3.5$</p>\n<blockquote>\n<p>从上面可知，<code>均值</code>是期望的特例：每次概率都是一样</p>\n</blockquote>\n<br/>\n### 相关阅读\n\n<p><a href=\"../%E6%96%B9%E5%B7%AE\">方差</a> <a href=\"../%E6%A0%87%E5%87%86%E5%B7%AE\">标准差</a> <a href=\"../%E5%8D%8F%E6%96%B9%E5%B7%AE\">协方差</a></p>\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Expected_value\">wikipedia-期望值</a></p>"},{"title":"方差","date":"2012-10-01T00:01:02.000Z","_content":"\n在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n设X为服从分布F的随机变量， 如果E[X]是随机变量X的期望值（$μ=E[X]$）\n随机变量X或者分布F的方差為：\n\n$$ Var(X)= E \\left[(X-\\mu)^{2} \\right]$$\n\n- 离散型\n$$Var(X) = \\sum_{i=1}^n p_i\\cdot(x_i - \\mu)^2 = \\sum_{i=1}^n (p_i\\cdot x_i^2) - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\sum_{i=1}^n p_{i} \\cdot x_{i}$\n \n\n\n- 连续型\n$$Var(X) = \\sigma^2 =\\int (x-\\mu)^2 \\, f(x) \\, dx\\, =\\int x^2 \\, f(x) \\, dx\\, - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\int x f(x)dx$\n\n\n\n\n<br/>\n### 范例\n\n\n\n---\n参考\n\n[wikipedia-方差](https://en.wikipedia.org/wiki/Variance)\n[baike-方差](https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE)","source":"_posts/方差.md","raw":"---\ntitle: 方差\ndate: 2012-10-01 08:01:02\ncategories: \n    - 概率与统计\ntags: \n    - 数学\n    - 概率与统计\n    - 方差\n---\n\n在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n设X为服从分布F的随机变量， 如果E[X]是随机变量X的期望值（$μ=E[X]$）\n随机变量X或者分布F的方差為：\n\n$$ Var(X)= E \\left[(X-\\mu)^{2} \\right]$$\n\n- 离散型\n$$Var(X) = \\sum_{i=1}^n p_i\\cdot(x_i - \\mu)^2 = \\sum_{i=1}^n (p_i\\cdot x_i^2) - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\sum_{i=1}^n p_{i} \\cdot x_{i}$\n \n\n\n- 连续型\n$$Var(X) = \\sigma^2 =\\int (x-\\mu)^2 \\, f(x) \\, dx\\, =\\int x^2 \\, f(x) \\, dx\\, - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\int x f(x)dx$\n\n\n\n\n<br/>\n### 范例\n\n\n\n---\n参考\n\n[wikipedia-方差](https://en.wikipedia.org/wiki/Variance)\n[baike-方差](https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE)","slug":"方差","published":1,"updated":"2021-06-30T02:33:24.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxu00adr5p7d42u6202","content":"<p>在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<span id=\"more\"></span>\n\n\n<br>\n### 定义\n\n<p>设X为服从分布F的随机变量， 如果E[X]是随机变量X的期望值（$μ=E[X]$）\n随机变量X或者分布F的方差為：</p>\n<p>$$ Var(X)= E \\left[(X-\\mu)^{2} \\right]$$</p>\n<ul>\n<li>离散型\n$$Var(X) = \\sum_{i=1}^n p_i\\cdot(x_i - \\mu)^2 = \\sum_{i=1}^n (p_i\\cdot x_i^2) - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\sum_{i=1}^n p_{i} \\cdot x_{i}$</li>\n</ul>\n<ul>\n<li>连续型\n$$Var(X) = \\sigma^2 =\\int (x-\\mu)^2 , f(x) , dx, =\\int x^2 , f(x) , dx, - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\int x f(x)dx$</li>\n</ul>\n<br>\n### 范例\n\n\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Variance\">wikipedia-方差</a>\n<a href=\"https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE\">baike-方差</a></p>\n","site":{"data":{}},"excerpt":"<p>在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>","more":"<br/>\n### 定义\n\n<p>设X为服从分布F的随机变量， 如果E[X]是随机变量X的期望值（$μ=E[X]$）\n随机变量X或者分布F的方差為：</p>\n<p>$$ Var(X)= E \\left[(X-\\mu)^{2} \\right]$$</p>\n<ul>\n<li>离散型\n$$Var(X) = \\sum_{i=1}^n p_i\\cdot(x_i - \\mu)^2 = \\sum_{i=1}^n (p_i\\cdot x_i^2) - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\sum_{i=1}^n p_{i} \\cdot x_{i}$</li>\n</ul>\n<ul>\n<li>连续型\n$$Var(X) = \\sigma^2 =\\int (x-\\mu)^2 , f(x) , dx, =\\int x^2 , f(x) , dx, - \\mu^2$$\n此处 $\\mu$ 是其期望值: $ \\mu = \\int x f(x)dx$</li>\n</ul>\n<br/>\n### 范例\n\n\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Variance\">wikipedia-方差</a>\n<a href=\"https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE\">baike-方差</a></p>"},{"title":"朴素贝叶斯算法","date":"2018-11-13T02:40:46.000Z","_content":"\n\n\n<!-- more -->","source":"_posts/朴素贝叶斯算法.md","raw":"---\ntitle: 朴素贝叶斯算法\ndate: 2018-11-13 10:40:46\ncategories: \n    - 机器学习\ntags: \n    - 算法\n    - 机器学习\n    - 监督学习\n    - 贝叶斯\n---\n\n\n\n<!-- more -->","slug":"朴素贝叶斯算法","published":1,"updated":"2021-06-30T02:33:24.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxv00afr5p7hu22di4c","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"机器学习","date":"2018-11-21T12:10:38.000Z","_content":"\n机器学习是人工智能的一个分支。人工智能的研究历史有着一条从以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。\n\n机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n\n---\n\n<!-- more -->\n\n\n<br/>\n### 分类\n- 监督学习\n从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。\n监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。\n训练集中的目标是由人标注的\n监督学习算法：`回归分析`和`统计分类`\n<br/>\n- 无监督学习\n与监督学习相比，训练集没有人为标注的结果\n常见的无监督学习算法：`生成对抗网络（GAN）`、`聚类`\n<br/>\n- 半监督学习\n<br/>\n- 增强学习\n\n\n\n### 算法\n\n[朴素贝叶斯算法]()\n[半朴素贝叶斯算法]()\n[贝叶斯网算法]()\n\n[ID3算法]()\n\n[感知器]()\n[支持向量机]()\n[集成学习AdaBoost]()\n[降维与度量学习]()\n[聚类]()\n\n\n\n\n<br/>\n### 模型评估方法\n\n\n- 过拟合\n- 欠拟合\n\n\n\n\n<br/>\n#### 留出法\n`留出法（hold-out）`：将`样本数据D`划分成两个互斥的集合，其中一个作为`训练集S`，另一个作为`测试集T`。在`S`上训练出模型后，用`T`来评估其测试误差，作为对泛化误差的评估\n\n<br/>\n#### 交叉验证法\n`交叉验证法（）`：将`样本数据划D`划分为k个大小相似的互斥子集。每个子集$D_j$\n\n<br/>\n#### 自助法\n`自助法（）`：\n\n\n\n\n<br/>\n\n---\n参考\n周志华《机器学习》\n[wikipedia-机器学习](https://en.wikipedia.org/wiki/Machine_learning)","source":"_posts/机器学习.md","raw":"---\ntitle: 机器学习\ndate: 2018-11-21 20:10:38\ncategories: \n    - 机器学习\ntags:\n    - 算法\n    - 人工智能\n    - 机器学习\n---\n\n机器学习是人工智能的一个分支。人工智能的研究历史有着一条从以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。\n\n机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n\n---\n\n<!-- more -->\n\n\n<br/>\n### 分类\n- 监督学习\n从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。\n监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。\n训练集中的目标是由人标注的\n监督学习算法：`回归分析`和`统计分类`\n<br/>\n- 无监督学习\n与监督学习相比，训练集没有人为标注的结果\n常见的无监督学习算法：`生成对抗网络（GAN）`、`聚类`\n<br/>\n- 半监督学习\n<br/>\n- 增强学习\n\n\n\n### 算法\n\n[朴素贝叶斯算法]()\n[半朴素贝叶斯算法]()\n[贝叶斯网算法]()\n\n[ID3算法]()\n\n[感知器]()\n[支持向量机]()\n[集成学习AdaBoost]()\n[降维与度量学习]()\n[聚类]()\n\n\n\n\n<br/>\n### 模型评估方法\n\n\n- 过拟合\n- 欠拟合\n\n\n\n\n<br/>\n#### 留出法\n`留出法（hold-out）`：将`样本数据D`划分成两个互斥的集合，其中一个作为`训练集S`，另一个作为`测试集T`。在`S`上训练出模型后，用`T`来评估其测试误差，作为对泛化误差的评估\n\n<br/>\n#### 交叉验证法\n`交叉验证法（）`：将`样本数据划D`划分为k个大小相似的互斥子集。每个子集$D_j$\n\n<br/>\n#### 自助法\n`自助法（）`：\n\n\n\n\n<br/>\n\n---\n参考\n周志华《机器学习》\n[wikipedia-机器学习](https://en.wikipedia.org/wiki/Machine_learning)","slug":"机器学习","published":1,"updated":"2021-06-30T02:33:24.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxw00ajr5p779c8fo4t","content":"<p>机器学习是人工智能的一个分支。人工智能的研究历史有着一条从以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。</p>\n<p>机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<span id=\"more\"></span>\n\n\n<br>\n### 分类\n- 监督学习\n从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。\n监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。\n训练集中的目标是由人标注的\n监督学习算法：`回归分析`和`统计分类`\n<br>\n- 无监督学习\n与监督学习相比，训练集没有人为标注的结果\n常见的无监督学习算法：`生成对抗网络（GAN）`、`聚类`\n<br>\n- 半监督学习\n<br>\n- 增强学习\n\n\n\n<h3 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h3><p><a href=\"\">朴素贝叶斯算法</a>\n<a href=\"\">半朴素贝叶斯算法</a>\n<a href=\"\">贝叶斯网算法</a></p>\n<p><a href=\"\">ID3算法</a></p>\n<p><a href=\"\">感知器</a>\n<a href=\"\">支持向量机</a>\n<a href=\"\">集成学习AdaBoost</a>\n<a href=\"\">降维与度量学习</a>\n<a href=\"\">聚类</a></p>\n<br>\n### 模型评估方法\n\n\n<ul>\n<li>过拟合</li>\n<li>欠拟合</li>\n</ul>\n<br>\n#### 留出法\n`留出法（hold-out）`：将`样本数据D`划分成两个互斥的集合，其中一个作为`训练集S`，另一个作为`测试集T`。在`S`上训练出模型后，用`T`来评估其测试误差，作为对泛化误差的评估\n\n<br>\n#### 交叉验证法\n`交叉验证法（）`：将`样本数据划D`划分为k个大小相似的互斥子集。每个子集$D_j$\n\n<br>\n#### 自助法\n`自助法（）`：\n\n\n\n\n<br>\n\n<hr>\n<p>参考\n周志华《机器学习》\n<a href=\"https://en.wikipedia.org/wiki/Machine_learning\">wikipedia-机器学习</a></p>\n","site":{"data":{}},"excerpt":"<p>机器学习是人工智能的一个分支。人工智能的研究历史有着一条从以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近30多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。</p>\n<p>机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>","more":"<br/>\n### 分类\n- 监督学习\n从给定的训练数据集中学习出一个函数，当新的数据到来时，可以根据这个函数预测结果。\n监督学习的训练集要求是包括输入和输出，也可以说是特征和目标。\n训练集中的目标是由人标注的\n监督学习算法：`回归分析`和`统计分类`\n<br/>\n- 无监督学习\n与监督学习相比，训练集没有人为标注的结果\n常见的无监督学习算法：`生成对抗网络（GAN）`、`聚类`\n<br/>\n- 半监督学习\n<br/>\n- 增强学习\n\n\n\n<h3 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h3><p><a href=\"\">朴素贝叶斯算法</a>\n<a href=\"\">半朴素贝叶斯算法</a>\n<a href=\"\">贝叶斯网算法</a></p>\n<p><a href=\"\">ID3算法</a></p>\n<p><a href=\"\">感知器</a>\n<a href=\"\">支持向量机</a>\n<a href=\"\">集成学习AdaBoost</a>\n<a href=\"\">降维与度量学习</a>\n<a href=\"\">聚类</a></p>\n<br/>\n### 模型评估方法\n\n\n<ul>\n<li>过拟合</li>\n<li>欠拟合</li>\n</ul>\n<br/>\n#### 留出法\n`留出法（hold-out）`：将`样本数据D`划分成两个互斥的集合，其中一个作为`训练集S`，另一个作为`测试集T`。在`S`上训练出模型后，用`T`来评估其测试误差，作为对泛化误差的评估\n\n<br/>\n#### 交叉验证法\n`交叉验证法（）`：将`样本数据划D`划分为k个大小相似的互斥子集。每个子集$D_j$\n\n<br/>\n#### 自助法\n`自助法（）`：\n\n\n\n\n<br/>\n\n<hr>\n<p>参考\n周志华《机器学习》\n<a href=\"https://en.wikipedia.org/wiki/Machine_learning\">wikipedia-机器学习</a></p>"},{"title":"条件熵","date":"2018-11-10T01:01:01.000Z","_content":"\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大，熵最小是0`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n---\n\n### 公式\n\n$$\nH(X|Y)=- \\sum_{i,j} p(x_{i},y_{j}) \\log \\frac {p(x_{i},y_{j})} {p(y_{j})}\n$$\n\n\n### 范例\n\n\n\n### 应用场景\n[ID3算法](../ID3算法) [C4.5算法](../C4.5算法)\n\n\n\n<br/>\n\n--- \n参考:\n[wikipedia-条件熵](https://en.wikipedia.org/wiki/Conditional_entropy)","source":"_posts/条件熵.md","raw":"---\ntitle: 条件熵\ndate: 2018-11-10 09:01:01\ncategories: \n    - 信息论\ntags:\n    - 算法\n    - 机器学习\n    - 信息论\n    - 信息熵\n---\n\n\n熵（英语：entropy）是接收的每条消息中包含的信息的平均量。\n\n熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量\n\n`结论：熵越大不确定性越大，熵最小是0`\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n---\n\n### 公式\n\n$$\nH(X|Y)=- \\sum_{i,j} p(x_{i},y_{j}) \\log \\frac {p(x_{i},y_{j})} {p(y_{j})}\n$$\n\n\n### 范例\n\n\n\n### 应用场景\n[ID3算法](../ID3算法) [C4.5算法](../C4.5算法)\n\n\n\n<br/>\n\n--- \n参考:\n[wikipedia-条件熵](https://en.wikipedia.org/wiki/Conditional_entropy)","slug":"条件熵","published":1,"updated":"2021-06-30T02:33:24.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxw00anr5p7h9wr6kqo","content":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大，熵最小是0</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n<hr>\n<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$\nH(X|Y)=- \\sum_{i,j} p(x_{i},y_{j}) \\log \\frac {p(x_{i},y_{j})} {p(y_{j})}\n$$</p>\n<h3 id=\"范例\"><a href=\"#范例\" class=\"headerlink\" title=\"范例\"></a>范例</h3><h3 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h3><p><a href=\"../ID3%E7%AE%97%E6%B3%95\">ID3算法</a> <a href=\"../C4.5%E7%AE%97%E6%B3%95\">C4.5算法</a></p>\n<br>\n\n<hr>\n<p>参考:\n<a href=\"https://en.wikipedia.org/wiki/Conditional_entropy\">wikipedia-条件熵</a></p>\n","site":{"data":{}},"excerpt":"<p>熵（英语：entropy）是接收的每条消息中包含的信息的平均量。</p>\n<p>熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量</p>\n<p><code>结论：熵越大不确定性越大，熵最小是0</code>\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<hr>\n<h3 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h3><p>$$\nH(X|Y)=- \\sum_{i,j} p(x_{i},y_{j}) \\log \\frac {p(x_{i},y_{j})} {p(y_{j})}\n$$</p>\n<h3 id=\"范例\"><a href=\"#范例\" class=\"headerlink\" title=\"范例\"></a>范例</h3><h3 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h3><p><a href=\"../ID3%E7%AE%97%E6%B3%95\">ID3算法</a> <a href=\"../C4.5%E7%AE%97%E6%B3%95\">C4.5算法</a></p>\n<br/>\n\n<hr>\n<p>参考:\n<a href=\"https://en.wikipedia.org/wiki/Conditional_entropy\">wikipedia-条件熵</a></p>"},{"title":"查看class文件的jdk编译版本","date":"2019-02-27T01:55:50.000Z","_content":"\n\n\n   版本号 |\t对应十进制 | jdk版本号\n---- | ---- | -------\n 2E | 46 | jdk1.2\n  2F | 47 | jdk1.3\n 30 | 48 | jdk1.4\n 31 | 49 | jdk1.5\n 32 | 50 | jdk1.6\n  33 | 51 | jdk1.7\n  34 |  52 | jdk1.8\n\n\n$f(x) = sinx +1$\n\nName | Description | Default key binding\n-----|-------------|--------------------\nmd-shortcut.showCommandPalette | Display all commands | ctrl+M ctrl+M\nmd-shortcut.toggleBold | Make **bold** | ctrl+B\nmd-shortcut.toggleItalic | Make _italic_ | ctrl+I | \n\n\n```flow\nst=>start: Start:>http://www.google.com[blank]\ne=>end:>http://www.google.com\nop1=>operation: My Operation\nsub1=>subroutine: My Subroutine\ncond=>condition: Yes\nor No?:>http://www.google.com\nio=>inputoutput: catch something...\npara=>parallel: parallel tasks\n\nst->op1->cond\ncond(yes)->io->e\ncond(no)->para\npara(path1, bottom)->sub1(right)->op1\npara(path2, top)->op1\n```\n\n```sequence{theme=\"hand\"}\nAndrew->China: Says Hello\nNote right of China: China thinks\\nabout it\nChina-->Andrew: How are you?\nAndrew->>China: I am good thanks!\n```","source":"_posts/查看class文件的jdk编译版本.md","raw":"---\ntitle: 查看class文件的jdk编译版本\ndate: 2019-02-27 09:55:50\ncategories: \n    - Java\ntags:\n    - Java\n---\n\n\n\n   版本号 |\t对应十进制 | jdk版本号\n---- | ---- | -------\n 2E | 46 | jdk1.2\n  2F | 47 | jdk1.3\n 30 | 48 | jdk1.4\n 31 | 49 | jdk1.5\n 32 | 50 | jdk1.6\n  33 | 51 | jdk1.7\n  34 |  52 | jdk1.8\n\n\n$f(x) = sinx +1$\n\nName | Description | Default key binding\n-----|-------------|--------------------\nmd-shortcut.showCommandPalette | Display all commands | ctrl+M ctrl+M\nmd-shortcut.toggleBold | Make **bold** | ctrl+B\nmd-shortcut.toggleItalic | Make _italic_ | ctrl+I | \n\n\n```flow\nst=>start: Start:>http://www.google.com[blank]\ne=>end:>http://www.google.com\nop1=>operation: My Operation\nsub1=>subroutine: My Subroutine\ncond=>condition: Yes\nor No?:>http://www.google.com\nio=>inputoutput: catch something...\npara=>parallel: parallel tasks\n\nst->op1->cond\ncond(yes)->io->e\ncond(no)->para\npara(path1, bottom)->sub1(right)->op1\npara(path2, top)->op1\n```\n\n```sequence{theme=\"hand\"}\nAndrew->China: Says Hello\nNote right of China: China thinks\\nabout it\nChina-->Andrew: How are you?\nAndrew->>China: I am good thanks!\n```","slug":"查看class文件的jdk编译版本","published":1,"updated":"2021-06-30T02:33:24.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxx00aqr5p7frs98jzh","content":"<table>\n<thead>\n<tr>\n<th>版本号</th>\n<th>对应十进制</th>\n<th>jdk版本号</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2E</td>\n<td>46</td>\n<td>jdk1.2</td>\n</tr>\n<tr>\n<td>2F</td>\n<td>47</td>\n<td>jdk1.3</td>\n</tr>\n<tr>\n<td>30</td>\n<td>48</td>\n<td>jdk1.4</td>\n</tr>\n<tr>\n<td>31</td>\n<td>49</td>\n<td>jdk1.5</td>\n</tr>\n<tr>\n<td>32</td>\n<td>50</td>\n<td>jdk1.6</td>\n</tr>\n<tr>\n<td>33</td>\n<td>51</td>\n<td>jdk1.7</td>\n</tr>\n<tr>\n<td>34</td>\n<td>52</td>\n<td>jdk1.8</td>\n</tr>\n</tbody></table>\n<p>$f(x) = sinx +1$</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Description</th>\n<th>Default key binding</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>md-shortcut.showCommandPalette</td>\n<td>Display all commands</td>\n<td>ctrl+M ctrl+M</td>\n</tr>\n<tr>\n<td>md-shortcut.toggleBold</td>\n<td>Make <strong>bold</strong></td>\n<td>ctrl+B</td>\n</tr>\n<tr>\n<td>md-shortcut.toggleItalic</td>\n<td>Make <em>italic</em></td>\n<td>ctrl+I</td>\n</tr>\n</tbody></table>\n<pre class=\" language-flow\"><code class=\"language-flow\">st=>start: Start:>http://www.google.com[blank]\ne=>end:>http://www.google.com\nop1=>operation: My Operation\nsub1=>subroutine: My Subroutine\ncond=>condition: Yes\nor No?:>http://www.google.com\nio=>inputoutput: catch something...\npara=>parallel: parallel tasks\n\nst->op1->cond\ncond(yes)->io->e\ncond(no)->para\npara(path1, bottom)->sub1(right)->op1\npara(path2, top)->op1\n</code></pre>\n<pre class=\" language-sequence{theme=&quot;hand&quot;}\"><code class=\"language-sequence{theme=&quot;hand&quot;}\">Andrew->China: Says Hello\nNote right of China: China thinks\\nabout it\nChina-->Andrew: How are you?\nAndrew->>China: I am good thanks!\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<table>\n<thead>\n<tr>\n<th>版本号</th>\n<th>对应十进制</th>\n<th>jdk版本号</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2E</td>\n<td>46</td>\n<td>jdk1.2</td>\n</tr>\n<tr>\n<td>2F</td>\n<td>47</td>\n<td>jdk1.3</td>\n</tr>\n<tr>\n<td>30</td>\n<td>48</td>\n<td>jdk1.4</td>\n</tr>\n<tr>\n<td>31</td>\n<td>49</td>\n<td>jdk1.5</td>\n</tr>\n<tr>\n<td>32</td>\n<td>50</td>\n<td>jdk1.6</td>\n</tr>\n<tr>\n<td>33</td>\n<td>51</td>\n<td>jdk1.7</td>\n</tr>\n<tr>\n<td>34</td>\n<td>52</td>\n<td>jdk1.8</td>\n</tr>\n</tbody></table>\n<p>$f(x) = sinx +1$</p>\n<table>\n<thead>\n<tr>\n<th>Name</th>\n<th>Description</th>\n<th>Default key binding</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>md-shortcut.showCommandPalette</td>\n<td>Display all commands</td>\n<td>ctrl+M ctrl+M</td>\n</tr>\n<tr>\n<td>md-shortcut.toggleBold</td>\n<td>Make <strong>bold</strong></td>\n<td>ctrl+B</td>\n</tr>\n<tr>\n<td>md-shortcut.toggleItalic</td>\n<td>Make <em>italic</em></td>\n<td>ctrl+I</td>\n</tr>\n</tbody></table>\n<pre><code class=\"flow\">st=&gt;start: Start:&gt;http://www.google.com[blank]\ne=&gt;end:&gt;http://www.google.com\nop1=&gt;operation: My Operation\nsub1=&gt;subroutine: My Subroutine\ncond=&gt;condition: Yes\nor No?:&gt;http://www.google.com\nio=&gt;inputoutput: catch something...\npara=&gt;parallel: parallel tasks\n\nst-&gt;op1-&gt;cond\ncond(yes)-&gt;io-&gt;e\ncond(no)-&gt;para\npara(path1, bottom)-&gt;sub1(right)-&gt;op1\npara(path2, top)-&gt;op1\n</code></pre>\n<pre><code class=\"sequence&#123;theme=&quot;hand&quot;&#125;\">Andrew-&gt;China: Says Hello\nNote right of China: China thinks\\nabout it\nChina--&gt;Andrew: How are you?\nAndrew-&gt;&gt;China: I am good thanks!\n</code></pre>\n"},{"title":"极限","date":"2008-09-01T00:01:01.000Z","_content":"\n极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n\n<br/>\n### 性质\n\n\n\n\n<br/>\n### 极限计算21种主要方法\n\n<br/>\n#### 1、直接代入法\n\n$【例1】\\lim\\limits_{x \\to 3} x^{2}-x=9-6=3 $\n\n$【例2】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$\n\n\n<br/>\n#### 2、因式分解法\n\n$【例3】\\lim\\limits_{x\\to3} \\frac{x^{2}-9}{x-3}=\\lim\\limits_{x\\to3} (x+3) = 6$\n\n$【例4】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$\n\n\n<br/>\n#### 3、化无穷大计算为无穷小计算法\n\n<br/>\n#### 4、有理化\n\n<br/>\n#### 5、重要极限\n\n<br/>\n#### 6、变量代换法\n\n\n<br/>\n#### 7、三角函数恒等变化法\n\n\n<br/>\n#### 单调有界函数法\n\n\n<br/>\n#### 概念判断法\n\n\n<br/>\n#### 等价无穷小代换法\n\n<br/>\n#### 洛必达求导法则\n\n<br/>\n#### 积分中值定理法\n\n<br/>\n#### \b偏导数法\n\n<br/>\n#### 夹逼法则\n\n<br/>\n#### 定积分法\n\n\n\n\n\n<br/>\n\n---\n参考\n[百度百科-极限](https://baike.baidu.com/item/%E6%9E%81%E9%99%90/3564509)\nhttps://en.wikipedia.org/wiki/Limit_(mathematics)","source":"_posts/极限.md","raw":"---\ntitle: 极限\ndate: 2008-09-01 08:01:01\ncategories:\n    - 数学\ntags:\n    - 数学\n    - 高等数学\n    - 极限\n    - 微积分\n---\n\n极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n### 定义\n\n\n<br/>\n### 性质\n\n\n\n\n<br/>\n### 极限计算21种主要方法\n\n<br/>\n#### 1、直接代入法\n\n$【例1】\\lim\\limits_{x \\to 3} x^{2}-x=9-6=3 $\n\n$【例2】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$\n\n\n<br/>\n#### 2、因式分解法\n\n$【例3】\\lim\\limits_{x\\to3} \\frac{x^{2}-9}{x-3}=\\lim\\limits_{x\\to3} (x+3) = 6$\n\n$【例4】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$\n\n\n<br/>\n#### 3、化无穷大计算为无穷小计算法\n\n<br/>\n#### 4、有理化\n\n<br/>\n#### 5、重要极限\n\n<br/>\n#### 6、变量代换法\n\n\n<br/>\n#### 7、三角函数恒等变化法\n\n\n<br/>\n#### 单调有界函数法\n\n\n<br/>\n#### 概念判断法\n\n\n<br/>\n#### 等价无穷小代换法\n\n<br/>\n#### 洛必达求导法则\n\n<br/>\n#### 积分中值定理法\n\n<br/>\n#### \b偏导数法\n\n<br/>\n#### 夹逼法则\n\n<br/>\n#### 定积分法\n\n\n\n\n\n<br/>\n\n---\n参考\n[百度百科-极限](https://baike.baidu.com/item/%E6%9E%81%E9%99%90/3564509)\nhttps://en.wikipedia.org/wiki/Limit_(mathematics)","slug":"极限","published":1,"updated":"2021-06-30T02:33:24.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxy00aur5p7hi144gq5","content":"<p>极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<br>\n### 定义\n\n\n<br>\n### 性质\n\n\n\n\n<br>\n### 极限计算21种主要方法\n\n<br>\n#### 1、直接代入法\n\n<p>$【例1】\\lim\\limits_{x \\to 3} x^{2}-x=9-6=3 $</p>\n<p>$【例2】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$</p>\n<br>\n#### 2、因式分解法\n\n<p>$【例3】\\lim\\limits_{x\\to3} \\frac{x^{2}-9}{x-3}=\\lim\\limits_{x\\to3} (x+3) = 6$</p>\n<p>$【例4】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$</p>\n<br>\n#### 3、化无穷大计算为无穷小计算法\n\n<br>\n#### 4、有理化\n\n<br>\n#### 5、重要极限\n\n<br>\n#### 6、变量代换法\n\n\n<br>\n#### 7、三角函数恒等变化法\n\n\n<br>\n#### 单调有界函数法\n\n\n<br>\n#### 概念判断法\n\n\n<br>\n#### 等价无穷小代换法\n\n<br>\n#### 洛必达求导法则\n\n<br>\n#### 积分中值定理法\n\n<br>\n#### \b偏导数法\n\n<br>\n#### 夹逼法则\n\n<br>\n#### 定积分法\n\n\n\n\n\n<br>\n\n<hr>\n<p>参考\n<a href=\"https://baike.baidu.com/item/%E6%9E%81%E9%99%90/3564509\">百度百科-极限</a>\n<a href=\"https://en.wikipedia.org/wiki/Limit_(mathematics)\">https://en.wikipedia.org/wiki/Limit_(mathematics)</a></p>\n","site":{"data":{}},"excerpt":"<p>极限是现代数学特别是分析学中的基础概念之一。极限可以用来描述一个序列的指标愈来愈大时，序列中元素的性质变化的趋势。极限也可以描述函数的自变量接近某一个值的时候，相对应的函数值变化的趋势。作为微积分和数学分析的其他分支最基本的概念之一，连续和导数的概念都是通过极限来定义的。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<br/>\n### 定义\n\n\n<br/>\n### 性质\n\n\n\n\n<br/>\n### 极限计算21种主要方法\n\n<br/>\n#### 1、直接代入法\n\n<p>$【例1】\\lim\\limits_{x \\to 3} x^{2}-x=9-6=3 $</p>\n<p>$【例2】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$</p>\n<br/>\n#### 2、因式分解法\n\n<p>$【例3】\\lim\\limits_{x\\to3} \\frac{x^{2}-9}{x-3}=\\lim\\limits_{x\\to3} (x+3) = 6$</p>\n<p>$【例4】\\lim\\limits_{x \\to 2} \\frac{35+x^2}{\\sqrt[3]{16-x^3}}  = \\frac{3}{2}$</p>\n<br/>\n#### 3、化无穷大计算为无穷小计算法\n\n<br/>\n#### 4、有理化\n\n<br/>\n#### 5、重要极限\n\n<br/>\n#### 6、变量代换法\n\n\n<br/>\n#### 7、三角函数恒等变化法\n\n\n<br/>\n#### 单调有界函数法\n\n\n<br/>\n#### 概念判断法\n\n\n<br/>\n#### 等价无穷小代换法\n\n<br/>\n#### 洛必达求导法则\n\n<br/>\n#### 积分中值定理法\n\n<br/>\n#### \b偏导数法\n\n<br/>\n#### 夹逼法则\n\n<br/>\n#### 定积分法\n\n\n\n\n\n<br/>\n\n<hr>\n<p>参考\n<a href=\"https://baike.baidu.com/item/%E6%9E%81%E9%99%90/3564509\">百度百科-极限</a>\n<a href=\"https://en.wikipedia.org/wiki/Limit_(mathematics)\">https://en.wikipedia.org/wiki/Limit_(mathematics)</a></p>"},{"title":"标准差","date":"2012-10-01T00:01:03.000Z","_content":"\n标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。测量到分布程度的结果，原则上具有两种性质：\n\n为非负数值（因为开平方后再做平方根）；\n与测量资料具有相同单位（这样才能比对）。\n一个总量的标准差或一个随机变量的标准差，及一个子集合样品数的标准差之间，有所差别。其公式如下所列。\n\n标准差的概念由卡尔·皮尔逊引入到统计中。\n\n\n<!-- more -->\n\n\n<br/>\n\n## 总体的标准差\n\n\n\n<br/>\n### 定义\n$$SD= \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}$$\n$\\mu$为期望\n\n\n\n\n<br/>\n## 样本的标准差\n\n\n<br/>\n### 定义\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-标准差](https://en.wikipedia.org/wiki/Standard_deviation)\n[baike-标准差](https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE)","source":"_posts/标准差.md","raw":"---\ntitle: 标准差\ndate: 2012-10-01 08:01:03\ncategories: \n    - 概率与统计\ntags: \n    - 数学\n    - 概率与统计\n    - 方差\n---\n\n标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n\n\n标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。测量到分布程度的结果，原则上具有两种性质：\n\n为非负数值（因为开平方后再做平方根）；\n与测量资料具有相同单位（这样才能比对）。\n一个总量的标准差或一个随机变量的标准差，及一个子集合样品数的标准差之间，有所差别。其公式如下所列。\n\n标准差的概念由卡尔·皮尔逊引入到统计中。\n\n\n<!-- more -->\n\n\n<br/>\n\n## 总体的标准差\n\n\n\n<br/>\n### 定义\n$$SD= \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}$$\n$\\mu$为期望\n\n\n\n\n<br/>\n## 样本的标准差\n\n\n<br/>\n### 定义\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-标准差](https://en.wikipedia.org/wiki/Standard_deviation)\n[baike-标准差](https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE)","slug":"标准差","published":1,"updated":"2021-06-30T02:33:24.781Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsxz00ayr5p726p44p9k","content":"<p>标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<p>标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。测量到分布程度的结果，原则上具有两种性质：</p>\n<p>为非负数值（因为开平方后再做平方根）；\n与测量资料具有相同单位（这样才能比对）。\n一个总量的标准差或一个随机变量的标准差，及一个子集合样品数的标准差之间，有所差别。其公式如下所列。</p>\n<p>标准差的概念由卡尔·皮尔逊引入到统计中。</p>\n<span id=\"more\"></span>\n\n\n<br>\n\n<h2 id=\"总体的标准差\"><a href=\"#总体的标准差\" class=\"headerlink\" title=\"总体的标准差\"></a>总体的标准差</h2><br>\n### 定义\n$$SD= \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}$$\n$\\mu$为期望\n\n\n\n\n<br>\n## 样本的标准差\n\n\n<br>\n### 定义\n\n\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Standard_deviation\">wikipedia-标准差</a>\n<a href=\"https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE\">baike-标准差</a></p>\n","site":{"data":{}},"excerpt":"<p>标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<p>标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度；标准差与期望值之比为标准离差率。测量到分布程度的结果，原则上具有两种性质：</p>\n<p>为非负数值（因为开平方后再做平方根）；\n与测量资料具有相同单位（这样才能比对）。\n一个总量的标准差或一个随机变量的标准差，及一个子集合样品数的标准差之间，有所差别。其公式如下所列。</p>\n<p>标准差的概念由卡尔·皮尔逊引入到统计中。</p>","more":"<br/>\n\n<h2 id=\"总体的标准差\"><a href=\"#总体的标准差\" class=\"headerlink\" title=\"总体的标准差\"></a>总体的标准差</h2><br/>\n### 定义\n$$SD= \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}$$\n$\\mu$为期望\n\n\n\n\n<br/>\n## 样本的标准差\n\n\n<br/>\n### 定义\n\n\n<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Standard_deviation\">wikipedia-标准差</a>\n<a href=\"https://baike.baidu.com/item/%E6%A0%87%E5%87%86%E5%B7%AE\">baike-标准差</a></p>"},{"title":"编译原理","date":"2021-07-15T10:23:37.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n摘要：学习编译原理笔记，方便后续回顾学习\n\n\n### 1、词法分析（Lexical Analysis）\n\n### 2、语法分析（Syntax Analysis）\n\n### 3、语义分析（Semantic Analysis）\n\n---\n参考：\n- [编译原理wiki](https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86_(%E6%95%99%E6%9D%90))","source":"_posts/编译原理.md","raw":"---\ntitle: 编译原理\ndate: 2021-07-15 18:23:37\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - 编译原理\ntags:\n    - 编译原理\n    - Compilers Principles\n---\n\n摘要：学习编译原理笔记，方便后续回顾学习\n\n\n### 1、词法分析（Lexical Analysis）\n\n### 2、语法分析（Syntax Analysis）\n\n### 3、语义分析（Semantic Analysis）\n\n---\n参考：\n- [编译原理wiki](https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86_(%E6%95%99%E6%9D%90))","slug":"编译原理","published":1,"updated":"2021-07-15T13:41:08.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy000b2r5p7giiy9zw1","content":"<p>摘要：学习编译原理笔记，方便后续回顾学习</p>\n<h3 id=\"1、词法分析（Lexical-Analysis）\"><a href=\"#1、词法分析（Lexical-Analysis）\" class=\"headerlink\" title=\"1、词法分析（Lexical Analysis）\"></a>1、词法分析（Lexical Analysis）</h3><h3 id=\"2、语法分析（Syntax-Analysis）\"><a href=\"#2、语法分析（Syntax-Analysis）\" class=\"headerlink\" title=\"2、语法分析（Syntax Analysis）\"></a>2、语法分析（Syntax Analysis）</h3><h3 id=\"3、语义分析（Semantic-Analysis）\"><a href=\"#3、语义分析（Semantic-Analysis）\" class=\"headerlink\" title=\"3、语义分析（Semantic Analysis）\"></a>3、语义分析（Semantic Analysis）</h3><hr>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86_(%E6%95%99%E6%9D%90)\">编译原理wiki</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>摘要：学习编译原理笔记，方便后续回顾学习</p>\n<h3 id=\"1、词法分析（Lexical-Analysis）\"><a href=\"#1、词法分析（Lexical-Analysis）\" class=\"headerlink\" title=\"1、词法分析（Lexical Analysis）\"></a>1、词法分析（Lexical Analysis）</h3><h3 id=\"2、语法分析（Syntax-Analysis）\"><a href=\"#2、语法分析（Syntax-Analysis）\" class=\"headerlink\" title=\"2、语法分析（Syntax Analysis）\"></a>2、语法分析（Syntax Analysis）</h3><h3 id=\"3、语义分析（Semantic-Analysis）\"><a href=\"#3、语义分析（Semantic-Analysis）\" class=\"headerlink\" title=\"3、语义分析（Semantic Analysis）\"></a>3、语义分析（Semantic Analysis）</h3><hr>\n<p>参考：</p>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86_(%E6%95%99%E6%9D%90)\">编译原理wiki</a></li>\n</ul>\n"},{"title":"编译器 vs 解释器：编译器和解释器之间的区别","date":"2019-06-05T11:14:21.000Z","_content":"\n### 编译器(Compiler)\n`编译器`是一种计算机程序，负责把一种编程语言编写的源码转换成`另外一种计算机代码`，往往是`二进制`的形式存在，被称为`目标代码(object code)`。这个转换的过程通常的目的是生成可执行的程序。\n`编译器`的产出是`另外一种代码`，然后这些代码等着被别人拿来执行，如果还不能直接被执行，那么还需要再编译或解释一遍，再交由计算机硬件执行。\n`编译器`往往是在「执行」之前完成，产出是一种可执行或需要再编译或者解释的`代码`。\n\n<!--more-->\n\n<br/>\n### 解释器(Interpreter)\n在计算机科学中，`解释器`是一种计算机程序，它直接执行由编程语言或脚本语言编写的代码，并不会把源代码预编译成机器码。\n一个解释器，通常会用以下的姿势来执行程序代码：\n- 分析源代码，并且直接执行。\n- 把源代码翻译成相对更加高效率的中间码，然后立即执行它。\n- 执行由解释器内部的编译器预编译后保存的代码\n- 可以把解释器看成一个黑盒子，我们输入源码，它就会实时返回结果。\n不同类型的解释器，黑盒子里面的构造不一样，有些还会集成编译器，缓存编译结果，用来提高执行效率（例如 Chrome V8 也是这么做的）。\n解释器通常是工作在「运行时」，并且对于我们输入的源码，是一行一行的解释然后执行，然后返回结果。\n\n\n<br/>\n### 编译器(Compiler) vs 解释器(Interpreter) \n\n | Compiler 编译器 | Interpreter 解释器\n ------- | ------- | -------\n功能 | 对整个程序进行分析，执行输出为另一种代码（一般为机器码，如目标代码，可能需要连接后才能执行），但是不执行该机器码 | 对源代码逐行执行，即包含分析和执行两步\n编程步骤 | 1、创建程序。<br/> 2、【编译】：解析或分析所有代码的正确性。如果不正确，则抛出错误如果没有错误，编译器会将源代码转换为机器代码。<br/> 3、它将不同的代码文件链接到一个可运行的程序（如 .exe） 4、 运行程序 | 1、创建程序 <br/> 2、逐行执行源语句\n优点 | 每次执行的是可运行程序，执行速度较快 | 更容易使用，特别是对于初学者\n缺点 | 只能通过修改源代码改变程序 | 只能在有解释器的计算机上执行\n执行速度 | 每次执行的是可运行程序，执行速度较快 | 每次执行都从源代码开始，且不保存执行过程中的机器代码，执行速度慢\n执行者权限 | 执行者一般得到的是可执行文件，执行者无法对程序进行更改 | 执行者可以对源程序进行更改\n程序运行对象 | CPU | 解释器\n适用环境 | .exe 限定特定CPU| 一份源代码只要有对应版本解释器即可运行<br />对于web环境`，由于代码往往是一部分一部分加载，因此无需对整个程序进行分析，采用逐行编译运行的解释型语言更适合 | \n代码优化 | 对整个代码进行复杂地分析优化，耗时较长，优化效果较好 | 逐行查看，分析和处理耗时较短，优化效果较差\n错误 | 编译之后显示所有错误 | 执行到有错误代码位置\n对应语言举例 | C，C ++，C＃，Scala，Java(既需要编译，又需要解释) | PHP，Perl，Ruby （一般可以认为，不需要编译器，直接通过解释器执行的语言就是脚本语言）\n\n\n---\n\n参考\nhttps://www.guru99.com/difference-compiler-vs-interpreter.html","source":"_posts/编译器-vs-解释器：编译器和解释器之间的区别.md","raw":"---\ntitle: 编译器 vs 解释器：编译器和解释器之间的区别\ndate: 2019-06-05 19:14:21\ncategories: \n    - 编译原理\ntags:\n    - 编译原理\n    - 编译器\n    - 解释器\n---\n\n### 编译器(Compiler)\n`编译器`是一种计算机程序，负责把一种编程语言编写的源码转换成`另外一种计算机代码`，往往是`二进制`的形式存在，被称为`目标代码(object code)`。这个转换的过程通常的目的是生成可执行的程序。\n`编译器`的产出是`另外一种代码`，然后这些代码等着被别人拿来执行，如果还不能直接被执行，那么还需要再编译或解释一遍，再交由计算机硬件执行。\n`编译器`往往是在「执行」之前完成，产出是一种可执行或需要再编译或者解释的`代码`。\n\n<!--more-->\n\n<br/>\n### 解释器(Interpreter)\n在计算机科学中，`解释器`是一种计算机程序，它直接执行由编程语言或脚本语言编写的代码，并不会把源代码预编译成机器码。\n一个解释器，通常会用以下的姿势来执行程序代码：\n- 分析源代码，并且直接执行。\n- 把源代码翻译成相对更加高效率的中间码，然后立即执行它。\n- 执行由解释器内部的编译器预编译后保存的代码\n- 可以把解释器看成一个黑盒子，我们输入源码，它就会实时返回结果。\n不同类型的解释器，黑盒子里面的构造不一样，有些还会集成编译器，缓存编译结果，用来提高执行效率（例如 Chrome V8 也是这么做的）。\n解释器通常是工作在「运行时」，并且对于我们输入的源码，是一行一行的解释然后执行，然后返回结果。\n\n\n<br/>\n### 编译器(Compiler) vs 解释器(Interpreter) \n\n | Compiler 编译器 | Interpreter 解释器\n ------- | ------- | -------\n功能 | 对整个程序进行分析，执行输出为另一种代码（一般为机器码，如目标代码，可能需要连接后才能执行），但是不执行该机器码 | 对源代码逐行执行，即包含分析和执行两步\n编程步骤 | 1、创建程序。<br/> 2、【编译】：解析或分析所有代码的正确性。如果不正确，则抛出错误如果没有错误，编译器会将源代码转换为机器代码。<br/> 3、它将不同的代码文件链接到一个可运行的程序（如 .exe） 4、 运行程序 | 1、创建程序 <br/> 2、逐行执行源语句\n优点 | 每次执行的是可运行程序，执行速度较快 | 更容易使用，特别是对于初学者\n缺点 | 只能通过修改源代码改变程序 | 只能在有解释器的计算机上执行\n执行速度 | 每次执行的是可运行程序，执行速度较快 | 每次执行都从源代码开始，且不保存执行过程中的机器代码，执行速度慢\n执行者权限 | 执行者一般得到的是可执行文件，执行者无法对程序进行更改 | 执行者可以对源程序进行更改\n程序运行对象 | CPU | 解释器\n适用环境 | .exe 限定特定CPU| 一份源代码只要有对应版本解释器即可运行<br />对于web环境`，由于代码往往是一部分一部分加载，因此无需对整个程序进行分析，采用逐行编译运行的解释型语言更适合 | \n代码优化 | 对整个代码进行复杂地分析优化，耗时较长，优化效果较好 | 逐行查看，分析和处理耗时较短，优化效果较差\n错误 | 编译之后显示所有错误 | 执行到有错误代码位置\n对应语言举例 | C，C ++，C＃，Scala，Java(既需要编译，又需要解释) | PHP，Perl，Ruby （一般可以认为，不需要编译器，直接通过解释器执行的语言就是脚本语言）\n\n\n---\n\n参考\nhttps://www.guru99.com/difference-compiler-vs-interpreter.html","slug":"编译器-vs-解释器：编译器和解释器之间的区别","published":1,"updated":"2021-06-30T02:33:24.782Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy000b6r5p70wfd33cw","content":"<h3 id=\"编译器-Compiler\"><a href=\"#编译器-Compiler\" class=\"headerlink\" title=\"编译器(Compiler)\"></a>编译器(Compiler)</h3><p><code>编译器</code>是一种计算机程序，负责把一种编程语言编写的源码转换成<code>另外一种计算机代码</code>，往往是<code>二进制</code>的形式存在，被称为<code>目标代码(object code)</code>。这个转换的过程通常的目的是生成可执行的程序。\n<code>编译器</code>的产出是<code>另外一种代码</code>，然后这些代码等着被别人拿来执行，如果还不能直接被执行，那么还需要再编译或解释一遍，再交由计算机硬件执行。\n<code>编译器</code>往往是在「执行」之前完成，产出是一种可执行或需要再编译或者解释的<code>代码</code>。</p>\n<span id=\"more\"></span>\n\n<br>\n### 解释器(Interpreter)\n在计算机科学中，`解释器`是一种计算机程序，它直接执行由编程语言或脚本语言编写的代码，并不会把源代码预编译成机器码。\n一个解释器，通常会用以下的姿势来执行程序代码：\n- 分析源代码，并且直接执行。\n- 把源代码翻译成相对更加高效率的中间码，然后立即执行它。\n- 执行由解释器内部的编译器预编译后保存的代码\n- 可以把解释器看成一个黑盒子，我们输入源码，它就会实时返回结果。\n不同类型的解释器，黑盒子里面的构造不一样，有些还会集成编译器，缓存编译结果，用来提高执行效率（例如 Chrome V8 也是这么做的）。\n解释器通常是工作在「运行时」，并且对于我们输入的源码，是一行一行的解释然后执行，然后返回结果。\n\n\n<br>\n### 编译器(Compiler) vs 解释器(Interpreter) \n\n<p> | Compiler 编译器 | Interpreter 解释器\n ——- | ——- | ——-\n功能 | 对整个程序进行分析，执行输出为另一种代码（一般为机器码，如目标代码，可能需要连接后才能执行），但是不执行该机器码 | 对源代码逐行执行，即包含分析和执行两步\n编程步骤 | 1、创建程序。<br> 2、【编译】：解析或分析所有代码的正确性。如果不正确，则抛出错误如果没有错误，编译器会将源代码转换为机器代码。<br> 3、它将不同的代码文件链接到一个可运行的程序（如 .exe） 4、 运行程序 | 1、创建程序 <br> 2、逐行执行源语句\n优点 | 每次执行的是可运行程序，执行速度较快 | 更容易使用，特别是对于初学者\n缺点 | 只能通过修改源代码改变程序 | 只能在有解释器的计算机上执行\n执行速度 | 每次执行的是可运行程序，执行速度较快 | 每次执行都从源代码开始，且不保存执行过程中的机器代码，执行速度慢\n执行者权限 | 执行者一般得到的是可执行文件，执行者无法对程序进行更改 | 执行者可以对源程序进行更改\n程序运行对象 | CPU | 解释器\n适用环境 | .exe 限定特定CPU| 一份源代码只要有对应版本解释器即可运行<br>对于web环境`，由于代码往往是一部分一部分加载，因此无需对整个程序进行分析，采用逐行编译运行的解释型语言更适合 | \n代码优化 | 对整个代码进行复杂地分析优化，耗时较长，优化效果较好 | 逐行查看，分析和处理耗时较短，优化效果较差\n错误 | 编译之后显示所有错误 | 执行到有错误代码位置\n对应语言举例 | C，C ++，C＃，Scala，Java(既需要编译，又需要解释) | PHP，Perl，Ruby （一般可以认为，不需要编译器，直接通过解释器执行的语言就是脚本语言）</p>\n<hr>\n<p>参考\n<a href=\"https://www.guru99.com/difference-compiler-vs-interpreter.html\">https://www.guru99.com/difference-compiler-vs-interpreter.html</a></p>\n","site":{"data":{}},"excerpt":"<h3 id=\"编译器-Compiler\"><a href=\"#编译器-Compiler\" class=\"headerlink\" title=\"编译器(Compiler)\"></a>编译器(Compiler)</h3><p><code>编译器</code>是一种计算机程序，负责把一种编程语言编写的源码转换成<code>另外一种计算机代码</code>，往往是<code>二进制</code>的形式存在，被称为<code>目标代码(object code)</code>。这个转换的过程通常的目的是生成可执行的程序。\n<code>编译器</code>的产出是<code>另外一种代码</code>，然后这些代码等着被别人拿来执行，如果还不能直接被执行，那么还需要再编译或解释一遍，再交由计算机硬件执行。\n<code>编译器</code>往往是在「执行」之前完成，产出是一种可执行或需要再编译或者解释的<code>代码</code>。</p>","more":"<br/>\n### 解释器(Interpreter)\n在计算机科学中，`解释器`是一种计算机程序，它直接执行由编程语言或脚本语言编写的代码，并不会把源代码预编译成机器码。\n一个解释器，通常会用以下的姿势来执行程序代码：\n- 分析源代码，并且直接执行。\n- 把源代码翻译成相对更加高效率的中间码，然后立即执行它。\n- 执行由解释器内部的编译器预编译后保存的代码\n- 可以把解释器看成一个黑盒子，我们输入源码，它就会实时返回结果。\n不同类型的解释器，黑盒子里面的构造不一样，有些还会集成编译器，缓存编译结果，用来提高执行效率（例如 Chrome V8 也是这么做的）。\n解释器通常是工作在「运行时」，并且对于我们输入的源码，是一行一行的解释然后执行，然后返回结果。\n\n\n<br/>\n### 编译器(Compiler) vs 解释器(Interpreter) \n\n<p> | Compiler 编译器 | Interpreter 解释器\n ——- | ——- | ——-\n功能 | 对整个程序进行分析，执行输出为另一种代码（一般为机器码，如目标代码，可能需要连接后才能执行），但是不执行该机器码 | 对源代码逐行执行，即包含分析和执行两步\n编程步骤 | 1、创建程序。<br/> 2、【编译】：解析或分析所有代码的正确性。如果不正确，则抛出错误如果没有错误，编译器会将源代码转换为机器代码。<br/> 3、它将不同的代码文件链接到一个可运行的程序（如 .exe） 4、 运行程序 | 1、创建程序 <br/> 2、逐行执行源语句\n优点 | 每次执行的是可运行程序，执行速度较快 | 更容易使用，特别是对于初学者\n缺点 | 只能通过修改源代码改变程序 | 只能在有解释器的计算机上执行\n执行速度 | 每次执行的是可运行程序，执行速度较快 | 每次执行都从源代码开始，且不保存执行过程中的机器代码，执行速度慢\n执行者权限 | 执行者一般得到的是可执行文件，执行者无法对程序进行更改 | 执行者可以对源程序进行更改\n程序运行对象 | CPU | 解释器\n适用环境 | .exe 限定特定CPU| 一份源代码只要有对应版本解释器即可运行<br />对于web环境`，由于代码往往是一部分一部分加载，因此无需对整个程序进行分析，采用逐行编译运行的解释型语言更适合 | \n代码优化 | 对整个代码进行复杂地分析优化，耗时较长，优化效果较好 | 逐行查看，分析和处理耗时较短，优化效果较差\n错误 | 编译之后显示所有错误 | 执行到有错误代码位置\n对应语言举例 | C，C ++，C＃，Scala，Java(既需要编译，又需要解释) | PHP，Perl，Ruby （一般可以认为，不需要编译器，直接通过解释器执行的语言就是脚本语言）</p>\n<hr>\n<p>参考\n<a href=\"https://www.guru99.com/difference-compiler-vs-interpreter.html\">https://www.guru99.com/difference-compiler-vs-interpreter.html</a></p>"},{"title":"设计模式总结","date":"2019-01-02T03:07:32.000Z","_content":"\n\n## 设计模式六大原则\n\n### 单一职责原则\n定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 \n\n问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。\n\n解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。\n\n### 里氏替换原则\n定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。\n\n定义2：所有引用基类的地方必须能透明地使用其子类的对象。\n\n问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。\n\n解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。\n\n### 依赖倒置原则\n\n### 接口隔离原则\n\n### 迪米特法则\n\n### 开闭原则\n\n\n\n<br/>\n\n---\n\n参考\n\n","source":"_posts/设计模式总结.md","raw":"---\ntitle: 设计模式总结\ndate: 2019-01-02 11:07:32\ncategories: \n    - 设计模式\ntags:\n    - 设计模式\n---\n\n\n## 设计模式六大原则\n\n### 单一职责原则\n定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 \n\n问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。\n\n解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。\n\n### 里氏替换原则\n定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。\n\n定义2：所有引用基类的地方必须能透明地使用其子类的对象。\n\n问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。\n\n解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。\n\n### 依赖倒置原则\n\n### 接口隔离原则\n\n### 迪米特法则\n\n### 开闭原则\n\n\n\n<br/>\n\n---\n\n参考\n\n","slug":"设计模式总结","published":1,"updated":"2021-06-30T02:33:24.782Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy200bar5p76ar92kh0","content":"<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><h3 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h3><p>定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 </p>\n<p>问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。</p>\n<p>解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。</p>\n<h3 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h3><p>定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。</p>\n<p>定义2：所有引用基类的地方必须能透明地使用其子类的对象。</p>\n<p>问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。</p>\n<p>解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。</p>\n<h3 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h3><h3 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h3><h3 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h3><h3 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h3><br>\n\n<hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><h3 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h3><p>定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 </p>\n<p>问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。</p>\n<p>解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。</p>\n<h3 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h3><p>定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。</p>\n<p>定义2：所有引用基类的地方必须能透明地使用其子类的对象。</p>\n<p>问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。</p>\n<p>解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。</p>\n<h3 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h3><h3 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h3><h3 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h3><h3 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h3><br/>\n\n<hr>\n<p>参考</p>\n"},{"title":"调用链上下文跨线程传递","date":"2019-10-10T07:48:46.000Z","_content":"\n\n在分布式系统的上下文传递过程中，需要传递的信息一般包括traceID、 spanID以及部分请求参数等,可以分为以下几种场景:\n\n在同一线程内传递\n跨线程传递\n跨应用传递\n在同一个线程内传递比较简单,通过ThreadLocal就能解决上下文传递的问题,如果是跨线程传递,大家可能会想到jdk里的实现java.lang.InheritableThreadLocal,它拥有和线程变量ThreadLocal一样的功能，并且在当前线程上创建一个新的线程实例时，会把这些线程变量从当前线程传递给新的线程实例.但是在实际的应用场景里，绝大多数都是使用线程池来进行多线程编程，线程由线程池创建好，并且线程是池化起来反复使用,这时父子线程关系的ThreadLocal值传递已经没有意义，应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时。所以jdk提供的inheritableThreadLocals类实用性不高,在线程池(ThreadPoolExecutor)中运行一个Runable实例并不会去新建一个线程，而是把Runable实例添加到队列中(在核心线程数已实例化满的时候),让ThreadPoolExecutor的workers去从队列里拿出Runable实例（这是一个典型的生产者消费者模式),然后运行Runable实例.run()方法,故jdk的inheritableThreadLocals这种实现方式没法适用。\n\n这篇文章主要介绍基于字节码修改的方法修改ThreadPoolExecutor和ForkJoinTask的字节码,实现非侵入式的上下文传递,我们先来看一下如果通过侵入式方式定制线程池怎么解决上下文传递,假设我们的调用链通过TraceContext类来保存上下文信息:\n\n```java\npublic class TraceContext {\n    private static final ThreadLocal<Object> CONTEXT = new ThreadLocal<>();\n    public static Object getContext() {\n        return CONTEXT.get();\n    }\n    public static void setContext(Object obj) {\n        CONTEXT.set(obj);\n    }\n    public static void removeContext() {\n        CONTEXT.remove();\n    }\n\n}\n```\n\n我们先定义2个类,分别继承自`Runnable`和`Callable`,目的在于初始化`Runnable`和`Callable`实例时保存调用线程的上下文信息到,在执行`run()`或者`call()`方法时,先把调用线程的上下文信息设置到当前执行的线程中,`run()/call()`方法执行后恢复执行线程的上下文,这2个类分别为`TraceRunnable`和`TraceCallable`:\n\n```java\npublic class TraceRunnable implements Runnable {\n    //在初始化TraceRunnable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Runnable runnable;\n\n    public TraceRunnable(Runnable runnable) {\n        this.runnable = runnable;\n    }\n    @Override\n    public void run() {\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        try {\n            this.runnable.run();\n        } finally {\n            TraceContextUtil.restoreBackup(backup);\n        }\n    }\n\n    public Runnable getRunnable() {\n        return this.runnable;\n    }\n\n    public static TraceRunnable get(Runnable runnable) {\n        if (runnable == null) {\n            return null;\n        } else {\n            return runnable instanceof TraceRunnable ? (TraceRunnable)runnable : new TraceRunnable(runnable);\n        }\n    }\n}\n\npublic class TraceCallable<V> implements Callable<V> {\n    //在初始化TraceCallable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Callable<V> callable;\n\n    public TraceCallable(Callable<V> callable) {\n        this.callable = callable;\n    }\n\n    @Override\n    public V call() throws Exception {\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        V result;\n        try {\n            result = this.callable.call();\n        } finally {\n            TraceContextUtil.restoreBackup(backup);\n        }\n\n        return result;\n    }\n\n    public Callable<V> getCallable() {\n        return this.callable;\n    }\n    //返回TraceCallable实例\n    public static <T> TraceCallable<T> get(Callable<T> callable) {\n        if (callable == null) {\n            return null;\n        } else {\n            return callable instanceof TraceCallable ? (TraceCallable)callable : new TraceCallable(callable);\n        }\n    }\n\n}\n\npublic class TraceContextUtil {\n    //设置调用线程的上下文到当前执行线程中,并返回执行线程之前的上下文\n    public static Object backupAndSet(Object currentContext) {\n        Object backupContext = TraceContext.getContext();\n        TraceContext.setContext(currentContext);\n        return backupContext;\n    }\n    //恢复执行线程的上下文\n    public static void restoreBackup(Object backup) {\n        TraceContext.setContext(backup);\n    }\n}\n```\n\n\n接下来就是定制线程池,重写`execute`和`submit`方法,把`Runnable/Callable`实例封装成`TraceRunnable/TraceCallable`,这样就把调用线程的上下文信息传递到线程池内部:\n\n```java\npublic class TraceThreadPoolExecutor extends java.util.concurrent.ThreadPoolExecutor{\n    public void submit(Runnable runnable) {\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        super.execute(traceRunnable);\n    }\n    \n    public Future<?> submit(Runnable task) {\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        return super.submit(traceRunnable);\n    }\n    public <T> Future<T> submit(Callable<T> task) {\n         TraceCallable traceCallable = new TraceCallable(task);\n         return super.submit(traceCallable);\n    }\n```\n\n上面的方法虽然实现了上下文跨线程传递,在Runnable/Callable方法内部可以通过TraceContext.getContext()来获取上下文信息,但前提是异步处理都要使用TraceThreadPoolExecutor来提交任务,这样对代码具有侵入性,需要业务做改造,\n为了减少业务开发人员的工作量，使用 javaagent和instrument技术，利用字节码修改技术修改ThreadPoolExecutor和ScheduledThreadPoolExecutor类的字节码,也就是说,只要在JVM参数里加上了javaagent的配置，不需要直接使用上面的TraceRunnable/TraceCallable包装类，也不需要使用TraceThreadPoolExecutor,即可实现上下文信息的自动传递。\n\n对于`ThreadPoolExecutor`和`ScheduledThreadPoolExecutor`,只需要修改它们的`execute/submit/schedule/scheduleAtFixedRate/scheduleWithFixedDelay`这些方法的字节码,逻辑和前面介绍的一致:\n\n```java\npublic interface TraceTransformer {\n    boolean needTransform(String className);\n\n    void doTransform(CtClass var1) throws NotFoundException, CannotCompileException, IOException;\n}\n\npublic class ThreadPoolTransformer implements TraceTransformer {\n    private static final String TRACE_RUNNABLE_CLASS_NAME = TraceRunnable.class.getName();\n    private static final String TRACE_CALLABLE_CLASS_NAME = TraceCallable.class.getName();\n\n    private static final Set<String> TO_TRANSFORM_METHODS = new HashSet<>();\n\n    static {\n        TO_TRANSFORM_METHODS.add(\"execute\");\n        TO_TRANSFORM_METHODS.add(\"submit\");\n        TO_TRANSFORM_METHODS.add(\"schedule\");\n        TO_TRANSFORM_METHODS.add(\"scheduleAtFixedRate\");\n        TO_TRANSFORM_METHODS.add(\"scheduleWithFixedDelay\");\n    }\n\n    @Override\n    public boolean needTransform(String className) {\n        return \"java.util.concurrent.ThreadPoolExecutor\".equals(className)\n                || \"java.util.concurrent.ScheduledThreadPoolExecutor\".equals(className);\n    }\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException {\n        CtMethod[] methods = clazz.getDeclaredMethods();\n        int length = methods.length;\n\n        for(int i = 0; i < length; ++i) {\n            CtMethod method = methods[i];\n            transformMethod(clazz, method);\n        }\n\n    }\n\n    static void transformMethod(CtClass clazz, CtMethod method) throws NotFoundException, CannotCompileException {\n        if (TO_TRANSFORM_METHODS.contains(method.getName())) {\n            if (method.getDeclaringClass() == clazz) {\n                int modifiers = method.getModifiers();\n                if (Modifier.isPublic(modifiers) && !Modifier.isStatic(modifiers)) {\n                    CtClass[] parameterTypes = method.getParameterTypes();\n                    StringBuilder insertCode = new StringBuilder();\n\n                    for(int i = 0; i < parameterTypes.length; ++i) {\n                        CtClass parameterType = parameterTypes[i];\n                        String code;\n                        if (\"java.lang.Runnable\".equals(parameterType.getName())) {\n                            //$1 = TraceRunnable.get($1)返回TraceRunnable实例\n                            code = String.format(\"$%d = %s.get($%d);\", i + 1, TRACE_RUNNABLE_CLASS_NAME, i + 1);\n                            System.out.println(\"insert code before method \" + method + \" of class \" + method.getDeclaringClass().getName() + \": \" + code);\n                            insertCode.append(code);\n                        } else if (\"java.util.concurrent.Callable\".equals(parameterType.getName())) {\n                            //$1 = TraceCallable.get($1)返回TraceCallable实例\n                            code = String.format(\"$%d = %s.get($%d);\", i + 1, TRACE_CALLABLE_CLASS_NAME, i + 1);\n                            System.out.println(\"insert code before method \" + method + \" of class \" + method.getDeclaringClass().getName() + \": \" + code);\n                            insertCode.append(code);\n                        }\n                    }\n\n                    if (insertCode.length() > 0) {\n                        method.insertBefore(insertCode.toString());\n                    }\n\n                }\n            }\n        }\n    }\n}\n```\n\n\n对于ForkJoinPool, 做法也类似,这里换一种修改方式,主要为了熟悉下javassist的语法,这次是在ForkJoinTask里添加一个context$field$add$by$trace字段,在初始化ForkJoinTask实例自动获取调用线程的上下文(TraceContext.getContext()),并修改ForkJoinTask的doExec()方法,修改逻辑和前面的一样\n\n```java\npublic class ForkJoinPoolTransformer implements TraceTransformer {\n    private static final String FORK_JOIN_TASK_CLASS_NAME = \"java.util.concurrent.ForkJoinTask\";\n\n    @Override\n    public boolean needTransform(String className) {\n        return FORK_JOIN_TASK_CLASS_NAME.equals(className);\n    }\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException {\n        String className = clazz.getName();\n        //添加context$field$add$by$trace字段,初始值为TraceContext.getContext(),这样就获取了调用线程的上下文\n        CtField contextField = CtField.make(\"private final java.lang.Object context$field$add$by$trace;\", clazz);\n        clazz.addField(contextField, \"com.ezlippi.trace.agent.context.TraceContext.getContext();\");\n        System.out.println(\"add new field context$field$add$by$trace to class \" + className);\n        CtMethod doExecMethod = clazz.getDeclaredMethod(\"doExec\");\n        CtMethod newDoExecMethod = CtNewMethod.copy(doExecMethod, \"doExec\", clazz, (ClassMap)null);\n        doExecMethod.setName(\"original$doExec$method$renamed$by$trace\");\n        doExecMethod.setModifiers(doExecMethod.getModifiers() & -2 | 2);\n        //java.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(this.context$field$add$by$trace);\n        //try {\n        //   return original$doExec$method$renamed$by$trace($$);\n        //} finally {\n        //    TraceContextUtil.restoreBackup(backup);\n        //}\n        newDoExecMethod.setBody(\"{\\njava.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(context$field$add$by$trace);\\ntry {\\n    return original$doExec$method$renamed$by$trace($$);\\n} finally {\\n    com.ezlippi.trace.agent.context.TraceContextUtil.restoreBackup(backup);\\n}\\n}\");\n        clazz.addMethod(newDoExecMethod);\n        System.out.println(\"insert code around method \" + doExecMethod + \" of class \" + className);\n\n\n    }\n}\n```\n\n\n接下来就是添加一个ClassFileTransformer,JVM启动时会传递Instrumentation对象给javaagent的preMain()方法,我们只需要往instrumentation中注册一个ClassFileTransformer实例,jvm在加载类时会把解析后的class字节数组传递给\nClassFileTransformer,执行修改逻辑后把字节数组返回给jvm.\n```java\npublic class TlTransformer implements ClassFileTransformer {\n    private List<TraceTransformer> transformers = new ArrayList<>();\n\n    public TlTransformer() {\n        this.transformers.add(new ForkJoinPoolTransformer());\n        this.transformers.add(new ThreadPoolTransformer());\n    }\n\n    @Override\n    public byte[] transform(ClassLoader loader, String classFile, Class<?> classBeingRedefined, ProtectionDomain protectionDomain, byte[] classFileBuffer) throws IllegalClassFormatException {\n        try {\n            if (classFile == null) {\n                return new byte[0];\n            }\n\n            String className = this.toClassName(classFile);\n            Iterator iterator = this.transformers.iterator();\n\n            while(iterator.hasNext()) {\n                TraceTransformer transformer = (TraceTransformer)iterator.next();\n                if (transformer.needTransform(className)) {\n                    System.out.println(\"Transforming class \" + className);\n                    CtClass clazz = this.getCtClass(classFileBuffer, loader);\n                    transformer.doTransform(clazz);\n                    return clazz.toBytecode();\n                }\n            }\n        } catch (Throwable throwable) {\n            String msg = \"Fail to transform class \" + classFile + \", cause: \" + throwable.toString();\n            System.out.println(msg);\n            throw new IllegalStateException(msg, throwable);\n        }\n\n        return new byte[0];\n    }\n\n    private String toClassName(String classFile) {\n        return classFile.replace('/', '.');\n    }\n\n    private CtClass getCtClass(byte[] classFileBuffer, ClassLoader classLoader) throws IOException {\n        ClassPool classPool = new ClassPool(true);\n        if (null != classLoader) {\n            classPool.appendClassPath(new LoaderClassPath(classLoader));\n        }\n\n        CtClass clazz = classPool.makeClass(new ByteArrayInputStream(classFileBuffer), false);\n        clazz.defrost();\n        return clazz;\n    }\n}\n\npublic class TraceAgent {\n    public static void premain(String agentArgs, Instrumentation instrumentation) {\n        ClassFileTransformer transformer = new TlTransformer();\n        instrumentation.addTransformer(transformer, true);\n    }\n}\n```\n\n\n因为修改了JDK的标准库的类，标准库由bootstrap class loader加载,上面修改后的ThreadPoolExecutor和ForkJoinTask类引用了agent的代码，所以agent的Jar需要加到boot class path上,可以通过maven-jar-plugin在agent jar的manifest添加Boot-Class-Path这个入口.\n\n```xml\n<plugin>\n        <artifactId>maven-jar-plugin</artifactId>\n        <version>3.0.2</version>\n        <configuration>\n            <archive>\n                <manifestEntries>\n                    <Premain-Class>com.ezlippi.trace.agent.TraceAgent</Premain-Class>\n                    <Boot-Class-Path>${project.artifactId}-${project.version}.jar</Boot-Class-Path>\n                    <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                    <Can-Retransform-Classes>true</Can-Retransform-Classes>\n                    <Can-Set-Native-Method-Prefix>false</Can-Set-Native-Method-Prefix>\n                </manifestEntries>\n            </archive>\n        </configuration>\n</plugin>\n```\n\n最后在Java的启动参数加上：-javaagent:path/to/trace-agent-x.x.x.jar后就大功告成了.","source":"_posts/调用链上下文跨线程传递.md","raw":"---\ntitle: 调用链上下文跨线程传递\ndate: 2019-10-10 15:48:46\ncategories: \n    - Java\n    - Trace\ntags:\n    - Java\n    - Trace\n---\n\n\n在分布式系统的上下文传递过程中，需要传递的信息一般包括traceID、 spanID以及部分请求参数等,可以分为以下几种场景:\n\n在同一线程内传递\n跨线程传递\n跨应用传递\n在同一个线程内传递比较简单,通过ThreadLocal就能解决上下文传递的问题,如果是跨线程传递,大家可能会想到jdk里的实现java.lang.InheritableThreadLocal,它拥有和线程变量ThreadLocal一样的功能，并且在当前线程上创建一个新的线程实例时，会把这些线程变量从当前线程传递给新的线程实例.但是在实际的应用场景里，绝大多数都是使用线程池来进行多线程编程，线程由线程池创建好，并且线程是池化起来反复使用,这时父子线程关系的ThreadLocal值传递已经没有意义，应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时。所以jdk提供的inheritableThreadLocals类实用性不高,在线程池(ThreadPoolExecutor)中运行一个Runable实例并不会去新建一个线程，而是把Runable实例添加到队列中(在核心线程数已实例化满的时候),让ThreadPoolExecutor的workers去从队列里拿出Runable实例（这是一个典型的生产者消费者模式),然后运行Runable实例.run()方法,故jdk的inheritableThreadLocals这种实现方式没法适用。\n\n这篇文章主要介绍基于字节码修改的方法修改ThreadPoolExecutor和ForkJoinTask的字节码,实现非侵入式的上下文传递,我们先来看一下如果通过侵入式方式定制线程池怎么解决上下文传递,假设我们的调用链通过TraceContext类来保存上下文信息:\n\n```java\npublic class TraceContext {\n    private static final ThreadLocal<Object> CONTEXT = new ThreadLocal<>();\n    public static Object getContext() {\n        return CONTEXT.get();\n    }\n    public static void setContext(Object obj) {\n        CONTEXT.set(obj);\n    }\n    public static void removeContext() {\n        CONTEXT.remove();\n    }\n\n}\n```\n\n我们先定义2个类,分别继承自`Runnable`和`Callable`,目的在于初始化`Runnable`和`Callable`实例时保存调用线程的上下文信息到,在执行`run()`或者`call()`方法时,先把调用线程的上下文信息设置到当前执行的线程中,`run()/call()`方法执行后恢复执行线程的上下文,这2个类分别为`TraceRunnable`和`TraceCallable`:\n\n```java\npublic class TraceRunnable implements Runnable {\n    //在初始化TraceRunnable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Runnable runnable;\n\n    public TraceRunnable(Runnable runnable) {\n        this.runnable = runnable;\n    }\n    @Override\n    public void run() {\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        try {\n            this.runnable.run();\n        } finally {\n            TraceContextUtil.restoreBackup(backup);\n        }\n    }\n\n    public Runnable getRunnable() {\n        return this.runnable;\n    }\n\n    public static TraceRunnable get(Runnable runnable) {\n        if (runnable == null) {\n            return null;\n        } else {\n            return runnable instanceof TraceRunnable ? (TraceRunnable)runnable : new TraceRunnable(runnable);\n        }\n    }\n}\n\npublic class TraceCallable<V> implements Callable<V> {\n    //在初始化TraceCallable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Callable<V> callable;\n\n    public TraceCallable(Callable<V> callable) {\n        this.callable = callable;\n    }\n\n    @Override\n    public V call() throws Exception {\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        V result;\n        try {\n            result = this.callable.call();\n        } finally {\n            TraceContextUtil.restoreBackup(backup);\n        }\n\n        return result;\n    }\n\n    public Callable<V> getCallable() {\n        return this.callable;\n    }\n    //返回TraceCallable实例\n    public static <T> TraceCallable<T> get(Callable<T> callable) {\n        if (callable == null) {\n            return null;\n        } else {\n            return callable instanceof TraceCallable ? (TraceCallable)callable : new TraceCallable(callable);\n        }\n    }\n\n}\n\npublic class TraceContextUtil {\n    //设置调用线程的上下文到当前执行线程中,并返回执行线程之前的上下文\n    public static Object backupAndSet(Object currentContext) {\n        Object backupContext = TraceContext.getContext();\n        TraceContext.setContext(currentContext);\n        return backupContext;\n    }\n    //恢复执行线程的上下文\n    public static void restoreBackup(Object backup) {\n        TraceContext.setContext(backup);\n    }\n}\n```\n\n\n接下来就是定制线程池,重写`execute`和`submit`方法,把`Runnable/Callable`实例封装成`TraceRunnable/TraceCallable`,这样就把调用线程的上下文信息传递到线程池内部:\n\n```java\npublic class TraceThreadPoolExecutor extends java.util.concurrent.ThreadPoolExecutor{\n    public void submit(Runnable runnable) {\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        super.execute(traceRunnable);\n    }\n    \n    public Future<?> submit(Runnable task) {\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        return super.submit(traceRunnable);\n    }\n    public <T> Future<T> submit(Callable<T> task) {\n         TraceCallable traceCallable = new TraceCallable(task);\n         return super.submit(traceCallable);\n    }\n```\n\n上面的方法虽然实现了上下文跨线程传递,在Runnable/Callable方法内部可以通过TraceContext.getContext()来获取上下文信息,但前提是异步处理都要使用TraceThreadPoolExecutor来提交任务,这样对代码具有侵入性,需要业务做改造,\n为了减少业务开发人员的工作量，使用 javaagent和instrument技术，利用字节码修改技术修改ThreadPoolExecutor和ScheduledThreadPoolExecutor类的字节码,也就是说,只要在JVM参数里加上了javaagent的配置，不需要直接使用上面的TraceRunnable/TraceCallable包装类，也不需要使用TraceThreadPoolExecutor,即可实现上下文信息的自动传递。\n\n对于`ThreadPoolExecutor`和`ScheduledThreadPoolExecutor`,只需要修改它们的`execute/submit/schedule/scheduleAtFixedRate/scheduleWithFixedDelay`这些方法的字节码,逻辑和前面介绍的一致:\n\n```java\npublic interface TraceTransformer {\n    boolean needTransform(String className);\n\n    void doTransform(CtClass var1) throws NotFoundException, CannotCompileException, IOException;\n}\n\npublic class ThreadPoolTransformer implements TraceTransformer {\n    private static final String TRACE_RUNNABLE_CLASS_NAME = TraceRunnable.class.getName();\n    private static final String TRACE_CALLABLE_CLASS_NAME = TraceCallable.class.getName();\n\n    private static final Set<String> TO_TRANSFORM_METHODS = new HashSet<>();\n\n    static {\n        TO_TRANSFORM_METHODS.add(\"execute\");\n        TO_TRANSFORM_METHODS.add(\"submit\");\n        TO_TRANSFORM_METHODS.add(\"schedule\");\n        TO_TRANSFORM_METHODS.add(\"scheduleAtFixedRate\");\n        TO_TRANSFORM_METHODS.add(\"scheduleWithFixedDelay\");\n    }\n\n    @Override\n    public boolean needTransform(String className) {\n        return \"java.util.concurrent.ThreadPoolExecutor\".equals(className)\n                || \"java.util.concurrent.ScheduledThreadPoolExecutor\".equals(className);\n    }\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException {\n        CtMethod[] methods = clazz.getDeclaredMethods();\n        int length = methods.length;\n\n        for(int i = 0; i < length; ++i) {\n            CtMethod method = methods[i];\n            transformMethod(clazz, method);\n        }\n\n    }\n\n    static void transformMethod(CtClass clazz, CtMethod method) throws NotFoundException, CannotCompileException {\n        if (TO_TRANSFORM_METHODS.contains(method.getName())) {\n            if (method.getDeclaringClass() == clazz) {\n                int modifiers = method.getModifiers();\n                if (Modifier.isPublic(modifiers) && !Modifier.isStatic(modifiers)) {\n                    CtClass[] parameterTypes = method.getParameterTypes();\n                    StringBuilder insertCode = new StringBuilder();\n\n                    for(int i = 0; i < parameterTypes.length; ++i) {\n                        CtClass parameterType = parameterTypes[i];\n                        String code;\n                        if (\"java.lang.Runnable\".equals(parameterType.getName())) {\n                            //$1 = TraceRunnable.get($1)返回TraceRunnable实例\n                            code = String.format(\"$%d = %s.get($%d);\", i + 1, TRACE_RUNNABLE_CLASS_NAME, i + 1);\n                            System.out.println(\"insert code before method \" + method + \" of class \" + method.getDeclaringClass().getName() + \": \" + code);\n                            insertCode.append(code);\n                        } else if (\"java.util.concurrent.Callable\".equals(parameterType.getName())) {\n                            //$1 = TraceCallable.get($1)返回TraceCallable实例\n                            code = String.format(\"$%d = %s.get($%d);\", i + 1, TRACE_CALLABLE_CLASS_NAME, i + 1);\n                            System.out.println(\"insert code before method \" + method + \" of class \" + method.getDeclaringClass().getName() + \": \" + code);\n                            insertCode.append(code);\n                        }\n                    }\n\n                    if (insertCode.length() > 0) {\n                        method.insertBefore(insertCode.toString());\n                    }\n\n                }\n            }\n        }\n    }\n}\n```\n\n\n对于ForkJoinPool, 做法也类似,这里换一种修改方式,主要为了熟悉下javassist的语法,这次是在ForkJoinTask里添加一个context$field$add$by$trace字段,在初始化ForkJoinTask实例自动获取调用线程的上下文(TraceContext.getContext()),并修改ForkJoinTask的doExec()方法,修改逻辑和前面的一样\n\n```java\npublic class ForkJoinPoolTransformer implements TraceTransformer {\n    private static final String FORK_JOIN_TASK_CLASS_NAME = \"java.util.concurrent.ForkJoinTask\";\n\n    @Override\n    public boolean needTransform(String className) {\n        return FORK_JOIN_TASK_CLASS_NAME.equals(className);\n    }\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException {\n        String className = clazz.getName();\n        //添加context$field$add$by$trace字段,初始值为TraceContext.getContext(),这样就获取了调用线程的上下文\n        CtField contextField = CtField.make(\"private final java.lang.Object context$field$add$by$trace;\", clazz);\n        clazz.addField(contextField, \"com.ezlippi.trace.agent.context.TraceContext.getContext();\");\n        System.out.println(\"add new field context$field$add$by$trace to class \" + className);\n        CtMethod doExecMethod = clazz.getDeclaredMethod(\"doExec\");\n        CtMethod newDoExecMethod = CtNewMethod.copy(doExecMethod, \"doExec\", clazz, (ClassMap)null);\n        doExecMethod.setName(\"original$doExec$method$renamed$by$trace\");\n        doExecMethod.setModifiers(doExecMethod.getModifiers() & -2 | 2);\n        //java.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(this.context$field$add$by$trace);\n        //try {\n        //   return original$doExec$method$renamed$by$trace($$);\n        //} finally {\n        //    TraceContextUtil.restoreBackup(backup);\n        //}\n        newDoExecMethod.setBody(\"{\\njava.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(context$field$add$by$trace);\\ntry {\\n    return original$doExec$method$renamed$by$trace($$);\\n} finally {\\n    com.ezlippi.trace.agent.context.TraceContextUtil.restoreBackup(backup);\\n}\\n}\");\n        clazz.addMethod(newDoExecMethod);\n        System.out.println(\"insert code around method \" + doExecMethod + \" of class \" + className);\n\n\n    }\n}\n```\n\n\n接下来就是添加一个ClassFileTransformer,JVM启动时会传递Instrumentation对象给javaagent的preMain()方法,我们只需要往instrumentation中注册一个ClassFileTransformer实例,jvm在加载类时会把解析后的class字节数组传递给\nClassFileTransformer,执行修改逻辑后把字节数组返回给jvm.\n```java\npublic class TlTransformer implements ClassFileTransformer {\n    private List<TraceTransformer> transformers = new ArrayList<>();\n\n    public TlTransformer() {\n        this.transformers.add(new ForkJoinPoolTransformer());\n        this.transformers.add(new ThreadPoolTransformer());\n    }\n\n    @Override\n    public byte[] transform(ClassLoader loader, String classFile, Class<?> classBeingRedefined, ProtectionDomain protectionDomain, byte[] classFileBuffer) throws IllegalClassFormatException {\n        try {\n            if (classFile == null) {\n                return new byte[0];\n            }\n\n            String className = this.toClassName(classFile);\n            Iterator iterator = this.transformers.iterator();\n\n            while(iterator.hasNext()) {\n                TraceTransformer transformer = (TraceTransformer)iterator.next();\n                if (transformer.needTransform(className)) {\n                    System.out.println(\"Transforming class \" + className);\n                    CtClass clazz = this.getCtClass(classFileBuffer, loader);\n                    transformer.doTransform(clazz);\n                    return clazz.toBytecode();\n                }\n            }\n        } catch (Throwable throwable) {\n            String msg = \"Fail to transform class \" + classFile + \", cause: \" + throwable.toString();\n            System.out.println(msg);\n            throw new IllegalStateException(msg, throwable);\n        }\n\n        return new byte[0];\n    }\n\n    private String toClassName(String classFile) {\n        return classFile.replace('/', '.');\n    }\n\n    private CtClass getCtClass(byte[] classFileBuffer, ClassLoader classLoader) throws IOException {\n        ClassPool classPool = new ClassPool(true);\n        if (null != classLoader) {\n            classPool.appendClassPath(new LoaderClassPath(classLoader));\n        }\n\n        CtClass clazz = classPool.makeClass(new ByteArrayInputStream(classFileBuffer), false);\n        clazz.defrost();\n        return clazz;\n    }\n}\n\npublic class TraceAgent {\n    public static void premain(String agentArgs, Instrumentation instrumentation) {\n        ClassFileTransformer transformer = new TlTransformer();\n        instrumentation.addTransformer(transformer, true);\n    }\n}\n```\n\n\n因为修改了JDK的标准库的类，标准库由bootstrap class loader加载,上面修改后的ThreadPoolExecutor和ForkJoinTask类引用了agent的代码，所以agent的Jar需要加到boot class path上,可以通过maven-jar-plugin在agent jar的manifest添加Boot-Class-Path这个入口.\n\n```xml\n<plugin>\n        <artifactId>maven-jar-plugin</artifactId>\n        <version>3.0.2</version>\n        <configuration>\n            <archive>\n                <manifestEntries>\n                    <Premain-Class>com.ezlippi.trace.agent.TraceAgent</Premain-Class>\n                    <Boot-Class-Path>${project.artifactId}-${project.version}.jar</Boot-Class-Path>\n                    <Can-Redefine-Classes>true</Can-Redefine-Classes>\n                    <Can-Retransform-Classes>true</Can-Retransform-Classes>\n                    <Can-Set-Native-Method-Prefix>false</Can-Set-Native-Method-Prefix>\n                </manifestEntries>\n            </archive>\n        </configuration>\n</plugin>\n```\n\n最后在Java的启动参数加上：-javaagent:path/to/trace-agent-x.x.x.jar后就大功告成了.","slug":"调用链上下文跨线程传递","published":1,"updated":"2021-06-30T02:33:24.807Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy200bdr5p76ludg8dr","content":"<p>在分布式系统的上下文传递过程中，需要传递的信息一般包括traceID、 spanID以及部分请求参数等,可以分为以下几种场景:</p>\n<p>在同一线程内传递\n跨线程传递\n跨应用传递\n在同一个线程内传递比较简单,通过ThreadLocal就能解决上下文传递的问题,如果是跨线程传递,大家可能会想到jdk里的实现java.lang.InheritableThreadLocal,它拥有和线程变量ThreadLocal一样的功能，并且在当前线程上创建一个新的线程实例时，会把这些线程变量从当前线程传递给新的线程实例.但是在实际的应用场景里，绝大多数都是使用线程池来进行多线程编程，线程由线程池创建好，并且线程是池化起来反复使用,这时父子线程关系的ThreadLocal值传递已经没有意义，应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时。所以jdk提供的inheritableThreadLocals类实用性不高,在线程池(ThreadPoolExecutor)中运行一个Runable实例并不会去新建一个线程，而是把Runable实例添加到队列中(在核心线程数已实例化满的时候),让ThreadPoolExecutor的workers去从队列里拿出Runable实例（这是一个典型的生产者消费者模式),然后运行Runable实例.run()方法,故jdk的inheritableThreadLocals这种实现方式没法适用。</p>\n<p>这篇文章主要介绍基于字节码修改的方法修改ThreadPoolExecutor和ForkJoinTask的字节码,实现非侵入式的上下文传递,我们先来看一下如果通过侵入式方式定制线程池怎么解决上下文传递,假设我们的调用链通过TraceContext类来保存上下文信息:</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceContext</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> ThreadLocal<span class=\"token operator\">&lt;</span>Object<span class=\"token operator\">></span> CONTEXT <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadLocal</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Object <span class=\"token function\">getContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> CONTEXT<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">setContext</span><span class=\"token punctuation\">(</span>Object obj<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        CONTEXT<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span>obj<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">removeContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        CONTEXT<span class=\"token punctuation\">.</span><span class=\"token function\">remove</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>我们先定义2个类,分别继承自<code>Runnable</code>和<code>Callable</code>,目的在于初始化<code>Runnable</code>和<code>Callable</code>实例时保存调用线程的上下文信息到,在执行<code>run()</code>或者<code>call()</code>方法时,先把调用线程的上下文信息设置到当前执行的线程中,<code>run()/call()</code>方法执行后恢复执行线程的上下文,这2个类分别为<code>TraceRunnable</code>和<code>TraceCallable</code>:</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceRunnable</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Runnable</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">//在初始化TraceRunnable时会获取调用线程的上下文</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Object context <span class=\"token operator\">=</span> TraceContext<span class=\"token punctuation\">.</span><span class=\"token function\">getContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Runnable runnable<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token function\">TraceRunnable</span><span class=\"token punctuation\">(</span>Runnable runnable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>runnable <span class=\"token operator\">=</span> runnable<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Object backup <span class=\"token operator\">=</span> TraceContextUtil<span class=\"token punctuation\">.</span><span class=\"token function\">backupAndSet</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>context<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>runnable<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n            TraceContextUtil<span class=\"token punctuation\">.</span><span class=\"token function\">restoreBackup</span><span class=\"token punctuation\">(</span>backup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> Runnable <span class=\"token function\">getRunnable</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>runnable<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> TraceRunnable <span class=\"token function\">get</span><span class=\"token punctuation\">(</span>Runnable runnable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>runnable <span class=\"token operator\">==</span> null<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> null<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> runnable <span class=\"token keyword\">instanceof</span> <span class=\"token class-name\">TraceRunnable</span> <span class=\"token operator\">?</span> <span class=\"token punctuation\">(</span>TraceRunnable<span class=\"token punctuation\">)</span>runnable <span class=\"token operator\">:</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TraceRunnable</span><span class=\"token punctuation\">(</span>runnable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceCallable</span><span class=\"token operator\">&lt;</span>V<span class=\"token operator\">></span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Callable</span><span class=\"token operator\">&lt;</span>V<span class=\"token operator\">></span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">//在初始化TraceCallable时会获取调用线程的上下文</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Object context <span class=\"token operator\">=</span> TraceContext<span class=\"token punctuation\">.</span><span class=\"token function\">getContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Callable<span class=\"token operator\">&lt;</span>V<span class=\"token operator\">></span> callable<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token function\">TraceCallable</span><span class=\"token punctuation\">(</span>Callable<span class=\"token operator\">&lt;</span>V<span class=\"token operator\">></span> callable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>callable <span class=\"token operator\">=</span> callable<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> V <span class=\"token function\">call</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> Exception <span class=\"token punctuation\">{</span>\n        Object backup <span class=\"token operator\">=</span> TraceContextUtil<span class=\"token punctuation\">.</span><span class=\"token function\">backupAndSet</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>context<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        V result<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            result <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>callable<span class=\"token punctuation\">.</span><span class=\"token function\">call</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{</span>\n            TraceContextUtil<span class=\"token punctuation\">.</span><span class=\"token function\">restoreBackup</span><span class=\"token punctuation\">(</span>backup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> Callable<span class=\"token operator\">&lt;</span>V<span class=\"token operator\">></span> <span class=\"token function\">getCallable</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>callable<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\" spellcheck=\"true\">//返回TraceCallable实例</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> TraceCallable<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token function\">get</span><span class=\"token punctuation\">(</span>Callable<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> callable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>callable <span class=\"token operator\">==</span> null<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> null<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">return</span> callable <span class=\"token keyword\">instanceof</span> <span class=\"token class-name\">TraceCallable</span> <span class=\"token operator\">?</span> <span class=\"token punctuation\">(</span>TraceCallable<span class=\"token punctuation\">)</span>callable <span class=\"token operator\">:</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TraceCallable</span><span class=\"token punctuation\">(</span>callable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceContextUtil</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\" spellcheck=\"true\">//设置调用线程的上下文到当前执行线程中,并返回执行线程之前的上下文</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> Object <span class=\"token function\">backupAndSet</span><span class=\"token punctuation\">(</span>Object currentContext<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Object backupContext <span class=\"token operator\">=</span> TraceContext<span class=\"token punctuation\">.</span><span class=\"token function\">getContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        TraceContext<span class=\"token punctuation\">.</span><span class=\"token function\">setContext</span><span class=\"token punctuation\">(</span>currentContext<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> backupContext<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\" spellcheck=\"true\">//恢复执行线程的上下文</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">restoreBackup</span><span class=\"token punctuation\">(</span>Object backup<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        TraceContext<span class=\"token punctuation\">.</span><span class=\"token function\">setContext</span><span class=\"token punctuation\">(</span>backup<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>接下来就是定制线程池,重写<code>execute</code>和<code>submit</code>方法,把<code>Runnable/Callable</code>实例封装成<code>TraceRunnable/TraceCallable</code>,这样就把调用线程的上下文信息传递到线程池内部:</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceThreadPoolExecutor</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>ThreadPoolExecutor</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">submit</span><span class=\"token punctuation\">(</span>Runnable runnable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        TraceRunnable traceRunnable <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TraceRunnable</span><span class=\"token punctuation\">(</span>runnable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">super</span><span class=\"token punctuation\">.</span><span class=\"token function\">execute</span><span class=\"token punctuation\">(</span>traceRunnable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    \n    <span class=\"token keyword\">public</span> Future<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span><span class=\"token operator\">></span> <span class=\"token function\">submit</span><span class=\"token punctuation\">(</span>Runnable task<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        TraceRunnable traceRunnable <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TraceRunnable</span><span class=\"token punctuation\">(</span>runnable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">super</span><span class=\"token punctuation\">.</span><span class=\"token function\">submit</span><span class=\"token punctuation\">(</span>traceRunnable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">public</span> <span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> Future<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> <span class=\"token function\">submit</span><span class=\"token punctuation\">(</span>Callable<span class=\"token operator\">&lt;</span>T<span class=\"token operator\">></span> task<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n         TraceCallable traceCallable <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TraceCallable</span><span class=\"token punctuation\">(</span>task<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n         <span class=\"token keyword\">return</span> <span class=\"token keyword\">super</span><span class=\"token punctuation\">.</span><span class=\"token function\">submit</span><span class=\"token punctuation\">(</span>traceCallable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre>\n<p>上面的方法虽然实现了上下文跨线程传递,在Runnable/Callable方法内部可以通过TraceContext.getContext()来获取上下文信息,但前提是异步处理都要使用TraceThreadPoolExecutor来提交任务,这样对代码具有侵入性,需要业务做改造,\n为了减少业务开发人员的工作量，使用 javaagent和instrument技术，利用字节码修改技术修改ThreadPoolExecutor和ScheduledThreadPoolExecutor类的字节码,也就是说,只要在JVM参数里加上了javaagent的配置，不需要直接使用上面的TraceRunnable/TraceCallable包装类，也不需要使用TraceThreadPoolExecutor,即可实现上下文信息的自动传递。</p>\n<p>对于<code>ThreadPoolExecutor</code>和<code>ScheduledThreadPoolExecutor</code>,只需要修改它们的<code>execute/submit/schedule/scheduleAtFixedRate/scheduleWithFixedDelay</code>这些方法的字节码,逻辑和前面介绍的一致:</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">interface</span> <span class=\"token class-name\">TraceTransformer</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">boolean</span> <span class=\"token function\">needTransform</span><span class=\"token punctuation\">(</span>String className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">void</span> <span class=\"token function\">doTransform</span><span class=\"token punctuation\">(</span>CtClass var1<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> NotFoundException<span class=\"token punctuation\">,</span> CannotCompileException<span class=\"token punctuation\">,</span> IOException<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ThreadPoolTransformer</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">TraceTransformer</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> String TRACE_RUNNABLE_CLASS_NAME <span class=\"token operator\">=</span> TraceRunnable<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> String TRACE_CALLABLE_CLASS_NAME <span class=\"token operator\">=</span> TraceCallable<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> Set<span class=\"token operator\">&lt;</span>String<span class=\"token operator\">></span> TO_TRANSFORM_METHODS <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashSet</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">static</span> <span class=\"token punctuation\">{</span>\n        TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"execute\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"submit\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"schedule\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"scheduleAtFixedRate\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"scheduleWithFixedDelay\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">boolean</span> <span class=\"token function\">needTransform</span><span class=\"token punctuation\">(</span>String className<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"java.util.concurrent.ThreadPoolExecutor\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>className<span class=\"token punctuation\">)</span>\n                <span class=\"token operator\">||</span> <span class=\"token string\">\"java.util.concurrent.ScheduledThreadPoolExecutor\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">doTransform</span><span class=\"token punctuation\">(</span>CtClass clazz<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> NotFoundException<span class=\"token punctuation\">,</span> CannotCompileException<span class=\"token punctuation\">,</span> IOException <span class=\"token punctuation\">{</span>\n        CtMethod<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> methods <span class=\"token operator\">=</span> clazz<span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaredMethods</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> length <span class=\"token operator\">=</span> methods<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> length<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            CtMethod method <span class=\"token operator\">=</span> methods<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token function\">transformMethod</span><span class=\"token punctuation\">(</span>clazz<span class=\"token punctuation\">,</span> method<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">transformMethod</span><span class=\"token punctuation\">(</span>CtClass clazz<span class=\"token punctuation\">,</span> CtMethod method<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> NotFoundException<span class=\"token punctuation\">,</span> CannotCompileException <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>TO_TRANSFORM_METHODS<span class=\"token punctuation\">.</span><span class=\"token function\">contains</span><span class=\"token punctuation\">(</span>method<span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>method<span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaringClass</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> clazz<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">int</span> modifiers <span class=\"token operator\">=</span> method<span class=\"token punctuation\">.</span><span class=\"token function\">getModifiers</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>Modifier<span class=\"token punctuation\">.</span><span class=\"token function\">isPublic</span><span class=\"token punctuation\">(</span>modifiers<span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token operator\">!</span>Modifier<span class=\"token punctuation\">.</span><span class=\"token function\">isStatic</span><span class=\"token punctuation\">(</span>modifiers<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    CtClass<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> parameterTypes <span class=\"token operator\">=</span> method<span class=\"token punctuation\">.</span><span class=\"token function\">getParameterTypes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    StringBuilder insertCode <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">StringBuilder</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> parameterTypes<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                        CtClass parameterType <span class=\"token operator\">=</span> parameterTypes<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n                        String code<span class=\"token punctuation\">;</span>\n                        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"java.lang.Runnable\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>parameterType<span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                            <span class=\"token comment\" spellcheck=\"true\">//$1 = TraceRunnable.get($1)返回TraceRunnable实例</span>\n                            code <span class=\"token operator\">=</span> String<span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"$%d = %s.get($%d);\"</span><span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> TRACE_RUNNABLE_CLASS_NAME<span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                            System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"insert code before method \"</span> <span class=\"token operator\">+</span> method <span class=\"token operator\">+</span> <span class=\"token string\">\" of class \"</span> <span class=\"token operator\">+</span> method<span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaringClass</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\": \"</span> <span class=\"token operator\">+</span> code<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                            insertCode<span class=\"token punctuation\">.</span><span class=\"token function\">append</span><span class=\"token punctuation\">(</span>code<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"java.util.concurrent.Callable\"</span><span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>parameterType<span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                            <span class=\"token comment\" spellcheck=\"true\">//$1 = TraceCallable.get($1)返回TraceCallable实例</span>\n                            code <span class=\"token operator\">=</span> String<span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"$%d = %s.get($%d);\"</span><span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> TRACE_CALLABLE_CLASS_NAME<span class=\"token punctuation\">,</span> i <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                            System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"insert code before method \"</span> <span class=\"token operator\">+</span> method <span class=\"token operator\">+</span> <span class=\"token string\">\" of class \"</span> <span class=\"token operator\">+</span> method<span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaringClass</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\": \"</span> <span class=\"token operator\">+</span> code<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                            insertCode<span class=\"token punctuation\">.</span><span class=\"token function\">append</span><span class=\"token punctuation\">(</span>code<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                        <span class=\"token punctuation\">}</span>\n                    <span class=\"token punctuation\">}</span>\n\n                    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>insertCode<span class=\"token punctuation\">.</span><span class=\"token function\">length</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                        method<span class=\"token punctuation\">.</span><span class=\"token function\">insertBefore</span><span class=\"token punctuation\">(</span>insertCode<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span>\n\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>对于ForkJoinPool, 做法也类似,这里换一种修改方式,主要为了熟悉下javassist的语法,这次是在ForkJoinTask里添加一个context$field$add$by$trace字段,在初始化ForkJoinTask实例自动获取调用线程的上下文(TraceContext.getContext()),并修改ForkJoinTask的doExec()方法,修改逻辑和前面的一样</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ForkJoinPoolTransformer</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">TraceTransformer</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> String FORK_JOIN_TASK_CLASS_NAME <span class=\"token operator\">=</span> <span class=\"token string\">\"java.util.concurrent.ForkJoinTask\"</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">boolean</span> <span class=\"token function\">needTransform</span><span class=\"token punctuation\">(</span>String className<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> FORK_JOIN_TASK_CLASS_NAME<span class=\"token punctuation\">.</span><span class=\"token function\">equals</span><span class=\"token punctuation\">(</span>className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">doTransform</span><span class=\"token punctuation\">(</span>CtClass clazz<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> NotFoundException<span class=\"token punctuation\">,</span> CannotCompileException<span class=\"token punctuation\">,</span> IOException <span class=\"token punctuation\">{</span>\n        String className <span class=\"token operator\">=</span> clazz<span class=\"token punctuation\">.</span><span class=\"token function\">getName</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\" spellcheck=\"true\">//添加context$field$add$by$trace字段,初始值为TraceContext.getContext(),这样就获取了调用线程的上下文</span>\n        CtField contextField <span class=\"token operator\">=</span> CtField<span class=\"token punctuation\">.</span><span class=\"token function\">make</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"private final java.lang.Object context$field$add$by$trace;\"</span><span class=\"token punctuation\">,</span> clazz<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        clazz<span class=\"token punctuation\">.</span><span class=\"token function\">addField</span><span class=\"token punctuation\">(</span>contextField<span class=\"token punctuation\">,</span> <span class=\"token string\">\"com.ezlippi.trace.agent.context.TraceContext.getContext();\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"add new field context$field$add$by$trace to class \"</span> <span class=\"token operator\">+</span> className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        CtMethod doExecMethod <span class=\"token operator\">=</span> clazz<span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaredMethod</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"doExec\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        CtMethod newDoExecMethod <span class=\"token operator\">=</span> CtNewMethod<span class=\"token punctuation\">.</span><span class=\"token function\">copy</span><span class=\"token punctuation\">(</span>doExecMethod<span class=\"token punctuation\">,</span> <span class=\"token string\">\"doExec\"</span><span class=\"token punctuation\">,</span> clazz<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ClassMap<span class=\"token punctuation\">)</span>null<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        doExecMethod<span class=\"token punctuation\">.</span><span class=\"token function\">setName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"original$doExec$method$renamed$by$trace\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        doExecMethod<span class=\"token punctuation\">.</span><span class=\"token function\">setModifiers</span><span class=\"token punctuation\">(</span>doExecMethod<span class=\"token punctuation\">.</span><span class=\"token function\">getModifiers</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;</span> <span class=\"token operator\">-</span><span class=\"token number\">2</span> <span class=\"token operator\">|</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\" spellcheck=\"true\">//java.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(this.context$field$add$by$trace);</span>\n        <span class=\"token comment\" spellcheck=\"true\">//try {</span>\n        <span class=\"token comment\" spellcheck=\"true\">//   return original$doExec$method$renamed$by$trace($$);</span>\n        <span class=\"token comment\" spellcheck=\"true\">//} finally {</span>\n        <span class=\"token comment\" spellcheck=\"true\">//    TraceContextUtil.restoreBackup(backup);</span>\n        <span class=\"token comment\" spellcheck=\"true\">//}</span>\n        newDoExecMethod<span class=\"token punctuation\">.</span><span class=\"token function\">setBody</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"{\\njava.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(context$field$add$by$trace);\\ntry {\\n    return original$doExec$method$renamed$by$trace($$);\\n} finally {\\n    com.ezlippi.trace.agent.context.TraceContextUtil.restoreBackup(backup);\\n}\\n}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        clazz<span class=\"token punctuation\">.</span><span class=\"token function\">addMethod</span><span class=\"token punctuation\">(</span>newDoExecMethod<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"insert code around method \"</span> <span class=\"token operator\">+</span> doExecMethod <span class=\"token operator\">+</span> <span class=\"token string\">\" of class \"</span> <span class=\"token operator\">+</span> className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>接下来就是添加一个ClassFileTransformer,JVM启动时会传递Instrumentation对象给javaagent的preMain()方法,我们只需要往instrumentation中注册一个ClassFileTransformer实例,jvm在加载类时会把解析后的class字节数组传递给\nClassFileTransformer,执行修改逻辑后把字节数组返回给jvm.</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TlTransformer</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ClassFileTransformer</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">private</span> List<span class=\"token operator\">&lt;</span>TraceTransformer<span class=\"token operator\">></span> transformers <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayList</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token function\">TlTransformer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>transformers<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">ForkJoinPoolTransformer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>transformers<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">ThreadPoolTransformer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token function\">transform</span><span class=\"token punctuation\">(</span>ClassLoader loader<span class=\"token punctuation\">,</span> String classFile<span class=\"token punctuation\">,</span> Class<span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span><span class=\"token operator\">></span> classBeingRedefined<span class=\"token punctuation\">,</span> ProtectionDomain protectionDomain<span class=\"token punctuation\">,</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> classFileBuffer<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> IllegalClassFormatException <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>classFile <span class=\"token operator\">==</span> null<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token keyword\">return</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">byte</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n\n            String className <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">toClassName</span><span class=\"token punctuation\">(</span>classFile<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            Iterator iterator <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>transformers<span class=\"token punctuation\">.</span><span class=\"token function\">iterator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span>iterator<span class=\"token punctuation\">.</span><span class=\"token function\">hasNext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                TraceTransformer transformer <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>TraceTransformer<span class=\"token punctuation\">)</span>iterator<span class=\"token punctuation\">.</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>transformer<span class=\"token punctuation\">.</span><span class=\"token function\">needTransform</span><span class=\"token punctuation\">(</span>className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Transforming class \"</span> <span class=\"token operator\">+</span> className<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    CtClass clazz <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">getCtClass</span><span class=\"token punctuation\">(</span>classFileBuffer<span class=\"token punctuation\">,</span> loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    transformer<span class=\"token punctuation\">.</span><span class=\"token function\">doTransform</span><span class=\"token punctuation\">(</span>clazz<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token keyword\">return</span> clazz<span class=\"token punctuation\">.</span><span class=\"token function\">toBytecode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Throwable</span> throwable<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            String msg <span class=\"token operator\">=</span> <span class=\"token string\">\"Fail to transform class \"</span> <span class=\"token operator\">+</span> classFile <span class=\"token operator\">+</span> <span class=\"token string\">\", cause: \"</span> <span class=\"token operator\">+</span> throwable<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>msg<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">IllegalStateException</span><span class=\"token punctuation\">(</span>msg<span class=\"token punctuation\">,</span> throwable<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">byte</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">private</span> String <span class=\"token function\">toClassName</span><span class=\"token punctuation\">(</span>String classFile<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">return</span> classFile<span class=\"token punctuation\">.</span><span class=\"token function\">replace</span><span class=\"token punctuation\">(</span><span class=\"token string\">'/'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'.'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">private</span> CtClass <span class=\"token function\">getCtClass</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> classFileBuffer<span class=\"token punctuation\">,</span> ClassLoader classLoader<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> IOException <span class=\"token punctuation\">{</span>\n        ClassPool classPool <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ClassPool</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>null <span class=\"token operator\">!=</span> classLoader<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            classPool<span class=\"token punctuation\">.</span><span class=\"token function\">appendClassPath</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">LoaderClassPath</span><span class=\"token punctuation\">(</span>classLoader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        CtClass clazz <span class=\"token operator\">=</span> classPool<span class=\"token punctuation\">.</span><span class=\"token function\">makeClass</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">ByteArrayInputStream</span><span class=\"token punctuation\">(</span>classFileBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        clazz<span class=\"token punctuation\">.</span><span class=\"token function\">defrost</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> clazz<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">TraceAgent</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">premain</span><span class=\"token punctuation\">(</span>String agentArgs<span class=\"token punctuation\">,</span> Instrumentation instrumentation<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        ClassFileTransformer transformer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TlTransformer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        instrumentation<span class=\"token punctuation\">.</span><span class=\"token function\">addTransformer</span><span class=\"token punctuation\">(</span>transformer<span class=\"token punctuation\">,</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>因为修改了JDK的标准库的类，标准库由bootstrap class loader加载,上面修改后的ThreadPoolExecutor和ForkJoinTask类引用了agent的代码，所以agent的Jar需要加到boot class path上,可以通过maven-jar-plugin在agent jar的manifest添加Boot-Class-Path这个入口.</p>\n<pre class=\" language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>plugin</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>maven-jar-plugin<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>3.0.2<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>configuration</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>archive</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Premain-Class</span><span class=\"token punctuation\">></span></span>com.ezlippi.trace.agent.TraceAgent<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Premain-Class</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Boot-Class-Path</span><span class=\"token punctuation\">></span></span>${project.artifactId}-${project.version}.jar<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Boot-Class-Path</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Redefine-Classes</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>true<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Retransform-Classes</span><span class=\"token punctuation\">></span></span>\n                    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Can-Set-Native-Method-Prefix</span><span class=\"token punctuation\">></span></span>false<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>Can-Set-Native-Method-Prefix</span><span class=\"token punctuation\">></span></span>\n                <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>manifestEntries</span><span class=\"token punctuation\">></span></span>\n            <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>archive</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>configuration</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>plugin</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n<p>最后在Java的启动参数加上：-javaagent:path/to/trace-agent-x.x.x.jar后就大功告成了.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>在分布式系统的上下文传递过程中，需要传递的信息一般包括traceID、 spanID以及部分请求参数等,可以分为以下几种场景:</p>\n<p>在同一线程内传递\n跨线程传递\n跨应用传递\n在同一个线程内传递比较简单,通过ThreadLocal就能解决上下文传递的问题,如果是跨线程传递,大家可能会想到jdk里的实现java.lang.InheritableThreadLocal,它拥有和线程变量ThreadLocal一样的功能，并且在当前线程上创建一个新的线程实例时，会把这些线程变量从当前线程传递给新的线程实例.但是在实际的应用场景里，绝大多数都是使用线程池来进行多线程编程，线程由线程池创建好，并且线程是池化起来反复使用,这时父子线程关系的ThreadLocal值传递已经没有意义，应用需要的实际上是把任务提交给线程池时的ThreadLocal值传递到任务执行时。所以jdk提供的inheritableThreadLocals类实用性不高,在线程池(ThreadPoolExecutor)中运行一个Runable实例并不会去新建一个线程，而是把Runable实例添加到队列中(在核心线程数已实例化满的时候),让ThreadPoolExecutor的workers去从队列里拿出Runable实例（这是一个典型的生产者消费者模式),然后运行Runable实例.run()方法,故jdk的inheritableThreadLocals这种实现方式没法适用。</p>\n<p>这篇文章主要介绍基于字节码修改的方法修改ThreadPoolExecutor和ForkJoinTask的字节码,实现非侵入式的上下文传递,我们先来看一下如果通过侵入式方式定制线程池怎么解决上下文传递,假设我们的调用链通过TraceContext类来保存上下文信息:</p>\n<pre><code class=\"java\">public class TraceContext &#123;\n    private static final ThreadLocal&lt;Object&gt; CONTEXT = new ThreadLocal&lt;&gt;();\n    public static Object getContext() &#123;\n        return CONTEXT.get();\n    &#125;\n    public static void setContext(Object obj) &#123;\n        CONTEXT.set(obj);\n    &#125;\n    public static void removeContext() &#123;\n        CONTEXT.remove();\n    &#125;\n\n&#125;\n</code></pre>\n<p>我们先定义2个类,分别继承自<code>Runnable</code>和<code>Callable</code>,目的在于初始化<code>Runnable</code>和<code>Callable</code>实例时保存调用线程的上下文信息到,在执行<code>run()</code>或者<code>call()</code>方法时,先把调用线程的上下文信息设置到当前执行的线程中,<code>run()/call()</code>方法执行后恢复执行线程的上下文,这2个类分别为<code>TraceRunnable</code>和<code>TraceCallable</code>:</p>\n<pre><code class=\"java\">public class TraceRunnable implements Runnable &#123;\n    //在初始化TraceRunnable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Runnable runnable;\n\n    public TraceRunnable(Runnable runnable) &#123;\n        this.runnable = runnable;\n    &#125;\n    @Override\n    public void run() &#123;\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        try &#123;\n            this.runnable.run();\n        &#125; finally &#123;\n            TraceContextUtil.restoreBackup(backup);\n        &#125;\n    &#125;\n\n    public Runnable getRunnable() &#123;\n        return this.runnable;\n    &#125;\n\n    public static TraceRunnable get(Runnable runnable) &#123;\n        if (runnable == null) &#123;\n            return null;\n        &#125; else &#123;\n            return runnable instanceof TraceRunnable ? (TraceRunnable)runnable : new TraceRunnable(runnable);\n        &#125;\n    &#125;\n&#125;\n\npublic class TraceCallable&lt;V&gt; implements Callable&lt;V&gt; &#123;\n    //在初始化TraceCallable时会获取调用线程的上下文\n    private final Object context = TraceContext.getContext();\n    private final Callable&lt;V&gt; callable;\n\n    public TraceCallable(Callable&lt;V&gt; callable) &#123;\n        this.callable = callable;\n    &#125;\n\n    @Override\n    public V call() throws Exception &#123;\n        Object backup = TraceContextUtil.backupAndSet(this.context);\n\n        V result;\n        try &#123;\n            result = this.callable.call();\n        &#125; finally &#123;\n            TraceContextUtil.restoreBackup(backup);\n        &#125;\n\n        return result;\n    &#125;\n\n    public Callable&lt;V&gt; getCallable() &#123;\n        return this.callable;\n    &#125;\n    //返回TraceCallable实例\n    public static &lt;T&gt; TraceCallable&lt;T&gt; get(Callable&lt;T&gt; callable) &#123;\n        if (callable == null) &#123;\n            return null;\n        &#125; else &#123;\n            return callable instanceof TraceCallable ? (TraceCallable)callable : new TraceCallable(callable);\n        &#125;\n    &#125;\n\n&#125;\n\npublic class TraceContextUtil &#123;\n    //设置调用线程的上下文到当前执行线程中,并返回执行线程之前的上下文\n    public static Object backupAndSet(Object currentContext) &#123;\n        Object backupContext = TraceContext.getContext();\n        TraceContext.setContext(currentContext);\n        return backupContext;\n    &#125;\n    //恢复执行线程的上下文\n    public static void restoreBackup(Object backup) &#123;\n        TraceContext.setContext(backup);\n    &#125;\n&#125;\n</code></pre>\n<p>接下来就是定制线程池,重写<code>execute</code>和<code>submit</code>方法,把<code>Runnable/Callable</code>实例封装成<code>TraceRunnable/TraceCallable</code>,这样就把调用线程的上下文信息传递到线程池内部:</p>\n<pre><code class=\"java\">public class TraceThreadPoolExecutor extends java.util.concurrent.ThreadPoolExecutor&#123;\n    public void submit(Runnable runnable) &#123;\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        super.execute(traceRunnable);\n    &#125;\n    \n    public Future&lt;?&gt; submit(Runnable task) &#123;\n        TraceRunnable traceRunnable = new TraceRunnable(runnable);\n        return super.submit(traceRunnable);\n    &#125;\n    public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123;\n         TraceCallable traceCallable = new TraceCallable(task);\n         return super.submit(traceCallable);\n    &#125;\n</code></pre>\n<p>上面的方法虽然实现了上下文跨线程传递,在Runnable/Callable方法内部可以通过TraceContext.getContext()来获取上下文信息,但前提是异步处理都要使用TraceThreadPoolExecutor来提交任务,这样对代码具有侵入性,需要业务做改造,\n为了减少业务开发人员的工作量，使用 javaagent和instrument技术，利用字节码修改技术修改ThreadPoolExecutor和ScheduledThreadPoolExecutor类的字节码,也就是说,只要在JVM参数里加上了javaagent的配置，不需要直接使用上面的TraceRunnable/TraceCallable包装类，也不需要使用TraceThreadPoolExecutor,即可实现上下文信息的自动传递。</p>\n<p>对于<code>ThreadPoolExecutor</code>和<code>ScheduledThreadPoolExecutor</code>,只需要修改它们的<code>execute/submit/schedule/scheduleAtFixedRate/scheduleWithFixedDelay</code>这些方法的字节码,逻辑和前面介绍的一致:</p>\n<pre><code class=\"java\">public interface TraceTransformer &#123;\n    boolean needTransform(String className);\n\n    void doTransform(CtClass var1) throws NotFoundException, CannotCompileException, IOException;\n&#125;\n\npublic class ThreadPoolTransformer implements TraceTransformer &#123;\n    private static final String TRACE_RUNNABLE_CLASS_NAME = TraceRunnable.class.getName();\n    private static final String TRACE_CALLABLE_CLASS_NAME = TraceCallable.class.getName();\n\n    private static final Set&lt;String&gt; TO_TRANSFORM_METHODS = new HashSet&lt;&gt;();\n\n    static &#123;\n        TO_TRANSFORM_METHODS.add(&quot;execute&quot;);\n        TO_TRANSFORM_METHODS.add(&quot;submit&quot;);\n        TO_TRANSFORM_METHODS.add(&quot;schedule&quot;);\n        TO_TRANSFORM_METHODS.add(&quot;scheduleAtFixedRate&quot;);\n        TO_TRANSFORM_METHODS.add(&quot;scheduleWithFixedDelay&quot;);\n    &#125;\n\n    @Override\n    public boolean needTransform(String className) &#123;\n        return &quot;java.util.concurrent.ThreadPoolExecutor&quot;.equals(className)\n                || &quot;java.util.concurrent.ScheduledThreadPoolExecutor&quot;.equals(className);\n    &#125;\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException &#123;\n        CtMethod[] methods = clazz.getDeclaredMethods();\n        int length = methods.length;\n\n        for(int i = 0; i &lt; length; ++i) &#123;\n            CtMethod method = methods[i];\n            transformMethod(clazz, method);\n        &#125;\n\n    &#125;\n\n    static void transformMethod(CtClass clazz, CtMethod method) throws NotFoundException, CannotCompileException &#123;\n        if (TO_TRANSFORM_METHODS.contains(method.getName())) &#123;\n            if (method.getDeclaringClass() == clazz) &#123;\n                int modifiers = method.getModifiers();\n                if (Modifier.isPublic(modifiers) &amp;&amp; !Modifier.isStatic(modifiers)) &#123;\n                    CtClass[] parameterTypes = method.getParameterTypes();\n                    StringBuilder insertCode = new StringBuilder();\n\n                    for(int i = 0; i &lt; parameterTypes.length; ++i) &#123;\n                        CtClass parameterType = parameterTypes[i];\n                        String code;\n                        if (&quot;java.lang.Runnable&quot;.equals(parameterType.getName())) &#123;\n                            //$1 = TraceRunnable.get($1)返回TraceRunnable实例\n                            code = String.format(&quot;$%d = %s.get($%d);&quot;, i + 1, TRACE_RUNNABLE_CLASS_NAME, i + 1);\n                            System.out.println(&quot;insert code before method &quot; + method + &quot; of class &quot; + method.getDeclaringClass().getName() + &quot;: &quot; + code);\n                            insertCode.append(code);\n                        &#125; else if (&quot;java.util.concurrent.Callable&quot;.equals(parameterType.getName())) &#123;\n                            //$1 = TraceCallable.get($1)返回TraceCallable实例\n                            code = String.format(&quot;$%d = %s.get($%d);&quot;, i + 1, TRACE_CALLABLE_CLASS_NAME, i + 1);\n                            System.out.println(&quot;insert code before method &quot; + method + &quot; of class &quot; + method.getDeclaringClass().getName() + &quot;: &quot; + code);\n                            insertCode.append(code);\n                        &#125;\n                    &#125;\n\n                    if (insertCode.length() &gt; 0) &#123;\n                        method.insertBefore(insertCode.toString());\n                    &#125;\n\n                &#125;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<p>对于ForkJoinPool, 做法也类似,这里换一种修改方式,主要为了熟悉下javassist的语法,这次是在ForkJoinTask里添加一个context$field$add$by$trace字段,在初始化ForkJoinTask实例自动获取调用线程的上下文(TraceContext.getContext()),并修改ForkJoinTask的doExec()方法,修改逻辑和前面的一样</p>\n<pre><code class=\"java\">public class ForkJoinPoolTransformer implements TraceTransformer &#123;\n    private static final String FORK_JOIN_TASK_CLASS_NAME = &quot;java.util.concurrent.ForkJoinTask&quot;;\n\n    @Override\n    public boolean needTransform(String className) &#123;\n        return FORK_JOIN_TASK_CLASS_NAME.equals(className);\n    &#125;\n\n    @Override\n    public void doTransform(CtClass clazz) throws NotFoundException, CannotCompileException, IOException &#123;\n        String className = clazz.getName();\n        //添加context$field$add$by$trace字段,初始值为TraceContext.getContext(),这样就获取了调用线程的上下文\n        CtField contextField = CtField.make(&quot;private final java.lang.Object context$field$add$by$trace;&quot;, clazz);\n        clazz.addField(contextField, &quot;com.ezlippi.trace.agent.context.TraceContext.getContext();&quot;);\n        System.out.println(&quot;add new field context$field$add$by$trace to class &quot; + className);\n        CtMethod doExecMethod = clazz.getDeclaredMethod(&quot;doExec&quot;);\n        CtMethod newDoExecMethod = CtNewMethod.copy(doExecMethod, &quot;doExec&quot;, clazz, (ClassMap)null);\n        doExecMethod.setName(&quot;original$doExec$method$renamed$by$trace&quot;);\n        doExecMethod.setModifiers(doExecMethod.getModifiers() &amp; -2 | 2);\n        //java.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(this.context$field$add$by$trace);\n        //try &#123;\n        //   return original$doExec$method$renamed$by$trace($$);\n        //&#125; finally &#123;\n        //    TraceContextUtil.restoreBackup(backup);\n        //&#125;\n        newDoExecMethod.setBody(&quot;&#123;\\njava.lang.Object backup = com.ezlippi.trace.agent.context.TraceContextUtil.backupAndSet(context$field$add$by$trace);\\ntry &#123;\\n    return original$doExec$method$renamed$by$trace($$);\\n&#125; finally &#123;\\n    com.ezlippi.trace.agent.context.TraceContextUtil.restoreBackup(backup);\\n&#125;\\n&#125;&quot;);\n        clazz.addMethod(newDoExecMethod);\n        System.out.println(&quot;insert code around method &quot; + doExecMethod + &quot; of class &quot; + className);\n\n\n    &#125;\n&#125;\n</code></pre>\n<p>接下来就是添加一个ClassFileTransformer,JVM启动时会传递Instrumentation对象给javaagent的preMain()方法,我们只需要往instrumentation中注册一个ClassFileTransformer实例,jvm在加载类时会把解析后的class字节数组传递给\nClassFileTransformer,执行修改逻辑后把字节数组返回给jvm.</p>\n<pre><code class=\"java\">public class TlTransformer implements ClassFileTransformer &#123;\n    private List&lt;TraceTransformer&gt; transformers = new ArrayList&lt;&gt;();\n\n    public TlTransformer() &#123;\n        this.transformers.add(new ForkJoinPoolTransformer());\n        this.transformers.add(new ThreadPoolTransformer());\n    &#125;\n\n    @Override\n    public byte[] transform(ClassLoader loader, String classFile, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classFileBuffer) throws IllegalClassFormatException &#123;\n        try &#123;\n            if (classFile == null) &#123;\n                return new byte[0];\n            &#125;\n\n            String className = this.toClassName(classFile);\n            Iterator iterator = this.transformers.iterator();\n\n            while(iterator.hasNext()) &#123;\n                TraceTransformer transformer = (TraceTransformer)iterator.next();\n                if (transformer.needTransform(className)) &#123;\n                    System.out.println(&quot;Transforming class &quot; + className);\n                    CtClass clazz = this.getCtClass(classFileBuffer, loader);\n                    transformer.doTransform(clazz);\n                    return clazz.toBytecode();\n                &#125;\n            &#125;\n        &#125; catch (Throwable throwable) &#123;\n            String msg = &quot;Fail to transform class &quot; + classFile + &quot;, cause: &quot; + throwable.toString();\n            System.out.println(msg);\n            throw new IllegalStateException(msg, throwable);\n        &#125;\n\n        return new byte[0];\n    &#125;\n\n    private String toClassName(String classFile) &#123;\n        return classFile.replace(&#39;/&#39;, &#39;.&#39;);\n    &#125;\n\n    private CtClass getCtClass(byte[] classFileBuffer, ClassLoader classLoader) throws IOException &#123;\n        ClassPool classPool = new ClassPool(true);\n        if (null != classLoader) &#123;\n            classPool.appendClassPath(new LoaderClassPath(classLoader));\n        &#125;\n\n        CtClass clazz = classPool.makeClass(new ByteArrayInputStream(classFileBuffer), false);\n        clazz.defrost();\n        return clazz;\n    &#125;\n&#125;\n\npublic class TraceAgent &#123;\n    public static void premain(String agentArgs, Instrumentation instrumentation) &#123;\n        ClassFileTransformer transformer = new TlTransformer();\n        instrumentation.addTransformer(transformer, true);\n    &#125;\n&#125;\n</code></pre>\n<p>因为修改了JDK的标准库的类，标准库由bootstrap class loader加载,上面修改后的ThreadPoolExecutor和ForkJoinTask类引用了agent的代码，所以agent的Jar需要加到boot class path上,可以通过maven-jar-plugin在agent jar的manifest添加Boot-Class-Path这个入口.</p>\n<pre><code class=\"xml\">&lt;plugin&gt;\n        &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n        &lt;version&gt;3.0.2&lt;/version&gt;\n        &lt;configuration&gt;\n            &lt;archive&gt;\n                &lt;manifestEntries&gt;\n                    &lt;Premain-Class&gt;com.ezlippi.trace.agent.TraceAgent&lt;/Premain-Class&gt;\n                    &lt;Boot-Class-Path&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;.jar&lt;/Boot-Class-Path&gt;\n                    &lt;Can-Redefine-Classes&gt;true&lt;/Can-Redefine-Classes&gt;\n                    &lt;Can-Retransform-Classes&gt;true&lt;/Can-Retransform-Classes&gt;\n                    &lt;Can-Set-Native-Method-Prefix&gt;false&lt;/Can-Set-Native-Method-Prefix&gt;\n                &lt;/manifestEntries&gt;\n            &lt;/archive&gt;\n        &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>\n<p>最后在Java的启动参数加上：-javaagent:path/to/trace-agent-x.x.x.jar后就大功告成了.</p>\n"},{"title":"语法分析器的设计和实现","date":"2019-07-18T03:04:07.000Z","_content":"\n\n过去`去O`是需要讨论的事，当今`去O`是已经在行动的事实。\n\n![Database Ranking](55821626-8701-4F00-879A-93B7D5039B06.png)\n\n从上图看`Oracle`很强大，要`去O`对企业来说挑战很大，之前对`Oracle`依赖越多、越大，`去O`难度越多、越大。\n\n阿里基于过去10年`去O`长征路程形成了一套成熟的`去O`解决方案:\n[ADAM](https://adam.console.aliyun.com) + [DTS](https://dts.console.aliyun.com) + [PolarDB](https://polardb.console.aliyun.com)\n\n\n[ADAM](https://adam.console.aliyun.com): `Advanced Database&Application Migration`（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。\n\n[DTS](https://dts.console.aliyun.com): `数据传输服务`(Data Transmission Service) DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。数据传输致力于在公共云、混合云场景下，解决远距离、毫秒级异步数据传输难题。 它底层的数据流基础设施为阿里双11异地多活基础架构， 为数千下游应用提供实时数据流，已在线上稳定运行6年之久。 您可以使用数据传输轻松构建安全、可扩展、高可用的数据架构。\n\n[PolarDB](https://polardb.console.aliyun.com): `PolarDB`是阿里巴巴自主研发的下一代关系型分布式云原生数据库，目前兼容三种数据库引擎：\nMySQL、PostgreSQL、高度兼容Oracle语法。 计算能力最高可扩展至1000核以上，存储容量最\n高可达 100T。经过阿里巴巴双十一活动的最佳实践，让用户既享受到开源的灵活性与价格，又享\n受到商业数据库的高性能和安全性\n\n\n我们今天重要讨论和介绍的是 [ADAM](https://adam.console.aliyun.com)\n\n\n### [ADAM](https://adam.console.aliyun.com)\n\n`ADAM`: `Advanced Database&Application Migration`（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。\n\n\n#### 功能\n\n- 采集：客户`数据库机器信息`、`Oracle`、`DDL`、`SQL`等数据收集\n- 画像：根据采集客户信息画像。如：`客户机器性能`、`容量`、`Oracle特性`\n- 评估报告：根据采集的信息ADAM给出改造迁移评估报告\n- 数据库改造迁移：迁移经过`ADAM`改造之后的DDL\n\n\n#### DDL解析揭秘\n今天主要讲解`ADAM`失败转换`DDL`、`SQL`\n\n##### 词法分析(Lexer)\n\n是计算机科学中将字符序列转换为标记（token）序列的过程，供语法分析器调用\n\n###### 标记(Token)\n\n标记是一个字串，是构成源代码的最小单位。 从输入字符流中生成标记的过程叫作标记化（tokenization），在这个过程中，词法分析器还会对标记进行分类。\n\n词法分析器通常不会关心标记之间的关系，词法分析器能够将字串识别为标记，但并不保证字串是否符合整个语法。\n\n针对如下查询语言表达式：\n```\nSELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n```\n将其标记化后可以得到下表内容：\n\n语素 | 标记类型\n------- | -------\nSELECT | `SELECT`关键词标识符\n* | `*`关键词标识符Token\nFROM | `FROM`关键词标识符Token\nDUAL| 标识符Token\nWHERE | `WHERE`关键词标识符\nID | 标识符Token\n= | `=`关键词标识符Token\nAND | `AND`关键词Token\nNAME | 标识符Token\n'name' | `文本值`Token\n; | `SEMI`标识符Token\n\n\n语法分析根据词法分析的Token进行语法分析。可识别判断Token是否符合语法规则。\n\n词法分析代码示例如下:\n![词法分析](55821626-8701-4F00-879A-93B7D5039B06.svg)\n\n\n##### 语法分析(Parser)\n\n根据某种给定的形式文法对由单词序列（如英语单词序列）构成的输入文本进行分析并确定其语法结构的一种过程。\n\n如上，针对查询语言表达式：\n```\nSELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n```\n\n1. `SELECT`关键词标识号Token, 语法分析知道根据`SELECT`语法来分析后续文本。\n2. 根据[`Select语法`](https://ronsavage.github.io/SQL/sql-2003-2.bnf.html#query%20specification) 分析`*`关键词标识符Token 等后面的`Token`\n\n###### 算符优先分析\n\n在语法分析当中有些`表达式`组合是有`优先级`的。\n\n如下所示:\n```\nE: E (+、-) E (+/-) E\nE: E (*、/) E E (*、/) E\n```\n\n`+`、`-`、`*`、`/` 中 `*`、`/`优先级比 `+`、`-`高，`*`、`/`优先组合\n\n分析我们可以得到如下表达式：\n```\nE: T (+、-) T (+、-) T\nT: X (*、/) X (*、/) X\n```\n\n1. 语法分析拿到第一个token，分析生成对应的对象\n2. 语法分析拿到第二个token，分析是 `+`、`-` Token\n3. 语法分析调用分析`*`、`/`的语法分析\n\n\n语法分析伪代码：\n![xx](carbon.svg)\n\n\n##### 抽象语法树(AST)\n`抽象语法树`（Abstract Syntax Tree，AST），或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构\n\n语法分析生成生成抽象语法树, 语法树具体如下：\n![xx](test1.drawio.png)\n\n##### 转换\n\n分析源数据库`DDL`、`SQL`转换对应的目标库`DDL`、`SQL`\n\n针对查询语言表达式，把 绑定变量`:id` 变成 `?`：\n```\nSELECT * FROM DUAL WHERE ID = :id\n```\n\n只需要把语法树中的 `定变量`语法对象替换成 `?`语法对象，如下：\n![xx](/assets/转换示例.svg)\n\n---\n\n### 参考\n- https://db-engines.com/en/ranking\n- https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90\n- https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90\n- https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9\n\n\n\n\n","source":"_posts/语法分析器的设计和实现.md","raw":"---\ntitle: 语法分析器的设计和实现\ndate: 2019-07-18 11:04:07\ncategories: \n    - 词法分析\n    - 语法分析\ntags:\n    - 词法分析\n    - 语法分析\n---\n\n\n过去`去O`是需要讨论的事，当今`去O`是已经在行动的事实。\n\n![Database Ranking](55821626-8701-4F00-879A-93B7D5039B06.png)\n\n从上图看`Oracle`很强大，要`去O`对企业来说挑战很大，之前对`Oracle`依赖越多、越大，`去O`难度越多、越大。\n\n阿里基于过去10年`去O`长征路程形成了一套成熟的`去O`解决方案:\n[ADAM](https://adam.console.aliyun.com) + [DTS](https://dts.console.aliyun.com) + [PolarDB](https://polardb.console.aliyun.com)\n\n\n[ADAM](https://adam.console.aliyun.com): `Advanced Database&Application Migration`（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。\n\n[DTS](https://dts.console.aliyun.com): `数据传输服务`(Data Transmission Service) DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。数据传输致力于在公共云、混合云场景下，解决远距离、毫秒级异步数据传输难题。 它底层的数据流基础设施为阿里双11异地多活基础架构， 为数千下游应用提供实时数据流，已在线上稳定运行6年之久。 您可以使用数据传输轻松构建安全、可扩展、高可用的数据架构。\n\n[PolarDB](https://polardb.console.aliyun.com): `PolarDB`是阿里巴巴自主研发的下一代关系型分布式云原生数据库，目前兼容三种数据库引擎：\nMySQL、PostgreSQL、高度兼容Oracle语法。 计算能力最高可扩展至1000核以上，存储容量最\n高可达 100T。经过阿里巴巴双十一活动的最佳实践，让用户既享受到开源的灵活性与价格，又享\n受到商业数据库的高性能和安全性\n\n\n我们今天重要讨论和介绍的是 [ADAM](https://adam.console.aliyun.com)\n\n\n### [ADAM](https://adam.console.aliyun.com)\n\n`ADAM`: `Advanced Database&Application Migration`（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。\n\n\n#### 功能\n\n- 采集：客户`数据库机器信息`、`Oracle`、`DDL`、`SQL`等数据收集\n- 画像：根据采集客户信息画像。如：`客户机器性能`、`容量`、`Oracle特性`\n- 评估报告：根据采集的信息ADAM给出改造迁移评估报告\n- 数据库改造迁移：迁移经过`ADAM`改造之后的DDL\n\n\n#### DDL解析揭秘\n今天主要讲解`ADAM`失败转换`DDL`、`SQL`\n\n##### 词法分析(Lexer)\n\n是计算机科学中将字符序列转换为标记（token）序列的过程，供语法分析器调用\n\n###### 标记(Token)\n\n标记是一个字串，是构成源代码的最小单位。 从输入字符流中生成标记的过程叫作标记化（tokenization），在这个过程中，词法分析器还会对标记进行分类。\n\n词法分析器通常不会关心标记之间的关系，词法分析器能够将字串识别为标记，但并不保证字串是否符合整个语法。\n\n针对如下查询语言表达式：\n```\nSELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n```\n将其标记化后可以得到下表内容：\n\n语素 | 标记类型\n------- | -------\nSELECT | `SELECT`关键词标识符\n* | `*`关键词标识符Token\nFROM | `FROM`关键词标识符Token\nDUAL| 标识符Token\nWHERE | `WHERE`关键词标识符\nID | 标识符Token\n= | `=`关键词标识符Token\nAND | `AND`关键词Token\nNAME | 标识符Token\n'name' | `文本值`Token\n; | `SEMI`标识符Token\n\n\n语法分析根据词法分析的Token进行语法分析。可识别判断Token是否符合语法规则。\n\n词法分析代码示例如下:\n![词法分析](55821626-8701-4F00-879A-93B7D5039B06.svg)\n\n\n##### 语法分析(Parser)\n\n根据某种给定的形式文法对由单词序列（如英语单词序列）构成的输入文本进行分析并确定其语法结构的一种过程。\n\n如上，针对查询语言表达式：\n```\nSELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n```\n\n1. `SELECT`关键词标识号Token, 语法分析知道根据`SELECT`语法来分析后续文本。\n2. 根据[`Select语法`](https://ronsavage.github.io/SQL/sql-2003-2.bnf.html#query%20specification) 分析`*`关键词标识符Token 等后面的`Token`\n\n###### 算符优先分析\n\n在语法分析当中有些`表达式`组合是有`优先级`的。\n\n如下所示:\n```\nE: E (+、-) E (+/-) E\nE: E (*、/) E E (*、/) E\n```\n\n`+`、`-`、`*`、`/` 中 `*`、`/`优先级比 `+`、`-`高，`*`、`/`优先组合\n\n分析我们可以得到如下表达式：\n```\nE: T (+、-) T (+、-) T\nT: X (*、/) X (*、/) X\n```\n\n1. 语法分析拿到第一个token，分析生成对应的对象\n2. 语法分析拿到第二个token，分析是 `+`、`-` Token\n3. 语法分析调用分析`*`、`/`的语法分析\n\n\n语法分析伪代码：\n![xx](carbon.svg)\n\n\n##### 抽象语法树(AST)\n`抽象语法树`（Abstract Syntax Tree，AST），或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构\n\n语法分析生成生成抽象语法树, 语法树具体如下：\n![xx](test1.drawio.png)\n\n##### 转换\n\n分析源数据库`DDL`、`SQL`转换对应的目标库`DDL`、`SQL`\n\n针对查询语言表达式，把 绑定变量`:id` 变成 `?`：\n```\nSELECT * FROM DUAL WHERE ID = :id\n```\n\n只需要把语法树中的 `定变量`语法对象替换成 `?`语法对象，如下：\n![xx](/assets/转换示例.svg)\n\n---\n\n### 参考\n- https://db-engines.com/en/ranking\n- https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90\n- https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90\n- https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9\n\n\n\n\n","slug":"语法分析器的设计和实现","published":1,"updated":"2021-06-30T02:33:24.782Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy300bhr5p7cnyidc6z","content":"<p>过去<code>去O</code>是需要讨论的事，当今<code>去O</code>是已经在行动的事实。</p>\n<p><img src=\"55821626-8701-4F00-879A-93B7D5039B06.png\" alt=\"Database Ranking\"></p>\n<p>从上图看<code>Oracle</code>很强大，要<code>去O</code>对企业来说挑战很大，之前对<code>Oracle</code>依赖越多、越大，<code>去O</code>难度越多、越大。</p>\n<p>阿里基于过去10年<code>去O</code>长征路程形成了一套成熟的<code>去O</code>解决方案:\n<a href=\"https://adam.console.aliyun.com/\">ADAM</a> + <a href=\"https://dts.console.aliyun.com/\">DTS</a> + <a href=\"https://polardb.console.aliyun.com/\">PolarDB</a></p>\n<p><a href=\"https://adam.console.aliyun.com/\">ADAM</a>: <code>Advanced Database&amp;Application Migration</code>（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。</p>\n<p><a href=\"https://dts.console.aliyun.com/\">DTS</a>: <code>数据传输服务</code>(Data Transmission Service) DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。数据传输致力于在公共云、混合云场景下，解决远距离、毫秒级异步数据传输难题。 它底层的数据流基础设施为阿里双11异地多活基础架构， 为数千下游应用提供实时数据流，已在线上稳定运行6年之久。 您可以使用数据传输轻松构建安全、可扩展、高可用的数据架构。</p>\n<p><a href=\"https://polardb.console.aliyun.com/\">PolarDB</a>: <code>PolarDB</code>是阿里巴巴自主研发的下一代关系型分布式云原生数据库，目前兼容三种数据库引擎：\nMySQL、PostgreSQL、高度兼容Oracle语法。 计算能力最高可扩展至1000核以上，存储容量最\n高可达 100T。经过阿里巴巴双十一活动的最佳实践，让用户既享受到开源的灵活性与价格，又享\n受到商业数据库的高性能和安全性</p>\n<p>我们今天重要讨论和介绍的是 <a href=\"https://adam.console.aliyun.com/\">ADAM</a></p>\n<h3 id=\"ADAM\"><a href=\"#ADAM\" class=\"headerlink\" title=\"ADAM\"></a><a href=\"https://adam.console.aliyun.com/\">ADAM</a></h3><p><code>ADAM</code>: <code>Advanced Database&amp;Application Migration</code>（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。</p>\n<h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h4><ul>\n<li>采集：客户<code>数据库机器信息</code>、<code>Oracle</code>、<code>DDL</code>、<code>SQL</code>等数据收集</li>\n<li>画像：根据采集客户信息画像。如：<code>客户机器性能</code>、<code>容量</code>、<code>Oracle特性</code></li>\n<li>评估报告：根据采集的信息ADAM给出改造迁移评估报告</li>\n<li>数据库改造迁移：迁移经过<code>ADAM</code>改造之后的DDL</li>\n</ul>\n<h4 id=\"DDL解析揭秘\"><a href=\"#DDL解析揭秘\" class=\"headerlink\" title=\"DDL解析揭秘\"></a>DDL解析揭秘</h4><p>今天主要讲解<code>ADAM</code>失败转换<code>DDL</code>、<code>SQL</code></p>\n<h5 id=\"词法分析-Lexer\"><a href=\"#词法分析-Lexer\" class=\"headerlink\" title=\"词法分析(Lexer)\"></a>词法分析(Lexer)</h5><p>是计算机科学中将字符序列转换为标记（token）序列的过程，供语法分析器调用</p>\n<h6 id=\"标记-Token\"><a href=\"#标记-Token\" class=\"headerlink\" title=\"标记(Token)\"></a>标记(Token)</h6><p>标记是一个字串，是构成源代码的最小单位。 从输入字符流中生成标记的过程叫作标记化（tokenization），在这个过程中，词法分析器还会对标记进行分类。</p>\n<p>词法分析器通常不会关心标记之间的关系，词法分析器能够将字串识别为标记，但并不保证字串是否符合整个语法。</p>\n<p>针对如下查询语言表达式：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n</code></pre>\n<p>将其标记化后可以得到下表内容：</p>\n<table>\n<thead>\n<tr>\n<th>语素</th>\n<th>标记类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SELECT</td>\n<td><code>SELECT</code>关键词标识符</td>\n</tr>\n</tbody></table>\n<ul>\n<li>| <code>*</code>关键词标识符Token\nFROM | <code>FROM</code>关键词标识符Token\nDUAL| 标识符Token\nWHERE | <code>WHERE</code>关键词标识符\nID | 标识符Token\n= | <code>=</code>关键词标识符Token\nAND | <code>AND</code>关键词Token\nNAME | 标识符Token\n‘name’ | <code>文本值</code>Token\n; | <code>SEMI</code>标识符Token</li>\n</ul>\n<p>语法分析根据词法分析的Token进行语法分析。可识别判断Token是否符合语法规则。</p>\n<p>词法分析代码示例如下:\n<img src=\"55821626-8701-4F00-879A-93B7D5039B06.svg\" alt=\"词法分析\"></p>\n<h5 id=\"语法分析-Parser\"><a href=\"#语法分析-Parser\" class=\"headerlink\" title=\"语法分析(Parser)\"></a>语法分析(Parser)</h5><p>根据某种给定的形式文法对由单词序列（如英语单词序列）构成的输入文本进行分析并确定其语法结构的一种过程。</p>\n<p>如上，针对查询语言表达式：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = 1 AND NAME = 'name';\n</code></pre>\n<ol>\n<li><code>SELECT</code>关键词标识号Token, 语法分析知道根据<code>SELECT</code>语法来分析后续文本。</li>\n<li>根据<a href=\"https://ronsavage.github.io/SQL/sql-2003-2.bnf.html#query%20specification\"><code>Select语法</code></a> 分析<code>*</code>关键词标识符Token 等后面的<code>Token</code></li>\n</ol>\n<h6 id=\"算符优先分析\"><a href=\"#算符优先分析\" class=\"headerlink\" title=\"算符优先分析\"></a>算符优先分析</h6><p>在语法分析当中有些<code>表达式</code>组合是有<code>优先级</code>的。</p>\n<p>如下所示:</p>\n<pre><code>E: E (+、-) E (+/-) E\nE: E (*、/) E E (*、/) E\n</code></pre>\n<p><code>+</code>、<code>-</code>、<code>*</code>、<code>/</code> 中 <code>*</code>、<code>/</code>优先级比 <code>+</code>、<code>-</code>高，<code>*</code>、<code>/</code>优先组合</p>\n<p>分析我们可以得到如下表达式：</p>\n<pre><code>E: T (+、-) T (+、-) T\nT: X (*、/) X (*、/) X\n</code></pre>\n<ol>\n<li>语法分析拿到第一个token，分析生成对应的对象</li>\n<li>语法分析拿到第二个token，分析是 <code>+</code>、<code>-</code> Token</li>\n<li>语法分析调用分析<code>*</code>、<code>/</code>的语法分析</li>\n</ol>\n<p>语法分析伪代码：\n<img src=\"carbon.svg\" alt=\"xx\"></p>\n<h5 id=\"抽象语法树-AST\"><a href=\"#抽象语法树-AST\" class=\"headerlink\" title=\"抽象语法树(AST)\"></a>抽象语法树(AST)</h5><p><code>抽象语法树</code>（Abstract Syntax Tree，AST），或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构</p>\n<p>语法分析生成生成抽象语法树, 语法树具体如下：\n<img src=\"test1.drawio.png\" alt=\"xx\"></p>\n<h5 id=\"转换\"><a href=\"#转换\" class=\"headerlink\" title=\"转换\"></a>转换</h5><p>分析源数据库<code>DDL</code>、<code>SQL</code>转换对应的目标库<code>DDL</code>、<code>SQL</code></p>\n<p>针对查询语言表达式，把 绑定变量<code>:id</code> 变成 <code>?</code>：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = :id\n</code></pre>\n<p>只需要把语法树中的 <code>定变量</code>语法对象替换成 <code>?</code>语法对象，如下：\n<img src=\"/assets/%E8%BD%AC%E6%8D%A2%E7%A4%BA%E4%BE%8B.svg\" alt=\"xx\"></p>\n<hr>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><ul>\n<li><a href=\"https://db-engines.com/en/ranking\">https://db-engines.com/en/ranking</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90\">https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90\">https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9\">https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>过去<code>去O</code>是需要讨论的事，当今<code>去O</code>是已经在行动的事实。</p>\n<p><img src=\"55821626-8701-4F00-879A-93B7D5039B06.png\" alt=\"Database Ranking\"></p>\n<p>从上图看<code>Oracle</code>很强大，要<code>去O</code>对企业来说挑战很大，之前对<code>Oracle</code>依赖越多、越大，<code>去O</code>难度越多、越大。</p>\n<p>阿里基于过去10年<code>去O</code>长征路程形成了一套成熟的<code>去O</code>解决方案:\n<a href=\"https://adam.console.aliyun.com/\">ADAM</a> + <a href=\"https://dts.console.aliyun.com/\">DTS</a> + <a href=\"https://polardb.console.aliyun.com/\">PolarDB</a></p>\n<p><a href=\"https://adam.console.aliyun.com/\">ADAM</a>: <code>Advanced Database&amp;Application Migration</code>（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。</p>\n<p><a href=\"https://dts.console.aliyun.com/\">DTS</a>: <code>数据传输服务</code>(Data Transmission Service) DTS支持关系型数据库、NoSQL、大数据(OLAP)等数据源间的数据传输。 它是一种集数据迁移、数据订阅及数据实时同步于一体的数据传输服务。数据传输致力于在公共云、混合云场景下，解决远距离、毫秒级异步数据传输难题。 它底层的数据流基础设施为阿里双11异地多活基础架构， 为数千下游应用提供实时数据流，已在线上稳定运行6年之久。 您可以使用数据传输轻松构建安全、可扩展、高可用的数据架构。</p>\n<p><a href=\"https://polardb.console.aliyun.com/\">PolarDB</a>: <code>PolarDB</code>是阿里巴巴自主研发的下一代关系型分布式云原生数据库，目前兼容三种数据库引擎：\nMySQL、PostgreSQL、高度兼容Oracle语法。 计算能力最高可扩展至1000核以上，存储容量最\n高可达 100T。经过阿里巴巴双十一活动的最佳实践，让用户既享受到开源的灵活性与价格，又享\n受到商业数据库的高性能和安全性</p>\n<p>我们今天重要讨论和介绍的是 <a href=\"https://adam.console.aliyun.com/\">ADAM</a></p>\n<h3 id=\"ADAM\"><a href=\"#ADAM\" class=\"headerlink\" title=\"ADAM\"></a><a href=\"https://adam.console.aliyun.com/\">ADAM</a></h3><p><code>ADAM</code>: <code>Advanced Database&amp;Application Migration</code>（以下简称ADAM） 是一款把数据库和应用迁移到阿里云（公共云或专有云）的产品，显著地降低了上云的技术难度和成本，尤其是Oracle数据库应用。ADAM全面评估上云可行性、成本和云存储选型，内置实施协助，数据、应用迁移等工具，确保可靠、快速上云。</p>\n<h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h4><ul>\n<li>采集：客户<code>数据库机器信息</code>、<code>Oracle</code>、<code>DDL</code>、<code>SQL</code>等数据收集</li>\n<li>画像：根据采集客户信息画像。如：<code>客户机器性能</code>、<code>容量</code>、<code>Oracle特性</code></li>\n<li>评估报告：根据采集的信息ADAM给出改造迁移评估报告</li>\n<li>数据库改造迁移：迁移经过<code>ADAM</code>改造之后的DDL</li>\n</ul>\n<h4 id=\"DDL解析揭秘\"><a href=\"#DDL解析揭秘\" class=\"headerlink\" title=\"DDL解析揭秘\"></a>DDL解析揭秘</h4><p>今天主要讲解<code>ADAM</code>失败转换<code>DDL</code>、<code>SQL</code></p>\n<h5 id=\"词法分析-Lexer\"><a href=\"#词法分析-Lexer\" class=\"headerlink\" title=\"词法分析(Lexer)\"></a>词法分析(Lexer)</h5><p>是计算机科学中将字符序列转换为标记（token）序列的过程，供语法分析器调用</p>\n<h6 id=\"标记-Token\"><a href=\"#标记-Token\" class=\"headerlink\" title=\"标记(Token)\"></a>标记(Token)</h6><p>标记是一个字串，是构成源代码的最小单位。 从输入字符流中生成标记的过程叫作标记化（tokenization），在这个过程中，词法分析器还会对标记进行分类。</p>\n<p>词法分析器通常不会关心标记之间的关系，词法分析器能够将字串识别为标记，但并不保证字串是否符合整个语法。</p>\n<p>针对如下查询语言表达式：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = 1 AND NAME = &#39;name&#39;;\n</code></pre>\n<p>将其标记化后可以得到下表内容：</p>\n<table>\n<thead>\n<tr>\n<th>语素</th>\n<th>标记类型</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>SELECT</td>\n<td><code>SELECT</code>关键词标识符</td>\n</tr>\n</tbody></table>\n<ul>\n<li>| <code>*</code>关键词标识符Token\nFROM | <code>FROM</code>关键词标识符Token\nDUAL| 标识符Token\nWHERE | <code>WHERE</code>关键词标识符\nID | 标识符Token\n= | <code>=</code>关键词标识符Token\nAND | <code>AND</code>关键词Token\nNAME | 标识符Token\n‘name’ | <code>文本值</code>Token\n; | <code>SEMI</code>标识符Token</li>\n</ul>\n<p>语法分析根据词法分析的Token进行语法分析。可识别判断Token是否符合语法规则。</p>\n<p>词法分析代码示例如下:\n<img src=\"55821626-8701-4F00-879A-93B7D5039B06.svg\" alt=\"词法分析\"></p>\n<h5 id=\"语法分析-Parser\"><a href=\"#语法分析-Parser\" class=\"headerlink\" title=\"语法分析(Parser)\"></a>语法分析(Parser)</h5><p>根据某种给定的形式文法对由单词序列（如英语单词序列）构成的输入文本进行分析并确定其语法结构的一种过程。</p>\n<p>如上，针对查询语言表达式：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = 1 AND NAME = &#39;name&#39;;\n</code></pre>\n<ol>\n<li><code>SELECT</code>关键词标识号Token, 语法分析知道根据<code>SELECT</code>语法来分析后续文本。</li>\n<li>根据<a href=\"https://ronsavage.github.io/SQL/sql-2003-2.bnf.html#query%20specification\"><code>Select语法</code></a> 分析<code>*</code>关键词标识符Token 等后面的<code>Token</code></li>\n</ol>\n<h6 id=\"算符优先分析\"><a href=\"#算符优先分析\" class=\"headerlink\" title=\"算符优先分析\"></a>算符优先分析</h6><p>在语法分析当中有些<code>表达式</code>组合是有<code>优先级</code>的。</p>\n<p>如下所示:</p>\n<pre><code>E: E (+、-) E (+/-) E\nE: E (*、/) E E (*、/) E\n</code></pre>\n<p><code>+</code>、<code>-</code>、<code>*</code>、<code>/</code> 中 <code>*</code>、<code>/</code>优先级比 <code>+</code>、<code>-</code>高，<code>*</code>、<code>/</code>优先组合</p>\n<p>分析我们可以得到如下表达式：</p>\n<pre><code>E: T (+、-) T (+、-) T\nT: X (*、/) X (*、/) X\n</code></pre>\n<ol>\n<li>语法分析拿到第一个token，分析生成对应的对象</li>\n<li>语法分析拿到第二个token，分析是 <code>+</code>、<code>-</code> Token</li>\n<li>语法分析调用分析<code>*</code>、<code>/</code>的语法分析</li>\n</ol>\n<p>语法分析伪代码：\n<img src=\"carbon.svg\" alt=\"xx\"></p>\n<h5 id=\"抽象语法树-AST\"><a href=\"#抽象语法树-AST\" class=\"headerlink\" title=\"抽象语法树(AST)\"></a>抽象语法树(AST)</h5><p><code>抽象语法树</code>（Abstract Syntax Tree，AST），或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构</p>\n<p>语法分析生成生成抽象语法树, 语法树具体如下：\n<img src=\"test1.drawio.png\" alt=\"xx\"></p>\n<h5 id=\"转换\"><a href=\"#转换\" class=\"headerlink\" title=\"转换\"></a>转换</h5><p>分析源数据库<code>DDL</code>、<code>SQL</code>转换对应的目标库<code>DDL</code>、<code>SQL</code></p>\n<p>针对查询语言表达式，把 绑定变量<code>:id</code> 变成 <code>?</code>：</p>\n<pre><code>SELECT * FROM DUAL WHERE ID = :id\n</code></pre>\n<p>只需要把语法树中的 <code>定变量</code>语法对象替换成 <code>?</code>语法对象，如下：\n<img src=\"/assets/%E8%BD%AC%E6%8D%A2%E7%A4%BA%E4%BE%8B.svg\" alt=\"xx\"></p>\n<hr>\n<h3 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h3><ul>\n<li><a href=\"https://db-engines.com/en/ranking\">https://db-engines.com/en/ranking</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90\">https://zh.wikipedia.org/wiki/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90\">https://zh.wikipedia.org/wiki/%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9\">https://zh.wikipedia.org/wiki/%E6%8A%BD%E8%B1%A1%E8%AA%9E%E6%B3%95%E6%A8%B9</a></li>\n</ul>\n"},{"title":"贝叶斯网算法","date":"2018-11-13T02:41:33.000Z","_content":"\n\n\n\n<!-- more -->","source":"_posts/贝叶斯网算法.md","raw":"---\ntitle: 贝叶斯网算法\ndate: 2018-11-13 10:41:33\ncategories: \n    - 机器学习\ntags: \n    - 算法\n    - 机器学习\n    - 监督学习\n    - 贝叶斯\n---\n\n\n\n\n<!-- more -->","slug":"贝叶斯网算法","published":1,"updated":"2021-06-30T02:33:24.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy500blr5p776azd4f2","content":"<span id=\"more\"></span>","site":{"data":{}},"excerpt":"","more":""},{"title":"递归神经网络","date":"2018-12-01T07:24:03.000Z","_content":"\n\n\n\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","source":"_posts/递归神经网络.md","raw":"---\ntitle: 递归神经网络\ndate: 2018-12-01 15:24:03\ncategories: \n    - 神经网络\ntags:\n    - 人工智能\n    - 神经网络\n---\n\n\n\n\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n<!-- more -->\n\n\n<br/>\n\n---\n参考\n\n[wikipedia-人工神经网络](https://en.wikipedia.org/wiki/Artificial_neural_network)\n周志华《机器学习》\n","slug":"递归神经网络","published":1,"updated":"2021-06-30T02:33:24.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy500bor5p772iw4089","content":"<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<span id=\"more\"></span>\n\n\n<br>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>\n","site":{"data":{}},"excerpt":"<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>","more":"<br/>\n\n<hr>\n<p>参考</p>\n<p><a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">wikipedia-人工神经网络</a>\n周志华《机器学习》</p>"},{"title":"面试知识点总结","date":"2018-12-01T07:22:04.000Z","_content":"## 算法\n\n### 排序\n\n#### 选择排序\n\n#### 插入排序\n\n#### 冒泡排序\n\n#### 希尔排序\n\n#### 堆排序\n\n#### 快速排序\n\n#### 归并排序\n\n#### 计数排序\n\n#### 基数排序\n\n#### 桶排序\n\n## 数据结构\n\n#### 数组\n\n#### 链表\n\n#### Hash\n\n#### 树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\n\n#### 图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\n\n## Java\n\n### atomic\n\n- AtomicBoolean\n- AtomicInteger\n- AtomicLong\n\n- AtomicIntegerArray\n- AtomicLongArray\n- AtomicReferenceArray\n\n- AtomicIntegerFieldUpdater\n- AtomicLongFieldUpdater\n- AtomicReferenceFieldUpdater\n\n- AtomicMarkableReference\n- AtomicStampedReference\n  \n- DoubleAdder  \n- LongAdder\n\n### 2、lock\n\n- ReentrantLock\n- ReentrantReadWriteLock\n- StampedLock\n\n###\t3、queue\n\n###\t4、ThreadLocal\n\n###\t5、cas\n\n###\t6、线程、线程池\n\n7、nio\n\n### JVM\n- 运行时数据区域（java内存区域）\n\t\t1、方法区：vm加载的类信息、常量、静态变量、即时编译器编译后的代码等数据\n\t\t\t1、HotSpot：永久代（利用堆特性）\n\t\t\t2、Metaspace\n\t\t\t\n\t\t\t运行时常量池：1.7 移除到堆里面\n\t\t\tJDK1.8 : Metaspace\n\n\t\t2、heap：存放对象实例。几乎所有的对象实例以及数组都在这里分配内存。\n\t\t\t1、新生代：Eden空间、From Survivor、To Survivor\n\t\t\t2、老年代\n\t\t3、vm stack：虚拟机栈为虚拟机执行Java方法服务。局部变量（基本数据类型，对象引用类型：起始引用指针、句柄）\n\t\t4、本地方法栈：本地方法栈为虚拟机使用到的Native方法服务\n\t\t5、程序计数器：当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完\n\n\t- 直接内存: DirectByteBuffer\n\t\tOutOfMemoryError\n\n\n\tClass加载：加载-验证-准备-解析-初始化-使用-卸载\n\tjava对象创建:类加载检查、分配内存、初始化零值、设置对象头、执行init方法\n\t\t1、类加载检查：参数\n\t\t2、分配内存：\n\t\t\t分配方式：\n\t\t\t\t\t指针碰撞、空闲列表\n\t\t\t\t\tjava堆内存是否规整（由GC是否有压缩整理）\n\t\t\t并发：\n\t\t\t\tCAS重试\n\t\t\t\ttlab： Thread Local alloctaion buffer\n\t\t3、初始化零值：方便没有赋值直接使用\n\t\t4、设置对象头：对象元信息、哈希码、GC分代年龄信息、运行状态（启动偏向锁）\n\t\t5、执行init方法：\n\n\t对象头、实例数据、填充数据\n\n对象访问：句柄、指针\n\t对象实例数据\n\t对象类型数据\n\n\n内存模型（JMM）：多线程变量可见性和同步\n\nGC ROOTS\n\t1、虚拟机栈引用对象\n\t2、本地方法栈引用对象\n\t3、方法区静态变量引用对象\n\t4、方法区常量引用对象\n\nGC算法：\n\t1、标记-清除算法：\t\n\t2、复制算法：\n\t3、标记-整理算法：\n\n收集器：\n\t1、Serial：新生代、老年代使用串行回收。新生代复制算法、老年代标记-压缩\n\t\t1、STW\n\t\t2、-XX:+UseSerialGC\n\n\t2、ParNew：新生代并行，老年代串行。新生代复制算法、老年代标记-压缩\n\t\t1、-XX:+UseParNewGC\n\t\t2、-XX:ParallelGCThreads\n\n\t2、Parallel Scavenge：新生代复制算法、老年代标记-压缩。\n\t\t1、-XX:+UseParallelGC\n\t\t2、\n\n\t3、Parallel Old ：老年代标记－整理\n\t\t1、-XX:+UseParallelOldGC\n\n\t4、CMS（Concurrent Mark Sweep）：老年代标记-清除\n\t\t1、初始标记（CMS initial mark）: 从GC ROOTS直接关联的对象, 放到 sets\n\t\t2、并发标记（CMS concurrent mark）: GC ROOTS\n\t\t3、重新标记（CMS remark）: \n\t\t4、并发清除（CMS concurrent sweep）: \n\n\t\t优点: 并发收集、低停顿\n\t\t缺点: 产生大量空间碎片、并发阶段会降低吞吐量\n\n\t\t-XX:+UseConcMarkSweepGC 使用CMS收集器\n\t\t-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长\n\t\t-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理\n\t\t-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）\n\n\n\t5、G1：标记-整理算法，可预测停顿\n\t\t1、\n\t\t2、\n\t\tHumongous: \n\t\t\tRegion size: 最小 1M，最大 32M\n\t\t\t<=jdk1.8u40 full gc 清理\n\n\t6、ZGC\n\t\t1、着色指针：指针64位的几位表示： Finalizable、Remapped、Marked1、Marked0\n\t\t2、读屏障：在被着色，触发读屏障，等待更新指针再返回结果\n\t\t3、内存多重映射\n\t\tRegion 的大小是会动态变化：1M、32M、n*2M(>=4M)\n\n\n当前线程执行字节码行号指示器。字节码解释器通过改变计数器来执行字节码\n\n\t2、内存屏障\n\t3、\n\t4、工具\n\t\t1、jps\n\t\t\t-l -q -v -m \n\t\t2、jinfo\n\t\t3、jstat\n\t\t3、jstack：\n\t\t\t1、\n\t\t\t2、\n\t\t4、jmap：jmap -histo:live 28920| more\n\t\t\t\tjmap -dump:live,format=b,file=heap.bin\n\n\n## MySQL\n\t1、执行计划\n\t\t1、\n\t\t2、\n\n\t\tkey_len: \n\t\t\t1、char n \n\t\t\t2、varchar utf8 3n+2 utf8mb4 4n+2\n\t\t\t3、TINYINT: 1字节\n\t\t\t4、SMALLINT: 2字节\n\t\t\t5、MEDIUMINT: 3字节\n\t\t\t6、INT: 4字节\n\t\t\t7、BIGINT: 8字节\n\t\t\t8、DATE: 3字节\n\t\t\t9、TIMESTAMP: 4字节\n\t\t\t10、DATETIME: 8字节\n\n\t\tforce index\n\t\tuse index\n\t\tignore index\n\t2、\n\t\t二叉树(BTS)\n\t\tAVL\n\t\t\t1、\n\t\t\t2、\n\t\t红黑树(Red-Black Tree)\n\t\t\t1、\n\t\t\t2、\n\t\tB+树\n\t\t\t1、添加（扩容）：\n\t\t\t\t1、\n\t\t\t\t2、\n\t\t\t2、删除（收缩）：\n\n\t3、索引\n\t\t1、hash索引\n\t\t2、\n\t\t3、B+树索引\n\t\t\t1、聚簇索引\n\t\t\t2、非聚簇索引\n\n\t4、锁\n\t\t行锁：\n\t\t\t1、共享锁：事物读取一行数据\n\t\t\t2、排它锁：事物删除、更新一行数据\n\t\t表锁：\n\t\t\t1、意向共享锁：事物获得表中某几行共享锁\n\t\t\t2、意向排它锁：事物获得表中某几行排它锁\n\n\n\t\t记录锁（record lock）\n\t\t间隙锁（gap lock）\n\t\t意向插入锁（）\n\t\tNext-Keys lock（）\n\n\tMVCC: \n\t\t1、read view\n\t\t2、\n\n\t5、事物\n\t\t等级：read uncommitted、 read commit、rr、\n\n\n## Spring\n\t1、生命周期\n\t2、AOP/IOC\n\t3、循环依赖\n\n### 事物\n\n#### 事物传播\n\n- PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。\n- PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。\n- PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。\n- PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。\n- PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n- PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。\n- PROPAGATION_NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。\n\n\t5、\n\t6、\n\n## SpringBoot\n\t1、原理\nSpringApplication run方法：\n1、实例化初始化：\n\t- webApplicationContextType\n\t- ApplicationContextInitializer\n\t- ApplicationLi\n2、SpringApplicationRunListener start 周知 要开始了\n3、environment 创建和配置\n4、SpringApplicationRunListener environment 配置\n5、printBanner\n6、创建 ApplicationContext\n7、ApplicationContext 配置 environment\n8、ApplicationContextInitializer initialize\n9、SpringApplicationRunListener  contextPrepared 执行\n10、加载\n11、SpringApplicationRunListener  contextLoaded 执行\n12、ApplicationContext 执行 refresh\n13、ApplicationRunner、CommandLineRunner 执行\n14、SpringApplicationRunListener running执行\n15、\n\n\n## Linux：\n\n### select，poll，epoll都是IO多路复用的机制\n\n### 进程：孤儿进程与僵尸进程\n\n- 孤儿进程\n  - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。\n- 僵尸进程\n  - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。\n\n### 命令操作\n\n#### 1、grep\n\n#### 2、sed\n\n#### 3、awk\n\n#### 4、top\n\n\n\n## 设计模式\n\n### 六大原则\n\n- 单一职责:\n- 接口隔离:\n- 里氏替换原则:\n- 依赖倒置:\n- 迪米特法则:\n- 开闭原则:\n- 合成复用:\n\n### 三大模式\n\n- 创建模式：\n- 结构模式：\n- 行为模式：\n\n#### 创建模式\n\n- 简单工厂\n- 工厂方法\n- 抽象工厂\n- 单列\n- 原型\n- 建造者\n\n#### 结构模式\n\n- 代理\n- 适配器\n- 装饰\n- 享元\n- 外观\n- 组合\n\n#### 行为模式\n\n- 责任链\n- 模板\n- 策略\n- 访问\n- 备忘录\n- 观察者\n- 迭代器\n- 状态\n- 命令\n\n\n## Readis\n\n### 1、数据结构\n\n\t\t1、sds:简单动态字符串\n\t\t\t结构：buf字符数组、len 长度、free长度\n\t\t\tvs C：\n\t\t\t\t1、常数级别获取字符串长度\n\t\t\t\t2、杜绝缓冲区溢出\t\n\t\t\t\t3、减少修改字符串带来内存重分配（增加：预分配（大于30m，1m）\t\t减少：惰性）\n\t\t\t\t4、二进制安全\n\t\t\t\t5、兼容部分C\n\n\t\t\t\n\t\t2、链表(linkedlist)\n\t\t\t结构：head、tail、len\n\n\n\t\t3、字典(map)：符号表（symbol table）\n\t\t\t结构：数组、size、sizemask、used、next\n\n\t\t\t扩容：加载因子 > 1  (空闲的时候) or 加载因子 > 5（繁忙的时候）\n\t\t\t收缩：加载因子 < 0.1\n\n\t\t4、skiplist：有序（用在有序集合）\n\t\t\t结构：\n\n\n\t\t5、intset：整数集合\n\t\t\t结构：\n\t\t\t\n\n\t\t6、ziplist：压缩列表\n\t\t\t结构：\n\n### 对象\n\n- string（字符串键）\n- hash（哈希）\n- list（列表键）\n- set（集合）\n- sortedset（）\n\n### 持久化：RDB、AOF\n\n- RDB\n- AOF\n\n\n\n\n## MQ\n###\tkafak\n\t\t1、mmp\n\t\t2、zero copy\n\t\t3、\n\t\t4、\n\t\t5、\n### RocketMQ:\n\t1、Producer\n\t2、Consumer\n\t3、NameServer\n\t4、Broker\n\n高性能\n\n\t- Producer\n\t- Broker\n\t- Consumer\n  \n高可用\n\n\t- Producer\n\t- Broke\n\t- Consumer\n\n1、Topic\n2、Message\n3、Tag\n\n生产\n\n存储\n1、CommitLog\n2、\n\n消费\n1、ConsumeQueue\n\n###\tRabbitmq：\n\t\t1、\n\t\t2、\n\n## Zookeeper\n\t1、paxor\n\t\t1、\n\t\t2、\n\t2、raft\n\t\t1、leader选举\n\t\t2、日志复制\n\t\t3、安全性\n\n\n## docker：\n\t1、\n\t2、\n\t3、\n\t4、\n\t5、\n## k8s:\n\t1、\n\t2、\n\t3、\t\n\n\n1小时科普：量子力学\n1、量子定义来源：\n\t旧量子力学：过渡量子利力学\n\t\t普朗克：黑体辐射：能量释放、吸收是一份份不连续的不可分割的能量，这一份能量称为量子\n\t\t\t黑体辐射：维恩公式-短波，瑞利公式-长波   ==> 普朗克 量子\n\t\t爱因斯旦-光量子：光电效应：频率、波长、能量\n\t\t波尔：原子量子理论\n\t\t德布罗意波：物质波--微观粒子均有一个波\n\t现代量子力学：\n\t\t海森堡：数学描述量子力学---矩阵力学\n\t\t薛定谔：描述物质连续时空演化的偏微方程---薛定谔方程---波动力学（另一种数学描述量子利力学）\n\t\t狄拉克：\n\t\t费恩曼：路径积分\n\n发展路线：\n\t一、普朗克量子论--波尔原子量子论--爱因斯坦辐射量子论--海森堡矩阵力学\n\t二、普朗克量子论--爱因斯坦光量子--德布罗意波---薛定谔波动力学\n\n应用：\n\t微观：原子、亚原子、分子、材料的微观领域\n\t宏观：超导、超流、量子霍尔效应\n\n2、","source":"_posts/面试知识点总结.md","raw":"---\ntitle: 面试知识点总结\ndate: 2018-12-01 15:22:04\ncategories: \n    - 面试\ntags:\n    - 面试\n---\n## 算法\n\n### 排序\n\n#### 选择排序\n\n#### 插入排序\n\n#### 冒泡排序\n\n#### 希尔排序\n\n#### 堆排序\n\n#### 快速排序\n\n#### 归并排序\n\n#### 计数排序\n\n#### 基数排序\n\n#### 桶排序\n\n## 数据结构\n\n#### 数组\n\n#### 链表\n\n#### Hash\n\n#### 树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\n\n#### 图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\n\n## Java\n\n### atomic\n\n- AtomicBoolean\n- AtomicInteger\n- AtomicLong\n\n- AtomicIntegerArray\n- AtomicLongArray\n- AtomicReferenceArray\n\n- AtomicIntegerFieldUpdater\n- AtomicLongFieldUpdater\n- AtomicReferenceFieldUpdater\n\n- AtomicMarkableReference\n- AtomicStampedReference\n  \n- DoubleAdder  \n- LongAdder\n\n### 2、lock\n\n- ReentrantLock\n- ReentrantReadWriteLock\n- StampedLock\n\n###\t3、queue\n\n###\t4、ThreadLocal\n\n###\t5、cas\n\n###\t6、线程、线程池\n\n7、nio\n\n### JVM\n- 运行时数据区域（java内存区域）\n\t\t1、方法区：vm加载的类信息、常量、静态变量、即时编译器编译后的代码等数据\n\t\t\t1、HotSpot：永久代（利用堆特性）\n\t\t\t2、Metaspace\n\t\t\t\n\t\t\t运行时常量池：1.7 移除到堆里面\n\t\t\tJDK1.8 : Metaspace\n\n\t\t2、heap：存放对象实例。几乎所有的对象实例以及数组都在这里分配内存。\n\t\t\t1、新生代：Eden空间、From Survivor、To Survivor\n\t\t\t2、老年代\n\t\t3、vm stack：虚拟机栈为虚拟机执行Java方法服务。局部变量（基本数据类型，对象引用类型：起始引用指针、句柄）\n\t\t4、本地方法栈：本地方法栈为虚拟机使用到的Native方法服务\n\t\t5、程序计数器：当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完\n\n\t- 直接内存: DirectByteBuffer\n\t\tOutOfMemoryError\n\n\n\tClass加载：加载-验证-准备-解析-初始化-使用-卸载\n\tjava对象创建:类加载检查、分配内存、初始化零值、设置对象头、执行init方法\n\t\t1、类加载检查：参数\n\t\t2、分配内存：\n\t\t\t分配方式：\n\t\t\t\t\t指针碰撞、空闲列表\n\t\t\t\t\tjava堆内存是否规整（由GC是否有压缩整理）\n\t\t\t并发：\n\t\t\t\tCAS重试\n\t\t\t\ttlab： Thread Local alloctaion buffer\n\t\t3、初始化零值：方便没有赋值直接使用\n\t\t4、设置对象头：对象元信息、哈希码、GC分代年龄信息、运行状态（启动偏向锁）\n\t\t5、执行init方法：\n\n\t对象头、实例数据、填充数据\n\n对象访问：句柄、指针\n\t对象实例数据\n\t对象类型数据\n\n\n内存模型（JMM）：多线程变量可见性和同步\n\nGC ROOTS\n\t1、虚拟机栈引用对象\n\t2、本地方法栈引用对象\n\t3、方法区静态变量引用对象\n\t4、方法区常量引用对象\n\nGC算法：\n\t1、标记-清除算法：\t\n\t2、复制算法：\n\t3、标记-整理算法：\n\n收集器：\n\t1、Serial：新生代、老年代使用串行回收。新生代复制算法、老年代标记-压缩\n\t\t1、STW\n\t\t2、-XX:+UseSerialGC\n\n\t2、ParNew：新生代并行，老年代串行。新生代复制算法、老年代标记-压缩\n\t\t1、-XX:+UseParNewGC\n\t\t2、-XX:ParallelGCThreads\n\n\t2、Parallel Scavenge：新生代复制算法、老年代标记-压缩。\n\t\t1、-XX:+UseParallelGC\n\t\t2、\n\n\t3、Parallel Old ：老年代标记－整理\n\t\t1、-XX:+UseParallelOldGC\n\n\t4、CMS（Concurrent Mark Sweep）：老年代标记-清除\n\t\t1、初始标记（CMS initial mark）: 从GC ROOTS直接关联的对象, 放到 sets\n\t\t2、并发标记（CMS concurrent mark）: GC ROOTS\n\t\t3、重新标记（CMS remark）: \n\t\t4、并发清除（CMS concurrent sweep）: \n\n\t\t优点: 并发收集、低停顿\n\t\t缺点: 产生大量空间碎片、并发阶段会降低吞吐量\n\n\t\t-XX:+UseConcMarkSweepGC 使用CMS收集器\n\t\t-XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长\n\t\t-XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理\n\t\t-XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）\n\n\n\t5、G1：标记-整理算法，可预测停顿\n\t\t1、\n\t\t2、\n\t\tHumongous: \n\t\t\tRegion size: 最小 1M，最大 32M\n\t\t\t<=jdk1.8u40 full gc 清理\n\n\t6、ZGC\n\t\t1、着色指针：指针64位的几位表示： Finalizable、Remapped、Marked1、Marked0\n\t\t2、读屏障：在被着色，触发读屏障，等待更新指针再返回结果\n\t\t3、内存多重映射\n\t\tRegion 的大小是会动态变化：1M、32M、n*2M(>=4M)\n\n\n当前线程执行字节码行号指示器。字节码解释器通过改变计数器来执行字节码\n\n\t2、内存屏障\n\t3、\n\t4、工具\n\t\t1、jps\n\t\t\t-l -q -v -m \n\t\t2、jinfo\n\t\t3、jstat\n\t\t3、jstack：\n\t\t\t1、\n\t\t\t2、\n\t\t4、jmap：jmap -histo:live 28920| more\n\t\t\t\tjmap -dump:live,format=b,file=heap.bin\n\n\n## MySQL\n\t1、执行计划\n\t\t1、\n\t\t2、\n\n\t\tkey_len: \n\t\t\t1、char n \n\t\t\t2、varchar utf8 3n+2 utf8mb4 4n+2\n\t\t\t3、TINYINT: 1字节\n\t\t\t4、SMALLINT: 2字节\n\t\t\t5、MEDIUMINT: 3字节\n\t\t\t6、INT: 4字节\n\t\t\t7、BIGINT: 8字节\n\t\t\t8、DATE: 3字节\n\t\t\t9、TIMESTAMP: 4字节\n\t\t\t10、DATETIME: 8字节\n\n\t\tforce index\n\t\tuse index\n\t\tignore index\n\t2、\n\t\t二叉树(BTS)\n\t\tAVL\n\t\t\t1、\n\t\t\t2、\n\t\t红黑树(Red-Black Tree)\n\t\t\t1、\n\t\t\t2、\n\t\tB+树\n\t\t\t1、添加（扩容）：\n\t\t\t\t1、\n\t\t\t\t2、\n\t\t\t2、删除（收缩）：\n\n\t3、索引\n\t\t1、hash索引\n\t\t2、\n\t\t3、B+树索引\n\t\t\t1、聚簇索引\n\t\t\t2、非聚簇索引\n\n\t4、锁\n\t\t行锁：\n\t\t\t1、共享锁：事物读取一行数据\n\t\t\t2、排它锁：事物删除、更新一行数据\n\t\t表锁：\n\t\t\t1、意向共享锁：事物获得表中某几行共享锁\n\t\t\t2、意向排它锁：事物获得表中某几行排它锁\n\n\n\t\t记录锁（record lock）\n\t\t间隙锁（gap lock）\n\t\t意向插入锁（）\n\t\tNext-Keys lock（）\n\n\tMVCC: \n\t\t1、read view\n\t\t2、\n\n\t5、事物\n\t\t等级：read uncommitted、 read commit、rr、\n\n\n## Spring\n\t1、生命周期\n\t2、AOP/IOC\n\t3、循环依赖\n\n### 事物\n\n#### 事物传播\n\n- PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。\n- PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。\n- PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。\n- PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。\n- PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n- PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。\n- PROPAGATION_NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。\n\n\t5、\n\t6、\n\n## SpringBoot\n\t1、原理\nSpringApplication run方法：\n1、实例化初始化：\n\t- webApplicationContextType\n\t- ApplicationContextInitializer\n\t- ApplicationLi\n2、SpringApplicationRunListener start 周知 要开始了\n3、environment 创建和配置\n4、SpringApplicationRunListener environment 配置\n5、printBanner\n6、创建 ApplicationContext\n7、ApplicationContext 配置 environment\n8、ApplicationContextInitializer initialize\n9、SpringApplicationRunListener  contextPrepared 执行\n10、加载\n11、SpringApplicationRunListener  contextLoaded 执行\n12、ApplicationContext 执行 refresh\n13、ApplicationRunner、CommandLineRunner 执行\n14、SpringApplicationRunListener running执行\n15、\n\n\n## Linux：\n\n### select，poll，epoll都是IO多路复用的机制\n\n### 进程：孤儿进程与僵尸进程\n\n- 孤儿进程\n  - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。\n- 僵尸进程\n  - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。\n\n### 命令操作\n\n#### 1、grep\n\n#### 2、sed\n\n#### 3、awk\n\n#### 4、top\n\n\n\n## 设计模式\n\n### 六大原则\n\n- 单一职责:\n- 接口隔离:\n- 里氏替换原则:\n- 依赖倒置:\n- 迪米特法则:\n- 开闭原则:\n- 合成复用:\n\n### 三大模式\n\n- 创建模式：\n- 结构模式：\n- 行为模式：\n\n#### 创建模式\n\n- 简单工厂\n- 工厂方法\n- 抽象工厂\n- 单列\n- 原型\n- 建造者\n\n#### 结构模式\n\n- 代理\n- 适配器\n- 装饰\n- 享元\n- 外观\n- 组合\n\n#### 行为模式\n\n- 责任链\n- 模板\n- 策略\n- 访问\n- 备忘录\n- 观察者\n- 迭代器\n- 状态\n- 命令\n\n\n## Readis\n\n### 1、数据结构\n\n\t\t1、sds:简单动态字符串\n\t\t\t结构：buf字符数组、len 长度、free长度\n\t\t\tvs C：\n\t\t\t\t1、常数级别获取字符串长度\n\t\t\t\t2、杜绝缓冲区溢出\t\n\t\t\t\t3、减少修改字符串带来内存重分配（增加：预分配（大于30m，1m）\t\t减少：惰性）\n\t\t\t\t4、二进制安全\n\t\t\t\t5、兼容部分C\n\n\t\t\t\n\t\t2、链表(linkedlist)\n\t\t\t结构：head、tail、len\n\n\n\t\t3、字典(map)：符号表（symbol table）\n\t\t\t结构：数组、size、sizemask、used、next\n\n\t\t\t扩容：加载因子 > 1  (空闲的时候) or 加载因子 > 5（繁忙的时候）\n\t\t\t收缩：加载因子 < 0.1\n\n\t\t4、skiplist：有序（用在有序集合）\n\t\t\t结构：\n\n\n\t\t5、intset：整数集合\n\t\t\t结构：\n\t\t\t\n\n\t\t6、ziplist：压缩列表\n\t\t\t结构：\n\n### 对象\n\n- string（字符串键）\n- hash（哈希）\n- list（列表键）\n- set（集合）\n- sortedset（）\n\n### 持久化：RDB、AOF\n\n- RDB\n- AOF\n\n\n\n\n## MQ\n###\tkafak\n\t\t1、mmp\n\t\t2、zero copy\n\t\t3、\n\t\t4、\n\t\t5、\n### RocketMQ:\n\t1、Producer\n\t2、Consumer\n\t3、NameServer\n\t4、Broker\n\n高性能\n\n\t- Producer\n\t- Broker\n\t- Consumer\n  \n高可用\n\n\t- Producer\n\t- Broke\n\t- Consumer\n\n1、Topic\n2、Message\n3、Tag\n\n生产\n\n存储\n1、CommitLog\n2、\n\n消费\n1、ConsumeQueue\n\n###\tRabbitmq：\n\t\t1、\n\t\t2、\n\n## Zookeeper\n\t1、paxor\n\t\t1、\n\t\t2、\n\t2、raft\n\t\t1、leader选举\n\t\t2、日志复制\n\t\t3、安全性\n\n\n## docker：\n\t1、\n\t2、\n\t3、\n\t4、\n\t5、\n## k8s:\n\t1、\n\t2、\n\t3、\t\n\n\n1小时科普：量子力学\n1、量子定义来源：\n\t旧量子力学：过渡量子利力学\n\t\t普朗克：黑体辐射：能量释放、吸收是一份份不连续的不可分割的能量，这一份能量称为量子\n\t\t\t黑体辐射：维恩公式-短波，瑞利公式-长波   ==> 普朗克 量子\n\t\t爱因斯旦-光量子：光电效应：频率、波长、能量\n\t\t波尔：原子量子理论\n\t\t德布罗意波：物质波--微观粒子均有一个波\n\t现代量子力学：\n\t\t海森堡：数学描述量子力学---矩阵力学\n\t\t薛定谔：描述物质连续时空演化的偏微方程---薛定谔方程---波动力学（另一种数学描述量子利力学）\n\t\t狄拉克：\n\t\t费恩曼：路径积分\n\n发展路线：\n\t一、普朗克量子论--波尔原子量子论--爱因斯坦辐射量子论--海森堡矩阵力学\n\t二、普朗克量子论--爱因斯坦光量子--德布罗意波---薛定谔波动力学\n\n应用：\n\t微观：原子、亚原子、分子、材料的微观领域\n\t宏观：超导、超流、量子霍尔效应\n\n2、","slug":"面试知识点总结","published":1,"updated":"2021-06-30T02:33:24.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy600bsr5p70e27hhgf","content":"<h2 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h2><h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><h4 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h4><h4 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h4><h4 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h4><h4 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h4><h4 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h4><h4 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h4><h4 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h4><h4 id=\"计数排序\"><a href=\"#计数排序\" class=\"headerlink\" title=\"计数排序\"></a>计数排序</h4><h4 id=\"基数排序\"><a href=\"#基数排序\" class=\"headerlink\" title=\"基数排序\"></a>基数排序</h4><h4 id=\"桶排序\"><a href=\"#桶排序\" class=\"headerlink\" title=\"桶排序\"></a>桶排序</h4><h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h4 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h4><h4 id=\"链表\"><a href=\"#链表\" class=\"headerlink\" title=\"链表\"></a>链表</h4><h4 id=\"Hash\"><a href=\"#Hash\" class=\"headerlink\" title=\"Hash\"></a>Hash</h4><h4 id=\"树-二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\"><a href=\"#树-二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\" class=\"headerlink\" title=\"树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\"></a>树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树</h4><h4 id=\"图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\"><a href=\"#图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\" class=\"headerlink\" title=\"图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\"></a>图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索</h4><h2 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h2><h3 id=\"atomic\"><a href=\"#atomic\" class=\"headerlink\" title=\"atomic\"></a>atomic</h3><ul>\n<li><p>AtomicBoolean</p>\n</li>\n<li><p>AtomicInteger</p>\n</li>\n<li><p>AtomicLong</p>\n</li>\n<li><p>AtomicIntegerArray</p>\n</li>\n<li><p>AtomicLongArray</p>\n</li>\n<li><p>AtomicReferenceArray</p>\n</li>\n<li><p>AtomicIntegerFieldUpdater</p>\n</li>\n<li><p>AtomicLongFieldUpdater</p>\n</li>\n<li><p>AtomicReferenceFieldUpdater</p>\n</li>\n<li><p>AtomicMarkableReference</p>\n</li>\n<li><p>AtomicStampedReference</p>\n</li>\n<li><p>DoubleAdder  </p>\n</li>\n<li><p>LongAdder</p>\n</li>\n</ul>\n<h3 id=\"2、lock\"><a href=\"#2、lock\" class=\"headerlink\" title=\"2、lock\"></a>2、lock</h3><ul>\n<li>ReentrantLock</li>\n<li>ReentrantReadWriteLock</li>\n<li>StampedLock</li>\n</ul>\n<h3 id=\"3、queue\"><a href=\"#3、queue\" class=\"headerlink\" title=\"3、queue\"></a>3、queue</h3><h3 id=\"4、ThreadLocal\"><a href=\"#4、ThreadLocal\" class=\"headerlink\" title=\"4、ThreadLocal\"></a>4、ThreadLocal</h3><h3 id=\"5、cas\"><a href=\"#5、cas\" class=\"headerlink\" title=\"5、cas\"></a>5、cas</h3><h3 id=\"6、线程、线程池\"><a href=\"#6、线程、线程池\" class=\"headerlink\" title=\"6、线程、线程池\"></a>6、线程、线程池</h3><p>7、nio</p>\n<h3 id=\"JVM\"><a href=\"#JVM\" class=\"headerlink\" title=\"JVM\"></a>JVM</h3><ul>\n<li><p>运行时数据区域（java内存区域）</p>\n<pre><code>  1、方法区：vm加载的类信息、常量、静态变量、即时编译器编译后的代码等数据\n      1、HotSpot：永久代（利用堆特性）\n      2、Metaspace\n      \n      运行时常量池：1.7 移除到堆里面\n      JDK1.8 : Metaspace\n\n  2、heap：存放对象实例。几乎所有的对象实例以及数组都在这里分配内存。\n      1、新生代：Eden空间、From Survivor、To Survivor\n      2、老年代\n  3、vm stack：虚拟机栈为虚拟机执行Java方法服务。局部变量（基本数据类型，对象引用类型：起始引用指针、句柄）\n  4、本地方法栈：本地方法栈为虚拟机使用到的Native方法服务\n  5、程序计数器：当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完\n</code></pre>\n<ul>\n<li>直接内存: DirectByteBuffer\n  OutOfMemoryError</li>\n</ul>\n</li>\n</ul>\n<pre><code>Class加载：加载-验证-准备-解析-初始化-使用-卸载\njava对象创建:类加载检查、分配内存、初始化零值、设置对象头、执行init方法\n    1、类加载检查：参数\n    2、分配内存：\n        分配方式：\n                指针碰撞、空闲列表\n                java堆内存是否规整（由GC是否有压缩整理）\n        并发：\n            CAS重试\n            tlab： Thread Local alloctaion buffer\n    3、初始化零值：方便没有赋值直接使用\n    4、设置对象头：对象元信息、哈希码、GC分代年龄信息、运行状态（启动偏向锁）\n    5、执行init方法：\n\n对象头、实例数据、填充数据\n</code></pre>\n<p>对象访问：句柄、指针\n    对象实例数据\n    对象类型数据</p>\n<p>内存模型（JMM）：多线程变量可见性和同步</p>\n<p>GC ROOTS\n    1、虚拟机栈引用对象\n    2、本地方法栈引用对象\n    3、方法区静态变量引用对象\n    4、方法区常量引用对象</p>\n<p>GC算法：\n    1、标记-清除算法：<br>    2、复制算法：\n    3、标记-整理算法：</p>\n<p>收集器：\n    1、Serial：新生代、老年代使用串行回收。新生代复制算法、老年代标记-压缩\n        1、STW\n        2、-XX:+UseSerialGC</p>\n<pre><code>2、ParNew：新生代并行，老年代串行。新生代复制算法、老年代标记-压缩\n    1、-XX:+UseParNewGC\n    2、-XX:ParallelGCThreads\n\n2、Parallel Scavenge：新生代复制算法、老年代标记-压缩。\n    1、-XX:+UseParallelGC\n    2、\n\n3、Parallel Old ：老年代标记－整理\n    1、-XX:+UseParallelOldGC\n\n4、CMS（Concurrent Mark Sweep）：老年代标记-清除\n    1、初始标记（CMS initial mark）: 从GC ROOTS直接关联的对象, 放到 sets\n    2、并发标记（CMS concurrent mark）: GC ROOTS\n    3、重新标记（CMS remark）: \n    4、并发清除（CMS concurrent sweep）: \n\n    优点: 并发收集、低停顿\n    缺点: 产生大量空间碎片、并发阶段会降低吞吐量\n\n    -XX:+UseConcMarkSweepGC 使用CMS收集器\n    -XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长\n    -XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理\n    -XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）\n\n\n5、G1：标记-整理算法，可预测停顿\n    1、\n    2、\n    Humongous: \n        Region size: 最小 1M，最大 32M\n        &lt;=jdk1.8u40 full gc 清理\n\n6、ZGC\n    1、着色指针：指针64位的几位表示： Finalizable、Remapped、Marked1、Marked0\n    2、读屏障：在被着色，触发读屏障，等待更新指针再返回结果\n    3、内存多重映射\n    Region 的大小是会动态变化：1M、32M、n*2M(&gt;=4M)\n</code></pre>\n<p>当前线程执行字节码行号指示器。字节码解释器通过改变计数器来执行字节码</p>\n<pre><code>2、内存屏障\n3、\n4、工具\n    1、jps\n        -l -q -v -m \n    2、jinfo\n    3、jstat\n    3、jstack：\n        1、\n        2、\n    4、jmap：jmap -histo:live 28920| more\n            jmap -dump:live,format=b,file=heap.bin\n</code></pre>\n<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><pre><code>1、执行计划\n    1、\n    2、\n\n    key_len: \n        1、char n \n        2、varchar utf8 3n+2 utf8mb4 4n+2\n        3、TINYINT: 1字节\n        4、SMALLINT: 2字节\n        5、MEDIUMINT: 3字节\n        6、INT: 4字节\n        7、BIGINT: 8字节\n        8、DATE: 3字节\n        9、TIMESTAMP: 4字节\n        10、DATETIME: 8字节\n\n    force index\n    use index\n    ignore index\n2、\n    二叉树(BTS)\n    AVL\n        1、\n        2、\n    红黑树(Red-Black Tree)\n        1、\n        2、\n    B+树\n        1、添加（扩容）：\n            1、\n            2、\n        2、删除（收缩）：\n\n3、索引\n    1、hash索引\n    2、\n    3、B+树索引\n        1、聚簇索引\n        2、非聚簇索引\n\n4、锁\n    行锁：\n        1、共享锁：事物读取一行数据\n        2、排它锁：事物删除、更新一行数据\n    表锁：\n        1、意向共享锁：事物获得表中某几行共享锁\n        2、意向排它锁：事物获得表中某几行排它锁\n\n\n    记录锁（record lock）\n    间隙锁（gap lock）\n    意向插入锁（）\n    Next-Keys lock（）\n\nMVCC: \n    1、read view\n    2、\n\n5、事物\n    等级：read uncommitted、 read commit、rr、\n</code></pre>\n<h2 id=\"Spring\"><a href=\"#Spring\" class=\"headerlink\" title=\"Spring\"></a>Spring</h2><pre><code>1、生命周期\n2、AOP/IOC\n3、循环依赖\n</code></pre>\n<h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><h4 id=\"事物传播\"><a href=\"#事物传播\" class=\"headerlink\" title=\"事物传播\"></a>事物传播</h4><ul>\n<li><p>PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。</p>\n</li>\n<li><p>PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。</p>\n</li>\n<li><p>PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。</p>\n</li>\n<li><p>PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。</p>\n</li>\n<li><p>PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</p>\n</li>\n<li><p>PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。</p>\n</li>\n<li><p>PROPAGATION_NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。</p>\n<p>  5、\n  6、</p>\n</li>\n</ul>\n<h2 id=\"SpringBoot\"><a href=\"#SpringBoot\" class=\"headerlink\" title=\"SpringBoot\"></a>SpringBoot</h2><pre><code>1、原理\n</code></pre>\n<p>SpringApplication run方法：\n1、实例化初始化：\n    - webApplicationContextType\n    - ApplicationContextInitializer\n    - ApplicationLi\n2、SpringApplicationRunListener start 周知 要开始了\n3、environment 创建和配置\n4、SpringApplicationRunListener environment 配置\n5、printBanner\n6、创建 ApplicationContext\n7、ApplicationContext 配置 environment\n8、ApplicationContextInitializer initialize\n9、SpringApplicationRunListener  contextPrepared 执行\n10、加载\n11、SpringApplicationRunListener  contextLoaded 执行\n12、ApplicationContext 执行 refresh\n13、ApplicationRunner、CommandLineRunner 执行\n14、SpringApplicationRunListener running执行\n15、</p>\n<h2 id=\"Linux：\"><a href=\"#Linux：\" class=\"headerlink\" title=\"Linux：\"></a>Linux：</h2><h3 id=\"select，poll，epoll都是IO多路复用的机制\"><a href=\"#select，poll，epoll都是IO多路复用的机制\" class=\"headerlink\" title=\"select，poll，epoll都是IO多路复用的机制\"></a>select，poll，epoll都是IO多路复用的机制</h3><h3 id=\"进程：孤儿进程与僵尸进程\"><a href=\"#进程：孤儿进程与僵尸进程\" class=\"headerlink\" title=\"进程：孤儿进程与僵尸进程\"></a>进程：孤儿进程与僵尸进程</h3><ul>\n<li>孤儿进程<ul>\n<li>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</li>\n</ul>\n</li>\n<li>僵尸进程<ul>\n<li>一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"命令操作\"><a href=\"#命令操作\" class=\"headerlink\" title=\"命令操作\"></a>命令操作</h3><h4 id=\"1、grep\"><a href=\"#1、grep\" class=\"headerlink\" title=\"1、grep\"></a>1、grep</h4><h4 id=\"2、sed\"><a href=\"#2、sed\" class=\"headerlink\" title=\"2、sed\"></a>2、sed</h4><h4 id=\"3、awk\"><a href=\"#3、awk\" class=\"headerlink\" title=\"3、awk\"></a>3、awk</h4><h4 id=\"4、top\"><a href=\"#4、top\" class=\"headerlink\" title=\"4、top\"></a>4、top</h4><h2 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h2><h3 id=\"六大原则\"><a href=\"#六大原则\" class=\"headerlink\" title=\"六大原则\"></a>六大原则</h3><ul>\n<li>单一职责:</li>\n<li>接口隔离:</li>\n<li>里氏替换原则:</li>\n<li>依赖倒置:</li>\n<li>迪米特法则:</li>\n<li>开闭原则:</li>\n<li>合成复用:</li>\n</ul>\n<h3 id=\"三大模式\"><a href=\"#三大模式\" class=\"headerlink\" title=\"三大模式\"></a>三大模式</h3><ul>\n<li>创建模式：</li>\n<li>结构模式：</li>\n<li>行为模式：</li>\n</ul>\n<h4 id=\"创建模式\"><a href=\"#创建模式\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h4><ul>\n<li>简单工厂</li>\n<li>工厂方法</li>\n<li>抽象工厂</li>\n<li>单列</li>\n<li>原型</li>\n<li>建造者</li>\n</ul>\n<h4 id=\"结构模式\"><a href=\"#结构模式\" class=\"headerlink\" title=\"结构模式\"></a>结构模式</h4><ul>\n<li>代理</li>\n<li>适配器</li>\n<li>装饰</li>\n<li>享元</li>\n<li>外观</li>\n<li>组合</li>\n</ul>\n<h4 id=\"行为模式\"><a href=\"#行为模式\" class=\"headerlink\" title=\"行为模式\"></a>行为模式</h4><ul>\n<li>责任链</li>\n<li>模板</li>\n<li>策略</li>\n<li>访问</li>\n<li>备忘录</li>\n<li>观察者</li>\n<li>迭代器</li>\n<li>状态</li>\n<li>命令</li>\n</ul>\n<h2 id=\"Readis\"><a href=\"#Readis\" class=\"headerlink\" title=\"Readis\"></a>Readis</h2><h3 id=\"1、数据结构\"><a href=\"#1、数据结构\" class=\"headerlink\" title=\"1、数据结构\"></a>1、数据结构</h3><pre><code>    1、sds:简单动态字符串\n        结构：buf字符数组、len 长度、free长度\n        vs C：\n            1、常数级别获取字符串长度\n            2、杜绝缓冲区溢出    \n            3、减少修改字符串带来内存重分配（增加：预分配（大于30m，1m）        减少：惰性）\n            4、二进制安全\n            5、兼容部分C\n\n        \n    2、链表(linkedlist)\n        结构：head、tail、len\n\n\n    3、字典(map)：符号表（symbol table）\n        结构：数组、size、sizemask、used、next\n\n        扩容：加载因子 &gt; 1  (空闲的时候) or 加载因子 &gt; 5（繁忙的时候）\n        收缩：加载因子 &lt; 0.1\n\n    4、skiplist：有序（用在有序集合）\n        结构：\n\n\n    5、intset：整数集合\n        结构：\n        \n\n    6、ziplist：压缩列表\n        结构：\n</code></pre>\n<h3 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h3><ul>\n<li>string（字符串键）</li>\n<li>hash（哈希）</li>\n<li>list（列表键）</li>\n<li>set（集合）</li>\n<li>sortedset（）</li>\n</ul>\n<h3 id=\"持久化：RDB、AOF\"><a href=\"#持久化：RDB、AOF\" class=\"headerlink\" title=\"持久化：RDB、AOF\"></a>持久化：RDB、AOF</h3><ul>\n<li>RDB</li>\n<li>AOF</li>\n</ul>\n<h2 id=\"MQ\"><a href=\"#MQ\" class=\"headerlink\" title=\"MQ\"></a>MQ</h2><h3 id=\"kafak\"><a href=\"#kafak\" class=\"headerlink\" title=\"kafak\"></a>kafak</h3><pre><code>    1、mmp\n    2、zero copy\n    3、\n    4、\n    5、\n</code></pre>\n<h3 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ:\"></a>RocketMQ:</h3><pre><code>1、Producer\n2、Consumer\n3、NameServer\n4、Broker\n</code></pre>\n<p>高性能</p>\n<pre><code>- Producer\n- Broker\n- Consumer\n</code></pre>\n<p>高可用</p>\n<pre><code>- Producer\n- Broke\n- Consumer\n</code></pre>\n<p>1、Topic\n2、Message\n3、Tag</p>\n<p>生产</p>\n<p>存储\n1、CommitLog\n2、</p>\n<p>消费\n1、ConsumeQueue</p>\n<h3 id=\"Rabbitmq：\"><a href=\"#Rabbitmq：\" class=\"headerlink\" title=\"Rabbitmq：\"></a>Rabbitmq：</h3><pre><code>    1、\n    2、\n</code></pre>\n<h2 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h2><pre><code>1、paxor\n    1、\n    2、\n2、raft\n    1、leader选举\n    2、日志复制\n    3、安全性\n</code></pre>\n<h2 id=\"docker：\"><a href=\"#docker：\" class=\"headerlink\" title=\"docker：\"></a>docker：</h2><pre><code>1、\n2、\n3、\n4、\n5、\n</code></pre>\n<h2 id=\"k8s\"><a href=\"#k8s\" class=\"headerlink\" title=\"k8s:\"></a>k8s:</h2><pre><code>1、\n2、\n3、    \n</code></pre>\n<p>1小时科普：量子力学\n1、量子定义来源：\n    旧量子力学：过渡量子利力学\n        普朗克：黑体辐射：能量释放、吸收是一份份不连续的不可分割的能量，这一份能量称为量子\n            黑体辐射：维恩公式-短波，瑞利公式-长波   ==&gt; 普朗克 量子\n        爱因斯旦-光量子：光电效应：频率、波长、能量\n        波尔：原子量子理论\n        德布罗意波：物质波–微观粒子均有一个波\n    现代量子力学：\n        海森堡：数学描述量子力学—矩阵力学\n        薛定谔：描述物质连续时空演化的偏微方程—薛定谔方程—波动力学（另一种数学描述量子利力学）\n        狄拉克：\n        费恩曼：路径积分</p>\n<p>发展路线：\n    一、普朗克量子论–波尔原子量子论–爱因斯坦辐射量子论–海森堡矩阵力学\n    二、普朗克量子论–爱因斯坦光量子–德布罗意波—薛定谔波动力学</p>\n<p>应用：\n    微观：原子、亚原子、分子、材料的微观领域\n    宏观：超导、超流、量子霍尔效应</p>\n<p>2、</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h2><h3 id=\"排序\"><a href=\"#排序\" class=\"headerlink\" title=\"排序\"></a>排序</h3><h4 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h4><h4 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h4><h4 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h4><h4 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h4><h4 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h4><h4 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h4><h4 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h4><h4 id=\"计数排序\"><a href=\"#计数排序\" class=\"headerlink\" title=\"计数排序\"></a>计数排序</h4><h4 id=\"基数排序\"><a href=\"#基数排序\" class=\"headerlink\" title=\"基数排序\"></a>基数排序</h4><h4 id=\"桶排序\"><a href=\"#桶排序\" class=\"headerlink\" title=\"桶排序\"></a>桶排序</h4><h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><h4 id=\"数组\"><a href=\"#数组\" class=\"headerlink\" title=\"数组\"></a>数组</h4><h4 id=\"链表\"><a href=\"#链表\" class=\"headerlink\" title=\"链表\"></a>链表</h4><h4 id=\"Hash\"><a href=\"#Hash\" class=\"headerlink\" title=\"Hash\"></a>Hash</h4><h4 id=\"树-二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\"><a href=\"#树-二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\" class=\"headerlink\" title=\"树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树\"></a>树:二叉树、完全平衡树、2-3、2-3-4、红黑树、左倾红黑树</h4><h4 id=\"图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\"><a href=\"#图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\" class=\"headerlink\" title=\"图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索\"></a>图：邻接矩阵、邻接链表、拓扑排序、广度搜索、深度搜索</h4><h2 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h2><h3 id=\"atomic\"><a href=\"#atomic\" class=\"headerlink\" title=\"atomic\"></a>atomic</h3><ul>\n<li><p>AtomicBoolean</p>\n</li>\n<li><p>AtomicInteger</p>\n</li>\n<li><p>AtomicLong</p>\n</li>\n<li><p>AtomicIntegerArray</p>\n</li>\n<li><p>AtomicLongArray</p>\n</li>\n<li><p>AtomicReferenceArray</p>\n</li>\n<li><p>AtomicIntegerFieldUpdater</p>\n</li>\n<li><p>AtomicLongFieldUpdater</p>\n</li>\n<li><p>AtomicReferenceFieldUpdater</p>\n</li>\n<li><p>AtomicMarkableReference</p>\n</li>\n<li><p>AtomicStampedReference</p>\n</li>\n<li><p>DoubleAdder  </p>\n</li>\n<li><p>LongAdder</p>\n</li>\n</ul>\n<h3 id=\"2、lock\"><a href=\"#2、lock\" class=\"headerlink\" title=\"2、lock\"></a>2、lock</h3><ul>\n<li>ReentrantLock</li>\n<li>ReentrantReadWriteLock</li>\n<li>StampedLock</li>\n</ul>\n<h3 id=\"3、queue\"><a href=\"#3、queue\" class=\"headerlink\" title=\"3、queue\"></a>3、queue</h3><h3 id=\"4、ThreadLocal\"><a href=\"#4、ThreadLocal\" class=\"headerlink\" title=\"4、ThreadLocal\"></a>4、ThreadLocal</h3><h3 id=\"5、cas\"><a href=\"#5、cas\" class=\"headerlink\" title=\"5、cas\"></a>5、cas</h3><h3 id=\"6、线程、线程池\"><a href=\"#6、线程、线程池\" class=\"headerlink\" title=\"6、线程、线程池\"></a>6、线程、线程池</h3><p>7、nio</p>\n<h3 id=\"JVM\"><a href=\"#JVM\" class=\"headerlink\" title=\"JVM\"></a>JVM</h3><ul>\n<li><p>运行时数据区域（java内存区域）</p>\n<pre><code>  1、方法区：vm加载的类信息、常量、静态变量、即时编译器编译后的代码等数据\n      1、HotSpot：永久代（利用堆特性）\n      2、Metaspace\n      \n      运行时常量池：1.7 移除到堆里面\n      JDK1.8 : Metaspace\n\n  2、heap：存放对象实例。几乎所有的对象实例以及数组都在这里分配内存。\n      1、新生代：Eden空间、From Survivor、To Survivor\n      2、老年代\n  3、vm stack：虚拟机栈为虚拟机执行Java方法服务。局部变量（基本数据类型，对象引用类型：起始引用指针、句柄）\n  4、本地方法栈：本地方法栈为虚拟机使用到的Native方法服务\n  5、程序计数器：当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完\n</code></pre>\n<ul>\n<li>直接内存: DirectByteBuffer\n  OutOfMemoryError</li>\n</ul>\n</li>\n</ul>\n<pre><code>Class加载：加载-验证-准备-解析-初始化-使用-卸载\njava对象创建:类加载检查、分配内存、初始化零值、设置对象头、执行init方法\n    1、类加载检查：参数\n    2、分配内存：\n        分配方式：\n                指针碰撞、空闲列表\n                java堆内存是否规整（由GC是否有压缩整理）\n        并发：\n            CAS重试\n            tlab： Thread Local alloctaion buffer\n    3、初始化零值：方便没有赋值直接使用\n    4、设置对象头：对象元信息、哈希码、GC分代年龄信息、运行状态（启动偏向锁）\n    5、执行init方法：\n\n对象头、实例数据、填充数据\n</code></pre>\n<p>对象访问：句柄、指针\n    对象实例数据\n    对象类型数据</p>\n<p>内存模型（JMM）：多线程变量可见性和同步</p>\n<p>GC ROOTS\n    1、虚拟机栈引用对象\n    2、本地方法栈引用对象\n    3、方法区静态变量引用对象\n    4、方法区常量引用对象</p>\n<p>GC算法：\n    1、标记-清除算法：<br>    2、复制算法：\n    3、标记-整理算法：</p>\n<p>收集器：\n    1、Serial：新生代、老年代使用串行回收。新生代复制算法、老年代标记-压缩\n        1、STW\n        2、-XX:+UseSerialGC</p>\n<pre><code>2、ParNew：新生代并行，老年代串行。新生代复制算法、老年代标记-压缩\n    1、-XX:+UseParNewGC\n    2、-XX:ParallelGCThreads\n\n2、Parallel Scavenge：新生代复制算法、老年代标记-压缩。\n    1、-XX:+UseParallelGC\n    2、\n\n3、Parallel Old ：老年代标记－整理\n    1、-XX:+UseParallelOldGC\n\n4、CMS（Concurrent Mark Sweep）：老年代标记-清除\n    1、初始标记（CMS initial mark）: 从GC ROOTS直接关联的对象, 放到 sets\n    2、并发标记（CMS concurrent mark）: GC ROOTS\n    3、重新标记（CMS remark）: \n    4、并发清除（CMS concurrent sweep）: \n\n    优点: 并发收集、低停顿\n    缺点: 产生大量空间碎片、并发阶段会降低吞吐量\n\n    -XX:+UseConcMarkSweepGC 使用CMS收集器\n    -XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长\n    -XX:+CMSFullGCsBeforeCompaction 设置进行几次Full GC后，进行一次碎片整理\n    -XX:ParallelCMSThreads 设定CMS的线程数量（一般情况约等于可用CPU数量）\n\n\n5、G1：标记-整理算法，可预测停顿\n    1、\n    2、\n    Humongous: \n        Region size: 最小 1M，最大 32M\n        &lt;=jdk1.8u40 full gc 清理\n\n6、ZGC\n    1、着色指针：指针64位的几位表示： Finalizable、Remapped、Marked1、Marked0\n    2、读屏障：在被着色，触发读屏障，等待更新指针再返回结果\n    3、内存多重映射\n    Region 的大小是会动态变化：1M、32M、n*2M(&gt;=4M)\n</code></pre>\n<p>当前线程执行字节码行号指示器。字节码解释器通过改变计数器来执行字节码</p>\n<pre><code>2、内存屏障\n3、\n4、工具\n    1、jps\n        -l -q -v -m \n    2、jinfo\n    3、jstat\n    3、jstack：\n        1、\n        2、\n    4、jmap：jmap -histo:live 28920| more\n            jmap -dump:live,format=b,file=heap.bin\n</code></pre>\n<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><pre><code>1、执行计划\n    1、\n    2、\n\n    key_len: \n        1、char n \n        2、varchar utf8 3n+2 utf8mb4 4n+2\n        3、TINYINT: 1字节\n        4、SMALLINT: 2字节\n        5、MEDIUMINT: 3字节\n        6、INT: 4字节\n        7、BIGINT: 8字节\n        8、DATE: 3字节\n        9、TIMESTAMP: 4字节\n        10、DATETIME: 8字节\n\n    force index\n    use index\n    ignore index\n2、\n    二叉树(BTS)\n    AVL\n        1、\n        2、\n    红黑树(Red-Black Tree)\n        1、\n        2、\n    B+树\n        1、添加（扩容）：\n            1、\n            2、\n        2、删除（收缩）：\n\n3、索引\n    1、hash索引\n    2、\n    3、B+树索引\n        1、聚簇索引\n        2、非聚簇索引\n\n4、锁\n    行锁：\n        1、共享锁：事物读取一行数据\n        2、排它锁：事物删除、更新一行数据\n    表锁：\n        1、意向共享锁：事物获得表中某几行共享锁\n        2、意向排它锁：事物获得表中某几行排它锁\n\n\n    记录锁（record lock）\n    间隙锁（gap lock）\n    意向插入锁（）\n    Next-Keys lock（）\n\nMVCC: \n    1、read view\n    2、\n\n5、事物\n    等级：read uncommitted、 read commit、rr、\n</code></pre>\n<h2 id=\"Spring\"><a href=\"#Spring\" class=\"headerlink\" title=\"Spring\"></a>Spring</h2><pre><code>1、生命周期\n2、AOP/IOC\n3、循环依赖\n</code></pre>\n<h3 id=\"事物\"><a href=\"#事物\" class=\"headerlink\" title=\"事物\"></a>事物</h3><h4 id=\"事物传播\"><a href=\"#事物传播\" class=\"headerlink\" title=\"事物传播\"></a>事物传播</h4><ul>\n<li><p>PROPAGATION_REQUIRED: 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。</p>\n</li>\n<li><p>PROPAGATION_SUPPORTS: 支持当前事务，如果当前没有事务，就以非事务方式执行。</p>\n</li>\n<li><p>PROPAGATION_MANDATORY: 支持当前事务，如果当前没有事务，就抛出异常。</p>\n</li>\n<li><p>PROPAGATION_REQUIRES_NEW: 新建事务，如果当前存在事务，把当前事务挂起。</p>\n</li>\n<li><p>PROPAGATION_NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</p>\n</li>\n<li><p>PROPAGATION_NEVER: 以非事务方式执行，如果当前存在事务，则抛出异常。</p>\n</li>\n<li><p>PROPAGATION_NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。</p>\n<p>  5、\n  6、</p>\n</li>\n</ul>\n<h2 id=\"SpringBoot\"><a href=\"#SpringBoot\" class=\"headerlink\" title=\"SpringBoot\"></a>SpringBoot</h2><pre><code>1、原理\n</code></pre>\n<p>SpringApplication run方法：\n1、实例化初始化：\n    - webApplicationContextType\n    - ApplicationContextInitializer\n    - ApplicationLi\n2、SpringApplicationRunListener start 周知 要开始了\n3、environment 创建和配置\n4、SpringApplicationRunListener environment 配置\n5、printBanner\n6、创建 ApplicationContext\n7、ApplicationContext 配置 environment\n8、ApplicationContextInitializer initialize\n9、SpringApplicationRunListener  contextPrepared 执行\n10、加载\n11、SpringApplicationRunListener  contextLoaded 执行\n12、ApplicationContext 执行 refresh\n13、ApplicationRunner、CommandLineRunner 执行\n14、SpringApplicationRunListener running执行\n15、</p>\n<h2 id=\"Linux：\"><a href=\"#Linux：\" class=\"headerlink\" title=\"Linux：\"></a>Linux：</h2><h3 id=\"select，poll，epoll都是IO多路复用的机制\"><a href=\"#select，poll，epoll都是IO多路复用的机制\" class=\"headerlink\" title=\"select，poll，epoll都是IO多路复用的机制\"></a>select，poll，epoll都是IO多路复用的机制</h3><h3 id=\"进程：孤儿进程与僵尸进程\"><a href=\"#进程：孤儿进程与僵尸进程\" class=\"headerlink\" title=\"进程：孤儿进程与僵尸进程\"></a>进程：孤儿进程与僵尸进程</h3><ul>\n<li>孤儿进程<ul>\n<li>一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</li>\n</ul>\n</li>\n<li>僵尸进程<ul>\n<li>一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"命令操作\"><a href=\"#命令操作\" class=\"headerlink\" title=\"命令操作\"></a>命令操作</h3><h4 id=\"1、grep\"><a href=\"#1、grep\" class=\"headerlink\" title=\"1、grep\"></a>1、grep</h4><h4 id=\"2、sed\"><a href=\"#2、sed\" class=\"headerlink\" title=\"2、sed\"></a>2、sed</h4><h4 id=\"3、awk\"><a href=\"#3、awk\" class=\"headerlink\" title=\"3、awk\"></a>3、awk</h4><h4 id=\"4、top\"><a href=\"#4、top\" class=\"headerlink\" title=\"4、top\"></a>4、top</h4><h2 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h2><h3 id=\"六大原则\"><a href=\"#六大原则\" class=\"headerlink\" title=\"六大原则\"></a>六大原则</h3><ul>\n<li>单一职责:</li>\n<li>接口隔离:</li>\n<li>里氏替换原则:</li>\n<li>依赖倒置:</li>\n<li>迪米特法则:</li>\n<li>开闭原则:</li>\n<li>合成复用:</li>\n</ul>\n<h3 id=\"三大模式\"><a href=\"#三大模式\" class=\"headerlink\" title=\"三大模式\"></a>三大模式</h3><ul>\n<li>创建模式：</li>\n<li>结构模式：</li>\n<li>行为模式：</li>\n</ul>\n<h4 id=\"创建模式\"><a href=\"#创建模式\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h4><ul>\n<li>简单工厂</li>\n<li>工厂方法</li>\n<li>抽象工厂</li>\n<li>单列</li>\n<li>原型</li>\n<li>建造者</li>\n</ul>\n<h4 id=\"结构模式\"><a href=\"#结构模式\" class=\"headerlink\" title=\"结构模式\"></a>结构模式</h4><ul>\n<li>代理</li>\n<li>适配器</li>\n<li>装饰</li>\n<li>享元</li>\n<li>外观</li>\n<li>组合</li>\n</ul>\n<h4 id=\"行为模式\"><a href=\"#行为模式\" class=\"headerlink\" title=\"行为模式\"></a>行为模式</h4><ul>\n<li>责任链</li>\n<li>模板</li>\n<li>策略</li>\n<li>访问</li>\n<li>备忘录</li>\n<li>观察者</li>\n<li>迭代器</li>\n<li>状态</li>\n<li>命令</li>\n</ul>\n<h2 id=\"Readis\"><a href=\"#Readis\" class=\"headerlink\" title=\"Readis\"></a>Readis</h2><h3 id=\"1、数据结构\"><a href=\"#1、数据结构\" class=\"headerlink\" title=\"1、数据结构\"></a>1、数据结构</h3><pre><code>    1、sds:简单动态字符串\n        结构：buf字符数组、len 长度、free长度\n        vs C：\n            1、常数级别获取字符串长度\n            2、杜绝缓冲区溢出    \n            3、减少修改字符串带来内存重分配（增加：预分配（大于30m，1m）        减少：惰性）\n            4、二进制安全\n            5、兼容部分C\n\n        \n    2、链表(linkedlist)\n        结构：head、tail、len\n\n\n    3、字典(map)：符号表（symbol table）\n        结构：数组、size、sizemask、used、next\n\n        扩容：加载因子 &gt; 1  (空闲的时候) or 加载因子 &gt; 5（繁忙的时候）\n        收缩：加载因子 &lt; 0.1\n\n    4、skiplist：有序（用在有序集合）\n        结构：\n\n\n    5、intset：整数集合\n        结构：\n        \n\n    6、ziplist：压缩列表\n        结构：\n</code></pre>\n<h3 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h3><ul>\n<li>string（字符串键）</li>\n<li>hash（哈希）</li>\n<li>list（列表键）</li>\n<li>set（集合）</li>\n<li>sortedset（）</li>\n</ul>\n<h3 id=\"持久化：RDB、AOF\"><a href=\"#持久化：RDB、AOF\" class=\"headerlink\" title=\"持久化：RDB、AOF\"></a>持久化：RDB、AOF</h3><ul>\n<li>RDB</li>\n<li>AOF</li>\n</ul>\n<h2 id=\"MQ\"><a href=\"#MQ\" class=\"headerlink\" title=\"MQ\"></a>MQ</h2><h3 id=\"kafak\"><a href=\"#kafak\" class=\"headerlink\" title=\"kafak\"></a>kafak</h3><pre><code>    1、mmp\n    2、zero copy\n    3、\n    4、\n    5、\n</code></pre>\n<h3 id=\"RocketMQ\"><a href=\"#RocketMQ\" class=\"headerlink\" title=\"RocketMQ:\"></a>RocketMQ:</h3><pre><code>1、Producer\n2、Consumer\n3、NameServer\n4、Broker\n</code></pre>\n<p>高性能</p>\n<pre><code>- Producer\n- Broker\n- Consumer\n</code></pre>\n<p>高可用</p>\n<pre><code>- Producer\n- Broke\n- Consumer\n</code></pre>\n<p>1、Topic\n2、Message\n3、Tag</p>\n<p>生产</p>\n<p>存储\n1、CommitLog\n2、</p>\n<p>消费\n1、ConsumeQueue</p>\n<h3 id=\"Rabbitmq：\"><a href=\"#Rabbitmq：\" class=\"headerlink\" title=\"Rabbitmq：\"></a>Rabbitmq：</h3><pre><code>    1、\n    2、\n</code></pre>\n<h2 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h2><pre><code>1、paxor\n    1、\n    2、\n2、raft\n    1、leader选举\n    2、日志复制\n    3、安全性\n</code></pre>\n<h2 id=\"docker：\"><a href=\"#docker：\" class=\"headerlink\" title=\"docker：\"></a>docker：</h2><pre><code>1、\n2、\n3、\n4、\n5、\n</code></pre>\n<h2 id=\"k8s\"><a href=\"#k8s\" class=\"headerlink\" title=\"k8s:\"></a>k8s:</h2><pre><code>1、\n2、\n3、    \n</code></pre>\n<p>1小时科普：量子力学\n1、量子定义来源：\n    旧量子力学：过渡量子利力学\n        普朗克：黑体辐射：能量释放、吸收是一份份不连续的不可分割的能量，这一份能量称为量子\n            黑体辐射：维恩公式-短波，瑞利公式-长波   ==&gt; 普朗克 量子\n        爱因斯旦-光量子：光电效应：频率、波长、能量\n        波尔：原子量子理论\n        德布罗意波：物质波–微观粒子均有一个波\n    现代量子力学：\n        海森堡：数学描述量子力学—矩阵力学\n        薛定谔：描述物质连续时空演化的偏微方程—薛定谔方程—波动力学（另一种数学描述量子利力学）\n        狄拉克：\n        费恩曼：路径积分</p>\n<p>发展路线：\n    一、普朗克量子论–波尔原子量子论–爱因斯坦辐射量子论–海森堡矩阵力学\n    二、普朗克量子论–爱因斯坦光量子–德布罗意波—薛定谔波动力学</p>\n<p>应用：\n    微观：原子、亚原子、分子、材料的微观领域\n    宏观：超导、超流、量子霍尔效应</p>\n<p>2、</p>\n"},{"title":"负载均衡算法","date":"2018-11-20T07:15:05.000Z","_content":"\n负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n<!-- more -->\n\n\n<br/>\n### 轮询（Round Robin）\n```java\n\n```\n\n<br/>\n### 加权轮询（Weight Round Robin）\n```java\npublic class RoundRobinLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"roundrobin\";\n\n    private final ConcurrentMap<String, AtomicPositiveInteger> sequences = new ConcurrentHashMap<String, AtomicPositiveInteger>();\n\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int length = invokers.size(); // 总个数\n        int maxWeight = 0; // 最大权重\n        int minWeight = Integer.MAX_VALUE; // 最小权重\n        final LinkedHashMap<Invoker<T>, IntegerWrapper> invokerToWeightMap = new LinkedHashMap<Invoker<T>, IntegerWrapper>();\n        int weightSum = 0;\n        for (int i = 0; i < length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            maxWeight = Math.max(maxWeight, weight); // 累计最大权重\n            minWeight = Math.min(minWeight, weight); // 累计最小权重\n            if (weight > 0) {\n                invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight));\n                weightSum += weight;\n            }\n        }\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) {\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        }\n        int currentSequence = sequence.getAndIncrement();\n        if (maxWeight > 0 && minWeight < maxWeight) { // 权重不一样\n            int mod = currentSequence % weightSum;\n            for (int i = 0; i < maxWeight; i++) {\n                for (Map.Entry<Invoker<T>, IntegerWrapper> each : invokerToWeightMap.entrySet()) {\n                    final Invoker<T> k = each.getKey();\n                    final IntegerWrapper v = each.getValue();\n                    if (mod == 0 && v.getValue() > 0) {\n                        return k;\n                    }\n                    if (v.getValue() > 0) {\n                        v.decrement();\n                        mod--;\n                    }\n                }\n            }\n        }\n        // 取模轮循\n        return invokers.get(currentSequence % length);\n    }\n\n    private static final class IntegerWrapper {\n        private int value;\n\n        public IntegerWrapper(int value) {\n            this.value = value;\n        }\n\n        public int getValue() {\n            return value;\n        }\n\n        public void setValue(int value) {\n            this.value = value;\n        }\n\n        public void decrement() {\n            this.value--;\n        }\n    }\n\n}\n```\n\n\n<br/>\n### 随机（Random）\n```java\n\n```\n\n\n<br/>\n### 加权随机（Weight Random）\n```java\npublic class RandomLoadBalance extends AbstractLoadBalance {\n\n    private final Random random = new Random();\n\n    @Override\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, Invocation invocation) {\n        int length = invokers.size(); // 总个数\n        int totalWeight = 0; // 总权重\n        boolean sameWeight = true; // 权重是否都一样\n        for (int i = 0; i < length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            totalWeight += weight; // 累计总权重\n            if (sameWeight && i > 0\n                    && weight != getWeight(invokers.get(i - 1), invocation)) {\n                sameWeight = false; // 计算所有权重是否一样\n            }\n        }\n        if (totalWeight > 0 && !sameWeight) {\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offset = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i < length; i++) {\n                offset -= getWeight(invokers.get(i), invocation);\n                if (offset < 0) {\n                    return invokers.get(i);\n                }\n            }\n        }\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(random.nextInt(length));\n    }\n\n}\n```\n\n\n<br/>\n### 源地址哈希（Hash）\n```java\n\n```\n\n<br/>\n### 一致性哈希（ConsistentHash）\n```java\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance {\n\n    private final ConcurrentMap<String, ConsistentHashSelector<?>> selectors = new ConcurrentHashMap<String, ConsistentHashSelector<?>>();\n\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int identityHashCode = System.identityHashCode(invokers);\n        ConsistentHashSelector<T> selector = (ConsistentHashSelector<T>) selectors.get(key);\n        if (selector == null || selector.identityHashCode != identityHashCode) {\n            selectors.put(key, new ConsistentHashSelector<T>(invokers, invocation.getMethodName(), identityHashCode));\n            selector = (ConsistentHashSelector<T>) selectors.get(key);\n        }\n        return selector.select(invocation);\n    }\n\n    private static final class ConsistentHashSelector<T> {\n\n        private final TreeMap<Long, Invoker<T>> virtualInvokers;\n\n        private final int replicaNumber;\n\n        private final int identityHashCode;\n\n        private final int[] argumentIndex;\n\n        ConsistentHashSelector(List<Invoker<T>> invokers, String methodName, int identityHashCode) {\n            this.virtualInvokers = new TreeMap<Long, Invoker<T>>();\n            this.identityHashCode = identityHashCode;\n            URL url = invokers.get(0).getUrl();\n            this.replicaNumber = url.getMethodParameter(methodName, \"hash.nodes\", 160);\n            String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, \"hash.arguments\", \"0\"));\n            argumentIndex = new int[index.length];\n            for (int i = 0; i < index.length; i++) {\n                argumentIndex[i] = Integer.parseInt(index[i]);\n            }\n            for (Invoker<T> invoker : invokers) {\n                String address = invoker.getUrl().getAddress();\n                for (int i = 0; i < replicaNumber / 4; i++) {\n                    byte[] digest = md5(address + i);\n                    for (int h = 0; h < 4; h++) {\n                        long m = hash(digest, h);\n                        virtualInvokers.put(m, invoker);\n                    }\n                }\n            }\n        }\n\n        public Invoker<T> select(Invocation invocation) {\n            String key = toKey(invocation.getArguments());\n            byte[] digest = md5(key);\n            return selectForKey(hash(digest, 0));\n        }\n\n        private String toKey(Object[] args) {\n            StringBuilder buf = new StringBuilder();\n            for (int i : argumentIndex) {\n                if (i >= 0 && i < args.length) {\n                    buf.append(args[i]);\n                }\n            }\n            return buf.toString();\n        }\n\n        private Invoker<T> selectForKey(long hash) {\n            Invoker<T> invoker;\n            Long key = hash;\n            if (!virtualInvokers.containsKey(key)) {\n                SortedMap<Long, Invoker<T>> tailMap = virtualInvokers.tailMap(key);\n                if (tailMap.isEmpty()) {\n                    key = virtualInvokers.firstKey();\n                } else {\n                    key = tailMap.firstKey();\n                }\n            }\n            invoker = virtualInvokers.get(key);\n            return invoker;\n        }\n\n        private long hash(byte[] digest, int number) {\n            return (((long) (digest[3 + number * 4] & 0xFF) << 24)\n                    | ((long) (digest[2 + number * 4] & 0xFF) << 16)\n                    | ((long) (digest[1 + number * 4] & 0xFF) << 8)\n                    | (digest[number * 4] & 0xFF))\n                    & 0xFFFFFFFFL;\n        }\n\n        private byte[] md5(String value) {\n            MessageDigest md5;\n            try {\n                md5 = MessageDigest.getInstance(\"MD5\");\n            } catch (NoSuchAlgorithmException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.reset();\n            byte[] bytes;\n            try {\n                bytes = value.getBytes(\"UTF-8\");\n            } catch (UnsupportedEncodingException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.update(bytes);\n            return md5.digest();\n        }\n\n    }\n\n}\n```\n\n<br/>\n### 最小连接数（Least Connections）\n```java\npublic class LeastActiveLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"leastactive\";\n\n    private final Random random = new Random();\n\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        int length = invokers.size(); // 总个数\n        int leastActive = -1; // 最小的活跃数\n        int leastCount = 0; // 相同最小活跃数的个数\n        int[] leastIndexs = new int[length]; // 相同最小活跃数的下标\n        int totalWeight = 0; // 总权重\n        int firstWeight = 0; // 第一个权重，用于于计算是否相同\n        boolean sameWeight = true; // 是否所有权重相同\n        for (int i = 0; i < length; i++) {\n            Invoker<T> invoker = invokers.get(i);\n            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 活跃数\n            int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // 权重\n            if (leastActive == -1 || active < leastActive) { // 发现更小的活跃数，重新开始\n                leastActive = active; // 记录最小活跃数\n                leastCount = 1; // 重新统计相同最小活跃数的个数\n                leastIndexs[0] = i; // 重新记录最小活跃数下标\n                totalWeight = weight; // 重新累计总权重\n                firstWeight = weight; // 记录第一个权重\n                sameWeight = true; // 还原权重相同标识\n            } else if (active == leastActive) { // 累计相同最小的活跃数\n                leastIndexs[leastCount++] = i; // 累计相同最小活跃数下标\n                totalWeight += weight; // 累计总权重\n                // 判断所有权重是否一样\n                if (sameWeight && i > 0\n                        && weight != firstWeight) {\n                    sameWeight = false;\n                }\n            }\n        }\n        // assert(leastCount > 0)\n        if (leastCount == 1) {\n            // 如果只有一个最小则直接返回\n            return invokers.get(leastIndexs[0]);\n        }\n        if (!sameWeight && totalWeight > 0) {\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offsetWeight = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i < leastCount; i++) {\n                int leastIndex = leastIndexs[i];\n                offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n                if (offsetWeight <= 0)\n                    return invokers.get(leastIndex);\n            }\n        }\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(leastIndexs[random.nextInt(leastCount)]);\n    }\n}\n```\n\n\n\n<br/>\n<!-- ### 低并发优先（Active Weight）\n```java\n\n``` -->\n\n\n\n\n<br/>\n\n\n\n---\n参考\nwikipedia-负载均衡：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n","source":"_posts/负载均衡算法.md","raw":"---\ntitle: 负载均衡算法\ndate: 2018-11-20 15:15:05\ncategories: \n    - 负载均衡\ntags: \n    - 算法\n    - 负载均衡\n---\n\n负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。\n\n\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》\n\n---\n<!-- more -->\n\n\n<br/>\n### 轮询（Round Robin）\n```java\n\n```\n\n<br/>\n### 加权轮询（Weight Round Robin）\n```java\npublic class RoundRobinLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"roundrobin\";\n\n    private final ConcurrentMap<String, AtomicPositiveInteger> sequences = new ConcurrentHashMap<String, AtomicPositiveInteger>();\n\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int length = invokers.size(); // 总个数\n        int maxWeight = 0; // 最大权重\n        int minWeight = Integer.MAX_VALUE; // 最小权重\n        final LinkedHashMap<Invoker<T>, IntegerWrapper> invokerToWeightMap = new LinkedHashMap<Invoker<T>, IntegerWrapper>();\n        int weightSum = 0;\n        for (int i = 0; i < length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            maxWeight = Math.max(maxWeight, weight); // 累计最大权重\n            minWeight = Math.min(minWeight, weight); // 累计最小权重\n            if (weight > 0) {\n                invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight));\n                weightSum += weight;\n            }\n        }\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) {\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        }\n        int currentSequence = sequence.getAndIncrement();\n        if (maxWeight > 0 && minWeight < maxWeight) { // 权重不一样\n            int mod = currentSequence % weightSum;\n            for (int i = 0; i < maxWeight; i++) {\n                for (Map.Entry<Invoker<T>, IntegerWrapper> each : invokerToWeightMap.entrySet()) {\n                    final Invoker<T> k = each.getKey();\n                    final IntegerWrapper v = each.getValue();\n                    if (mod == 0 && v.getValue() > 0) {\n                        return k;\n                    }\n                    if (v.getValue() > 0) {\n                        v.decrement();\n                        mod--;\n                    }\n                }\n            }\n        }\n        // 取模轮循\n        return invokers.get(currentSequence % length);\n    }\n\n    private static final class IntegerWrapper {\n        private int value;\n\n        public IntegerWrapper(int value) {\n            this.value = value;\n        }\n\n        public int getValue() {\n            return value;\n        }\n\n        public void setValue(int value) {\n            this.value = value;\n        }\n\n        public void decrement() {\n            this.value--;\n        }\n    }\n\n}\n```\n\n\n<br/>\n### 随机（Random）\n```java\n\n```\n\n\n<br/>\n### 加权随机（Weight Random）\n```java\npublic class RandomLoadBalance extends AbstractLoadBalance {\n\n    private final Random random = new Random();\n\n    @Override\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, Invocation invocation) {\n        int length = invokers.size(); // 总个数\n        int totalWeight = 0; // 总权重\n        boolean sameWeight = true; // 权重是否都一样\n        for (int i = 0; i < length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            totalWeight += weight; // 累计总权重\n            if (sameWeight && i > 0\n                    && weight != getWeight(invokers.get(i - 1), invocation)) {\n                sameWeight = false; // 计算所有权重是否一样\n            }\n        }\n        if (totalWeight > 0 && !sameWeight) {\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offset = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i < length; i++) {\n                offset -= getWeight(invokers.get(i), invocation);\n                if (offset < 0) {\n                    return invokers.get(i);\n                }\n            }\n        }\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(random.nextInt(length));\n    }\n\n}\n```\n\n\n<br/>\n### 源地址哈希（Hash）\n```java\n\n```\n\n<br/>\n### 一致性哈希（ConsistentHash）\n```java\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance {\n\n    private final ConcurrentMap<String, ConsistentHashSelector<?>> selectors = new ConcurrentHashMap<String, ConsistentHashSelector<?>>();\n\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int identityHashCode = System.identityHashCode(invokers);\n        ConsistentHashSelector<T> selector = (ConsistentHashSelector<T>) selectors.get(key);\n        if (selector == null || selector.identityHashCode != identityHashCode) {\n            selectors.put(key, new ConsistentHashSelector<T>(invokers, invocation.getMethodName(), identityHashCode));\n            selector = (ConsistentHashSelector<T>) selectors.get(key);\n        }\n        return selector.select(invocation);\n    }\n\n    private static final class ConsistentHashSelector<T> {\n\n        private final TreeMap<Long, Invoker<T>> virtualInvokers;\n\n        private final int replicaNumber;\n\n        private final int identityHashCode;\n\n        private final int[] argumentIndex;\n\n        ConsistentHashSelector(List<Invoker<T>> invokers, String methodName, int identityHashCode) {\n            this.virtualInvokers = new TreeMap<Long, Invoker<T>>();\n            this.identityHashCode = identityHashCode;\n            URL url = invokers.get(0).getUrl();\n            this.replicaNumber = url.getMethodParameter(methodName, \"hash.nodes\", 160);\n            String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, \"hash.arguments\", \"0\"));\n            argumentIndex = new int[index.length];\n            for (int i = 0; i < index.length; i++) {\n                argumentIndex[i] = Integer.parseInt(index[i]);\n            }\n            for (Invoker<T> invoker : invokers) {\n                String address = invoker.getUrl().getAddress();\n                for (int i = 0; i < replicaNumber / 4; i++) {\n                    byte[] digest = md5(address + i);\n                    for (int h = 0; h < 4; h++) {\n                        long m = hash(digest, h);\n                        virtualInvokers.put(m, invoker);\n                    }\n                }\n            }\n        }\n\n        public Invoker<T> select(Invocation invocation) {\n            String key = toKey(invocation.getArguments());\n            byte[] digest = md5(key);\n            return selectForKey(hash(digest, 0));\n        }\n\n        private String toKey(Object[] args) {\n            StringBuilder buf = new StringBuilder();\n            for (int i : argumentIndex) {\n                if (i >= 0 && i < args.length) {\n                    buf.append(args[i]);\n                }\n            }\n            return buf.toString();\n        }\n\n        private Invoker<T> selectForKey(long hash) {\n            Invoker<T> invoker;\n            Long key = hash;\n            if (!virtualInvokers.containsKey(key)) {\n                SortedMap<Long, Invoker<T>> tailMap = virtualInvokers.tailMap(key);\n                if (tailMap.isEmpty()) {\n                    key = virtualInvokers.firstKey();\n                } else {\n                    key = tailMap.firstKey();\n                }\n            }\n            invoker = virtualInvokers.get(key);\n            return invoker;\n        }\n\n        private long hash(byte[] digest, int number) {\n            return (((long) (digest[3 + number * 4] & 0xFF) << 24)\n                    | ((long) (digest[2 + number * 4] & 0xFF) << 16)\n                    | ((long) (digest[1 + number * 4] & 0xFF) << 8)\n                    | (digest[number * 4] & 0xFF))\n                    & 0xFFFFFFFFL;\n        }\n\n        private byte[] md5(String value) {\n            MessageDigest md5;\n            try {\n                md5 = MessageDigest.getInstance(\"MD5\");\n            } catch (NoSuchAlgorithmException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.reset();\n            byte[] bytes;\n            try {\n                bytes = value.getBytes(\"UTF-8\");\n            } catch (UnsupportedEncodingException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.update(bytes);\n            return md5.digest();\n        }\n\n    }\n\n}\n```\n\n<br/>\n### 最小连接数（Least Connections）\n```java\npublic class LeastActiveLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"leastactive\";\n\n    private final Random random = new Random();\n\n    protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        int length = invokers.size(); // 总个数\n        int leastActive = -1; // 最小的活跃数\n        int leastCount = 0; // 相同最小活跃数的个数\n        int[] leastIndexs = new int[length]; // 相同最小活跃数的下标\n        int totalWeight = 0; // 总权重\n        int firstWeight = 0; // 第一个权重，用于于计算是否相同\n        boolean sameWeight = true; // 是否所有权重相同\n        for (int i = 0; i < length; i++) {\n            Invoker<T> invoker = invokers.get(i);\n            int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 活跃数\n            int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // 权重\n            if (leastActive == -1 || active < leastActive) { // 发现更小的活跃数，重新开始\n                leastActive = active; // 记录最小活跃数\n                leastCount = 1; // 重新统计相同最小活跃数的个数\n                leastIndexs[0] = i; // 重新记录最小活跃数下标\n                totalWeight = weight; // 重新累计总权重\n                firstWeight = weight; // 记录第一个权重\n                sameWeight = true; // 还原权重相同标识\n            } else if (active == leastActive) { // 累计相同最小的活跃数\n                leastIndexs[leastCount++] = i; // 累计相同最小活跃数下标\n                totalWeight += weight; // 累计总权重\n                // 判断所有权重是否一样\n                if (sameWeight && i > 0\n                        && weight != firstWeight) {\n                    sameWeight = false;\n                }\n            }\n        }\n        // assert(leastCount > 0)\n        if (leastCount == 1) {\n            // 如果只有一个最小则直接返回\n            return invokers.get(leastIndexs[0]);\n        }\n        if (!sameWeight && totalWeight > 0) {\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offsetWeight = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i < leastCount; i++) {\n                int leastIndex = leastIndexs[i];\n                offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n                if (offsetWeight <= 0)\n                    return invokers.get(leastIndex);\n            }\n        }\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(leastIndexs[random.nextInt(leastCount)]);\n    }\n}\n```\n\n\n\n<br/>\n<!-- ### 低并发优先（Active Weight）\n```java\n\n``` -->\n\n\n\n\n<br/>\n\n\n\n---\n参考\nwikipedia-负载均衡：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n","slug":"负载均衡算法","published":1,"updated":"2021-06-30T02:33:24.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckr8tjsy700bvr5p75zgbbm5q","content":"<p>负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>\n<span id=\"more\"></span>\n\n\n<br>\n### 轮询（Round Robin）\n```java\n\n<pre><code>\n&lt;br/&gt;\n### 加权轮询（Weight Round Robin）\n```java\npublic class RoundRobinLoadBalance extends AbstractLoadBalance {\n\n    public static final String NAME = \"roundrobin\";\n\n    private final ConcurrentMap&lt;String, AtomicPositiveInteger&gt; sequences = new ConcurrentHashMap&lt;String, AtomicPositiveInteger&gt;();\n\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int length = invokers.size(); // 总个数\n        int maxWeight = 0; // 最大权重\n        int minWeight = Integer.MAX_VALUE; // 最小权重\n        final LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; invokerToWeightMap = new LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt;();\n        int weightSum = 0;\n        for (int i = 0; i &lt; length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            maxWeight = Math.max(maxWeight, weight); // 累计最大权重\n            minWeight = Math.min(minWeight, weight); // 累计最小权重\n            if (weight &gt; 0) {\n                invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight));\n                weightSum += weight;\n            }\n        }\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) {\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        }\n        int currentSequence = sequence.getAndIncrement();\n        if (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) { // 权重不一样\n            int mod = currentSequence % weightSum;\n            for (int i = 0; i &lt; maxWeight; i++) {\n                for (Map.Entry&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; each : invokerToWeightMap.entrySet()) {\n                    final Invoker&lt;T&gt; k = each.getKey();\n                    final IntegerWrapper v = each.getValue();\n                    if (mod == 0 &amp;&amp; v.getValue() &gt; 0) {\n                        return k;\n                    }\n                    if (v.getValue() &gt; 0) {\n                        v.decrement();\n                        mod--;\n                    }\n                }\n            }\n        }\n        // 取模轮循\n        return invokers.get(currentSequence % length);\n    }\n\n    private static final class IntegerWrapper {\n        private int value;\n\n        public IntegerWrapper(int value) {\n            this.value = value;\n        }\n\n        public int getValue() {\n            return value;\n        }\n\n        public void setValue(int value) {\n            this.value = value;\n        }\n\n        public void decrement() {\n            this.value--;\n        }\n    }\n\n}\n</code></pre>\n<br>\n### 随机（Random）\n```java\n\n<pre><code>\n\n&lt;br/&gt;\n### 加权随机（Weight Random）\n```java\npublic class RandomLoadBalance extends AbstractLoadBalance {\n\n    private final Random random = new Random();\n\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, Invocation invocation) {\n        int length = invokers.size(); // 总个数\n        int totalWeight = 0; // 总权重\n        boolean sameWeight = true; // 权重是否都一样\n        for (int i = 0; i &lt; length; i++) {\n            int weight = getWeight(invokers.get(i), invocation);\n            totalWeight += weight; // 累计总权重\n            if (sameWeight &amp;&amp; i &gt; 0\n                    &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) {\n                sameWeight = false; // 计算所有权重是否一样\n            }\n        }\n        if (totalWeight &gt; 0 &amp;&amp; !sameWeight) {\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offset = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i &lt; length; i++) {\n                offset -= getWeight(invokers.get(i), invocation);\n                if (offset &lt; 0) {\n                    return invokers.get(i);\n                }\n            }\n        }\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(random.nextInt(length));\n    }\n\n}\n</code></pre>\n<br>\n### 源地址哈希（Hash）\n```java\n\n<pre><code>\n&lt;br/&gt;\n### 一致性哈希（ConsistentHash）\n```java\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance {\n\n    private final ConcurrentMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt; selectors = new ConcurrentHashMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt;();\n\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {\n        String key = invokers.get(0).getUrl().getServiceKey() + \".\" + invocation.getMethodName();\n        int identityHashCode = System.identityHashCode(invokers);\n        ConsistentHashSelector&lt;T&gt; selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key);\n        if (selector == null || selector.identityHashCode != identityHashCode) {\n            selectors.put(key, new ConsistentHashSelector&lt;T&gt;(invokers, invocation.getMethodName(), identityHashCode));\n            selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key);\n        }\n        return selector.select(invocation);\n    }\n\n    private static final class ConsistentHashSelector&lt;T&gt; {\n\n        private final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers;\n\n        private final int replicaNumber;\n\n        private final int identityHashCode;\n\n        private final int[] argumentIndex;\n\n        ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) {\n            this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;();\n            this.identityHashCode = identityHashCode;\n            URL url = invokers.get(0).getUrl();\n            this.replicaNumber = url.getMethodParameter(methodName, \"hash.nodes\", 160);\n            String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, \"hash.arguments\", \"0\"));\n            argumentIndex = new int[index.length];\n            for (int i = 0; i &lt; index.length; i++) {\n                argumentIndex[i] = Integer.parseInt(index[i]);\n            }\n            for (Invoker&lt;T&gt; invoker : invokers) {\n                String address = invoker.getUrl().getAddress();\n                for (int i = 0; i &lt; replicaNumber / 4; i++) {\n                    byte[] digest = md5(address + i);\n                    for (int h = 0; h &lt; 4; h++) {\n                        long m = hash(digest, h);\n                        virtualInvokers.put(m, invoker);\n                    }\n                }\n            }\n        }\n\n        public Invoker&lt;T&gt; select(Invocation invocation) {\n            String key = toKey(invocation.getArguments());\n            byte[] digest = md5(key);\n            return selectForKey(hash(digest, 0));\n        }\n\n        private String toKey(Object[] args) {\n            StringBuilder buf = new StringBuilder();\n            for (int i : argumentIndex) {\n                if (i &gt;= 0 &amp;&amp; i &lt; args.length) {\n                    buf.append(args[i]);\n                }\n            }\n            return buf.toString();\n        }\n\n        private Invoker&lt;T&gt; selectForKey(long hash) {\n            Invoker&lt;T&gt; invoker;\n            Long key = hash;\n            if (!virtualInvokers.containsKey(key)) {\n                SortedMap&lt;Long, Invoker&lt;T&gt;&gt; tailMap = virtualInvokers.tailMap(key);\n                if (tailMap.isEmpty()) {\n                    key = virtualInvokers.firstKey();\n                } else {\n                    key = tailMap.firstKey();\n                }\n            }\n            invoker = virtualInvokers.get(key);\n            return invoker;\n        }\n\n        private long hash(byte[] digest, int number) {\n            return (((long) (digest[3 + number * 4] &amp; 0xFF) &lt;&lt; 24)\n                    | ((long) (digest[2 + number * 4] &amp; 0xFF) &lt;&lt; 16)\n                    | ((long) (digest[1 + number * 4] &amp; 0xFF) &lt;&lt; 8)\n                    | (digest[number * 4] &amp; 0xFF))\n                    &amp; 0xFFFFFFFFL;\n        }\n\n        private byte[] md5(String value) {\n            MessageDigest md5;\n            try {\n                md5 = MessageDigest.getInstance(\"MD5\");\n            } catch (NoSuchAlgorithmException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.reset();\n            byte[] bytes;\n            try {\n                bytes = value.getBytes(\"UTF-8\");\n            } catch (UnsupportedEncodingException e) {\n                throw new IllegalStateException(e.getMessage(), e);\n            }\n            md5.update(bytes);\n            return md5.digest();\n        }\n\n    }\n\n}\n</code></pre>\n<br>\n### 最小连接数（Least Connections）\n```java\npublic class LeastActiveLoadBalance extends AbstractLoadBalance {\n\n<pre><code>public static final String NAME = \"leastactive\";\n\nprivate final Random random = new Random();\n\nprotected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) {\n    int length = invokers.size(); // 总个数\n    int leastActive = -1; // 最小的活跃数\n    int leastCount = 0; // 相同最小活跃数的个数\n    int[] leastIndexs = new int[length]; // 相同最小活跃数的下标\n    int totalWeight = 0; // 总权重\n    int firstWeight = 0; // 第一个权重，用于于计算是否相同\n    boolean sameWeight = true; // 是否所有权重相同\n    for (int i = 0; i &lt; length; i++) {\n        Invoker&lt;T&gt; invoker = invokers.get(i);\n        int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 活跃数\n        int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // 权重\n        if (leastActive == -1 || active &lt; leastActive) { // 发现更小的活跃数，重新开始\n            leastActive = active; // 记录最小活跃数\n            leastCount = 1; // 重新统计相同最小活跃数的个数\n            leastIndexs[0] = i; // 重新记录最小活跃数下标\n            totalWeight = weight; // 重新累计总权重\n            firstWeight = weight; // 记录第一个权重\n            sameWeight = true; // 还原权重相同标识\n        } else if (active == leastActive) { // 累计相同最小的活跃数\n            leastIndexs[leastCount++] = i; // 累计相同最小活跃数下标\n            totalWeight += weight; // 累计总权重\n            // 判断所有权重是否一样\n            if (sameWeight &amp;&amp; i &gt; 0\n                    &amp;&amp; weight != firstWeight) {\n                sameWeight = false;\n            }\n        }\n    }\n    // assert(leastCount &gt; 0)\n    if (leastCount == 1) {\n        // 如果只有一个最小则直接返回\n        return invokers.get(leastIndexs[0]);\n    }\n    if (!sameWeight &amp;&amp; totalWeight &gt; 0) {\n        // 如果权重不相同且权重大于0则按总权重数随机\n        int offsetWeight = random.nextInt(totalWeight);\n        // 并确定随机值落在哪个片断上\n        for (int i = 0; i &lt; leastCount; i++) {\n            int leastIndex = leastIndexs[i];\n            offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n            if (offsetWeight &lt;= 0)\n                return invokers.get(leastIndex);\n        }\n    }\n    // 如果权重相同或权重为0则均等随机\n    return invokers.get(leastIndexs[random.nextInt(leastCount)]);\n}\n</code></pre>\n<p>}</p>\n<pre><code>\n\n\n&lt;br/&gt;\n&lt;!-- ### 低并发优先（Active Weight）\n```java\n\n``` --&gt;\n\n\n\n\n&lt;br/&gt;\n\n\n\n---\n参考\nwikipedia-负载均衡：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。</p>\n<p>　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　———摘自《维基百科》</p>\n<hr>","more":"<br/>\n### 轮询（Round Robin）\n```java\n\n<pre><code>\n&lt;br/&gt;\n### 加权轮询（Weight Round Robin）\n```java\npublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123;\n\n    public static final String NAME = &quot;roundrobin&quot;;\n\n    private final ConcurrentMap&lt;String, AtomicPositiveInteger&gt; sequences = new ConcurrentHashMap&lt;String, AtomicPositiveInteger&gt;();\n\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123;\n        String key = invokers.get(0).getUrl().getServiceKey() + &quot;.&quot; + invocation.getMethodName();\n        int length = invokers.size(); // 总个数\n        int maxWeight = 0; // 最大权重\n        int minWeight = Integer.MAX_VALUE; // 最小权重\n        final LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; invokerToWeightMap = new LinkedHashMap&lt;Invoker&lt;T&gt;, IntegerWrapper&gt;();\n        int weightSum = 0;\n        for (int i = 0; i &lt; length; i++) &#123;\n            int weight = getWeight(invokers.get(i), invocation);\n            maxWeight = Math.max(maxWeight, weight); // 累计最大权重\n            minWeight = Math.min(minWeight, weight); // 累计最小权重\n            if (weight &gt; 0) &#123;\n                invokerToWeightMap.put(invokers.get(i), new IntegerWrapper(weight));\n                weightSum += weight;\n            &#125;\n        &#125;\n        AtomicPositiveInteger sequence = sequences.get(key);\n        if (sequence == null) &#123;\n            sequences.putIfAbsent(key, new AtomicPositiveInteger());\n            sequence = sequences.get(key);\n        &#125;\n        int currentSequence = sequence.getAndIncrement();\n        if (maxWeight &gt; 0 &amp;&amp; minWeight &lt; maxWeight) &#123; // 权重不一样\n            int mod = currentSequence % weightSum;\n            for (int i = 0; i &lt; maxWeight; i++) &#123;\n                for (Map.Entry&lt;Invoker&lt;T&gt;, IntegerWrapper&gt; each : invokerToWeightMap.entrySet()) &#123;\n                    final Invoker&lt;T&gt; k = each.getKey();\n                    final IntegerWrapper v = each.getValue();\n                    if (mod == 0 &amp;&amp; v.getValue() &gt; 0) &#123;\n                        return k;\n                    &#125;\n                    if (v.getValue() &gt; 0) &#123;\n                        v.decrement();\n                        mod--;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n        // 取模轮循\n        return invokers.get(currentSequence % length);\n    &#125;\n\n    private static final class IntegerWrapper &#123;\n        private int value;\n\n        public IntegerWrapper(int value) &#123;\n            this.value = value;\n        &#125;\n\n        public int getValue() &#123;\n            return value;\n        &#125;\n\n        public void setValue(int value) &#123;\n            this.value = value;\n        &#125;\n\n        public void decrement() &#123;\n            this.value--;\n        &#125;\n    &#125;\n\n&#125;\n</code></pre>\n<br/>\n### 随机（Random）\n```java\n\n<pre><code>\n\n&lt;br/&gt;\n### 加权随机（Weight Random）\n```java\npublic class RandomLoadBalance extends AbstractLoadBalance &#123;\n\n    private final Random random = new Random();\n\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, Invocation invocation) &#123;\n        int length = invokers.size(); // 总个数\n        int totalWeight = 0; // 总权重\n        boolean sameWeight = true; // 权重是否都一样\n        for (int i = 0; i &lt; length; i++) &#123;\n            int weight = getWeight(invokers.get(i), invocation);\n            totalWeight += weight; // 累计总权重\n            if (sameWeight &amp;&amp; i &gt; 0\n                    &amp;&amp; weight != getWeight(invokers.get(i - 1), invocation)) &#123;\n                sameWeight = false; // 计算所有权重是否一样\n            &#125;\n        &#125;\n        if (totalWeight &gt; 0 &amp;&amp; !sameWeight) &#123;\n            // 如果权重不相同且权重大于0则按总权重数随机\n            int offset = random.nextInt(totalWeight);\n            // 并确定随机值落在哪个片断上\n            for (int i = 0; i &lt; length; i++) &#123;\n                offset -= getWeight(invokers.get(i), invocation);\n                if (offset &lt; 0) &#123;\n                    return invokers.get(i);\n                &#125;\n            &#125;\n        &#125;\n        // 如果权重相同或权重为0则均等随机\n        return invokers.get(random.nextInt(length));\n    &#125;\n\n&#125;\n</code></pre>\n<br/>\n### 源地址哈希（Hash）\n```java\n\n<pre><code>\n&lt;br/&gt;\n### 一致性哈希（ConsistentHash）\n```java\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance &#123;\n\n    private final ConcurrentMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt; selectors = new ConcurrentHashMap&lt;String, ConsistentHashSelector&lt;?&gt;&gt;();\n\n    @SuppressWarnings(&quot;unchecked&quot;)\n    @Override\n    protected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123;\n        String key = invokers.get(0).getUrl().getServiceKey() + &quot;.&quot; + invocation.getMethodName();\n        int identityHashCode = System.identityHashCode(invokers);\n        ConsistentHashSelector&lt;T&gt; selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key);\n        if (selector == null || selector.identityHashCode != identityHashCode) &#123;\n            selectors.put(key, new ConsistentHashSelector&lt;T&gt;(invokers, invocation.getMethodName(), identityHashCode));\n            selector = (ConsistentHashSelector&lt;T&gt;) selectors.get(key);\n        &#125;\n        return selector.select(invocation);\n    &#125;\n\n    private static final class ConsistentHashSelector&lt;T&gt; &#123;\n\n        private final TreeMap&lt;Long, Invoker&lt;T&gt;&gt; virtualInvokers;\n\n        private final int replicaNumber;\n\n        private final int identityHashCode;\n\n        private final int[] argumentIndex;\n\n        ConsistentHashSelector(List&lt;Invoker&lt;T&gt;&gt; invokers, String methodName, int identityHashCode) &#123;\n            this.virtualInvokers = new TreeMap&lt;Long, Invoker&lt;T&gt;&gt;();\n            this.identityHashCode = identityHashCode;\n            URL url = invokers.get(0).getUrl();\n            this.replicaNumber = url.getMethodParameter(methodName, &quot;hash.nodes&quot;, 160);\n            String[] index = Constants.COMMA_SPLIT_PATTERN.split(url.getMethodParameter(methodName, &quot;hash.arguments&quot;, &quot;0&quot;));\n            argumentIndex = new int[index.length];\n            for (int i = 0; i &lt; index.length; i++) &#123;\n                argumentIndex[i] = Integer.parseInt(index[i]);\n            &#125;\n            for (Invoker&lt;T&gt; invoker : invokers) &#123;\n                String address = invoker.getUrl().getAddress();\n                for (int i = 0; i &lt; replicaNumber / 4; i++) &#123;\n                    byte[] digest = md5(address + i);\n                    for (int h = 0; h &lt; 4; h++) &#123;\n                        long m = hash(digest, h);\n                        virtualInvokers.put(m, invoker);\n                    &#125;\n                &#125;\n            &#125;\n        &#125;\n\n        public Invoker&lt;T&gt; select(Invocation invocation) &#123;\n            String key = toKey(invocation.getArguments());\n            byte[] digest = md5(key);\n            return selectForKey(hash(digest, 0));\n        &#125;\n\n        private String toKey(Object[] args) &#123;\n            StringBuilder buf = new StringBuilder();\n            for (int i : argumentIndex) &#123;\n                if (i &gt;= 0 &amp;&amp; i &lt; args.length) &#123;\n                    buf.append(args[i]);\n                &#125;\n            &#125;\n            return buf.toString();\n        &#125;\n\n        private Invoker&lt;T&gt; selectForKey(long hash) &#123;\n            Invoker&lt;T&gt; invoker;\n            Long key = hash;\n            if (!virtualInvokers.containsKey(key)) &#123;\n                SortedMap&lt;Long, Invoker&lt;T&gt;&gt; tailMap = virtualInvokers.tailMap(key);\n                if (tailMap.isEmpty()) &#123;\n                    key = virtualInvokers.firstKey();\n                &#125; else &#123;\n                    key = tailMap.firstKey();\n                &#125;\n            &#125;\n            invoker = virtualInvokers.get(key);\n            return invoker;\n        &#125;\n\n        private long hash(byte[] digest, int number) &#123;\n            return (((long) (digest[3 + number * 4] &amp; 0xFF) &lt;&lt; 24)\n                    | ((long) (digest[2 + number * 4] &amp; 0xFF) &lt;&lt; 16)\n                    | ((long) (digest[1 + number * 4] &amp; 0xFF) &lt;&lt; 8)\n                    | (digest[number * 4] &amp; 0xFF))\n                    &amp; 0xFFFFFFFFL;\n        &#125;\n\n        private byte[] md5(String value) &#123;\n            MessageDigest md5;\n            try &#123;\n                md5 = MessageDigest.getInstance(&quot;MD5&quot;);\n            &#125; catch (NoSuchAlgorithmException e) &#123;\n                throw new IllegalStateException(e.getMessage(), e);\n            &#125;\n            md5.reset();\n            byte[] bytes;\n            try &#123;\n                bytes = value.getBytes(&quot;UTF-8&quot;);\n            &#125; catch (UnsupportedEncodingException e) &#123;\n                throw new IllegalStateException(e.getMessage(), e);\n            &#125;\n            md5.update(bytes);\n            return md5.digest();\n        &#125;\n\n    &#125;\n\n&#125;\n</code></pre>\n<br/>\n### 最小连接数（Least Connections）\n```java\npublic class LeastActiveLoadBalance extends AbstractLoadBalance {\n\n<pre><code>public static final String NAME = &quot;leastactive&quot;;\n\nprivate final Random random = new Random();\n\nprotected &lt;T&gt; Invoker&lt;T&gt; doSelect(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) &#123;\n    int length = invokers.size(); // 总个数\n    int leastActive = -1; // 最小的活跃数\n    int leastCount = 0; // 相同最小活跃数的个数\n    int[] leastIndexs = new int[length]; // 相同最小活跃数的下标\n    int totalWeight = 0; // 总权重\n    int firstWeight = 0; // 第一个权重，用于于计算是否相同\n    boolean sameWeight = true; // 是否所有权重相同\n    for (int i = 0; i &lt; length; i++) &#123;\n        Invoker&lt;T&gt; invoker = invokers.get(i);\n        int active = RpcStatus.getStatus(invoker.getUrl(), invocation.getMethodName()).getActive(); // 活跃数\n        int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT); // 权重\n        if (leastActive == -1 || active &lt; leastActive) &#123; // 发现更小的活跃数，重新开始\n            leastActive = active; // 记录最小活跃数\n            leastCount = 1; // 重新统计相同最小活跃数的个数\n            leastIndexs[0] = i; // 重新记录最小活跃数下标\n            totalWeight = weight; // 重新累计总权重\n            firstWeight = weight; // 记录第一个权重\n            sameWeight = true; // 还原权重相同标识\n        &#125; else if (active == leastActive) &#123; // 累计相同最小的活跃数\n            leastIndexs[leastCount++] = i; // 累计相同最小活跃数下标\n            totalWeight += weight; // 累计总权重\n            // 判断所有权重是否一样\n            if (sameWeight &amp;&amp; i &gt; 0\n                    &amp;&amp; weight != firstWeight) &#123;\n                sameWeight = false;\n            &#125;\n        &#125;\n    &#125;\n    // assert(leastCount &gt; 0)\n    if (leastCount == 1) &#123;\n        // 如果只有一个最小则直接返回\n        return invokers.get(leastIndexs[0]);\n    &#125;\n    if (!sameWeight &amp;&amp; totalWeight &gt; 0) &#123;\n        // 如果权重不相同且权重大于0则按总权重数随机\n        int offsetWeight = random.nextInt(totalWeight);\n        // 并确定随机值落在哪个片断上\n        for (int i = 0; i &lt; leastCount; i++) &#123;\n            int leastIndex = leastIndexs[i];\n            offsetWeight -= getWeight(invokers.get(leastIndex), invocation);\n            if (offsetWeight &lt;= 0)\n                return invokers.get(leastIndex);\n        &#125;\n    &#125;\n    // 如果权重相同或权重为0则均等随机\n    return invokers.get(leastIndexs[random.nextInt(leastCount)]);\n&#125;\n</code></pre>\n<p>}</p>\n<pre><code>\n\n\n&lt;br/&gt;\n&lt;!-- ### 低并发优先（Active Weight）\n```java\n\n``` --&gt;\n\n\n\n\n&lt;br/&gt;\n\n\n\n---\n参考\nwikipedia-负载均衡：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n</code></pre>"},{"title":"Git 分布式版本控制系统","date":"2014-08-07T09:34:41.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要: 学习`Git`, 从概念、发展脉络、安装、基本使用、分支模型、服务器端配置&使用、分布式工作流、高级命令以及实现细节等\n\n\n## 基础认识\n\n### 版本控制\n一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统\n\n#### 发展脉络\n##### `本地版本控制系统`\n补丁方式，重新计算各个版本文件内容。\n- `优势`：简单\n- `缺点`：单点故障\n    \n##### `集中化的版本控制`\n客服端存储项目最新快照（协同工作）\n- `优势`：可以看到项目中的其他人正在做什么。\n- `缺点`：服务器单点故障\n\n##### `分布式版本控制系统`\n客户端存储项目完整镜像（包括完整历史记录、）（可以定制协作流程）  \n- `优势`：无单点故障 \n- `缺点`：\n\n### Git\n一个分布式控制系统。最开始基于存储Linux项目版本控制\n\n#### Git发展脉络\n- 1991~2002: 手动保存归档\n- 2002~2005：使用`BitKeeper`来管理和维护代码（后面与`BitKeeper`公司产生冲突，不准Linux使用BitKeeper）\n- 2005~：`Linus Torvalds`开发Git代替`BitKeeper`\n\n#### Git设计目标\n- 速度\n- 简单\n- 对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n- 完全分布式\n- 管理大规模项目（类似 Linux 内核一样的超大规模项目（速度和数据量）)\n\n#### Git优势&区别\n- `数据存储结构`: `直接记录快照，而非差异比较`. 对当时的提交更新的文件创建一个快照并保存这个快照的索引；文件没有修改,只保留一个链接指向之前存储的文件\n- `数据提交速度`：`近乎所有操作都是本地执行`\n- `数据提交传输完整性`：所有的数据在存储前都计算校验和，然后以校验和来引用。校验和：`SHA-1`算法, 40个十六进制字符（0-9 和 a-f）组成的字符串，基于 `Git` 中文件的`内容`或`目录结构`计算出来\n- `持久化不会丢失`：`Git`几乎不会执行任何可能导致文件不可恢复的操作。一般只添加数据，很难从Git删除数据\n\n#### Git状态\n- `已提交(committed)`：数据已经安全地保存在本地数据库中\n- `已修改(modified)`：修改了文件，但还没保存到数据库中\n- `已暂存(staged)`：对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中\n\n#### Git三个阶段\n- `工作区`: 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n- `暂存区`: `暂存区`是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫`暂存区`\n- `Git 仓库目录`: 是 `Git` 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。\n\n![Git工作流程](areas.png)\n**工作流程：**\n- 在工作区中修改文件\n- 将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。\n- 提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。\n\n## Git安装\n> macOS 环境\n- 安装`Git`\n```bash\nbrew install git\n```\n- 安装`Git可视化界面`\n```bash\nbrew install git-gui\n```\n\n## Git配置\n```bash\ngit config --global user.name \"John Doe\"\ngit config --global user.email johndoe@example.com\n```\n\n---\n\n## Git命令使用\n### 配置&管理\n- 查看Git当前所有配置\n```bash\ngit config --list\n```\n\n- 查看Git指定变量配置\n```bash\ngit config user.name\n```\n\n- 获取帮助命令\n```bash\ngit help <verb>\ngit <verb> --help\nman git-<verb>\n```\n如：获取`git config`命令手册\n```bash\ngit help config\n```\n\n### 获取仓库\n- 将尚未进行版本控制的本地目录转换为`Git 仓库`\n```bash\ngit init\n```\n- 克隆 一个已存在的`Git 仓库`\n```bash\ngit clone https://github.com/xxx\n```\n\n### 本地文件操作\n- 查看当前文件状态\n```bash\ngit status\n```\n\n- 将内容添加到下一次提交中\n```bash\ngit add .\n```\n\n- 提交文件, 产生一次提交记录\n```bash\ngit commit -m 'xx'\n```\n\n- 提交文件，向前面提交记录追加文件\n```bash\ngit commit --amend\n```\n\n- 删除跟踪，但是保留文件\n```bash\ngit rm --cached README\n```\n\n- 查看提交历史\n```bash\ngit log\n```\n\n- 查看每次提交的简略统计信息\n```bash\ngit log --stat\n```\n| 选项\t| 说明\n|:----:|:---:|\n| -p | 按补丁格式显示每个提交引入的差异。\n| --stat | 显示每次提交的文件修改统计信息。\n| --shortstat | 只显示 --stat 中最后的行数修改添加移除统计。\n| --name-only | 仅在提交信息后显示已修改的文件清单。\n| --name-status | 显示新增、修改、删除的文件清单。\n| --abbrev-commit | 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。\n| --relative-date | 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。\n| --graph | 在日志旁以 ASCII 图形显示分支与合并历史。\n\n\n- 按照预订格式:`oneline`、`short`、`full` 和 `fuller` 查看每次提交历史\n```bash\ngit log --pretty=oneline\n```\n\n- 按照格式:查看每次提交历史\n```bash\ngit log --pretty=\"format:\"%h - %an, %ar : %s\"\n```\n| 选项\t| 说明 |\n|:---:|:---:|\n| %H | 提交的完整哈希值\n| %h | 提交的简写哈希值\n| %T | 树的完整哈希值\n| %t | 树的简写哈希值\n| %P | 父提交的完整哈希值\n| %p | 父提交的简写哈希值\n| %an | 作者名字\n| %ae | 作者的电子邮件地址\n| %ad | 作者修订日期（可以用 --date=选项 来定制格式）\n| %ar | 作者修订日期，按多久以前的方式显示\n| %cn | 提交者的名字\n| %ce | 提交者的电子邮件地址\n| %cd | 提交日期\n| %cr | 提交日期（距今多长时间）\n| %s | 提交说明\n\n\n### 远程仓库\n- 查看远程仓库\n```bash\ngit remote -v\n```\n\n- 添加远程仓库\n```bash\ngit remote add <shortname> <url>\n```\n\n- 从远程仓库中获得数据\n```bash\ngit fetch <remote>\n```\n\n- 从远程仓库中获得数据&并自动尝试合并当前分支\n```bash\ngit pull <remote>\n```\n\n- 推送到远程仓库\n```bash\ngit push <remote> <branch>\n```\n\n- 查看某个远程仓库\n```bash\ngit remote show <remote>\n```\n\n- 远程仓库重命名\n```bash\ngit remote rename pb paul\n```\n\n- 远程仓库移除\n```bash\ngit remote remove paul\n```\n\n\n### 标签\n- 查看标签\n```bash\ngit tag\n```\n\n- 查看某个系列标签\n```bash\ngit tag -l \"1.8.0\"\n```\n\n- 创建轻量标签\n```bash\ngit tag v1.4\n```\n\n- 创建附注标签\n```bash\ngit tag -a v1.4 -m \"version 1.4\"\n```\n\n- 查询具体标签信息\n```\ngit show v1.4\n```\n\n- 推送指定标签\n```bash\ngit push origin v1.4\n```\n\n- 推送全部标签\n```bash\ngit push origin --tags\n```\n\n- 删除本地标签\n```bash\ngit tag -d v1.4\n```\n\n- 删除远程标签\n```bash\ngit tag --delete v1.4\n```\n\n### Git别名配置\n- 设置别名\n```bash\ngit config --global alias.co checkout\ngit config --global alias.br branch\ngit config --global alias.ci commit\ngit config --global alias.st status\n```\n\n### 分支管理\n\n- 创建分支\n```bash\ngit branch testing\n```\n\n- 切换分支\n```bash\ngit checkout testing\n```\n\n- 删除本地分支\n```bash\ngit branch -d testing\n```\n- 删除远程分支\n```bash\ngit push -delete testing\n```\n\n- 修改分支跟踪\n```bash\ngit branch -u origin/serverfix\n```\n\n### 分支合并\n分支合并有2中方式\n- `merge`\n- `rebase`\n#### Merge\n会把两个分支的最新快照以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）\n- 分支合并: 把<branch>分支代码合并到当前分支\n```bash\ngit merge <branch>\n```\n![merge合并](basic-merging-2.png)\n\n\n- 分支合并冲突解决\n合并两个分支，如果有冲突，合并会停止，必须先解决冲突\n如：\n```html\n<<<<<<< HEAD:index.html\n<div id=\"footer\">contact : email.support@github.com</div>\n=======\n<div id=\"footer\">\n please contact us at support@github.com\n</div>\n>>>>>>> iss53:index.html\n```\n\n留下有效代码，把 `<<<<<<<`、`=======`、`>>>>>>>` 移除\n\n#### 变基（rebase）\n```bash\ngit rebase <branch>\n```\n\n首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master） 的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用.\n案例：\n```bash\ngit checkout experiment\ngit rebase master\n```\n\n![将 C4 中的修改变基到 C3 上](basic-rebase-3.png)\n\n\n> `优点`：变基使得提交历史更加整洁, 提交历史是一条直线没有分叉\n> `风险`：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基\n\n## Git服务器\n### 协议\nGit 可以使用四种不同的协议来传输资料: `本地协议（Local）`、`HTTP 协议`、`SSH（Secure Shell）协议`及 `Git协议`\n#### 本地协议\n远程版本库就是同一主机上的另一个目录\n\n去克隆一个版本库或者增加一个远程到现有的项目中，使用版本库路径作为 URL\n```bash\ngit clone /srv/git/project.git\n\n## 或者\ngit clone file:///srv/git/project.git\n```\n\n> **优点：**\n> - 简单\n> - 直接使用了现有的文件权限和网络访问权限\n>\n> **缺点：**\n> - 共享文件系统比较难配置，并且比起基本的网络连接访问，这不方便从多个位置访问\n> - 并不保护仓库避免意外的损坏。 每一个用户都有“远程”目录的完整 shell 权限，没有方法可以阻止他们修改或删除 Git 内部文件和损坏仓库\n\n#### HTTP协议\n> **优点：**\n> - 像 `git:// 协议`一样提供匿名服务\n> - 像 `SSH 协议`一样提供传输时的授权和加密\n> - 使用比SSH简单\n>\n> **缺点：**\n> - 架设 HTTPS 协议的服务端会比 SSH 协议的棘手一些\n> - 管理凭证会比使用 SSH 密钥认证麻烦一些\n\n#### SSH协议\n> **优点：**\n> - 容易架设\n> - 访问安全：所有传输数据都要经过授权和加密\n> - 协议很高效: 在传输前也会尽量压缩数据\n>\n> **缺点：**\n> - 不支持匿名访问 `Git` 仓库\n\n#### Git协议\n> **优点：**\n> - 网络传输协议里最快的\n> - 使用与 SSH 相同的数据传输机制，但是省去了加密和授权的开销\n>\n> **缺点：**\n> - 缺乏授权机制\n> - 是最难架设的\n\n\n### 搭建服务器\n#### GitLab \n\n\n### SSH配置\n- 查看用户的 `SSH 密钥`\n```bash\n$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n```\n\n- 创建`SSH 密钥`\n```bash\nssh-keygen -o\n```\n\n- 获取公钥&配置公钥\n```bash\ncat ~/.ssh/id_rsa.pub\n```\n\n## Git工作流程\n\n### 集中式工作流\n单点协作模型\n![集中式工作流](centralized_workflow.png)\n\n### 集成管理者工作流\n1. 项目维护者推送到主仓库。\n\n2. 贡献者克隆此仓库，做出修改。\n\n3. 贡献者将数据推送到自己的公开仓库。\n\n4. 贡献者给维护者发送邮件，请求拉取自己的更新。\n\n5. 维护者在自己本地的仓库中，将贡献者的仓库加为远程仓库并合并修改。\n\n6. 维护者将合并后的修改推送到主仓库。\n\n![集成管理者工作流](integration-manager.png)\n\n见于Github平台最常用的工作流程.\n\n### 主管与副主管工作流\n多仓库工作流程的变种。 一般拥有数百位协作开发者的超大型项目才会用到这样的工作方式\n\n![主管与副主管工作流](benevolent-dictator.png)\n\n\n## Git工具\n### grep搜索\n从提交历史、工作目录、甚至索引中查找一个字符串或者正则表达式.\n\n```bash\ngit grep <option> <字符串、正则表达式>\n```\n\n### 日志搜索\n- 想找到 `<搜索>` 是什么时候引入的\n```bash\ngit log -S <搜索> --oneline\n```\n\n\n\n---\n\n## Git原理&实现\n### Git目录结构\n- 切换到`.git`目录\n```bash\ncd .git\n```\n\n- Git目录结构\n```bash\nls -F1\n```\n目录:\n```bash\nCOMMIT_EDITMSG\nFETCH_HEAD\nHEAD\nORIG_HEAD\nconfig\ndescription\nhooks/\nindex\ninfo/\nlogs/\nobjects/\npacked-refs\nrefs/\n```\n\n- `objects` 目录存储所有数据内容；\n- `refs` 目录存储指向数据（分支、远程仓库和标签等）的提交对象的指针； \n- `HEAD` 文件指向目前被检出的分支；\n- `index` 文件保存暂存区信息\n\n\n### 读取文件内容\n- \n```bash\ngit cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4\n```\n\n\n\n### 存储结构\n- `blob对象`：存储文件快照，而不是差异内容\n- `tree对象`：记录着目录结构和 blob 对象索引\n- `commit对象`：包含指向前述树对象的指针和所有提交信息\n\n![提交对象及其树结构](commit-and-tree.png)\n\n![提交对象及其父对象](commits-and-parents.png)\n\n\n\n\n\n\n---\n参考\n- [Pro Git](https://git-scm.com/book/zh/v2)\n- [Git macOS安装](https://git-scm.com/download/mac)\n- Git权威指南","source":"_posts/Git.md","raw":"---\ntitle: Git 分布式版本控制系统\ndate: 2014-08-07 17:34:41\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - 版本控制系统\ntags:\n    - 版本控制系统\n    - Git\n---\n\n> 摘要: 学习`Git`, 从概念、发展脉络、安装、基本使用、分支模型、服务器端配置&使用、分布式工作流、高级命令以及实现细节等\n\n\n## 基础认识\n\n### 版本控制\n一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统\n\n#### 发展脉络\n##### `本地版本控制系统`\n补丁方式，重新计算各个版本文件内容。\n- `优势`：简单\n- `缺点`：单点故障\n    \n##### `集中化的版本控制`\n客服端存储项目最新快照（协同工作）\n- `优势`：可以看到项目中的其他人正在做什么。\n- `缺点`：服务器单点故障\n\n##### `分布式版本控制系统`\n客户端存储项目完整镜像（包括完整历史记录、）（可以定制协作流程）  \n- `优势`：无单点故障 \n- `缺点`：\n\n### Git\n一个分布式控制系统。最开始基于存储Linux项目版本控制\n\n#### Git发展脉络\n- 1991~2002: 手动保存归档\n- 2002~2005：使用`BitKeeper`来管理和维护代码（后面与`BitKeeper`公司产生冲突，不准Linux使用BitKeeper）\n- 2005~：`Linus Torvalds`开发Git代替`BitKeeper`\n\n#### Git设计目标\n- 速度\n- 简单\n- 对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n- 完全分布式\n- 管理大规模项目（类似 Linux 内核一样的超大规模项目（速度和数据量）)\n\n#### Git优势&区别\n- `数据存储结构`: `直接记录快照，而非差异比较`. 对当时的提交更新的文件创建一个快照并保存这个快照的索引；文件没有修改,只保留一个链接指向之前存储的文件\n- `数据提交速度`：`近乎所有操作都是本地执行`\n- `数据提交传输完整性`：所有的数据在存储前都计算校验和，然后以校验和来引用。校验和：`SHA-1`算法, 40个十六进制字符（0-9 和 a-f）组成的字符串，基于 `Git` 中文件的`内容`或`目录结构`计算出来\n- `持久化不会丢失`：`Git`几乎不会执行任何可能导致文件不可恢复的操作。一般只添加数据，很难从Git删除数据\n\n#### Git状态\n- `已提交(committed)`：数据已经安全地保存在本地数据库中\n- `已修改(modified)`：修改了文件，但还没保存到数据库中\n- `已暂存(staged)`：对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中\n\n#### Git三个阶段\n- `工作区`: 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n- `暂存区`: `暂存区`是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫`暂存区`\n- `Git 仓库目录`: 是 `Git` 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。\n\n![Git工作流程](areas.png)\n**工作流程：**\n- 在工作区中修改文件\n- 将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。\n- 提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。\n\n## Git安装\n> macOS 环境\n- 安装`Git`\n```bash\nbrew install git\n```\n- 安装`Git可视化界面`\n```bash\nbrew install git-gui\n```\n\n## Git配置\n```bash\ngit config --global user.name \"John Doe\"\ngit config --global user.email johndoe@example.com\n```\n\n---\n\n## Git命令使用\n### 配置&管理\n- 查看Git当前所有配置\n```bash\ngit config --list\n```\n\n- 查看Git指定变量配置\n```bash\ngit config user.name\n```\n\n- 获取帮助命令\n```bash\ngit help <verb>\ngit <verb> --help\nman git-<verb>\n```\n如：获取`git config`命令手册\n```bash\ngit help config\n```\n\n### 获取仓库\n- 将尚未进行版本控制的本地目录转换为`Git 仓库`\n```bash\ngit init\n```\n- 克隆 一个已存在的`Git 仓库`\n```bash\ngit clone https://github.com/xxx\n```\n\n### 本地文件操作\n- 查看当前文件状态\n```bash\ngit status\n```\n\n- 将内容添加到下一次提交中\n```bash\ngit add .\n```\n\n- 提交文件, 产生一次提交记录\n```bash\ngit commit -m 'xx'\n```\n\n- 提交文件，向前面提交记录追加文件\n```bash\ngit commit --amend\n```\n\n- 删除跟踪，但是保留文件\n```bash\ngit rm --cached README\n```\n\n- 查看提交历史\n```bash\ngit log\n```\n\n- 查看每次提交的简略统计信息\n```bash\ngit log --stat\n```\n| 选项\t| 说明\n|:----:|:---:|\n| -p | 按补丁格式显示每个提交引入的差异。\n| --stat | 显示每次提交的文件修改统计信息。\n| --shortstat | 只显示 --stat 中最后的行数修改添加移除统计。\n| --name-only | 仅在提交信息后显示已修改的文件清单。\n| --name-status | 显示新增、修改、删除的文件清单。\n| --abbrev-commit | 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。\n| --relative-date | 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。\n| --graph | 在日志旁以 ASCII 图形显示分支与合并历史。\n\n\n- 按照预订格式:`oneline`、`short`、`full` 和 `fuller` 查看每次提交历史\n```bash\ngit log --pretty=oneline\n```\n\n- 按照格式:查看每次提交历史\n```bash\ngit log --pretty=\"format:\"%h - %an, %ar : %s\"\n```\n| 选项\t| 说明 |\n|:---:|:---:|\n| %H | 提交的完整哈希值\n| %h | 提交的简写哈希值\n| %T | 树的完整哈希值\n| %t | 树的简写哈希值\n| %P | 父提交的完整哈希值\n| %p | 父提交的简写哈希值\n| %an | 作者名字\n| %ae | 作者的电子邮件地址\n| %ad | 作者修订日期（可以用 --date=选项 来定制格式）\n| %ar | 作者修订日期，按多久以前的方式显示\n| %cn | 提交者的名字\n| %ce | 提交者的电子邮件地址\n| %cd | 提交日期\n| %cr | 提交日期（距今多长时间）\n| %s | 提交说明\n\n\n### 远程仓库\n- 查看远程仓库\n```bash\ngit remote -v\n```\n\n- 添加远程仓库\n```bash\ngit remote add <shortname> <url>\n```\n\n- 从远程仓库中获得数据\n```bash\ngit fetch <remote>\n```\n\n- 从远程仓库中获得数据&并自动尝试合并当前分支\n```bash\ngit pull <remote>\n```\n\n- 推送到远程仓库\n```bash\ngit push <remote> <branch>\n```\n\n- 查看某个远程仓库\n```bash\ngit remote show <remote>\n```\n\n- 远程仓库重命名\n```bash\ngit remote rename pb paul\n```\n\n- 远程仓库移除\n```bash\ngit remote remove paul\n```\n\n\n### 标签\n- 查看标签\n```bash\ngit tag\n```\n\n- 查看某个系列标签\n```bash\ngit tag -l \"1.8.0\"\n```\n\n- 创建轻量标签\n```bash\ngit tag v1.4\n```\n\n- 创建附注标签\n```bash\ngit tag -a v1.4 -m \"version 1.4\"\n```\n\n- 查询具体标签信息\n```\ngit show v1.4\n```\n\n- 推送指定标签\n```bash\ngit push origin v1.4\n```\n\n- 推送全部标签\n```bash\ngit push origin --tags\n```\n\n- 删除本地标签\n```bash\ngit tag -d v1.4\n```\n\n- 删除远程标签\n```bash\ngit tag --delete v1.4\n```\n\n### Git别名配置\n- 设置别名\n```bash\ngit config --global alias.co checkout\ngit config --global alias.br branch\ngit config --global alias.ci commit\ngit config --global alias.st status\n```\n\n### 分支管理\n\n- 创建分支\n```bash\ngit branch testing\n```\n\n- 切换分支\n```bash\ngit checkout testing\n```\n\n- 删除本地分支\n```bash\ngit branch -d testing\n```\n- 删除远程分支\n```bash\ngit push -delete testing\n```\n\n- 修改分支跟踪\n```bash\ngit branch -u origin/serverfix\n```\n\n### 分支合并\n分支合并有2中方式\n- `merge`\n- `rebase`\n#### Merge\n会把两个分支的最新快照以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）\n- 分支合并: 把<branch>分支代码合并到当前分支\n```bash\ngit merge <branch>\n```\n![merge合并](basic-merging-2.png)\n\n\n- 分支合并冲突解决\n合并两个分支，如果有冲突，合并会停止，必须先解决冲突\n如：\n```html\n<<<<<<< HEAD:index.html\n<div id=\"footer\">contact : email.support@github.com</div>\n=======\n<div id=\"footer\">\n please contact us at support@github.com\n</div>\n>>>>>>> iss53:index.html\n```\n\n留下有效代码，把 `<<<<<<<`、`=======`、`>>>>>>>` 移除\n\n#### 变基（rebase）\n```bash\ngit rebase <branch>\n```\n\n首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master） 的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用.\n案例：\n```bash\ngit checkout experiment\ngit rebase master\n```\n\n![将 C4 中的修改变基到 C3 上](basic-rebase-3.png)\n\n\n> `优点`：变基使得提交历史更加整洁, 提交历史是一条直线没有分叉\n> `风险`：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基\n\n## Git服务器\n### 协议\nGit 可以使用四种不同的协议来传输资料: `本地协议（Local）`、`HTTP 协议`、`SSH（Secure Shell）协议`及 `Git协议`\n#### 本地协议\n远程版本库就是同一主机上的另一个目录\n\n去克隆一个版本库或者增加一个远程到现有的项目中，使用版本库路径作为 URL\n```bash\ngit clone /srv/git/project.git\n\n## 或者\ngit clone file:///srv/git/project.git\n```\n\n> **优点：**\n> - 简单\n> - 直接使用了现有的文件权限和网络访问权限\n>\n> **缺点：**\n> - 共享文件系统比较难配置，并且比起基本的网络连接访问，这不方便从多个位置访问\n> - 并不保护仓库避免意外的损坏。 每一个用户都有“远程”目录的完整 shell 权限，没有方法可以阻止他们修改或删除 Git 内部文件和损坏仓库\n\n#### HTTP协议\n> **优点：**\n> - 像 `git:// 协议`一样提供匿名服务\n> - 像 `SSH 协议`一样提供传输时的授权和加密\n> - 使用比SSH简单\n>\n> **缺点：**\n> - 架设 HTTPS 协议的服务端会比 SSH 协议的棘手一些\n> - 管理凭证会比使用 SSH 密钥认证麻烦一些\n\n#### SSH协议\n> **优点：**\n> - 容易架设\n> - 访问安全：所有传输数据都要经过授权和加密\n> - 协议很高效: 在传输前也会尽量压缩数据\n>\n> **缺点：**\n> - 不支持匿名访问 `Git` 仓库\n\n#### Git协议\n> **优点：**\n> - 网络传输协议里最快的\n> - 使用与 SSH 相同的数据传输机制，但是省去了加密和授权的开销\n>\n> **缺点：**\n> - 缺乏授权机制\n> - 是最难架设的\n\n\n### 搭建服务器\n#### GitLab \n\n\n### SSH配置\n- 查看用户的 `SSH 密钥`\n```bash\n$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n```\n\n- 创建`SSH 密钥`\n```bash\nssh-keygen -o\n```\n\n- 获取公钥&配置公钥\n```bash\ncat ~/.ssh/id_rsa.pub\n```\n\n## Git工作流程\n\n### 集中式工作流\n单点协作模型\n![集中式工作流](centralized_workflow.png)\n\n### 集成管理者工作流\n1. 项目维护者推送到主仓库。\n\n2. 贡献者克隆此仓库，做出修改。\n\n3. 贡献者将数据推送到自己的公开仓库。\n\n4. 贡献者给维护者发送邮件，请求拉取自己的更新。\n\n5. 维护者在自己本地的仓库中，将贡献者的仓库加为远程仓库并合并修改。\n\n6. 维护者将合并后的修改推送到主仓库。\n\n![集成管理者工作流](integration-manager.png)\n\n见于Github平台最常用的工作流程.\n\n### 主管与副主管工作流\n多仓库工作流程的变种。 一般拥有数百位协作开发者的超大型项目才会用到这样的工作方式\n\n![主管与副主管工作流](benevolent-dictator.png)\n\n\n## Git工具\n### grep搜索\n从提交历史、工作目录、甚至索引中查找一个字符串或者正则表达式.\n\n```bash\ngit grep <option> <字符串、正则表达式>\n```\n\n### 日志搜索\n- 想找到 `<搜索>` 是什么时候引入的\n```bash\ngit log -S <搜索> --oneline\n```\n\n\n\n---\n\n## Git原理&实现\n### Git目录结构\n- 切换到`.git`目录\n```bash\ncd .git\n```\n\n- Git目录结构\n```bash\nls -F1\n```\n目录:\n```bash\nCOMMIT_EDITMSG\nFETCH_HEAD\nHEAD\nORIG_HEAD\nconfig\ndescription\nhooks/\nindex\ninfo/\nlogs/\nobjects/\npacked-refs\nrefs/\n```\n\n- `objects` 目录存储所有数据内容；\n- `refs` 目录存储指向数据（分支、远程仓库和标签等）的提交对象的指针； \n- `HEAD` 文件指向目前被检出的分支；\n- `index` 文件保存暂存区信息\n\n\n### 读取文件内容\n- \n```bash\ngit cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4\n```\n\n\n\n### 存储结构\n- `blob对象`：存储文件快照，而不是差异内容\n- `tree对象`：记录着目录结构和 blob 对象索引\n- `commit对象`：包含指向前述树对象的指针和所有提交信息\n\n![提交对象及其树结构](commit-and-tree.png)\n\n![提交对象及其父对象](commits-and-parents.png)\n\n\n\n\n\n\n---\n参考\n- [Pro Git](https://git-scm.com/book/zh/v2)\n- [Git macOS安装](https://git-scm.com/download/mac)\n- Git权威指南","slug":"Git","published":1,"updated":"2022-03-11T03:18:53.373Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw7o00009op7356id00e","content":"<blockquote>\n<p>摘要: 学习<code>Git</code>, 从概念、发展脉络、安装、基本使用、分支模型、服务器端配置&amp;使用、分布式工作流、高级命令以及实现细节等</p>\n</blockquote>\n<h2 id=\"基础认识\"><a href=\"#基础认识\" class=\"headerlink\" title=\"基础认识\"></a>基础认识</h2><h3 id=\"版本控制\"><a href=\"#版本控制\" class=\"headerlink\" title=\"版本控制\"></a>版本控制</h3><p>一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统</p>\n<h4 id=\"发展脉络\"><a href=\"#发展脉络\" class=\"headerlink\" title=\"发展脉络\"></a>发展脉络</h4><h5 id=\"本地版本控制系统\"><a href=\"#本地版本控制系统\" class=\"headerlink\" title=\"本地版本控制系统\"></a><code>本地版本控制系统</code></h5><p>补丁方式，重新计算各个版本文件内容。</p>\n<ul>\n<li><code>优势</code>：简单</li>\n<li><code>缺点</code>：单点故障</li>\n</ul>\n<h5 id=\"集中化的版本控制\"><a href=\"#集中化的版本控制\" class=\"headerlink\" title=\"集中化的版本控制\"></a><code>集中化的版本控制</code></h5><p>客服端存储项目最新快照（协同工作）</p>\n<ul>\n<li><code>优势</code>：可以看到项目中的其他人正在做什么。</li>\n<li><code>缺点</code>：服务器单点故障</li>\n</ul>\n<h5 id=\"分布式版本控制系统\"><a href=\"#分布式版本控制系统\" class=\"headerlink\" title=\"分布式版本控制系统\"></a><code>分布式版本控制系统</code></h5><p>客户端存储项目完整镜像（包括完整历史记录、）（可以定制协作流程）  </p>\n<ul>\n<li><code>优势</code>：无单点故障 </li>\n<li><code>缺点</code>：</li>\n</ul>\n<h3 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h3><p>一个分布式控制系统。最开始基于存储Linux项目版本控制</p>\n<h4 id=\"Git发展脉络\"><a href=\"#Git发展脉络\" class=\"headerlink\" title=\"Git发展脉络\"></a>Git发展脉络</h4><ul>\n<li>1991~2002: 手动保存归档</li>\n<li>2002~2005：使用<code>BitKeeper</code>来管理和维护代码（后面与<code>BitKeeper</code>公司产生冲突，不准Linux使用BitKeeper）</li>\n<li>2005~：<code>Linus Torvalds</code>开发Git代替<code>BitKeeper</code></li>\n</ul>\n<h4 id=\"Git设计目标\"><a href=\"#Git设计目标\" class=\"headerlink\" title=\"Git设计目标\"></a>Git设计目标</h4><ul>\n<li>速度</li>\n<li>简单</li>\n<li>对非线性开发模式的强力支持（允许成千上万个并行开发的分支）</li>\n<li>完全分布式</li>\n<li>管理大规模项目（类似 Linux 内核一样的超大规模项目（速度和数据量）)</li>\n</ul>\n<h4 id=\"Git优势-amp-区别\"><a href=\"#Git优势-amp-区别\" class=\"headerlink\" title=\"Git优势&amp;区别\"></a>Git优势&amp;区别</h4><ul>\n<li><code>数据存储结构</code>: <code>直接记录快照，而非差异比较</code>. 对当时的提交更新的文件创建一个快照并保存这个快照的索引；文件没有修改,只保留一个链接指向之前存储的文件</li>\n<li><code>数据提交速度</code>：<code>近乎所有操作都是本地执行</code></li>\n<li><code>数据提交传输完整性</code>：所有的数据在存储前都计算校验和，然后以校验和来引用。校验和：<code>SHA-1</code>算法, 40个十六进制字符（0-9 和 a-f）组成的字符串，基于 <code>Git</code> 中文件的<code>内容</code>或<code>目录结构</code>计算出来</li>\n<li><code>持久化不会丢失</code>：<code>Git</code>几乎不会执行任何可能导致文件不可恢复的操作。一般只添加数据，很难从Git删除数据</li>\n</ul>\n<h4 id=\"Git状态\"><a href=\"#Git状态\" class=\"headerlink\" title=\"Git状态\"></a>Git状态</h4><ul>\n<li><code>已提交(committed)</code>：数据已经安全地保存在本地数据库中</li>\n<li><code>已修改(modified)</code>：修改了文件，但还没保存到数据库中</li>\n<li><code>已暂存(staged)</code>：对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中</li>\n</ul>\n<h4 id=\"Git三个阶段\"><a href=\"#Git三个阶段\" class=\"headerlink\" title=\"Git三个阶段\"></a>Git三个阶段</h4><ul>\n<li><code>工作区</code>: 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。</li>\n<li><code>暂存区</code>: <code>暂存区</code>是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫<code>暂存区</code></li>\n<li><code>Git 仓库目录</code>: 是 <code>Git</code> 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。</li>\n</ul>\n<p><img src=\"areas.png\" alt=\"Git工作流程\">\n<strong>工作流程：</strong></p>\n<ul>\n<li>在工作区中修改文件</li>\n<li>将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。</li>\n<li>提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。</li>\n</ul>\n<h2 id=\"Git安装\"><a href=\"#Git安装\" class=\"headerlink\" title=\"Git安装\"></a>Git安装</h2><blockquote>\n<p>macOS 环境</p>\n</blockquote>\n<ul>\n<li>安装<code>Git</code><pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> <span class=\"token function\">git</span>\n</code></pre>\n</li>\n<li>安装<code>Git可视化界面</code><pre class=\" language-bash\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> git-gui\n</code></pre>\n</li>\n</ul>\n<h2 id=\"Git配置\"><a href=\"#Git配置\" class=\"headerlink\" title=\"Git配置\"></a>Git配置</h2><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> config --global user.name <span class=\"token string\">\"John Doe\"</span>\n<span class=\"token function\">git</span> config --global user.email johndoe@example.com\n</code></pre>\n<hr>\n<h2 id=\"Git命令使用\"><a href=\"#Git命令使用\" class=\"headerlink\" title=\"Git命令使用\"></a>Git命令使用</h2><h3 id=\"配置-amp-管理\"><a href=\"#配置-amp-管理\" class=\"headerlink\" title=\"配置&amp;管理\"></a>配置&amp;管理</h3><ul>\n<li><p>查看Git当前所有配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> config --list\n</code></pre>\n</li>\n<li><p>查看Git指定变量配置</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> config user.name\n</code></pre>\n</li>\n<li><p>获取帮助命令</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> <span class=\"token function\">help</span> <span class=\"token operator\">&lt;</span>verb<span class=\"token operator\">></span>\n<span class=\"token function\">git</span> <span class=\"token operator\">&lt;</span>verb<span class=\"token operator\">></span> --help\n<span class=\"token function\">man</span> git-<span class=\"token operator\">&lt;</span>verb<span class=\"token operator\">></span>\n</code></pre>\n<p>如：获取<code>git config</code>命令手册</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> <span class=\"token function\">help</span> config\n</code></pre>\n</li>\n</ul>\n<h3 id=\"获取仓库\"><a href=\"#获取仓库\" class=\"headerlink\" title=\"获取仓库\"></a>获取仓库</h3><ul>\n<li>将尚未进行版本控制的本地目录转换为<code>Git 仓库</code><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> init\n</code></pre>\n</li>\n<li>克隆 一个已存在的<code>Git 仓库</code><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/xxx\n</code></pre>\n</li>\n</ul>\n<h3 id=\"本地文件操作\"><a href=\"#本地文件操作\" class=\"headerlink\" title=\"本地文件操作\"></a>本地文件操作</h3><ul>\n<li><p>查看当前文件状态</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> status\n</code></pre>\n</li>\n<li><p>将内容添加到下一次提交中</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> add <span class=\"token keyword\">.</span>\n</code></pre>\n</li>\n<li><p>提交文件, 产生一次提交记录</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> commit -m <span class=\"token string\">'xx'</span>\n</code></pre>\n</li>\n<li><p>提交文件，向前面提交记录追加文件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> commit --amend\n</code></pre>\n</li>\n<li><p>删除跟踪，但是保留文件</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> <span class=\"token function\">rm</span> --cached README\n</code></pre>\n</li>\n<li><p>查看提交历史</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> log\n</code></pre>\n</li>\n<li><p>查看每次提交的简略统计信息</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> log --stat\n</code></pre>\n<table>\n<thead>\n<tr>\n<th align=\"center\">选项</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-p</td>\n<td align=\"center\">按补丁格式显示每个提交引入的差异。</td>\n</tr>\n<tr>\n<td align=\"center\">–stat</td>\n<td align=\"center\">显示每次提交的文件修改统计信息。</td>\n</tr>\n<tr>\n<td align=\"center\">–shortstat</td>\n<td align=\"center\">只显示 –stat 中最后的行数修改添加移除统计。</td>\n</tr>\n<tr>\n<td align=\"center\">–name-only</td>\n<td align=\"center\">仅在提交信息后显示已修改的文件清单。</td>\n</tr>\n<tr>\n<td align=\"center\">–name-status</td>\n<td align=\"center\">显示新增、修改、删除的文件清单。</td>\n</tr>\n<tr>\n<td align=\"center\">–abbrev-commit</td>\n<td align=\"center\">仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。</td>\n</tr>\n<tr>\n<td align=\"center\">–relative-date</td>\n<td align=\"center\">使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。</td>\n</tr>\n<tr>\n<td align=\"center\">–graph</td>\n<td align=\"center\">在日志旁以 ASCII 图形显示分支与合并历史。</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<ul>\n<li><p>按照预订格式:<code>oneline</code>、<code>short</code>、<code>full</code> 和 <code>fuller</code> 查看每次提交历史</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> log --pretty<span class=\"token operator\">=</span>oneline\n</code></pre>\n</li>\n<li><p>按照格式:查看每次提交历史</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> log --pretty<span class=\"token operator\">=</span><span class=\"token string\">\"format:\"</span>%h - %an, %ar <span class=\"token keyword\">:</span> %s\"\n</code></pre>\n<table>\n<thead>\n<tr>\n<th align=\"center\">选项</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">%H</td>\n<td align=\"center\">提交的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%h</td>\n<td align=\"center\">提交的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%T</td>\n<td align=\"center\">树的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%t</td>\n<td align=\"center\">树的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%P</td>\n<td align=\"center\">父提交的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%p</td>\n<td align=\"center\">父提交的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%an</td>\n<td align=\"center\">作者名字</td>\n</tr>\n<tr>\n<td align=\"center\">%ae</td>\n<td align=\"center\">作者的电子邮件地址</td>\n</tr>\n<tr>\n<td align=\"center\">%ad</td>\n<td align=\"center\">作者修订日期（可以用 –date=选项 来定制格式）</td>\n</tr>\n<tr>\n<td align=\"center\">%ar</td>\n<td align=\"center\">作者修订日期，按多久以前的方式显示</td>\n</tr>\n<tr>\n<td align=\"center\">%cn</td>\n<td align=\"center\">提交者的名字</td>\n</tr>\n<tr>\n<td align=\"center\">%ce</td>\n<td align=\"center\">提交者的电子邮件地址</td>\n</tr>\n<tr>\n<td align=\"center\">%cd</td>\n<td align=\"center\">提交日期</td>\n</tr>\n<tr>\n<td align=\"center\">%cr</td>\n<td align=\"center\">提交日期（距今多长时间）</td>\n</tr>\n<tr>\n<td align=\"center\">%s</td>\n<td align=\"center\">提交说明</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<h3 id=\"远程仓库\"><a href=\"#远程仓库\" class=\"headerlink\" title=\"远程仓库\"></a>远程仓库</h3><ul>\n<li><p>查看远程仓库</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> remote -v\n</code></pre>\n</li>\n<li><p>添加远程仓库</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> remote add <span class=\"token operator\">&lt;</span>shortname<span class=\"token operator\">></span> <span class=\"token operator\">&lt;</span>url<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>从远程仓库中获得数据</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> fetch <span class=\"token operator\">&lt;</span>remote<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>从远程仓库中获得数据&amp;并自动尝试合并当前分支</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> pull <span class=\"token operator\">&lt;</span>remote<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>推送到远程仓库</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> push <span class=\"token operator\">&lt;</span>remote<span class=\"token operator\">></span> <span class=\"token operator\">&lt;</span>branch<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>查看某个远程仓库</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> remote show <span class=\"token operator\">&lt;</span>remote<span class=\"token operator\">></span>\n</code></pre>\n</li>\n<li><p>远程仓库重命名</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> remote <span class=\"token function\">rename</span> pb paul\n</code></pre>\n</li>\n<li><p>远程仓库移除</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> remote remove paul\n</code></pre>\n</li>\n</ul>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><ul>\n<li><p>查看标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag\n</code></pre>\n</li>\n<li><p>查看某个系列标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag -l <span class=\"token string\">\"1.8.0\"</span>\n</code></pre>\n</li>\n<li><p>创建轻量标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag v1.4\n</code></pre>\n</li>\n<li><p>创建附注标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag -a v1.4 -m <span class=\"token string\">\"version 1.4\"</span>\n</code></pre>\n</li>\n<li><p>查询具体标签信息</p>\n<pre><code>git show v1.4\n</code></pre>\n</li>\n<li><p>推送指定标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> push origin v1.4\n</code></pre>\n</li>\n<li><p>推送全部标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> push origin --tags\n</code></pre>\n</li>\n<li><p>删除本地标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag -d v1.4\n</code></pre>\n</li>\n<li><p>删除远程标签</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> tag --delete v1.4\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Git别名配置\"><a href=\"#Git别名配置\" class=\"headerlink\" title=\"Git别名配置\"></a>Git别名配置</h3><ul>\n<li>设置别名<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> config --global alias.co checkout\n<span class=\"token function\">git</span> config --global alias.br branch\n<span class=\"token function\">git</span> config --global alias.ci commit\n<span class=\"token function\">git</span> config --global alias.st status\n</code></pre>\n</li>\n</ul>\n<h3 id=\"分支管理\"><a href=\"#分支管理\" class=\"headerlink\" title=\"分支管理\"></a>分支管理</h3><ul>\n<li><p>创建分支</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> branch testing\n</code></pre>\n</li>\n<li><p>切换分支</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> checkout testing\n</code></pre>\n</li>\n<li><p>删除本地分支</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> branch -d testing\n</code></pre>\n</li>\n<li><p>删除远程分支</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> push -delete testing\n</code></pre>\n</li>\n<li><p>修改分支跟踪</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> branch -u origin/serverfix\n</code></pre>\n</li>\n</ul>\n<h3 id=\"分支合并\"><a href=\"#分支合并\" class=\"headerlink\" title=\"分支合并\"></a>分支合并</h3><p>分支合并有2中方式</p>\n<ul>\n<li><code>merge</code></li>\n<li><code>rebase</code><h4 id=\"Merge\"><a href=\"#Merge\" class=\"headerlink\" title=\"Merge\"></a>Merge</h4>会把两个分支的最新快照以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）</li>\n<li>分支合并: 把<branch>分支代码合并到当前分支<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> merge <span class=\"token operator\">&lt;</span>branch<span class=\"token operator\">></span>\n</code></pre>\n<img src=\"basic-merging-2.png\" alt=\"merge合并\"></branch></li>\n</ul>\n<ul>\n<li>分支合并冲突解决\n合并两个分支，如果有冲突，合并会停止，必须先解决冲突\n如：<pre class=\" language-html\"><code class=\"language-html\">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>div</span> <span class=\"token attr-name\">id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>footer<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>contact : email.support@github.com<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>div</span><span class=\"token punctuation\">></span></span>\n=======\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>div</span> <span class=\"token attr-name\">id</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>footer<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\nplease contact us at support@github.com\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>div</span><span class=\"token punctuation\">></span></span>\n>>>>>>> iss53:index.html\n</code></pre>\n</li>\n</ul>\n<p>留下有效代码，把 <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>、<code>=======</code>、<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code> 移除</p>\n<h4 id=\"变基（rebase）\"><a href=\"#变基（rebase）\" class=\"headerlink\" title=\"变基（rebase）\"></a>变基（rebase）</h4><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> rebase <span class=\"token operator\">&lt;</span>branch<span class=\"token operator\">></span>\n</code></pre>\n<p>首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master） 的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用.\n案例：</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> checkout experiment\n<span class=\"token function\">git</span> rebase master\n</code></pre>\n<p><img src=\"basic-rebase-3.png\" alt=\"将 C4 中的修改变基到 C3 上\"></p>\n<blockquote>\n<p><code>优点</code>：变基使得提交历史更加整洁, 提交历史是一条直线没有分叉\n<code>风险</code>：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基</p>\n</blockquote>\n<h2 id=\"Git服务器\"><a href=\"#Git服务器\" class=\"headerlink\" title=\"Git服务器\"></a>Git服务器</h2><h3 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h3><p>Git 可以使用四种不同的协议来传输资料: <code>本地协议（Local）</code>、<code>HTTP 协议</code>、<code>SSH（Secure Shell）协议</code>及 <code>Git协议</code></p>\n<h4 id=\"本地协议\"><a href=\"#本地协议\" class=\"headerlink\" title=\"本地协议\"></a>本地协议</h4><p>远程版本库就是同一主机上的另一个目录</p>\n<p>去克隆一个版本库或者增加一个远程到现有的项目中，使用版本库路径作为 URL</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone /srv/git/project.git\n\n<span class=\"token comment\" spellcheck=\"true\">## 或者</span>\n<span class=\"token function\">git</span> clone file:///srv/git/project.git\n</code></pre>\n<blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>简单</li>\n<li>直接使用了现有的文件权限和网络访问权限</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>共享文件系统比较难配置，并且比起基本的网络连接访问，这不方便从多个位置访问</li>\n<li>并不保护仓库避免意外的损坏。 每一个用户都有“远程”目录的完整 shell 权限，没有方法可以阻止他们修改或删除 Git 内部文件和损坏仓库</li>\n</ul>\n</blockquote>\n<h4 id=\"HTTP协议\"><a href=\"#HTTP协议\" class=\"headerlink\" title=\"HTTP协议\"></a>HTTP协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>像 <code>git:// 协议</code>一样提供匿名服务</li>\n<li>像 <code>SSH 协议</code>一样提供传输时的授权和加密</li>\n<li>使用比SSH简单</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>架设 HTTPS 协议的服务端会比 SSH 协议的棘手一些</li>\n<li>管理凭证会比使用 SSH 密钥认证麻烦一些</li>\n</ul>\n</blockquote>\n<h4 id=\"SSH协议\"><a href=\"#SSH协议\" class=\"headerlink\" title=\"SSH协议\"></a>SSH协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>容易架设</li>\n<li>访问安全：所有传输数据都要经过授权和加密</li>\n<li>协议很高效: 在传输前也会尽量压缩数据</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>不支持匿名访问 <code>Git</code> 仓库</li>\n</ul>\n</blockquote>\n<h4 id=\"Git协议\"><a href=\"#Git协议\" class=\"headerlink\" title=\"Git协议\"></a>Git协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>网络传输协议里最快的</li>\n<li>使用与 SSH 相同的数据传输机制，但是省去了加密和授权的开销</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>缺乏授权机制</li>\n<li>是最难架设的</li>\n</ul>\n</blockquote>\n<h3 id=\"搭建服务器\"><a href=\"#搭建服务器\" class=\"headerlink\" title=\"搭建服务器\"></a>搭建服务器</h3><h4 id=\"GitLab\"><a href=\"#GitLab\" class=\"headerlink\" title=\"GitLab\"></a>GitLab</h4><h3 id=\"SSH配置\"><a href=\"#SSH配置\" class=\"headerlink\" title=\"SSH配置\"></a>SSH配置</h3><ul>\n<li><p>查看用户的 <code>SSH 密钥</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">cd</span> ~/.ssh\n$ <span class=\"token function\">ls</span>\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n</code></pre>\n</li>\n<li><p>创建<code>SSH 密钥</code></p>\n<pre class=\" language-bash\"><code class=\"language-bash\">ssh-keygen -o\n</code></pre>\n</li>\n<li><p>获取公钥&amp;配置公钥</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> ~/.ssh/id_rsa.pub\n</code></pre>\n</li>\n</ul>\n<h2 id=\"Git工作流程\"><a href=\"#Git工作流程\" class=\"headerlink\" title=\"Git工作流程\"></a>Git工作流程</h2><h3 id=\"集中式工作流\"><a href=\"#集中式工作流\" class=\"headerlink\" title=\"集中式工作流\"></a>集中式工作流</h3><p>单点协作模型\n<img src=\"centralized_workflow.png\" alt=\"集中式工作流\"></p>\n<h3 id=\"集成管理者工作流\"><a href=\"#集成管理者工作流\" class=\"headerlink\" title=\"集成管理者工作流\"></a>集成管理者工作流</h3><ol>\n<li><p>项目维护者推送到主仓库。</p>\n</li>\n<li><p>贡献者克隆此仓库，做出修改。</p>\n</li>\n<li><p>贡献者将数据推送到自己的公开仓库。</p>\n</li>\n<li><p>贡献者给维护者发送邮件，请求拉取自己的更新。</p>\n</li>\n<li><p>维护者在自己本地的仓库中，将贡献者的仓库加为远程仓库并合并修改。</p>\n</li>\n<li><p>维护者将合并后的修改推送到主仓库。</p>\n</li>\n</ol>\n<p><img src=\"integration-manager.png\" alt=\"集成管理者工作流\"></p>\n<p>见于Github平台最常用的工作流程.</p>\n<h3 id=\"主管与副主管工作流\"><a href=\"#主管与副主管工作流\" class=\"headerlink\" title=\"主管与副主管工作流\"></a>主管与副主管工作流</h3><p>多仓库工作流程的变种。 一般拥有数百位协作开发者的超大型项目才会用到这样的工作方式</p>\n<p><img src=\"benevolent-dictator.png\" alt=\"主管与副主管工作流\"></p>\n<h2 id=\"Git工具\"><a href=\"#Git工具\" class=\"headerlink\" title=\"Git工具\"></a>Git工具</h2><h3 id=\"grep搜索\"><a href=\"#grep搜索\" class=\"headerlink\" title=\"grep搜索\"></a>grep搜索</h3><p>从提交历史、工作目录、甚至索引中查找一个字符串或者正则表达式.</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> <span class=\"token function\">grep</span> <span class=\"token operator\">&lt;</span>option<span class=\"token operator\">></span> <span class=\"token operator\">&lt;</span>字符串、正则表达式<span class=\"token operator\">></span>\n</code></pre>\n<h3 id=\"日志搜索\"><a href=\"#日志搜索\" class=\"headerlink\" title=\"日志搜索\"></a>日志搜索</h3><ul>\n<li>想找到 <code>&lt;搜索&gt;</code> 是什么时候引入的<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> log -S <span class=\"token operator\">&lt;</span>搜索<span class=\"token operator\">></span> --oneline\n</code></pre>\n</li>\n</ul>\n<hr>\n<h2 id=\"Git原理-amp-实现\"><a href=\"#Git原理-amp-实现\" class=\"headerlink\" title=\"Git原理&amp;实现\"></a>Git原理&amp;实现</h2><h3 id=\"Git目录结构\"><a href=\"#Git目录结构\" class=\"headerlink\" title=\"Git目录结构\"></a>Git目录结构</h3><ul>\n<li><p>切换到<code>.git</code>目录</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">cd</span> .git\n</code></pre>\n</li>\n<li><p>Git目录结构</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">ls</span> -F1\n</code></pre>\n<p>目录:</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">COMMIT_EDITMSG\nFETCH_HEAD\nHEAD\nORIG_HEAD\nconfig\ndescription\nhooks/\nindex\ninfo/\nlogs/\nobjects/\npacked-refs\nrefs/\n</code></pre>\n</li>\n<li><p><code>objects</code> 目录存储所有数据内容；</p>\n</li>\n<li><p><code>refs</code> 目录存储指向数据（分支、远程仓库和标签等）的提交对象的指针； </p>\n</li>\n<li><p><code>HEAD</code> 文件指向目前被检出的分支；</p>\n</li>\n<li><p><code>index</code> 文件保存暂存区信息</p>\n</li>\n</ul>\n<h3 id=\"读取文件内容\"><a href=\"#读取文件内容\" class=\"headerlink\" title=\"读取文件内容\"></a>读取文件内容</h3><ul>\n<li><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4\n</code></pre>\n</li>\n</ul>\n<h3 id=\"存储结构\"><a href=\"#存储结构\" class=\"headerlink\" title=\"存储结构\"></a>存储结构</h3><ul>\n<li><code>blob对象</code>：存储文件快照，而不是差异内容</li>\n<li><code>tree对象</code>：记录着目录结构和 blob 对象索引</li>\n<li><code>commit对象</code>：包含指向前述树对象的指针和所有提交信息</li>\n</ul>\n<p><img src=\"commit-and-tree.png\" alt=\"提交对象及其树结构\"></p>\n<p><img src=\"commits-and-parents.png\" alt=\"提交对象及其父对象\"></p>\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://git-scm.com/book/zh/v2\">Pro Git</a></li>\n<li><a href=\"https://git-scm.com/download/mac\">Git macOS安装</a></li>\n<li>Git权威指南</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要: 学习<code>Git</code>, 从概念、发展脉络、安装、基本使用、分支模型、服务器端配置&amp;使用、分布式工作流、高级命令以及实现细节等</p>\n</blockquote>\n<h2 id=\"基础认识\"><a href=\"#基础认识\" class=\"headerlink\" title=\"基础认识\"></a>基础认识</h2><h3 id=\"版本控制\"><a href=\"#版本控制\" class=\"headerlink\" title=\"版本控制\"></a>版本控制</h3><p>一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统</p>\n<h4 id=\"发展脉络\"><a href=\"#发展脉络\" class=\"headerlink\" title=\"发展脉络\"></a>发展脉络</h4><h5 id=\"本地版本控制系统\"><a href=\"#本地版本控制系统\" class=\"headerlink\" title=\"本地版本控制系统\"></a><code>本地版本控制系统</code></h5><p>补丁方式，重新计算各个版本文件内容。</p>\n<ul>\n<li><code>优势</code>：简单</li>\n<li><code>缺点</code>：单点故障</li>\n</ul>\n<h5 id=\"集中化的版本控制\"><a href=\"#集中化的版本控制\" class=\"headerlink\" title=\"集中化的版本控制\"></a><code>集中化的版本控制</code></h5><p>客服端存储项目最新快照（协同工作）</p>\n<ul>\n<li><code>优势</code>：可以看到项目中的其他人正在做什么。</li>\n<li><code>缺点</code>：服务器单点故障</li>\n</ul>\n<h5 id=\"分布式版本控制系统\"><a href=\"#分布式版本控制系统\" class=\"headerlink\" title=\"分布式版本控制系统\"></a><code>分布式版本控制系统</code></h5><p>客户端存储项目完整镜像（包括完整历史记录、）（可以定制协作流程）  </p>\n<ul>\n<li><code>优势</code>：无单点故障 </li>\n<li><code>缺点</code>：</li>\n</ul>\n<h3 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h3><p>一个分布式控制系统。最开始基于存储Linux项目版本控制</p>\n<h4 id=\"Git发展脉络\"><a href=\"#Git发展脉络\" class=\"headerlink\" title=\"Git发展脉络\"></a>Git发展脉络</h4><ul>\n<li>1991~2002: 手动保存归档</li>\n<li>2002~2005：使用<code>BitKeeper</code>来管理和维护代码（后面与<code>BitKeeper</code>公司产生冲突，不准Linux使用BitKeeper）</li>\n<li>2005~：<code>Linus Torvalds</code>开发Git代替<code>BitKeeper</code></li>\n</ul>\n<h4 id=\"Git设计目标\"><a href=\"#Git设计目标\" class=\"headerlink\" title=\"Git设计目标\"></a>Git设计目标</h4><ul>\n<li>速度</li>\n<li>简单</li>\n<li>对非线性开发模式的强力支持（允许成千上万个并行开发的分支）</li>\n<li>完全分布式</li>\n<li>管理大规模项目（类似 Linux 内核一样的超大规模项目（速度和数据量）)</li>\n</ul>\n<h4 id=\"Git优势-amp-区别\"><a href=\"#Git优势-amp-区别\" class=\"headerlink\" title=\"Git优势&amp;区别\"></a>Git优势&amp;区别</h4><ul>\n<li><code>数据存储结构</code>: <code>直接记录快照，而非差异比较</code>. 对当时的提交更新的文件创建一个快照并保存这个快照的索引；文件没有修改,只保留一个链接指向之前存储的文件</li>\n<li><code>数据提交速度</code>：<code>近乎所有操作都是本地执行</code></li>\n<li><code>数据提交传输完整性</code>：所有的数据在存储前都计算校验和，然后以校验和来引用。校验和：<code>SHA-1</code>算法, 40个十六进制字符（0-9 和 a-f）组成的字符串，基于 <code>Git</code> 中文件的<code>内容</code>或<code>目录结构</code>计算出来</li>\n<li><code>持久化不会丢失</code>：<code>Git</code>几乎不会执行任何可能导致文件不可恢复的操作。一般只添加数据，很难从Git删除数据</li>\n</ul>\n<h4 id=\"Git状态\"><a href=\"#Git状态\" class=\"headerlink\" title=\"Git状态\"></a>Git状态</h4><ul>\n<li><code>已提交(committed)</code>：数据已经安全地保存在本地数据库中</li>\n<li><code>已修改(modified)</code>：修改了文件，但还没保存到数据库中</li>\n<li><code>已暂存(staged)</code>：对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中</li>\n</ul>\n<h4 id=\"Git三个阶段\"><a href=\"#Git三个阶段\" class=\"headerlink\" title=\"Git三个阶段\"></a>Git三个阶段</h4><ul>\n<li><code>工作区</code>: 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。</li>\n<li><code>暂存区</code>: <code>暂存区</code>是一个文件，保存了下次将要提交的文件列表信息，一般在 Git 仓库目录中。 按照 Git 的术语叫做“索引”，不过一般说法还是叫<code>暂存区</code></li>\n<li><code>Git 仓库目录</code>: 是 <code>Git</code> 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，复制的就是这里的数据。</li>\n</ul>\n<p><img src=\"areas.png\" alt=\"Git工作流程\">\n<strong>工作流程：</strong></p>\n<ul>\n<li>在工作区中修改文件</li>\n<li>将你想要下次提交的更改选择性地暂存，这样只会将更改的部分添加到暂存区。</li>\n<li>提交更新，找到暂存区的文件，将快照永久性存储到 Git 目录。</li>\n</ul>\n<h2 id=\"Git安装\"><a href=\"#Git安装\" class=\"headerlink\" title=\"Git安装\"></a>Git安装</h2><blockquote>\n<p>macOS 环境</p>\n</blockquote>\n<ul>\n<li>安装<code>Git</code><pre><code class=\"bash\">brew install git\n</code></pre>\n</li>\n<li>安装<code>Git可视化界面</code><pre><code class=\"bash\">brew install git-gui\n</code></pre>\n</li>\n</ul>\n<h2 id=\"Git配置\"><a href=\"#Git配置\" class=\"headerlink\" title=\"Git配置\"></a>Git配置</h2><pre><code class=\"bash\">git config --global user.name &quot;John Doe&quot;\ngit config --global user.email johndoe@example.com\n</code></pre>\n<hr>\n<h2 id=\"Git命令使用\"><a href=\"#Git命令使用\" class=\"headerlink\" title=\"Git命令使用\"></a>Git命令使用</h2><h3 id=\"配置-amp-管理\"><a href=\"#配置-amp-管理\" class=\"headerlink\" title=\"配置&amp;管理\"></a>配置&amp;管理</h3><ul>\n<li><p>查看Git当前所有配置</p>\n<pre><code class=\"bash\">git config --list\n</code></pre>\n</li>\n<li><p>查看Git指定变量配置</p>\n<pre><code class=\"bash\">git config user.name\n</code></pre>\n</li>\n<li><p>获取帮助命令</p>\n<pre><code class=\"bash\">git help &lt;verb&gt;\ngit &lt;verb&gt; --help\nman git-&lt;verb&gt;\n</code></pre>\n<p>如：获取<code>git config</code>命令手册</p>\n<pre><code class=\"bash\">git help config\n</code></pre>\n</li>\n</ul>\n<h3 id=\"获取仓库\"><a href=\"#获取仓库\" class=\"headerlink\" title=\"获取仓库\"></a>获取仓库</h3><ul>\n<li>将尚未进行版本控制的本地目录转换为<code>Git 仓库</code><pre><code class=\"bash\">git init\n</code></pre>\n</li>\n<li>克隆 一个已存在的<code>Git 仓库</code><pre><code class=\"bash\">git clone https://github.com/xxx\n</code></pre>\n</li>\n</ul>\n<h3 id=\"本地文件操作\"><a href=\"#本地文件操作\" class=\"headerlink\" title=\"本地文件操作\"></a>本地文件操作</h3><ul>\n<li><p>查看当前文件状态</p>\n<pre><code class=\"bash\">git status\n</code></pre>\n</li>\n<li><p>将内容添加到下一次提交中</p>\n<pre><code class=\"bash\">git add .\n</code></pre>\n</li>\n<li><p>提交文件, 产生一次提交记录</p>\n<pre><code class=\"bash\">git commit -m &#39;xx&#39;\n</code></pre>\n</li>\n<li><p>提交文件，向前面提交记录追加文件</p>\n<pre><code class=\"bash\">git commit --amend\n</code></pre>\n</li>\n<li><p>删除跟踪，但是保留文件</p>\n<pre><code class=\"bash\">git rm --cached README\n</code></pre>\n</li>\n<li><p>查看提交历史</p>\n<pre><code class=\"bash\">git log\n</code></pre>\n</li>\n<li><p>查看每次提交的简略统计信息</p>\n<pre><code class=\"bash\">git log --stat\n</code></pre>\n<table>\n<thead>\n<tr>\n<th align=\"center\">选项</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">-p</td>\n<td align=\"center\">按补丁格式显示每个提交引入的差异。</td>\n</tr>\n<tr>\n<td align=\"center\">–stat</td>\n<td align=\"center\">显示每次提交的文件修改统计信息。</td>\n</tr>\n<tr>\n<td align=\"center\">–shortstat</td>\n<td align=\"center\">只显示 –stat 中最后的行数修改添加移除统计。</td>\n</tr>\n<tr>\n<td align=\"center\">–name-only</td>\n<td align=\"center\">仅在提交信息后显示已修改的文件清单。</td>\n</tr>\n<tr>\n<td align=\"center\">–name-status</td>\n<td align=\"center\">显示新增、修改、删除的文件清单。</td>\n</tr>\n<tr>\n<td align=\"center\">–abbrev-commit</td>\n<td align=\"center\">仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。</td>\n</tr>\n<tr>\n<td align=\"center\">–relative-date</td>\n<td align=\"center\">使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。</td>\n</tr>\n<tr>\n<td align=\"center\">–graph</td>\n<td align=\"center\">在日志旁以 ASCII 图形显示分支与合并历史。</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<ul>\n<li><p>按照预订格式:<code>oneline</code>、<code>short</code>、<code>full</code> 和 <code>fuller</code> 查看每次提交历史</p>\n<pre><code class=\"bash\">git log --pretty=oneline\n</code></pre>\n</li>\n<li><p>按照格式:查看每次提交历史</p>\n<pre><code class=\"bash\">git log --pretty=&quot;format:&quot;%h - %an, %ar : %s&quot;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th align=\"center\">选项</th>\n<th align=\"center\">说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">%H</td>\n<td align=\"center\">提交的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%h</td>\n<td align=\"center\">提交的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%T</td>\n<td align=\"center\">树的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%t</td>\n<td align=\"center\">树的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%P</td>\n<td align=\"center\">父提交的完整哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%p</td>\n<td align=\"center\">父提交的简写哈希值</td>\n</tr>\n<tr>\n<td align=\"center\">%an</td>\n<td align=\"center\">作者名字</td>\n</tr>\n<tr>\n<td align=\"center\">%ae</td>\n<td align=\"center\">作者的电子邮件地址</td>\n</tr>\n<tr>\n<td align=\"center\">%ad</td>\n<td align=\"center\">作者修订日期（可以用 –date=选项 来定制格式）</td>\n</tr>\n<tr>\n<td align=\"center\">%ar</td>\n<td align=\"center\">作者修订日期，按多久以前的方式显示</td>\n</tr>\n<tr>\n<td align=\"center\">%cn</td>\n<td align=\"center\">提交者的名字</td>\n</tr>\n<tr>\n<td align=\"center\">%ce</td>\n<td align=\"center\">提交者的电子邮件地址</td>\n</tr>\n<tr>\n<td align=\"center\">%cd</td>\n<td align=\"center\">提交日期</td>\n</tr>\n<tr>\n<td align=\"center\">%cr</td>\n<td align=\"center\">提交日期（距今多长时间）</td>\n</tr>\n<tr>\n<td align=\"center\">%s</td>\n<td align=\"center\">提交说明</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<h3 id=\"远程仓库\"><a href=\"#远程仓库\" class=\"headerlink\" title=\"远程仓库\"></a>远程仓库</h3><ul>\n<li><p>查看远程仓库</p>\n<pre><code class=\"bash\">git remote -v\n</code></pre>\n</li>\n<li><p>添加远程仓库</p>\n<pre><code class=\"bash\">git remote add &lt;shortname&gt; &lt;url&gt;\n</code></pre>\n</li>\n<li><p>从远程仓库中获得数据</p>\n<pre><code class=\"bash\">git fetch &lt;remote&gt;\n</code></pre>\n</li>\n<li><p>从远程仓库中获得数据&amp;并自动尝试合并当前分支</p>\n<pre><code class=\"bash\">git pull &lt;remote&gt;\n</code></pre>\n</li>\n<li><p>推送到远程仓库</p>\n<pre><code class=\"bash\">git push &lt;remote&gt; &lt;branch&gt;\n</code></pre>\n</li>\n<li><p>查看某个远程仓库</p>\n<pre><code class=\"bash\">git remote show &lt;remote&gt;\n</code></pre>\n</li>\n<li><p>远程仓库重命名</p>\n<pre><code class=\"bash\">git remote rename pb paul\n</code></pre>\n</li>\n<li><p>远程仓库移除</p>\n<pre><code class=\"bash\">git remote remove paul\n</code></pre>\n</li>\n</ul>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><ul>\n<li><p>查看标签</p>\n<pre><code class=\"bash\">git tag\n</code></pre>\n</li>\n<li><p>查看某个系列标签</p>\n<pre><code class=\"bash\">git tag -l &quot;1.8.0&quot;\n</code></pre>\n</li>\n<li><p>创建轻量标签</p>\n<pre><code class=\"bash\">git tag v1.4\n</code></pre>\n</li>\n<li><p>创建附注标签</p>\n<pre><code class=\"bash\">git tag -a v1.4 -m &quot;version 1.4&quot;\n</code></pre>\n</li>\n<li><p>查询具体标签信息</p>\n<pre><code>git show v1.4\n</code></pre>\n</li>\n<li><p>推送指定标签</p>\n<pre><code class=\"bash\">git push origin v1.4\n</code></pre>\n</li>\n<li><p>推送全部标签</p>\n<pre><code class=\"bash\">git push origin --tags\n</code></pre>\n</li>\n<li><p>删除本地标签</p>\n<pre><code class=\"bash\">git tag -d v1.4\n</code></pre>\n</li>\n<li><p>删除远程标签</p>\n<pre><code class=\"bash\">git tag --delete v1.4\n</code></pre>\n</li>\n</ul>\n<h3 id=\"Git别名配置\"><a href=\"#Git别名配置\" class=\"headerlink\" title=\"Git别名配置\"></a>Git别名配置</h3><ul>\n<li>设置别名<pre><code class=\"bash\">git config --global alias.co checkout\ngit config --global alias.br branch\ngit config --global alias.ci commit\ngit config --global alias.st status\n</code></pre>\n</li>\n</ul>\n<h3 id=\"分支管理\"><a href=\"#分支管理\" class=\"headerlink\" title=\"分支管理\"></a>分支管理</h3><ul>\n<li><p>创建分支</p>\n<pre><code class=\"bash\">git branch testing\n</code></pre>\n</li>\n<li><p>切换分支</p>\n<pre><code class=\"bash\">git checkout testing\n</code></pre>\n</li>\n<li><p>删除本地分支</p>\n<pre><code class=\"bash\">git branch -d testing\n</code></pre>\n</li>\n<li><p>删除远程分支</p>\n<pre><code class=\"bash\">git push -delete testing\n</code></pre>\n</li>\n<li><p>修改分支跟踪</p>\n<pre><code class=\"bash\">git branch -u origin/serverfix\n</code></pre>\n</li>\n</ul>\n<h3 id=\"分支合并\"><a href=\"#分支合并\" class=\"headerlink\" title=\"分支合并\"></a>分支合并</h3><p>分支合并有2中方式</p>\n<ul>\n<li><code>merge</code></li>\n<li><code>rebase</code><h4 id=\"Merge\"><a href=\"#Merge\" class=\"headerlink\" title=\"Merge\"></a>Merge</h4>会把两个分支的最新快照以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）</li>\n<li>分支合并: 把<branch>分支代码合并到当前分支<pre><code class=\"bash\">git merge &lt;branch&gt;\n</code></pre>\n<img src=\"basic-merging-2.png\" alt=\"merge合并\"></li>\n</ul>\n<ul>\n<li>分支合并冲突解决\n合并两个分支，如果有冲突，合并会停止，必须先解决冲突\n如：<pre><code class=\"html\">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:index.html\n&lt;div id=&quot;footer&quot;&gt;contact : email.support@github.com&lt;/div&gt;\n=======\n&lt;div id=&quot;footer&quot;&gt;\nplease contact us at support@github.com\n&lt;/div&gt;\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; iss53:index.html\n</code></pre>\n</li>\n</ul>\n<p>留下有效代码，把 <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>、<code>=======</code>、<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code> 移除</p>\n<h4 id=\"变基（rebase）\"><a href=\"#变基（rebase）\" class=\"headerlink\" title=\"变基（rebase）\"></a>变基（rebase）</h4><pre><code class=\"bash\">git rebase &lt;branch&gt;\n</code></pre>\n<p>首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master） 的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用.\n案例：</p>\n<pre><code class=\"bash\">git checkout experiment\ngit rebase master\n</code></pre>\n<p><img src=\"basic-rebase-3.png\" alt=\"将 C4 中的修改变基到 C3 上\"></p>\n<blockquote>\n<p><code>优点</code>：变基使得提交历史更加整洁, 提交历史是一条直线没有分叉\n<code>风险</code>：如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基</p>\n</blockquote>\n<h2 id=\"Git服务器\"><a href=\"#Git服务器\" class=\"headerlink\" title=\"Git服务器\"></a>Git服务器</h2><h3 id=\"协议\"><a href=\"#协议\" class=\"headerlink\" title=\"协议\"></a>协议</h3><p>Git 可以使用四种不同的协议来传输资料: <code>本地协议（Local）</code>、<code>HTTP 协议</code>、<code>SSH（Secure Shell）协议</code>及 <code>Git协议</code></p>\n<h4 id=\"本地协议\"><a href=\"#本地协议\" class=\"headerlink\" title=\"本地协议\"></a>本地协议</h4><p>远程版本库就是同一主机上的另一个目录</p>\n<p>去克隆一个版本库或者增加一个远程到现有的项目中，使用版本库路径作为 URL</p>\n<pre><code class=\"bash\">git clone /srv/git/project.git\n\n## 或者\ngit clone file:///srv/git/project.git\n</code></pre>\n<blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>简单</li>\n<li>直接使用了现有的文件权限和网络访问权限</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>共享文件系统比较难配置，并且比起基本的网络连接访问，这不方便从多个位置访问</li>\n<li>并不保护仓库避免意外的损坏。 每一个用户都有“远程”目录的完整 shell 权限，没有方法可以阻止他们修改或删除 Git 内部文件和损坏仓库</li>\n</ul>\n</blockquote>\n<h4 id=\"HTTP协议\"><a href=\"#HTTP协议\" class=\"headerlink\" title=\"HTTP协议\"></a>HTTP协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>像 <code>git:// 协议</code>一样提供匿名服务</li>\n<li>像 <code>SSH 协议</code>一样提供传输时的授权和加密</li>\n<li>使用比SSH简单</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>架设 HTTPS 协议的服务端会比 SSH 协议的棘手一些</li>\n<li>管理凭证会比使用 SSH 密钥认证麻烦一些</li>\n</ul>\n</blockquote>\n<h4 id=\"SSH协议\"><a href=\"#SSH协议\" class=\"headerlink\" title=\"SSH协议\"></a>SSH协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>容易架设</li>\n<li>访问安全：所有传输数据都要经过授权和加密</li>\n<li>协议很高效: 在传输前也会尽量压缩数据</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>不支持匿名访问 <code>Git</code> 仓库</li>\n</ul>\n</blockquote>\n<h4 id=\"Git协议\"><a href=\"#Git协议\" class=\"headerlink\" title=\"Git协议\"></a>Git协议</h4><blockquote>\n<p><strong>优点：</strong></p>\n<ul>\n<li>网络传输协议里最快的</li>\n<li>使用与 SSH 相同的数据传输机制，但是省去了加密和授权的开销</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>缺乏授权机制</li>\n<li>是最难架设的</li>\n</ul>\n</blockquote>\n<h3 id=\"搭建服务器\"><a href=\"#搭建服务器\" class=\"headerlink\" title=\"搭建服务器\"></a>搭建服务器</h3><h4 id=\"GitLab\"><a href=\"#GitLab\" class=\"headerlink\" title=\"GitLab\"></a>GitLab</h4><h3 id=\"SSH配置\"><a href=\"#SSH配置\" class=\"headerlink\" title=\"SSH配置\"></a>SSH配置</h3><ul>\n<li><p>查看用户的 <code>SSH 密钥</code></p>\n<pre><code class=\"bash\">$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n</code></pre>\n</li>\n<li><p>创建<code>SSH 密钥</code></p>\n<pre><code class=\"bash\">ssh-keygen -o\n</code></pre>\n</li>\n<li><p>获取公钥&amp;配置公钥</p>\n<pre><code class=\"bash\">cat ~/.ssh/id_rsa.pub\n</code></pre>\n</li>\n</ul>\n<h2 id=\"Git工作流程\"><a href=\"#Git工作流程\" class=\"headerlink\" title=\"Git工作流程\"></a>Git工作流程</h2><h3 id=\"集中式工作流\"><a href=\"#集中式工作流\" class=\"headerlink\" title=\"集中式工作流\"></a>集中式工作流</h3><p>单点协作模型\n<img src=\"centralized_workflow.png\" alt=\"集中式工作流\"></p>\n<h3 id=\"集成管理者工作流\"><a href=\"#集成管理者工作流\" class=\"headerlink\" title=\"集成管理者工作流\"></a>集成管理者工作流</h3><ol>\n<li><p>项目维护者推送到主仓库。</p>\n</li>\n<li><p>贡献者克隆此仓库，做出修改。</p>\n</li>\n<li><p>贡献者将数据推送到自己的公开仓库。</p>\n</li>\n<li><p>贡献者给维护者发送邮件，请求拉取自己的更新。</p>\n</li>\n<li><p>维护者在自己本地的仓库中，将贡献者的仓库加为远程仓库并合并修改。</p>\n</li>\n<li><p>维护者将合并后的修改推送到主仓库。</p>\n</li>\n</ol>\n<p><img src=\"integration-manager.png\" alt=\"集成管理者工作流\"></p>\n<p>见于Github平台最常用的工作流程.</p>\n<h3 id=\"主管与副主管工作流\"><a href=\"#主管与副主管工作流\" class=\"headerlink\" title=\"主管与副主管工作流\"></a>主管与副主管工作流</h3><p>多仓库工作流程的变种。 一般拥有数百位协作开发者的超大型项目才会用到这样的工作方式</p>\n<p><img src=\"benevolent-dictator.png\" alt=\"主管与副主管工作流\"></p>\n<h2 id=\"Git工具\"><a href=\"#Git工具\" class=\"headerlink\" title=\"Git工具\"></a>Git工具</h2><h3 id=\"grep搜索\"><a href=\"#grep搜索\" class=\"headerlink\" title=\"grep搜索\"></a>grep搜索</h3><p>从提交历史、工作目录、甚至索引中查找一个字符串或者正则表达式.</p>\n<pre><code class=\"bash\">git grep &lt;option&gt; &lt;字符串、正则表达式&gt;\n</code></pre>\n<h3 id=\"日志搜索\"><a href=\"#日志搜索\" class=\"headerlink\" title=\"日志搜索\"></a>日志搜索</h3><ul>\n<li>想找到 <code>&lt;搜索&gt;</code> 是什么时候引入的<pre><code class=\"bash\">git log -S &lt;搜索&gt; --oneline\n</code></pre>\n</li>\n</ul>\n<hr>\n<h2 id=\"Git原理-amp-实现\"><a href=\"#Git原理-amp-实现\" class=\"headerlink\" title=\"Git原理&amp;实现\"></a>Git原理&amp;实现</h2><h3 id=\"Git目录结构\"><a href=\"#Git目录结构\" class=\"headerlink\" title=\"Git目录结构\"></a>Git目录结构</h3><ul>\n<li><p>切换到<code>.git</code>目录</p>\n<pre><code class=\"bash\">cd .git\n</code></pre>\n</li>\n<li><p>Git目录结构</p>\n<pre><code class=\"bash\">ls -F1\n</code></pre>\n<p>目录:</p>\n<pre><code class=\"bash\">COMMIT_EDITMSG\nFETCH_HEAD\nHEAD\nORIG_HEAD\nconfig\ndescription\nhooks/\nindex\ninfo/\nlogs/\nobjects/\npacked-refs\nrefs/\n</code></pre>\n</li>\n<li><p><code>objects</code> 目录存储所有数据内容；</p>\n</li>\n<li><p><code>refs</code> 目录存储指向数据（分支、远程仓库和标签等）的提交对象的指针； </p>\n</li>\n<li><p><code>HEAD</code> 文件指向目前被检出的分支；</p>\n</li>\n<li><p><code>index</code> 文件保存暂存区信息</p>\n</li>\n</ul>\n<h3 id=\"读取文件内容\"><a href=\"#读取文件内容\" class=\"headerlink\" title=\"读取文件内容\"></a>读取文件内容</h3><ul>\n<li><pre><code class=\"bash\">git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4\n</code></pre>\n</li>\n</ul>\n<h3 id=\"存储结构\"><a href=\"#存储结构\" class=\"headerlink\" title=\"存储结构\"></a>存储结构</h3><ul>\n<li><code>blob对象</code>：存储文件快照，而不是差异内容</li>\n<li><code>tree对象</code>：记录着目录结构和 blob 对象索引</li>\n<li><code>commit对象</code>：包含指向前述树对象的指针和所有提交信息</li>\n</ul>\n<p><img src=\"commit-and-tree.png\" alt=\"提交对象及其树结构\"></p>\n<p><img src=\"commits-and-parents.png\" alt=\"提交对象及其父对象\"></p>\n<hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://git-scm.com/book/zh/v2\">Pro Git</a></li>\n<li><a href=\"https://git-scm.com/download/mac\">Git macOS安装</a></li>\n<li>Git权威指南</li>\n</ul>\n"},{"title":"Google分布式系统: BigTable","date":"2021-07-22T10:30:33.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"","source":"_posts/Google分布式系统-BigTable.md","raw":"---\ntitle: 'Google分布式系统: BigTable'\ndate: 2021-07-22 18:30:33\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Google分布式系统\ntags:\n    - 分布式系统\n    - Google分布式系统\n    - 大数据\n---\n","slug":"Google分布式系统-BigTable","published":1,"updated":"2022-03-08T07:37:31.309Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw7q00019op7bqi66d56","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Google Protocol Buffers","date":"2022-02-23T03:19:18.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"","source":"_posts/Google-Protocol-Buffers.md","raw":"---\ntitle: Google Protocol Buffers\ndate: 2022-02-23 11:19:18\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Google分布式系统\ntags:\n    - 分布式系统\n    - Google分布式系统\n    - 大数据\n---\n","slug":"Google-Protocol-Buffers","published":1,"updated":"2022-02-23T03:21:10.184Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8600049op78e3f5zr8","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Google分布式系统——————Dapper，大规模分布式系统的跟踪系统","date":"2022-02-25T03:46:32.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：学习`Google Dapper paper`笔记\n\n\n- 低损耗\n- 应用透明的\n- 大范围部署\n\n---\n\n**参考**\n- [Dapper大规模分布式系统的跟踪系统](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf)\n- [开源Trace标准](https://opentelemetry.io/)","source":"_posts/Google分布式系统-Dapper.md","raw":"---\ntitle: Google分布式系统——————Dapper，大规模分布式系统的跟踪系统\ndate: 2022-02-25 11:46:32\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Google分布式系统\ntags:\n    - Google\n    - 分布式系统\n    - 分布式系统的跟踪系统\n---\n\n> 摘要：学习`Google Dapper paper`笔记\n\n\n- 低损耗\n- 应用透明的\n- 大范围部署\n\n---\n\n**参考**\n- [Dapper大规模分布式系统的跟踪系统](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf)\n- [开源Trace标准](https://opentelemetry.io/)","slug":"Google分布式系统-Dapper","published":1,"updated":"2022-02-25T09:20:54.387Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8700059op7ge6p6duu","content":"<blockquote>\n<p>摘要：学习<code>Google Dapper paper</code>笔记</p>\n</blockquote>\n<ul>\n<li>低损耗</li>\n<li>应用透明的</li>\n<li>大范围部署</li>\n</ul>\n<hr>\n<p><strong>参考</strong></p>\n<ul>\n<li><a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf\">Dapper大规模分布式系统的跟踪系统</a></li>\n<li><a href=\"https://opentelemetry.io/\">开源Trace标准</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：学习<code>Google Dapper paper</code>笔记</p>\n</blockquote>\n<ul>\n<li>低损耗</li>\n<li>应用透明的</li>\n<li>大范围部署</li>\n</ul>\n<hr>\n<p><strong>参考</strong></p>\n<ul>\n<li><a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf\">Dapper大规模分布式系统的跟踪系统</a></li>\n<li><a href=\"https://opentelemetry.io/\">开源Trace标准</a></li>\n</ul>\n"},{"title":"Google分布式系统: GFS","date":"2021-07-22T10:30:33.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：学习`GFS`论文，汇总`GFS`知识点、翻译`GFS`论文等, 方便后续回顾\n\n---\n\n---\n## 翻译\n### ABSTRACT（摘要）\n\n> We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications.\n> It provides fault tolerance while running on inexpensive commodity hardware,\n> and it delivers high aggregate performance to a large number of clients.\n>\n> 我们设计并实现了 Google File System，\n> 这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用程序。\n> 它提供容错，同时在廉价的商品硬件上运行，它提供为大量客户提供高聚合性能.\n\n> While sharing many of the same goals as previous distributed file systems,\n> our design has been driven by observations of our application workloads and technological environment, both current and anticipated,\n> that reflect a marked departure from some earlier file system assumptions.\n> This has led us to reexamine traditional choices and explore radically different design points.\n>\n> 虽然与以前的分布式文件系统有许多相同的目标,\n> 但我们的设计是由对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n> 这反映了与早期文件系统假设的明显不同。\n> 这导致我们重新审视传统选择并探索完全不同的设计点。\n\nThe file system has successfully met our storage needs.\nIt is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets.\nThe largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines,\nand it is concurrently accessed by hundreds of clients\n\n> 文件系统已经成功满足了我们的存储需求。\n> 它作为存储平台广泛部署在 Google 内部用于我们服务所使用的数据的生成和处理以及需要的研究和开发工作大数据集.\n> 迄今为止最大的集群在数千个磁盘上提供数百 TB 的存储空间上千台机器，\n> 并发访问由数百名客户\n\nIn this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.\n\n> 在本文中, 我们介绍了文件系统接口扩展旨在支持分布式应用程序, 讨论许多我们设计的各个方面，并报告两者的测量结果微基准和现实世界的使用。\n\n### INTRODUCTION（引言）\n```text\n    We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs.\nGFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.\nHowever, its design has been driven by key observations of our application workloads and technological environment,\nboth current and anticipated,\nthat reflect a marked departure from some earlier file system design assumptions.\nWe have reexamined traditional choices and explored radically different points in the design space.\n\n我们设计并实施了 Google 文件系统 (GFS)，以满足 Google 快速增长的数据处理需求。\nGFS与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。 \n然而，它的设计受到对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统设计假设的明显不同。\n我们重新审视了传统的选择，并探索了设计空间中截然不同的点。\n\n    First, component failures are the norm rather than the exception.\nThe file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures.\nWe have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. \nTherefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.\n\n    首先, 组件故障是常态而不是例外.\n文件系统由数百甚至数千台廉价存储机器构建组成的，并由相当数量的客户端机器访问。 \n组件的数量和质量实际上保证了某些组件在任何时间都正常工作，有些组件甚至无法从当前的故障中恢复。\n我们已经看到了由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。\n因此，持续监控、错误检测、容错和自动恢复必须是系统的组成部分。\n\n    Second, files are huge by traditional standards.\nMulti-GB files are common. Each file typically contains many application objects such as web documents.\nWhen we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it.\nAs a result, design assumptions and parameters such as I/O operation and blocksizes have to be revisited.\n\n    其次，按照传统标准，文件很大.\n多 GB 文件很常见。 每个文件通常包含许多应用程序对象，例如 Web 文档。\n当我们经常处理包含数十亿对象许多 TB 级的快速增长的数据集时，即使文件系统可以支持它，但管理数十亿大约 KB 大小的文件也很笨拙。\n因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n\n    Third, most files are mutated by appending new data rather than overwriting existing data. \nRandom writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. \nSome may be data streams continuously generated by running applications.\nSome may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. \nGiven this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.\n\n    第三，大多数文件是通过附加新数据而不是覆盖现有数据来改变的。\n文件中的随机写入实际上是不存在的。 一旦写入，文件就只能被读取，而且通常只能按顺序读取。 各种数据共享这些特征。 有些可能构成数据分析程序扫描的大型存储库。\n有些可能是运行应用程序不断产生的数据流。\n有些可能是档案数据。 有些可能是在一台机器上产生并在另一台机器上处理的中间结果，无论是同时还是稍后。\n鉴于这种对大文件的访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块就失去了吸引力。\n\n    Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.\nFor example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. \nThese will be discussed in more details later in the paper.\n\n    第四，共同设计应用程序和文件系统 API 通过增加我们的灵活性使整个系统受益。\n例如，我们放宽了 GFS 的一致性模型，以极大地简化文件系统，而不会给应用程序带来繁重的负担。 我们还引入了原子追加操作，以便多个客户端可以同时追加到一个文件，而无需在它们之间进行额外的同步。\n这些将在本文后面更详细地讨论。\n\n    Multiple GFS clusters are currently deployed for different purposes. \nThe largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis.\n\n    目前为不同的目的部署了多个 GFS 集群。\n最大的有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并且被不同机器上的数百个客户端持续频繁地访问。\n```\n\n### 2 DESIGN OVERVIEW（设计概述）\n#### 2.1 Assumptions\n#### 2.2 Interface\n#### 2.3 Architecture\n#### 2.4 Single Master\n#### 2.5 Chunk Size\n#### 2.6 Metadata\n#### 2.7 Consistency Mode\n\n### 3. SYSTEM INTERACTIONS（系统交互）\n#### 3.1 Leases and Mutation Order\n#### 3.2 Data Flow\n#### 3.3 Atomic Record Appends\n#### 3.4 Snapshot\n\n\n### 4. MASTER OPERATION（Master节点操作）\n#### 4.1 Namespace Management and Locking\n#### 4.2 Replica Placement\n#### 4.3 Creation, Re-replication, Rebalancing\n#### 4.4 Garbage Collection\n#### 4.5  Stale Replica Detection\n\n\n### 5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）\n#### 5.1 High Availability\n#### 5.2 Data Integrity\n#### 5.3 Diagnostic Tools\n\n\n### 6. MEASUREMENTS（度量）\n#### 6.1 Micro-benchmarks\n##### 6.1.3 Record Appends\n#### 6.2 Real World Clusters\n\n\n### 7. MEASUREMENTS（经验）\n\n### 8. MEASUREMENTS（相关工作）\n\n### 9. MEASUREMENTS（结束语）\n\n---\n\n##### 参考\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf)\n","source":"_posts/Google分布式系统-GFS.md","raw":"---\ntitle: 'Google分布式系统: GFS'\ndate: 2021-07-22 18:30:33\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Google分布式系统\ntags:\n    - 分布式系统\n    - Google\n    - 分布式文件系统\n---\n\n> 摘要：学习`GFS`论文，汇总`GFS`知识点、翻译`GFS`论文等, 方便后续回顾\n\n---\n\n---\n## 翻译\n### ABSTRACT（摘要）\n\n> We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications.\n> It provides fault tolerance while running on inexpensive commodity hardware,\n> and it delivers high aggregate performance to a large number of clients.\n>\n> 我们设计并实现了 Google File System，\n> 这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用程序。\n> 它提供容错，同时在廉价的商品硬件上运行，它提供为大量客户提供高聚合性能.\n\n> While sharing many of the same goals as previous distributed file systems,\n> our design has been driven by observations of our application workloads and technological environment, both current and anticipated,\n> that reflect a marked departure from some earlier file system assumptions.\n> This has led us to reexamine traditional choices and explore radically different design points.\n>\n> 虽然与以前的分布式文件系统有许多相同的目标,\n> 但我们的设计是由对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n> 这反映了与早期文件系统假设的明显不同。\n> 这导致我们重新审视传统选择并探索完全不同的设计点。\n\nThe file system has successfully met our storage needs.\nIt is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets.\nThe largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines,\nand it is concurrently accessed by hundreds of clients\n\n> 文件系统已经成功满足了我们的存储需求。\n> 它作为存储平台广泛部署在 Google 内部用于我们服务所使用的数据的生成和处理以及需要的研究和开发工作大数据集.\n> 迄今为止最大的集群在数千个磁盘上提供数百 TB 的存储空间上千台机器，\n> 并发访问由数百名客户\n\nIn this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.\n\n> 在本文中, 我们介绍了文件系统接口扩展旨在支持分布式应用程序, 讨论许多我们设计的各个方面，并报告两者的测量结果微基准和现实世界的使用。\n\n### INTRODUCTION（引言）\n```text\n    We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs.\nGFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.\nHowever, its design has been driven by key observations of our application workloads and technological environment,\nboth current and anticipated,\nthat reflect a marked departure from some earlier file system design assumptions.\nWe have reexamined traditional choices and explored radically different points in the design space.\n\n我们设计并实施了 Google 文件系统 (GFS)，以满足 Google 快速增长的数据处理需求。\nGFS与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。 \n然而，它的设计受到对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统设计假设的明显不同。\n我们重新审视了传统的选择，并探索了设计空间中截然不同的点。\n\n    First, component failures are the norm rather than the exception.\nThe file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures.\nWe have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. \nTherefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.\n\n    首先, 组件故障是常态而不是例外.\n文件系统由数百甚至数千台廉价存储机器构建组成的，并由相当数量的客户端机器访问。 \n组件的数量和质量实际上保证了某些组件在任何时间都正常工作，有些组件甚至无法从当前的故障中恢复。\n我们已经看到了由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。\n因此，持续监控、错误检测、容错和自动恢复必须是系统的组成部分。\n\n    Second, files are huge by traditional standards.\nMulti-GB files are common. Each file typically contains many application objects such as web documents.\nWhen we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it.\nAs a result, design assumptions and parameters such as I/O operation and blocksizes have to be revisited.\n\n    其次，按照传统标准，文件很大.\n多 GB 文件很常见。 每个文件通常包含许多应用程序对象，例如 Web 文档。\n当我们经常处理包含数十亿对象许多 TB 级的快速增长的数据集时，即使文件系统可以支持它，但管理数十亿大约 KB 大小的文件也很笨拙。\n因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n\n    Third, most files are mutated by appending new data rather than overwriting existing data. \nRandom writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. \nSome may be data streams continuously generated by running applications.\nSome may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. \nGiven this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.\n\n    第三，大多数文件是通过附加新数据而不是覆盖现有数据来改变的。\n文件中的随机写入实际上是不存在的。 一旦写入，文件就只能被读取，而且通常只能按顺序读取。 各种数据共享这些特征。 有些可能构成数据分析程序扫描的大型存储库。\n有些可能是运行应用程序不断产生的数据流。\n有些可能是档案数据。 有些可能是在一台机器上产生并在另一台机器上处理的中间结果，无论是同时还是稍后。\n鉴于这种对大文件的访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块就失去了吸引力。\n\n    Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.\nFor example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. \nThese will be discussed in more details later in the paper.\n\n    第四，共同设计应用程序和文件系统 API 通过增加我们的灵活性使整个系统受益。\n例如，我们放宽了 GFS 的一致性模型，以极大地简化文件系统，而不会给应用程序带来繁重的负担。 我们还引入了原子追加操作，以便多个客户端可以同时追加到一个文件，而无需在它们之间进行额外的同步。\n这些将在本文后面更详细地讨论。\n\n    Multiple GFS clusters are currently deployed for different purposes. \nThe largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis.\n\n    目前为不同的目的部署了多个 GFS 集群。\n最大的有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并且被不同机器上的数百个客户端持续频繁地访问。\n```\n\n### 2 DESIGN OVERVIEW（设计概述）\n#### 2.1 Assumptions\n#### 2.2 Interface\n#### 2.3 Architecture\n#### 2.4 Single Master\n#### 2.5 Chunk Size\n#### 2.6 Metadata\n#### 2.7 Consistency Mode\n\n### 3. SYSTEM INTERACTIONS（系统交互）\n#### 3.1 Leases and Mutation Order\n#### 3.2 Data Flow\n#### 3.3 Atomic Record Appends\n#### 3.4 Snapshot\n\n\n### 4. MASTER OPERATION（Master节点操作）\n#### 4.1 Namespace Management and Locking\n#### 4.2 Replica Placement\n#### 4.3 Creation, Re-replication, Rebalancing\n#### 4.4 Garbage Collection\n#### 4.5  Stale Replica Detection\n\n\n### 5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）\n#### 5.1 High Availability\n#### 5.2 Data Integrity\n#### 5.3 Diagnostic Tools\n\n\n### 6. MEASUREMENTS（度量）\n#### 6.1 Micro-benchmarks\n##### 6.1.3 Record Appends\n#### 6.2 Real World Clusters\n\n\n### 7. MEASUREMENTS（经验）\n\n### 8. MEASUREMENTS（相关工作）\n\n### 9. MEASUREMENTS（结束语）\n\n---\n\n##### 参考\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf)\n","slug":"Google分布式系统-GFS","published":1,"updated":"2022-02-18T04:07:08.901Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8800069op75b8ke8qf","content":"<blockquote>\n<p>摘要：学习<code>GFS</code>论文，汇总<code>GFS</code>知识点、翻译<code>GFS</code>论文等, 方便后续回顾</p>\n</blockquote>\n<hr>\n<hr>\n<h2 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h2><h3 id=\"ABSTRACT（摘要）\"><a href=\"#ABSTRACT（摘要）\" class=\"headerlink\" title=\"ABSTRACT（摘要）\"></a>ABSTRACT（摘要）</h3><blockquote>\n<p>We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications.\nIt provides fault tolerance while running on inexpensive commodity hardware,\nand it delivers high aggregate performance to a large number of clients.</p>\n<p>我们设计并实现了 Google File System，\n这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用程序。\n它提供容错，同时在廉价的商品硬件上运行，它提供为大量客户提供高聚合性能.</p>\n</blockquote>\n<blockquote>\n<p>While sharing many of the same goals as previous distributed file systems,\nour design has been driven by observations of our application workloads and technological environment, both current and anticipated,\nthat reflect a marked departure from some earlier file system assumptions.\nThis has led us to reexamine traditional choices and explore radically different design points.</p>\n<p>虽然与以前的分布式文件系统有许多相同的目标,\n但我们的设计是由对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统假设的明显不同。\n这导致我们重新审视传统选择并探索完全不同的设计点。</p>\n</blockquote>\n<p>The file system has successfully met our storage needs.\nIt is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets.\nThe largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines,\nand it is concurrently accessed by hundreds of clients</p>\n<blockquote>\n<p>文件系统已经成功满足了我们的存储需求。\n它作为存储平台广泛部署在 Google 内部用于我们服务所使用的数据的生成和处理以及需要的研究和开发工作大数据集.\n迄今为止最大的集群在数千个磁盘上提供数百 TB 的存储空间上千台机器，\n并发访问由数百名客户</p>\n</blockquote>\n<p>In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.</p>\n<blockquote>\n<p>在本文中, 我们介绍了文件系统接口扩展旨在支持分布式应用程序, 讨论许多我们设计的各个方面，并报告两者的测量结果微基准和现实世界的使用。</p>\n</blockquote>\n<h3 id=\"INTRODUCTION（引言）\"><a href=\"#INTRODUCTION（引言）\" class=\"headerlink\" title=\"INTRODUCTION（引言）\"></a>INTRODUCTION（引言）</h3><pre class=\" language-text\"><code class=\"language-text\">    We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs.\nGFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.\nHowever, its design has been driven by key observations of our application workloads and technological environment,\nboth current and anticipated,\nthat reflect a marked departure from some earlier file system design assumptions.\nWe have reexamined traditional choices and explored radically different points in the design space.\n\n我们设计并实施了 Google 文件系统 (GFS)，以满足 Google 快速增长的数据处理需求。\nGFS与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。 \n然而，它的设计受到对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统设计假设的明显不同。\n我们重新审视了传统的选择，并探索了设计空间中截然不同的点。\n\n    First, component failures are the norm rather than the exception.\nThe file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures.\nWe have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. \nTherefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.\n\n    首先, 组件故障是常态而不是例外.\n文件系统由数百甚至数千台廉价存储机器构建组成的，并由相当数量的客户端机器访问。 \n组件的数量和质量实际上保证了某些组件在任何时间都正常工作，有些组件甚至无法从当前的故障中恢复。\n我们已经看到了由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。\n因此，持续监控、错误检测、容错和自动恢复必须是系统的组成部分。\n\n    Second, files are huge by traditional standards.\nMulti-GB files are common. Each file typically contains many application objects such as web documents.\nWhen we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it.\nAs a result, design assumptions and parameters such as I/O operation and blocksizes have to be revisited.\n\n    其次，按照传统标准，文件很大.\n多 GB 文件很常见。 每个文件通常包含许多应用程序对象，例如 Web 文档。\n当我们经常处理包含数十亿对象许多 TB 级的快速增长的数据集时，即使文件系统可以支持它，但管理数十亿大约 KB 大小的文件也很笨拙。\n因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n\n    Third, most files are mutated by appending new data rather than overwriting existing data. \nRandom writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. \nSome may be data streams continuously generated by running applications.\nSome may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. \nGiven this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.\n\n    第三，大多数文件是通过附加新数据而不是覆盖现有数据来改变的。\n文件中的随机写入实际上是不存在的。 一旦写入，文件就只能被读取，而且通常只能按顺序读取。 各种数据共享这些特征。 有些可能构成数据分析程序扫描的大型存储库。\n有些可能是运行应用程序不断产生的数据流。\n有些可能是档案数据。 有些可能是在一台机器上产生并在另一台机器上处理的中间结果，无论是同时还是稍后。\n鉴于这种对大文件的访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块就失去了吸引力。\n\n    Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.\nFor example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. \nThese will be discussed in more details later in the paper.\n\n    第四，共同设计应用程序和文件系统 API 通过增加我们的灵活性使整个系统受益。\n例如，我们放宽了 GFS 的一致性模型，以极大地简化文件系统，而不会给应用程序带来繁重的负担。 我们还引入了原子追加操作，以便多个客户端可以同时追加到一个文件，而无需在它们之间进行额外的同步。\n这些将在本文后面更详细地讨论。\n\n    Multiple GFS clusters are currently deployed for different purposes. \nThe largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis.\n\n    目前为不同的目的部署了多个 GFS 集群。\n最大的有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并且被不同机器上的数百个客户端持续频繁地访问。\n</code></pre>\n<h3 id=\"2-DESIGN-OVERVIEW（设计概述）\"><a href=\"#2-DESIGN-OVERVIEW（设计概述）\" class=\"headerlink\" title=\"2 DESIGN OVERVIEW（设计概述）\"></a>2 DESIGN OVERVIEW（设计概述）</h3><h4 id=\"2-1-Assumptions\"><a href=\"#2-1-Assumptions\" class=\"headerlink\" title=\"2.1 Assumptions\"></a>2.1 Assumptions</h4><h4 id=\"2-2-Interface\"><a href=\"#2-2-Interface\" class=\"headerlink\" title=\"2.2 Interface\"></a>2.2 Interface</h4><h4 id=\"2-3-Architecture\"><a href=\"#2-3-Architecture\" class=\"headerlink\" title=\"2.3 Architecture\"></a>2.3 Architecture</h4><h4 id=\"2-4-Single-Master\"><a href=\"#2-4-Single-Master\" class=\"headerlink\" title=\"2.4 Single Master\"></a>2.4 Single Master</h4><h4 id=\"2-5-Chunk-Size\"><a href=\"#2-5-Chunk-Size\" class=\"headerlink\" title=\"2.5 Chunk Size\"></a>2.5 Chunk Size</h4><h4 id=\"2-6-Metadata\"><a href=\"#2-6-Metadata\" class=\"headerlink\" title=\"2.6 Metadata\"></a>2.6 Metadata</h4><h4 id=\"2-7-Consistency-Mode\"><a href=\"#2-7-Consistency-Mode\" class=\"headerlink\" title=\"2.7 Consistency Mode\"></a>2.7 Consistency Mode</h4><h3 id=\"3-SYSTEM-INTERACTIONS（系统交互）\"><a href=\"#3-SYSTEM-INTERACTIONS（系统交互）\" class=\"headerlink\" title=\"3. SYSTEM INTERACTIONS（系统交互）\"></a>3. SYSTEM INTERACTIONS（系统交互）</h3><h4 id=\"3-1-Leases-and-Mutation-Order\"><a href=\"#3-1-Leases-and-Mutation-Order\" class=\"headerlink\" title=\"3.1 Leases and Mutation Order\"></a>3.1 Leases and Mutation Order</h4><h4 id=\"3-2-Data-Flow\"><a href=\"#3-2-Data-Flow\" class=\"headerlink\" title=\"3.2 Data Flow\"></a>3.2 Data Flow</h4><h4 id=\"3-3-Atomic-Record-Appends\"><a href=\"#3-3-Atomic-Record-Appends\" class=\"headerlink\" title=\"3.3 Atomic Record Appends\"></a>3.3 Atomic Record Appends</h4><h4 id=\"3-4-Snapshot\"><a href=\"#3-4-Snapshot\" class=\"headerlink\" title=\"3.4 Snapshot\"></a>3.4 Snapshot</h4><h3 id=\"4-MASTER-OPERATION（Master节点操作）\"><a href=\"#4-MASTER-OPERATION（Master节点操作）\" class=\"headerlink\" title=\"4. MASTER OPERATION（Master节点操作）\"></a>4. MASTER OPERATION（Master节点操作）</h3><h4 id=\"4-1-Namespace-Management-and-Locking\"><a href=\"#4-1-Namespace-Management-and-Locking\" class=\"headerlink\" title=\"4.1 Namespace Management and Locking\"></a>4.1 Namespace Management and Locking</h4><h4 id=\"4-2-Replica-Placement\"><a href=\"#4-2-Replica-Placement\" class=\"headerlink\" title=\"4.2 Replica Placement\"></a>4.2 Replica Placement</h4><h4 id=\"4-3-Creation-Re-replication-Rebalancing\"><a href=\"#4-3-Creation-Re-replication-Rebalancing\" class=\"headerlink\" title=\"4.3 Creation, Re-replication, Rebalancing\"></a>4.3 Creation, Re-replication, Rebalancing</h4><h4 id=\"4-4-Garbage-Collection\"><a href=\"#4-4-Garbage-Collection\" class=\"headerlink\" title=\"4.4 Garbage Collection\"></a>4.4 Garbage Collection</h4><h4 id=\"4-5-Stale-Replica-Detection\"><a href=\"#4-5-Stale-Replica-Detection\" class=\"headerlink\" title=\"4.5  Stale Replica Detection\"></a>4.5  Stale Replica Detection</h4><h3 id=\"5-FAULT-TOLERANCE-AND-DIAGNOSIS（容错和诊断）\"><a href=\"#5-FAULT-TOLERANCE-AND-DIAGNOSIS（容错和诊断）\" class=\"headerlink\" title=\"5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）\"></a>5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）</h3><h4 id=\"5-1-High-Availability\"><a href=\"#5-1-High-Availability\" class=\"headerlink\" title=\"5.1 High Availability\"></a>5.1 High Availability</h4><h4 id=\"5-2-Data-Integrity\"><a href=\"#5-2-Data-Integrity\" class=\"headerlink\" title=\"5.2 Data Integrity\"></a>5.2 Data Integrity</h4><h4 id=\"5-3-Diagnostic-Tools\"><a href=\"#5-3-Diagnostic-Tools\" class=\"headerlink\" title=\"5.3 Diagnostic Tools\"></a>5.3 Diagnostic Tools</h4><h3 id=\"6-MEASUREMENTS（度量）\"><a href=\"#6-MEASUREMENTS（度量）\" class=\"headerlink\" title=\"6. MEASUREMENTS（度量）\"></a>6. MEASUREMENTS（度量）</h3><h4 id=\"6-1-Micro-benchmarks\"><a href=\"#6-1-Micro-benchmarks\" class=\"headerlink\" title=\"6.1 Micro-benchmarks\"></a>6.1 Micro-benchmarks</h4><h5 id=\"6-1-3-Record-Appends\"><a href=\"#6-1-3-Record-Appends\" class=\"headerlink\" title=\"6.1.3 Record Appends\"></a>6.1.3 Record Appends</h5><h4 id=\"6-2-Real-World-Clusters\"><a href=\"#6-2-Real-World-Clusters\" class=\"headerlink\" title=\"6.2 Real World Clusters\"></a>6.2 Real World Clusters</h4><h3 id=\"7-MEASUREMENTS（经验）\"><a href=\"#7-MEASUREMENTS（经验）\" class=\"headerlink\" title=\"7. MEASUREMENTS（经验）\"></a>7. MEASUREMENTS（经验）</h3><h3 id=\"8-MEASUREMENTS（相关工作）\"><a href=\"#8-MEASUREMENTS（相关工作）\" class=\"headerlink\" title=\"8. MEASUREMENTS（相关工作）\"></a>8. MEASUREMENTS（相关工作）</h3><h3 id=\"9-MEASUREMENTS（结束语）\"><a href=\"#9-MEASUREMENTS（结束语）\" class=\"headerlink\" title=\"9. MEASUREMENTS（结束语）\"></a>9. MEASUREMENTS（结束语）</h3><hr>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ul>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf\">The Google File System</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：学习<code>GFS</code>论文，汇总<code>GFS</code>知识点、翻译<code>GFS</code>论文等, 方便后续回顾</p>\n</blockquote>\n<hr>\n<hr>\n<h2 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h2><h3 id=\"ABSTRACT（摘要）\"><a href=\"#ABSTRACT（摘要）\" class=\"headerlink\" title=\"ABSTRACT（摘要）\"></a>ABSTRACT（摘要）</h3><blockquote>\n<p>We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications.\nIt provides fault tolerance while running on inexpensive commodity hardware,\nand it delivers high aggregate performance to a large number of clients.</p>\n<p>我们设计并实现了 Google File System，\n这是一个可扩展的分布式文件系统，适用于大型分布式数据密集型应用程序。\n它提供容错，同时在廉价的商品硬件上运行，它提供为大量客户提供高聚合性能.</p>\n</blockquote>\n<blockquote>\n<p>While sharing many of the same goals as previous distributed file systems,\nour design has been driven by observations of our application workloads and technological environment, both current and anticipated,\nthat reflect a marked departure from some earlier file system assumptions.\nThis has led us to reexamine traditional choices and explore radically different design points.</p>\n<p>虽然与以前的分布式文件系统有许多相同的目标,\n但我们的设计是由对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统假设的明显不同。\n这导致我们重新审视传统选择并探索完全不同的设计点。</p>\n</blockquote>\n<p>The file system has successfully met our storage needs.\nIt is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets.\nThe largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines,\nand it is concurrently accessed by hundreds of clients</p>\n<blockquote>\n<p>文件系统已经成功满足了我们的存储需求。\n它作为存储平台广泛部署在 Google 内部用于我们服务所使用的数据的生成和处理以及需要的研究和开发工作大数据集.\n迄今为止最大的集群在数千个磁盘上提供数百 TB 的存储空间上千台机器，\n并发访问由数百名客户</p>\n</blockquote>\n<p>In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.</p>\n<blockquote>\n<p>在本文中, 我们介绍了文件系统接口扩展旨在支持分布式应用程序, 讨论许多我们设计的各个方面，并报告两者的测量结果微基准和现实世界的使用。</p>\n</blockquote>\n<h3 id=\"INTRODUCTION（引言）\"><a href=\"#INTRODUCTION（引言）\" class=\"headerlink\" title=\"INTRODUCTION（引言）\"></a>INTRODUCTION（引言）</h3><pre><code class=\"text\">    We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs.\nGFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability.\nHowever, its design has been driven by key observations of our application workloads and technological environment,\nboth current and anticipated,\nthat reflect a marked departure from some earlier file system design assumptions.\nWe have reexamined traditional choices and explored radically different points in the design space.\n\n我们设计并实施了 Google 文件系统 (GFS)，以满足 Google 快速增长的数据处理需求。\nGFS与以前的分布式文件系统有许多相同的目标，如性能、可扩展性、可靠性和可用性。 \n然而，它的设计受到对我们当前和预期的应用程序工作负载和技术环境的关键观察推动的，\n这反映了与早期文件系统设计假设的明显不同。\n我们重新审视了传统的选择，并探索了设计空间中截然不同的点。\n\n    First, component failures are the norm rather than the exception.\nThe file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures.\nWe have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. \nTherefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system.\n\n    首先, 组件故障是常态而不是例外.\n文件系统由数百甚至数千台廉价存储机器构建组成的，并由相当数量的客户端机器访问。 \n组件的数量和质量实际上保证了某些组件在任何时间都正常工作，有些组件甚至无法从当前的故障中恢复。\n我们已经看到了由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。\n因此，持续监控、错误检测、容错和自动恢复必须是系统的组成部分。\n\n    Second, files are huge by traditional standards.\nMulti-GB files are common. Each file typically contains many application objects such as web documents.\nWhen we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it.\nAs a result, design assumptions and parameters such as I/O operation and blocksizes have to be revisited.\n\n    其次，按照传统标准，文件很大.\n多 GB 文件很常见。 每个文件通常包含许多应用程序对象，例如 Web 文档。\n当我们经常处理包含数十亿对象许多 TB 级的快速增长的数据集时，即使文件系统可以支持它，但管理数十亿大约 KB 大小的文件也很笨拙。\n因此，必须重新审视 I/O 操作和块大小等设计假设和参数。\n\n    Third, most files are mutated by appending new data rather than overwriting existing data. \nRandom writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. \nSome may be data streams continuously generated by running applications.\nSome may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. \nGiven this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal.\n\n    第三，大多数文件是通过附加新数据而不是覆盖现有数据来改变的。\n文件中的随机写入实际上是不存在的。 一旦写入，文件就只能被读取，而且通常只能按顺序读取。 各种数据共享这些特征。 有些可能构成数据分析程序扫描的大型存储库。\n有些可能是运行应用程序不断产生的数据流。\n有些可能是档案数据。 有些可能是在一台机器上产生并在另一台机器上处理的中间结果，无论是同时还是稍后。\n鉴于这种对大文件的访问模式，追加成为性能优化和原子性保证的重点，而在客户端缓存数据块就失去了吸引力。\n\n    Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility.\nFor example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. \nThese will be discussed in more details later in the paper.\n\n    第四，共同设计应用程序和文件系统 API 通过增加我们的灵活性使整个系统受益。\n例如，我们放宽了 GFS 的一致性模型，以极大地简化文件系统，而不会给应用程序带来繁重的负担。 我们还引入了原子追加操作，以便多个客户端可以同时追加到一个文件，而无需在它们之间进行额外的同步。\n这些将在本文后面更详细地讨论。\n\n    Multiple GFS clusters are currently deployed for different purposes. \nThe largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis.\n\n    目前为不同的目的部署了多个 GFS 集群。\n最大的有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并且被不同机器上的数百个客户端持续频繁地访问。\n</code></pre>\n<h3 id=\"2-DESIGN-OVERVIEW（设计概述）\"><a href=\"#2-DESIGN-OVERVIEW（设计概述）\" class=\"headerlink\" title=\"2 DESIGN OVERVIEW（设计概述）\"></a>2 DESIGN OVERVIEW（设计概述）</h3><h4 id=\"2-1-Assumptions\"><a href=\"#2-1-Assumptions\" class=\"headerlink\" title=\"2.1 Assumptions\"></a>2.1 Assumptions</h4><h4 id=\"2-2-Interface\"><a href=\"#2-2-Interface\" class=\"headerlink\" title=\"2.2 Interface\"></a>2.2 Interface</h4><h4 id=\"2-3-Architecture\"><a href=\"#2-3-Architecture\" class=\"headerlink\" title=\"2.3 Architecture\"></a>2.3 Architecture</h4><h4 id=\"2-4-Single-Master\"><a href=\"#2-4-Single-Master\" class=\"headerlink\" title=\"2.4 Single Master\"></a>2.4 Single Master</h4><h4 id=\"2-5-Chunk-Size\"><a href=\"#2-5-Chunk-Size\" class=\"headerlink\" title=\"2.5 Chunk Size\"></a>2.5 Chunk Size</h4><h4 id=\"2-6-Metadata\"><a href=\"#2-6-Metadata\" class=\"headerlink\" title=\"2.6 Metadata\"></a>2.6 Metadata</h4><h4 id=\"2-7-Consistency-Mode\"><a href=\"#2-7-Consistency-Mode\" class=\"headerlink\" title=\"2.7 Consistency Mode\"></a>2.7 Consistency Mode</h4><h3 id=\"3-SYSTEM-INTERACTIONS（系统交互）\"><a href=\"#3-SYSTEM-INTERACTIONS（系统交互）\" class=\"headerlink\" title=\"3. SYSTEM INTERACTIONS（系统交互）\"></a>3. SYSTEM INTERACTIONS（系统交互）</h3><h4 id=\"3-1-Leases-and-Mutation-Order\"><a href=\"#3-1-Leases-and-Mutation-Order\" class=\"headerlink\" title=\"3.1 Leases and Mutation Order\"></a>3.1 Leases and Mutation Order</h4><h4 id=\"3-2-Data-Flow\"><a href=\"#3-2-Data-Flow\" class=\"headerlink\" title=\"3.2 Data Flow\"></a>3.2 Data Flow</h4><h4 id=\"3-3-Atomic-Record-Appends\"><a href=\"#3-3-Atomic-Record-Appends\" class=\"headerlink\" title=\"3.3 Atomic Record Appends\"></a>3.3 Atomic Record Appends</h4><h4 id=\"3-4-Snapshot\"><a href=\"#3-4-Snapshot\" class=\"headerlink\" title=\"3.4 Snapshot\"></a>3.4 Snapshot</h4><h3 id=\"4-MASTER-OPERATION（Master节点操作）\"><a href=\"#4-MASTER-OPERATION（Master节点操作）\" class=\"headerlink\" title=\"4. MASTER OPERATION（Master节点操作）\"></a>4. MASTER OPERATION（Master节点操作）</h3><h4 id=\"4-1-Namespace-Management-and-Locking\"><a href=\"#4-1-Namespace-Management-and-Locking\" class=\"headerlink\" title=\"4.1 Namespace Management and Locking\"></a>4.1 Namespace Management and Locking</h4><h4 id=\"4-2-Replica-Placement\"><a href=\"#4-2-Replica-Placement\" class=\"headerlink\" title=\"4.2 Replica Placement\"></a>4.2 Replica Placement</h4><h4 id=\"4-3-Creation-Re-replication-Rebalancing\"><a href=\"#4-3-Creation-Re-replication-Rebalancing\" class=\"headerlink\" title=\"4.3 Creation, Re-replication, Rebalancing\"></a>4.3 Creation, Re-replication, Rebalancing</h4><h4 id=\"4-4-Garbage-Collection\"><a href=\"#4-4-Garbage-Collection\" class=\"headerlink\" title=\"4.4 Garbage Collection\"></a>4.4 Garbage Collection</h4><h4 id=\"4-5-Stale-Replica-Detection\"><a href=\"#4-5-Stale-Replica-Detection\" class=\"headerlink\" title=\"4.5  Stale Replica Detection\"></a>4.5  Stale Replica Detection</h4><h3 id=\"5-FAULT-TOLERANCE-AND-DIAGNOSIS（容错和诊断）\"><a href=\"#5-FAULT-TOLERANCE-AND-DIAGNOSIS（容错和诊断）\" class=\"headerlink\" title=\"5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）\"></a>5. FAULT TOLERANCE AND DIAGNOSIS（容错和诊断）</h3><h4 id=\"5-1-High-Availability\"><a href=\"#5-1-High-Availability\" class=\"headerlink\" title=\"5.1 High Availability\"></a>5.1 High Availability</h4><h4 id=\"5-2-Data-Integrity\"><a href=\"#5-2-Data-Integrity\" class=\"headerlink\" title=\"5.2 Data Integrity\"></a>5.2 Data Integrity</h4><h4 id=\"5-3-Diagnostic-Tools\"><a href=\"#5-3-Diagnostic-Tools\" class=\"headerlink\" title=\"5.3 Diagnostic Tools\"></a>5.3 Diagnostic Tools</h4><h3 id=\"6-MEASUREMENTS（度量）\"><a href=\"#6-MEASUREMENTS（度量）\" class=\"headerlink\" title=\"6. MEASUREMENTS（度量）\"></a>6. MEASUREMENTS（度量）</h3><h4 id=\"6-1-Micro-benchmarks\"><a href=\"#6-1-Micro-benchmarks\" class=\"headerlink\" title=\"6.1 Micro-benchmarks\"></a>6.1 Micro-benchmarks</h4><h5 id=\"6-1-3-Record-Appends\"><a href=\"#6-1-3-Record-Appends\" class=\"headerlink\" title=\"6.1.3 Record Appends\"></a>6.1.3 Record Appends</h5><h4 id=\"6-2-Real-World-Clusters\"><a href=\"#6-2-Real-World-Clusters\" class=\"headerlink\" title=\"6.2 Real World Clusters\"></a>6.2 Real World Clusters</h4><h3 id=\"7-MEASUREMENTS（经验）\"><a href=\"#7-MEASUREMENTS（经验）\" class=\"headerlink\" title=\"7. MEASUREMENTS（经验）\"></a>7. MEASUREMENTS（经验）</h3><h3 id=\"8-MEASUREMENTS（相关工作）\"><a href=\"#8-MEASUREMENTS（相关工作）\" class=\"headerlink\" title=\"8. MEASUREMENTS（相关工作）\"></a>8. MEASUREMENTS（相关工作）</h3><h3 id=\"9-MEASUREMENTS（结束语）\"><a href=\"#9-MEASUREMENTS（结束语）\" class=\"headerlink\" title=\"9. MEASUREMENTS（结束语）\"></a>9. MEASUREMENTS（结束语）</h3><hr>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ul>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf\">The Google File System</a></li>\n</ul>\n"},{"title":"Google分布式系统: MapReduce","date":"2021-07-22T10:30:33.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：学习`MapReduce`论文，方便后续回顾\n\nMapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型\n\n\n## 翻译","source":"_posts/Google分布式系统-MapReduce.md","raw":"---\ntitle: 'Google分布式系统: MapReduce'\ndate: 2021-07-22 18:30:33\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Google分布式系统\ntags:\n    - 分布式系统\n    - Google分布式系统\n    - MapReduce\n---\n\n> 摘要：学习`MapReduce`论文，方便后续回顾\n\nMapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型\n\n\n## 翻译","slug":"Google分布式系统-MapReduce","published":1,"updated":"2022-02-18T03:53:41.353Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8b000a9op7g1pc4oqp","content":"<blockquote>\n<p>摘要：学习<code>MapReduce</code>论文，方便后续回顾</p>\n</blockquote>\n<p>MapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型</p>\n<h2 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h2>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：学习<code>MapReduce</code>论文，方便后续回顾</p>\n</blockquote>\n<p>MapReduce 是由 Google 开发的一个针对大规模群组中的海量数据处理的分布式编程模型</p>\n<h2 id=\"翻译\"><a href=\"#翻译\" class=\"headerlink\" title=\"翻译\"></a>翻译</h2>"},{"title":"Google分布式系统","date":"2021-07-22T10:30:33.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n![xx](landing-2.svg)","source":"_posts/Google分布式系统.md","raw":"---\ntitle: Google分布式系统\ndate: 2021-07-22 18:30:33\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - gRPC\ntags:\n    - 分布式系统\n    - Google分布式系统\n    - 大数据\n---\n\n![xx](landing-2.svg)","slug":"Google分布式系统","published":1,"updated":"2022-02-23T03:24:42.545Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8c000c9op7dkio9hyh","content":"<p><img src=\"landing-2.svg\" alt=\"xx\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"landing-2.svg\" alt=\"xx\"></p>\n"},{"title":"Java11新特性","date":"2021-10-17T06:43:40.000Z","_content":"","source":"_posts/Java11新特性.md","raw":"---\ntitle: Java11新特性\ndate: 2021-10-17 14:43:40\ntags:\n---\n","slug":"Java11新特性","published":1,"updated":"2021-10-17T06:43:40.294Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8g000g9op7614134xd","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"IntelliJ IDEA破解","date":"2022-02-21T02:52:51.000Z","_content":"\n> 摘要：汇总`IntelliJ IDEA破解`, 方便后续使用\n\n## 版本大于等于 IntelliJ IDEA 2021.3\n\n> **环境：MacOS**\n\n![破解](1645412947773.jpg)\n\n\n- 下载 ja-netfilter 最新版本: v2.3.0.zip\n```http\nhttps://github.com/ja-netfilter/ja-netfilter/releases\n```\n\n解压 放到 `Library`目录下面 `Library/ja-netfilter`\n\n- 下载 ja-netfilter-mymap-plugin 最新版本: v1.2.0.jar\n```http\nhttps://github.com/zfkun/ja-netfilter-mymap-plugin/releases\n```\n\n放到`Library/ja-netfilter/plugins`目录下面\n\n- 配置\n\n> `ja-netfilter-mymap-plugin`生效配置\n\n在 `Library/ja-netfilter/conf`目录下面创建mymap.conf文件，文件配置如下:\n\n```yaml\n# jb 的 mymap.conf 配置文件\n[DNS]\nEQUAL,jetbrains.com\n \n[URL]\nPREFIX,https://account.jetbrains.com/lservice/rpc/validateKey.action\n \n[MyMap]\nEQUAL,licenseeName-> Kent\nEQUAL,gracePeriodDays->100000\nEQUAL,paidUpTo->5000-12-31\n```\n\n> `ja-netfilter.jar`生效配置\n\n打开 `/Help/Edit Custom VM Options` 如图：\n![打开Edit Custom VM Options配置文件](1645497394807.jpg)\n\n然后配置`ja-netfilter.jar` 如图：\n![ja-netfilter.jar配置](1645497851808.jpg)\n\n\n\n### IntelliJ IDEA 2020.2 <= 版本 < IntelliJ IDEA 2021.3\n安装`IDE Eval Reset`插件\n\n打开 `Preferences/Plugins` 搜索 `IDE Eval Reset` ，安装\n\n","source":"_posts/IntelliJ-IDEA破解.md","raw":"---\ntitle: IntelliJ IDEA破解\ndate: 2022-02-21 10:52:51\ncategories: \n    - [IntelliJ IDEA]\ntags:\n    - IntelliJ IDEA破解\n    - 破解\n---\n\n> 摘要：汇总`IntelliJ IDEA破解`, 方便后续使用\n\n## 版本大于等于 IntelliJ IDEA 2021.3\n\n> **环境：MacOS**\n\n![破解](1645412947773.jpg)\n\n\n- 下载 ja-netfilter 最新版本: v2.3.0.zip\n```http\nhttps://github.com/ja-netfilter/ja-netfilter/releases\n```\n\n解压 放到 `Library`目录下面 `Library/ja-netfilter`\n\n- 下载 ja-netfilter-mymap-plugin 最新版本: v1.2.0.jar\n```http\nhttps://github.com/zfkun/ja-netfilter-mymap-plugin/releases\n```\n\n放到`Library/ja-netfilter/plugins`目录下面\n\n- 配置\n\n> `ja-netfilter-mymap-plugin`生效配置\n\n在 `Library/ja-netfilter/conf`目录下面创建mymap.conf文件，文件配置如下:\n\n```yaml\n# jb 的 mymap.conf 配置文件\n[DNS]\nEQUAL,jetbrains.com\n \n[URL]\nPREFIX,https://account.jetbrains.com/lservice/rpc/validateKey.action\n \n[MyMap]\nEQUAL,licenseeName-> Kent\nEQUAL,gracePeriodDays->100000\nEQUAL,paidUpTo->5000-12-31\n```\n\n> `ja-netfilter.jar`生效配置\n\n打开 `/Help/Edit Custom VM Options` 如图：\n![打开Edit Custom VM Options配置文件](1645497394807.jpg)\n\n然后配置`ja-netfilter.jar` 如图：\n![ja-netfilter.jar配置](1645497851808.jpg)\n\n\n\n### IntelliJ IDEA 2020.2 <= 版本 < IntelliJ IDEA 2021.3\n安装`IDE Eval Reset`插件\n\n打开 `Preferences/Plugins` 搜索 `IDE Eval Reset` ，安装\n\n","slug":"IntelliJ-IDEA破解","published":1,"updated":"2022-02-23T02:47:01.534Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8h000h9op7h8k1dkp6","content":"<blockquote>\n<p>摘要：汇总<code>IntelliJ IDEA破解</code>, 方便后续使用</p>\n</blockquote>\n<h2 id=\"版本大于等于-IntelliJ-IDEA-2021-3\"><a href=\"#版本大于等于-IntelliJ-IDEA-2021-3\" class=\"headerlink\" title=\"版本大于等于 IntelliJ IDEA 2021.3\"></a>版本大于等于 IntelliJ IDEA 2021.3</h2><blockquote>\n<p><strong>环境：MacOS</strong></p>\n</blockquote>\n<p><img src=\"1645412947773.jpg\" alt=\"破解\"></p>\n<ul>\n<li>下载 ja-netfilter 最新版本: v2.3.0.zip<pre class=\" language-http\"><code class=\"language-http\"><span class=\"token header-name keyword\">https:</span>//github.com/ja-netfilter/ja-netfilter/releases\n</code></pre>\n</li>\n</ul>\n<p>解压 放到 <code>Library</code>目录下面 <code>Library/ja-netfilter</code></p>\n<ul>\n<li>下载 ja-netfilter-mymap-plugin 最新版本: v1.2.0.jar<pre class=\" language-http\"><code class=\"language-http\"><span class=\"token header-name keyword\">https:</span>//github.com/zfkun/ja-netfilter-mymap-plugin/releases\n</code></pre>\n</li>\n</ul>\n<p>放到<code>Library/ja-netfilter/plugins</code>目录下面</p>\n<ul>\n<li>配置</li>\n</ul>\n<blockquote>\n<p><code>ja-netfilter-mymap-plugin</code>生效配置</p>\n</blockquote>\n<p>在 <code>Library/ja-netfilter/conf</code>目录下面创建mymap.conf文件，文件配置如下:</p>\n<pre class=\" language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\" spellcheck=\"true\"># jb 的 mymap.conf 配置文件</span>\n<span class=\"token punctuation\">[</span>DNS<span class=\"token punctuation\">]</span>\nEQUAL<span class=\"token punctuation\">,</span>jetbrains.com\n \n<span class=\"token punctuation\">[</span>URL<span class=\"token punctuation\">]</span>\nPREFIX<span class=\"token punctuation\">,</span>https<span class=\"token punctuation\">:</span>//account.jetbrains.com/lservice/rpc/validateKey.action\n \n<span class=\"token punctuation\">[</span>MyMap<span class=\"token punctuation\">]</span>\nEQUAL<span class=\"token punctuation\">,</span>licenseeName<span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span> Kent\nEQUAL<span class=\"token punctuation\">,</span>gracePeriodDays<span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span>100000\nEQUAL<span class=\"token punctuation\">,</span>paidUpTo<span class=\"token punctuation\">-</span><span class=\"token punctuation\">></span>5000<span class=\"token punctuation\">-</span>12<span class=\"token punctuation\">-</span><span class=\"token number\">31</span>\n</code></pre>\n<blockquote>\n<p><code>ja-netfilter.jar</code>生效配置</p>\n</blockquote>\n<p>打开 <code>/Help/Edit Custom VM Options</code> 如图：\n<img src=\"1645497394807.jpg\" alt=\"打开Edit Custom VM Options配置文件\"></p>\n<p>然后配置<code>ja-netfilter.jar</code> 如图：\n<img src=\"1645497851808.jpg\" alt=\"ja-netfilter.jar配置\"></p>\n<h3 id=\"IntelliJ-IDEA-2020-2-lt-版本-lt-IntelliJ-IDEA-2021-3\"><a href=\"#IntelliJ-IDEA-2020-2-lt-版本-lt-IntelliJ-IDEA-2021-3\" class=\"headerlink\" title=\"IntelliJ IDEA 2020.2 <= 版本 < IntelliJ IDEA 2021.3\"></a>IntelliJ IDEA 2020.2 &lt;= 版本 &lt; IntelliJ IDEA 2021.3</h3><p>安装<code>IDE Eval Reset</code>插件</p>\n<p>打开 <code>Preferences/Plugins</code> 搜索 <code>IDE Eval Reset</code> ，安装</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：汇总<code>IntelliJ IDEA破解</code>, 方便后续使用</p>\n</blockquote>\n<h2 id=\"版本大于等于-IntelliJ-IDEA-2021-3\"><a href=\"#版本大于等于-IntelliJ-IDEA-2021-3\" class=\"headerlink\" title=\"版本大于等于 IntelliJ IDEA 2021.3\"></a>版本大于等于 IntelliJ IDEA 2021.3</h2><blockquote>\n<p><strong>环境：MacOS</strong></p>\n</blockquote>\n<p><img src=\"1645412947773.jpg\" alt=\"破解\"></p>\n<ul>\n<li>下载 ja-netfilter 最新版本: v2.3.0.zip<pre><code class=\"http\">https://github.com/ja-netfilter/ja-netfilter/releases\n</code></pre>\n</li>\n</ul>\n<p>解压 放到 <code>Library</code>目录下面 <code>Library/ja-netfilter</code></p>\n<ul>\n<li>下载 ja-netfilter-mymap-plugin 最新版本: v1.2.0.jar<pre><code class=\"http\">https://github.com/zfkun/ja-netfilter-mymap-plugin/releases\n</code></pre>\n</li>\n</ul>\n<p>放到<code>Library/ja-netfilter/plugins</code>目录下面</p>\n<ul>\n<li>配置</li>\n</ul>\n<blockquote>\n<p><code>ja-netfilter-mymap-plugin</code>生效配置</p>\n</blockquote>\n<p>在 <code>Library/ja-netfilter/conf</code>目录下面创建mymap.conf文件，文件配置如下:</p>\n<pre><code class=\"yaml\"># jb 的 mymap.conf 配置文件\n[DNS]\nEQUAL,jetbrains.com\n \n[URL]\nPREFIX,https://account.jetbrains.com/lservice/rpc/validateKey.action\n \n[MyMap]\nEQUAL,licenseeName-&gt; Kent\nEQUAL,gracePeriodDays-&gt;100000\nEQUAL,paidUpTo-&gt;5000-12-31\n</code></pre>\n<blockquote>\n<p><code>ja-netfilter.jar</code>生效配置</p>\n</blockquote>\n<p>打开 <code>/Help/Edit Custom VM Options</code> 如图：\n<img src=\"1645497394807.jpg\" alt=\"打开Edit Custom VM Options配置文件\"></p>\n<p>然后配置<code>ja-netfilter.jar</code> 如图：\n<img src=\"1645497851808.jpg\" alt=\"ja-netfilter.jar配置\"></p>\n<h3 id=\"IntelliJ-IDEA-2020-2-lt-版本-lt-IntelliJ-IDEA-2021-3\"><a href=\"#IntelliJ-IDEA-2020-2-lt-版本-lt-IntelliJ-IDEA-2021-3\" class=\"headerlink\" title=\"IntelliJ IDEA 2020.2 &lt;= 版本 &lt; IntelliJ IDEA 2021.3\"></a>IntelliJ IDEA 2020.2 &lt;= 版本 &lt; IntelliJ IDEA 2021.3</h3><p>安装<code>IDE Eval Reset</code>插件</p>\n<p>打开 <code>Preferences/Plugins</code> 搜索 <code>IDE Eval Reset</code> ，安装</p>\n"},{"title":"Java17新特性","date":"2021-10-17T06:42:02.000Z","_content":"","source":"_posts/Java17新特性.md","raw":"---\ntitle: Java17新特性\ndate: 2021-10-17 14:42:02\ntags:\n---\n","slug":"Java17新特性","published":1,"updated":"2021-10-17T06:42:02.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8j000l9op7d9f15mdn","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Java中多态性：重写和重载","date":"2010-10-01T00:00:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n`方法覆盖`和`方法重载`是 `Java` 展示`多态性`的两种方式\n\n### 方法覆盖\n`方法重载`是指在同名的类中定义不同的方法.\n\n`动态绑定`\n\n\n\n### 方法重载\n`方法重载`是指在同名的类中定义`相同的方法名称`.\n\n这些方法必须具有不同的签名。方法签名是方法名称和参数列表的组合。它不包括返回类型\n\n\n编译器通过检查`参数的类型`、`参数数量`和`放置顺序`来知道使用哪种方法\n`静态绑定`","source":"_posts/Java中多态性：重写和重载.md","raw":"---\ntitle: Java中多态性：重写和重载\ndate: 2010-10-01 08:00:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Java\n    - OOP\ntags:\n    - Java\n    - 多态性\n    - 重写\n    - 重载\n---\n\n`方法覆盖`和`方法重载`是 `Java` 展示`多态性`的两种方式\n\n### 方法覆盖\n`方法重载`是指在同名的类中定义不同的方法.\n\n`动态绑定`\n\n\n\n### 方法重载\n`方法重载`是指在同名的类中定义`相同的方法名称`.\n\n这些方法必须具有不同的签名。方法签名是方法名称和参数列表的组合。它不包括返回类型\n\n\n编译器通过检查`参数的类型`、`参数数量`和`放置顺序`来知道使用哪种方法\n`静态绑定`","slug":"Java中多态性：重写和重载","published":1,"updated":"2022-01-23T10:46:35.292Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8l000n9op7gzwt5dky","content":"<p><code>方法覆盖</code>和<code>方法重载</code>是 <code>Java</code> 展示<code>多态性</code>的两种方式</p>\n<h3 id=\"方法覆盖\"><a href=\"#方法覆盖\" class=\"headerlink\" title=\"方法覆盖\"></a>方法覆盖</h3><p><code>方法重载</code>是指在同名的类中定义不同的方法.</p>\n<p><code>动态绑定</code></p>\n<h3 id=\"方法重载\"><a href=\"#方法重载\" class=\"headerlink\" title=\"方法重载\"></a>方法重载</h3><p><code>方法重载</code>是指在同名的类中定义<code>相同的方法名称</code>.</p>\n<p>这些方法必须具有不同的签名。方法签名是方法名称和参数列表的组合。它不包括返回类型</p>\n<p>编译器通过检查<code>参数的类型</code>、<code>参数数量</code>和<code>放置顺序</code>来知道使用哪种方法\n<code>静态绑定</code></p>\n","site":{"data":{}},"excerpt":"","more":"<p><code>方法覆盖</code>和<code>方法重载</code>是 <code>Java</code> 展示<code>多态性</code>的两种方式</p>\n<h3 id=\"方法覆盖\"><a href=\"#方法覆盖\" class=\"headerlink\" title=\"方法覆盖\"></a>方法覆盖</h3><p><code>方法重载</code>是指在同名的类中定义不同的方法.</p>\n<p><code>动态绑定</code></p>\n<h3 id=\"方法重载\"><a href=\"#方法重载\" class=\"headerlink\" title=\"方法重载\"></a>方法重载</h3><p><code>方法重载</code>是指在同名的类中定义<code>相同的方法名称</code>.</p>\n<p>这些方法必须具有不同的签名。方法签名是方法名称和参数列表的组合。它不包括返回类型</p>\n<p>编译器通过检查<code>参数的类型</code>、<code>参数数量</code>和<code>放置顺序</code>来知道使用哪种方法\n<code>静态绑定</code></p>\n"},{"title":"Java中抽象类与接口之间的区别","date":"2010-10-01T00:00:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"","source":"_posts/Java中抽象类与接口之间的区别.md","raw":"---\ntitle: Java中抽象类与接口之间的区别\ndate: 2010-10-01 08:00:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Java\ntags:\n    - Java\n    - \n---\n","slug":"Java中抽象类与接口之间的区别","published":1,"updated":"2022-01-22T13:37:11.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8m000r9op7484o95wd","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Java中静态绑定与动态绑定区别","date":"2010-10-01T00:00:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n**`绑定`**: 将方法调用连接到方法体称为绑定\n\n**`绑定`** 有两种类型：\n- **静态绑定** ：在编译时映射方法。也叫`早期绑定`\n- **动态绑定**：在运行时被解析。也叫`后期绑定`\n\n### 静态绑定\n\n编译器可以`在编译时解析的绑定`称为`静态绑定`或`早期绑定`。所有`private`、`static`和`final`方法的绑定都是`在编译时完成`的\n\n#### 案例\n\n`方法重载`是`静态绑定`的最好例子\n\n```java\n\npublic class Main {\n\n    public void print(Man man) {\n        System.out.println(\"男人\");\n    }\n\n    public void print(Women wm) {\n        System.out.println(\"女人\");\n    }\n\n    public static void main(String[] args) {\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        print(m);\n        print(wm);\n    }\n}\n\npublic interface Humanity{}\n\npublic class Man implements Humanity {\n}\n\npublic class Women implements Humanity {\n}\n```\n\n### 动态绑定\n\n程序`执行期间`解析方法调用`绑定`时，对象的类型是在程序执行过程中确定的，这样的过程在 `Java` 中称为`动态绑定`或`后期绑定`\n\n#### 案例\n\n`动态绑定`的最佳示例是`方法重写`，其中父类和派生类具有相同的方法。因此，对象的类型决定了要执行的方法\n\n```java\npublic class Main {\n    public static void main(String[] args) {\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        m.print();\n        wm.print();\n    }\n}\n\npublic interface Humanity{\n    void print();\n}\n\npublic class Man implements Humanity {\n    public void print() {\n        System.out.println(\"男人\");\n    }\n}\n\npublic class Women implements Humanity {\n    public void print() {\n        System.out.println(\"女人\");\n    }\n}\n```\n\n### 静态绑定和动态绑定的区别\n|序列号\t| 静态绑定\t| 动态绑定 |\n|:----:|:-----|:-------|\n|  1.\t|\t一种{% post_link Java中多态性：重写和重载 多态性 %}，它收集信息以在`编译时调用方法`。\t|\t一种{% post_link Java中多态性：重写和重载 多态性 %}，它收集信息以在`运行时调用方法`\n|  2. \t|\t绑定`发生在编译时`\t| \t绑定`发生在运行时`\n|  3. \t|\t使用类型信息进行绑定\t|\t使用对象解析绑定\n|  4. \t|\t它也称为`早期绑定`，因为绑定`发生在编译期间`\t|\t它也称为`后期绑定`，因为`绑定发生在运行时`\n|  5.\t|\t执行速度`很快`(相对于动态绑定)\t|\t执行速度`很慢`(相对于静态绑定)\n|  6. \t|\t方法重载是静态绑定的最好例子。\t|\t方法重写是动态绑定的最佳示例\n|  7. \t|\t`private`、`static`和`final`的方法静态绑定，因为`不能重写`它们。\t|\t其他非`private`、`static`和`final`方法的方法动态绑定，因为这些`方法可以重写`","source":"_posts/Java中静态绑定与动态绑定区别.md","raw":"---\ntitle: Java中静态绑定与动态绑定区别\ndate: 2010-10-01 08:00:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Java\ntags:\n    - Java\n    - 静态绑定\n    - 动态绑定\n---\n\n**`绑定`**: 将方法调用连接到方法体称为绑定\n\n**`绑定`** 有两种类型：\n- **静态绑定** ：在编译时映射方法。也叫`早期绑定`\n- **动态绑定**：在运行时被解析。也叫`后期绑定`\n\n### 静态绑定\n\n编译器可以`在编译时解析的绑定`称为`静态绑定`或`早期绑定`。所有`private`、`static`和`final`方法的绑定都是`在编译时完成`的\n\n#### 案例\n\n`方法重载`是`静态绑定`的最好例子\n\n```java\n\npublic class Main {\n\n    public void print(Man man) {\n        System.out.println(\"男人\");\n    }\n\n    public void print(Women wm) {\n        System.out.println(\"女人\");\n    }\n\n    public static void main(String[] args) {\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        print(m);\n        print(wm);\n    }\n}\n\npublic interface Humanity{}\n\npublic class Man implements Humanity {\n}\n\npublic class Women implements Humanity {\n}\n```\n\n### 动态绑定\n\n程序`执行期间`解析方法调用`绑定`时，对象的类型是在程序执行过程中确定的，这样的过程在 `Java` 中称为`动态绑定`或`后期绑定`\n\n#### 案例\n\n`动态绑定`的最佳示例是`方法重写`，其中父类和派生类具有相同的方法。因此，对象的类型决定了要执行的方法\n\n```java\npublic class Main {\n    public static void main(String[] args) {\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        m.print();\n        wm.print();\n    }\n}\n\npublic interface Humanity{\n    void print();\n}\n\npublic class Man implements Humanity {\n    public void print() {\n        System.out.println(\"男人\");\n    }\n}\n\npublic class Women implements Humanity {\n    public void print() {\n        System.out.println(\"女人\");\n    }\n}\n```\n\n### 静态绑定和动态绑定的区别\n|序列号\t| 静态绑定\t| 动态绑定 |\n|:----:|:-----|:-------|\n|  1.\t|\t一种{% post_link Java中多态性：重写和重载 多态性 %}，它收集信息以在`编译时调用方法`。\t|\t一种{% post_link Java中多态性：重写和重载 多态性 %}，它收集信息以在`运行时调用方法`\n|  2. \t|\t绑定`发生在编译时`\t| \t绑定`发生在运行时`\n|  3. \t|\t使用类型信息进行绑定\t|\t使用对象解析绑定\n|  4. \t|\t它也称为`早期绑定`，因为绑定`发生在编译期间`\t|\t它也称为`后期绑定`，因为`绑定发生在运行时`\n|  5.\t|\t执行速度`很快`(相对于动态绑定)\t|\t执行速度`很慢`(相对于静态绑定)\n|  6. \t|\t方法重载是静态绑定的最好例子。\t|\t方法重写是动态绑定的最佳示例\n|  7. \t|\t`private`、`static`和`final`的方法静态绑定，因为`不能重写`它们。\t|\t其他非`private`、`static`和`final`方法的方法动态绑定，因为这些`方法可以重写`","slug":"Java中静态绑定与动态绑定区别","published":1,"updated":"2022-01-27T09:25:31.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8o000t9op75nbe6zuf","content":"<p><strong><code>绑定</code></strong>: 将方法调用连接到方法体称为绑定</p>\n<p><strong><code>绑定</code></strong> 有两种类型：</p>\n<ul>\n<li><strong>静态绑定</strong> ：在编译时映射方法。也叫<code>早期绑定</code></li>\n<li><strong>动态绑定</strong>：在运行时被解析。也叫<code>后期绑定</code></li>\n</ul>\n<h3 id=\"静态绑定\"><a href=\"#静态绑定\" class=\"headerlink\" title=\"静态绑定\"></a>静态绑定</h3><p>编译器可以<code>在编译时解析的绑定</code>称为<code>静态绑定</code>或<code>早期绑定</code>。所有<code>private</code>、<code>static</code>和<code>final</code>方法的绑定都是<code>在编译时完成</code>的</p>\n<h4 id=\"案例\"><a href=\"#案例\" class=\"headerlink\" title=\"案例\"></a>案例</h4><p><code>方法重载</code>是<code>静态绑定</code>的最好例子</p>\n<pre class=\" language-java\"><code class=\"language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Main</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">print</span><span class=\"token punctuation\">(</span>Man man<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"男人\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">print</span><span class=\"token punctuation\">(</span>Women wm<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"女人\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Humanity m <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Man</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        Humanity wm <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Women</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">print</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">print</span><span class=\"token punctuation\">(</span>wm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">interface</span> <span class=\"token class-name\">Humanity</span><span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Man</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Humanity</span> <span class=\"token punctuation\">{</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Women</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Humanity</span> <span class=\"token punctuation\">{</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h3 id=\"动态绑定\"><a href=\"#动态绑定\" class=\"headerlink\" title=\"动态绑定\"></a>动态绑定</h3><p>程序<code>执行期间</code>解析方法调用<code>绑定</code>时，对象的类型是在程序执行过程中确定的，这样的过程在 <code>Java</code> 中称为<code>动态绑定</code>或<code>后期绑定</code></p>\n<h4 id=\"案例-1\"><a href=\"#案例-1\" class=\"headerlink\" title=\"案例\"></a>案例</h4><p><code>动态绑定</code>的最佳示例是<code>方法重写</code>，其中父类和派生类具有相同的方法。因此，对象的类型决定了要执行的方法</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Main</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        Humanity m <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Man</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        Humanity wm <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Women</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        m<span class=\"token punctuation\">.</span><span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        wm<span class=\"token punctuation\">.</span><span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">interface</span> <span class=\"token class-name\">Humanity</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Man</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Humanity</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"男人\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Women</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Humanity</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"女人\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<h3 id=\"静态绑定和动态绑定的区别\"><a href=\"#静态绑定和动态绑定的区别\" class=\"headerlink\" title=\"静态绑定和动态绑定的区别\"></a>静态绑定和动态绑定的区别</h3><table>\n<thead>\n<tr>\n<th align=\"center\">序列号</th>\n<th align=\"left\">静态绑定</th>\n<th align=\"left\">动态绑定</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1.</td>\n<td align=\"left\">一种<a href=\"/2010/10/01/java-zhong-duo-tai-xing-chong-xie-he-chong-zai/\" title=\"多态性\">多态性</a>，它收集信息以在<code>编译时调用方法</code>。</td>\n<td align=\"left\">一种<a href=\"/2010/10/01/java-zhong-duo-tai-xing-chong-xie-he-chong-zai/\" title=\"多态性\">多态性</a>，它收集信息以在<code>运行时调用方法</code></td>\n</tr>\n<tr>\n<td align=\"center\">2.</td>\n<td align=\"left\">绑定<code>发生在编译时</code></td>\n<td align=\"left\">绑定<code>发生在运行时</code></td>\n</tr>\n<tr>\n<td align=\"center\">3.</td>\n<td align=\"left\">使用类型信息进行绑定</td>\n<td align=\"left\">使用对象解析绑定</td>\n</tr>\n<tr>\n<td align=\"center\">4.</td>\n<td align=\"left\">它也称为<code>早期绑定</code>，因为绑定<code>发生在编译期间</code></td>\n<td align=\"left\">它也称为<code>后期绑定</code>，因为<code>绑定发生在运行时</code></td>\n</tr>\n<tr>\n<td align=\"center\">5.</td>\n<td align=\"left\">执行速度<code>很快</code>(相对于动态绑定)</td>\n<td align=\"left\">执行速度<code>很慢</code>(相对于静态绑定)</td>\n</tr>\n<tr>\n<td align=\"center\">6.</td>\n<td align=\"left\">方法重载是静态绑定的最好例子。</td>\n<td align=\"left\">方法重写是动态绑定的最佳示例</td>\n</tr>\n<tr>\n<td align=\"center\">7.</td>\n<td align=\"left\"><code>private</code>、<code>static</code>和<code>final</code>的方法静态绑定，因为<code>不能重写</code>它们。</td>\n<td align=\"left\">其他非<code>private</code>、<code>static</code>和<code>final</code>方法的方法动态绑定，因为这些<code>方法可以重写</code></td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"excerpt":"","more":"<p><strong><code>绑定</code></strong>: 将方法调用连接到方法体称为绑定</p>\n<p><strong><code>绑定</code></strong> 有两种类型：</p>\n<ul>\n<li><strong>静态绑定</strong> ：在编译时映射方法。也叫<code>早期绑定</code></li>\n<li><strong>动态绑定</strong>：在运行时被解析。也叫<code>后期绑定</code></li>\n</ul>\n<h3 id=\"静态绑定\"><a href=\"#静态绑定\" class=\"headerlink\" title=\"静态绑定\"></a>静态绑定</h3><p>编译器可以<code>在编译时解析的绑定</code>称为<code>静态绑定</code>或<code>早期绑定</code>。所有<code>private</code>、<code>static</code>和<code>final</code>方法的绑定都是<code>在编译时完成</code>的</p>\n<h4 id=\"案例\"><a href=\"#案例\" class=\"headerlink\" title=\"案例\"></a>案例</h4><p><code>方法重载</code>是<code>静态绑定</code>的最好例子</p>\n<pre><code class=\"java\">\npublic class Main &#123;\n\n    public void print(Man man) &#123;\n        System.out.println(&quot;男人&quot;);\n    &#125;\n\n    public void print(Women wm) &#123;\n        System.out.println(&quot;女人&quot;);\n    &#125;\n\n    public static void main(String[] args) &#123;\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        print(m);\n        print(wm);\n    &#125;\n&#125;\n\npublic interface Humanity&#123;&#125;\n\npublic class Man implements Humanity &#123;\n&#125;\n\npublic class Women implements Humanity &#123;\n&#125;\n</code></pre>\n<h3 id=\"动态绑定\"><a href=\"#动态绑定\" class=\"headerlink\" title=\"动态绑定\"></a>动态绑定</h3><p>程序<code>执行期间</code>解析方法调用<code>绑定</code>时，对象的类型是在程序执行过程中确定的，这样的过程在 <code>Java</code> 中称为<code>动态绑定</code>或<code>后期绑定</code></p>\n<h4 id=\"案例-1\"><a href=\"#案例-1\" class=\"headerlink\" title=\"案例\"></a>案例</h4><p><code>动态绑定</code>的最佳示例是<code>方法重写</code>，其中父类和派生类具有相同的方法。因此，对象的类型决定了要执行的方法</p>\n<pre><code class=\"java\">public class Main &#123;\n    public static void main(String[] args) &#123;\n        Humanity m = new Man();\n        Humanity wm = new Women();\n        m.print();\n        wm.print();\n    &#125;\n&#125;\n\npublic interface Humanity&#123;\n    void print();\n&#125;\n\npublic class Man implements Humanity &#123;\n    public void print() &#123;\n        System.out.println(&quot;男人&quot;);\n    &#125;\n&#125;\n\npublic class Women implements Humanity &#123;\n    public void print() &#123;\n        System.out.println(&quot;女人&quot;);\n    &#125;\n&#125;\n</code></pre>\n<h3 id=\"静态绑定和动态绑定的区别\"><a href=\"#静态绑定和动态绑定的区别\" class=\"headerlink\" title=\"静态绑定和动态绑定的区别\"></a>静态绑定和动态绑定的区别</h3><table>\n<thead>\n<tr>\n<th align=\"center\">序列号</th>\n<th align=\"left\">静态绑定</th>\n<th align=\"left\">动态绑定</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">1.</td>\n<td align=\"left\">一种<a href=\"/2010/10/01/java-zhong-duo-tai-xing-chong-xie-he-chong-zai/\" title=\"多态性\">多态性</a>，它收集信息以在<code>编译时调用方法</code>。</td>\n<td align=\"left\">一种<a href=\"/2010/10/01/java-zhong-duo-tai-xing-chong-xie-he-chong-zai/\" title=\"多态性\">多态性</a>，它收集信息以在<code>运行时调用方法</code></td>\n</tr>\n<tr>\n<td align=\"center\">2.</td>\n<td align=\"left\">绑定<code>发生在编译时</code></td>\n<td align=\"left\">绑定<code>发生在运行时</code></td>\n</tr>\n<tr>\n<td align=\"center\">3.</td>\n<td align=\"left\">使用类型信息进行绑定</td>\n<td align=\"left\">使用对象解析绑定</td>\n</tr>\n<tr>\n<td align=\"center\">4.</td>\n<td align=\"left\">它也称为<code>早期绑定</code>，因为绑定<code>发生在编译期间</code></td>\n<td align=\"left\">它也称为<code>后期绑定</code>，因为<code>绑定发生在运行时</code></td>\n</tr>\n<tr>\n<td align=\"center\">5.</td>\n<td align=\"left\">执行速度<code>很快</code>(相对于动态绑定)</td>\n<td align=\"left\">执行速度<code>很慢</code>(相对于静态绑定)</td>\n</tr>\n<tr>\n<td align=\"center\">6.</td>\n<td align=\"left\">方法重载是静态绑定的最好例子。</td>\n<td align=\"left\">方法重写是动态绑定的最佳示例</td>\n</tr>\n<tr>\n<td align=\"center\">7.</td>\n<td align=\"left\"><code>private</code>、<code>static</code>和<code>final</code>的方法静态绑定，因为<code>不能重写</code>它们。</td>\n<td align=\"left\">其他非<code>private</code>、<code>static</code>和<code>final</code>方法的方法动态绑定，因为这些<code>方法可以重写</code></td>\n</tr>\n</tbody></table>\n"},{"title":"Java源码分析-原子类-AtomicBoolean","date":"2022-02-24T06:24:05.000Z","_content":"","source":"_posts/Java源码分析-原子类-AtomicBoolean.md","raw":"---\ntitle: Java源码分析-原子类-AtomicBoolean\ndate: 2022-02-24 14:24:05\ntags:\n---\n","slug":"Java源码分析-原子类-AtomicBoolean","published":1,"updated":"2022-02-24T06:24:05.057Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8q000y9op743qi34vo","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Java程序设计","date":"2010-09-01T00:01:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n\n> 摘要：汇总Java程序设计，方便后续使用查阅.\n\n## 注释\n\n### 单行注释: //\n```java\n// 单行注释\n```\n\n### 多行注释: /* */\n```java\n/* 多行注释 */\n\n/*\n * 多行注释\n * 多行注释\n */\n```\n> /* */ 不能嵌套使用, 必须 /\\* 开始, 中介注释, */ 结束\n\n### 文档注释: /** */\n自动生成文档\n```java\n/**\n * 文档注释\n *\n * @author Kent\n */\n```\n\n---\n\n## 变量\n\n`变量`就是申请内存来存储的值，当创建`变量`的时候，需要在内存中`申请空间`，`内存管理系统`根据变量的类型为变量分配存储空间，分配的空间只能用来存储该类型的数据\n\n![变量-内存](变量-内存.jpg)\n\n`变量名`必须是一个以`字母`开头并由字母或数字构成的序列, `大小写敏感`。\n- 声明\n`声明变量`时，`变量`的`类型`位于变量名之前\n```java\nint i;\nfloat f;\n```\n\n- 赋值\n```java\ni = 0;\nf = 0f;\n```\n\n> 注意：\n> 1. `字母`判断可以使用`Character`类的`isJavaIdentifierStart`和`isJavaIdentifierPart`方法来检查\n> 2. 不可以使用`Java保留字`\n\n--- \n\n## 数据类型\n`Java`是`强类型语言`, 分为`基本数据类型(Primitive Type)`、`引用数据类型(Reference Type)`\n\n\n\n### 基本数据类型\n\n`8种`基本数据类型\n\n| 项目        | 价格   |  数量  |\n| --------   | -----:  | :----:  |\n| 计算机     | \\$1600 |   5     |\n| 手机        |   \\$12   |   12   |\n| 管线        |    \\$1    |  234  |\n\n\n\n### 引用数据类型\n\n\n--- \n\n\n\n\n\n## 运算符\n\n## 控制流程\n\n\n","source":"_posts/Java程序设计.md","raw":"---\ntitle: Java程序设计\ndate: 2010-09-01 08:01:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java在Mac系统中的开发环境配置\ncategories:\n    - [Java程序设计]\ntags:\n    - Java\n    - 程序设计\n---\n\n\n> 摘要：汇总Java程序设计，方便后续使用查阅.\n\n## 注释\n\n### 单行注释: //\n```java\n// 单行注释\n```\n\n### 多行注释: /* */\n```java\n/* 多行注释 */\n\n/*\n * 多行注释\n * 多行注释\n */\n```\n> /* */ 不能嵌套使用, 必须 /\\* 开始, 中介注释, */ 结束\n\n### 文档注释: /** */\n自动生成文档\n```java\n/**\n * 文档注释\n *\n * @author Kent\n */\n```\n\n---\n\n## 变量\n\n`变量`就是申请内存来存储的值，当创建`变量`的时候，需要在内存中`申请空间`，`内存管理系统`根据变量的类型为变量分配存储空间，分配的空间只能用来存储该类型的数据\n\n![变量-内存](变量-内存.jpg)\n\n`变量名`必须是一个以`字母`开头并由字母或数字构成的序列, `大小写敏感`。\n- 声明\n`声明变量`时，`变量`的`类型`位于变量名之前\n```java\nint i;\nfloat f;\n```\n\n- 赋值\n```java\ni = 0;\nf = 0f;\n```\n\n> 注意：\n> 1. `字母`判断可以使用`Character`类的`isJavaIdentifierStart`和`isJavaIdentifierPart`方法来检查\n> 2. 不可以使用`Java保留字`\n\n--- \n\n## 数据类型\n`Java`是`强类型语言`, 分为`基本数据类型(Primitive Type)`、`引用数据类型(Reference Type)`\n\n\n\n### 基本数据类型\n\n`8种`基本数据类型\n\n| 项目        | 价格   |  数量  |\n| --------   | -----:  | :----:  |\n| 计算机     | \\$1600 |   5     |\n| 手机        |   \\$12   |   12   |\n| 管线        |    \\$1    |  234  |\n\n\n\n### 引用数据类型\n\n\n--- \n\n\n\n\n\n## 运算符\n\n## 控制流程\n\n\n","slug":"Java程序设计","published":1,"updated":"2021-12-31T12:45:42.110Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8r00109op75fu7912q","content":"<blockquote>\n<p>摘要：汇总Java程序设计，方便后续使用查阅.</p>\n</blockquote>\n<h2 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h2><h3 id=\"单行注释\"><a href=\"#单行注释\" class=\"headerlink\" title=\"单行注释: //\"></a>单行注释: //</h3><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">// 单行注释</span>\n</code></pre>\n<h3 id=\"多行注释\"><a href=\"#多行注释\" class=\"headerlink\" title=\"多行注释: /* */\"></a>多行注释: /* */</h3><pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">/* 多行注释 */</span>\n\n<span class=\"token comment\" spellcheck=\"true\">/*\n * 多行注释\n * 多行注释\n */</span>\n</code></pre>\n<blockquote>\n<p>/* */ 不能嵌套使用, 必须 /* 开始, 中介注释, */ 结束</p>\n</blockquote>\n<h3 id=\"文档注释\"><a href=\"#文档注释\" class=\"headerlink\" title=\"文档注释: /** */\"></a>文档注释: /** */</h3><p>自动生成文档</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token comment\" spellcheck=\"true\">/**\n * 文档注释\n *\n * @author Kent\n */</span>\n</code></pre>\n<hr>\n<h2 id=\"变量\"><a href=\"#变量\" class=\"headerlink\" title=\"变量\"></a>变量</h2><p><code>变量</code>就是申请内存来存储的值，当创建<code>变量</code>的时候，需要在内存中<code>申请空间</code>，<code>内存管理系统</code>根据变量的类型为变量分配存储空间，分配的空间只能用来存储该类型的数据</p>\n<p><img src=\"%E5%8F%98%E9%87%8F-%E5%86%85%E5%AD%98.jpg\" alt=\"变量-内存\"></p>\n<p><code>变量名</code>必须是一个以<code>字母</code>开头并由字母或数字构成的序列, <code>大小写敏感</code>。</p>\n<ul>\n<li><p>声明\n<code>声明变量</code>时，<code>变量</code>的<code>类型</code>位于变量名之前</p>\n<pre class=\" language-java\"><code class=\"language-java\"><span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">float</span> f<span class=\"token punctuation\">;</span>\n</code></pre>\n</li>\n<li><p>赋值</p>\n<pre class=\" language-java\"><code class=\"language-java\">i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\nf <span class=\"token operator\">=</span> <span class=\"token number\">0f</span><span class=\"token punctuation\">;</span>\n</code></pre>\n</li>\n</ul>\n<blockquote>\n<p>注意：</p>\n<ol>\n<li><code>字母</code>判断可以使用<code>Character</code>类的<code>isJavaIdentifierStart</code>和<code>isJavaIdentifierPart</code>方法来检查</li>\n<li>不可以使用<code>Java保留字</code></li>\n</ol>\n</blockquote>\n<hr>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p><code>Java</code>是<code>强类型语言</code>, 分为<code>基本数据类型(Primitive Type)</code>、<code>引用数据类型(Reference Type)</code></p>\n<h3 id=\"基本数据类型\"><a href=\"#基本数据类型\" class=\"headerlink\" title=\"基本数据类型\"></a>基本数据类型</h3><p><code>8种</code>基本数据类型</p>\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th align=\"right\">价格</th>\n<th align=\"center\">数量</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>计算机</td>\n<td align=\"right\">$1600</td>\n<td align=\"center\">5</td>\n</tr>\n<tr>\n<td>手机</td>\n<td align=\"right\">$12</td>\n<td align=\"center\">12</td>\n</tr>\n<tr>\n<td>管线</td>\n<td align=\"right\">$1</td>\n<td align=\"center\">234</td>\n</tr>\n</tbody></table>\n<h3 id=\"引用数据类型\"><a href=\"#引用数据类型\" class=\"headerlink\" title=\"引用数据类型\"></a>引用数据类型</h3><hr>\n<h2 id=\"运算符\"><a href=\"#运算符\" class=\"headerlink\" title=\"运算符\"></a>运算符</h2><h2 id=\"控制流程\"><a href=\"#控制流程\" class=\"headerlink\" title=\"控制流程\"></a>控制流程</h2>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：汇总Java程序设计，方便后续使用查阅.</p>\n</blockquote>\n<h2 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h2><h3 id=\"单行注释\"><a href=\"#单行注释\" class=\"headerlink\" title=\"单行注释: //\"></a>单行注释: //</h3><pre><code class=\"java\">// 单行注释\n</code></pre>\n<h3 id=\"多行注释\"><a href=\"#多行注释\" class=\"headerlink\" title=\"多行注释: /* */\"></a>多行注释: /* */</h3><pre><code class=\"java\">/* 多行注释 */\n\n/*\n * 多行注释\n * 多行注释\n */\n</code></pre>\n<blockquote>\n<p>/* */ 不能嵌套使用, 必须 /* 开始, 中介注释, */ 结束</p>\n</blockquote>\n<h3 id=\"文档注释\"><a href=\"#文档注释\" class=\"headerlink\" title=\"文档注释: /** */\"></a>文档注释: /** */</h3><p>自动生成文档</p>\n<pre><code class=\"java\">/**\n * 文档注释\n *\n * @author Kent\n */\n</code></pre>\n<hr>\n<h2 id=\"变量\"><a href=\"#变量\" class=\"headerlink\" title=\"变量\"></a>变量</h2><p><code>变量</code>就是申请内存来存储的值，当创建<code>变量</code>的时候，需要在内存中<code>申请空间</code>，<code>内存管理系统</code>根据变量的类型为变量分配存储空间，分配的空间只能用来存储该类型的数据</p>\n<p><img src=\"%E5%8F%98%E9%87%8F-%E5%86%85%E5%AD%98.jpg\" alt=\"变量-内存\"></p>\n<p><code>变量名</code>必须是一个以<code>字母</code>开头并由字母或数字构成的序列, <code>大小写敏感</code>。</p>\n<ul>\n<li><p>声明\n<code>声明变量</code>时，<code>变量</code>的<code>类型</code>位于变量名之前</p>\n<pre><code class=\"java\">int i;\nfloat f;\n</code></pre>\n</li>\n<li><p>赋值</p>\n<pre><code class=\"java\">i = 0;\nf = 0f;\n</code></pre>\n</li>\n</ul>\n<blockquote>\n<p>注意：</p>\n<ol>\n<li><code>字母</code>判断可以使用<code>Character</code>类的<code>isJavaIdentifierStart</code>和<code>isJavaIdentifierPart</code>方法来检查</li>\n<li>不可以使用<code>Java保留字</code></li>\n</ol>\n</blockquote>\n<hr>\n<h2 id=\"数据类型\"><a href=\"#数据类型\" class=\"headerlink\" title=\"数据类型\"></a>数据类型</h2><p><code>Java</code>是<code>强类型语言</code>, 分为<code>基本数据类型(Primitive Type)</code>、<code>引用数据类型(Reference Type)</code></p>\n<h3 id=\"基本数据类型\"><a href=\"#基本数据类型\" class=\"headerlink\" title=\"基本数据类型\"></a>基本数据类型</h3><p><code>8种</code>基本数据类型</p>\n<table>\n<thead>\n<tr>\n<th>项目</th>\n<th align=\"right\">价格</th>\n<th align=\"center\">数量</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>计算机</td>\n<td align=\"right\">$1600</td>\n<td align=\"center\">5</td>\n</tr>\n<tr>\n<td>手机</td>\n<td align=\"right\">$12</td>\n<td align=\"center\">12</td>\n</tr>\n<tr>\n<td>管线</td>\n<td align=\"right\">$1</td>\n<td align=\"center\">234</td>\n</tr>\n</tbody></table>\n<h3 id=\"引用数据类型\"><a href=\"#引用数据类型\" class=\"headerlink\" title=\"引用数据类型\"></a>引用数据类型</h3><hr>\n<h2 id=\"运算符\"><a href=\"#运算符\" class=\"headerlink\" title=\"运算符\"></a>运算符</h2><h2 id=\"控制流程\"><a href=\"#控制流程\" class=\"headerlink\" title=\"控制流程\"></a>控制流程</h2>"},{"title":"Maven | Maven安装&配置","date":"2021-10-29T07:06:06.000Z","_content":"","source":"_posts/Maven-Maven安装-配置.md","raw":"---\ntitle: Maven | Maven安装&配置\ndate: 2021-10-29 15:06:06\ntags:\n---\n","slug":"Maven-Maven安装-配置","published":1,"updated":"2021-10-29T07:06:06.019Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8t00159op7hvzx5rev","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"MySQL InnoDB存储引擎","date":"2022-03-01T01:35:11.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n\n> 摘要\n\n## 发展\n## 体系架构\n\n\n**参考**\n[MySQL innodb-introduction](https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html)","source":"_posts/MySQL-InnoDB.md","raw":"---\ntitle: MySQL InnoDB存储引擎\ndate: 2022-03-01 09:35:11\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - MySQL\ntags:\n    - 数据库\n    - MySQL\n    - Innodb\n---\n\n\n> 摘要\n\n## 发展\n## 体系架构\n\n\n**参考**\n[MySQL innodb-introduction](https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html)","slug":"MySQL-InnoDB","published":1,"updated":"2022-04-10T12:38:15.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8u00179op70ie56308","content":"<blockquote>\n<p>摘要</p>\n</blockquote>\n<h2 id=\"发展\"><a href=\"#发展\" class=\"headerlink\" title=\"发展\"></a>发展</h2><h2 id=\"体系架构\"><a href=\"#体系架构\" class=\"headerlink\" title=\"体系架构\"></a>体系架构</h2><p><strong>参考</strong>\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html\">MySQL innodb-introduction</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要</p>\n</blockquote>\n<h2 id=\"发展\"><a href=\"#发展\" class=\"headerlink\" title=\"发展\"></a>发展</h2><h2 id=\"体系架构\"><a href=\"#体系架构\" class=\"headerlink\" title=\"体系架构\"></a>体系架构</h2><p><strong>参考</strong>\n<a href=\"https://dev.mysql.com/doc/refman/8.0/en/innodb-introduction.html\">MySQL innodb-introduction</a></p>\n"},{"title":"Redis中对象类型","date":"2022-03-01T01:35:11.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：\n\n\n## 字符串(String)\n\n\n## 哈希(Hash）\n\n## 列表(List)\n\n## 集合(Set)\n\n## 有序集合(Zset)\n\n","source":"_posts/Redis中对象类型.md","raw":"---\ntitle: Redis中对象类型\ndate: 2022-03-01 09:35:11\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Redis\ntags:\n    - Redis\n    - Redis对象类型\n---\n\n> 摘要：\n\n\n## 字符串(String)\n\n\n## 哈希(Hash）\n\n## 列表(List)\n\n## 集合(Set)\n\n## 有序集合(Zset)\n\n","slug":"Redis中对象类型","published":1,"updated":"2022-03-02T01:33:14.953Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8w001b9op79ja8bqr1","content":"<blockquote>\n<p>摘要：</p>\n</blockquote>\n<h2 id=\"字符串-String\"><a href=\"#字符串-String\" class=\"headerlink\" title=\"字符串(String)\"></a>字符串(String)</h2><h2 id=\"哈希-Hash）\"><a href=\"#哈希-Hash）\" class=\"headerlink\" title=\"哈希(Hash）\"></a>哈希(Hash）</h2><h2 id=\"列表-List\"><a href=\"#列表-List\" class=\"headerlink\" title=\"列表(List)\"></a>列表(List)</h2><h2 id=\"集合-Set\"><a href=\"#集合-Set\" class=\"headerlink\" title=\"集合(Set)\"></a>集合(Set)</h2><h2 id=\"有序集合-Zset\"><a href=\"#有序集合-Zset\" class=\"headerlink\" title=\"有序集合(Zset)\"></a>有序集合(Zset)</h2>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：</p>\n</blockquote>\n<h2 id=\"字符串-String\"><a href=\"#字符串-String\" class=\"headerlink\" title=\"字符串(String)\"></a>字符串(String)</h2><h2 id=\"哈希-Hash）\"><a href=\"#哈希-Hash）\" class=\"headerlink\" title=\"哈希(Hash）\"></a>哈希(Hash）</h2><h2 id=\"列表-List\"><a href=\"#列表-List\" class=\"headerlink\" title=\"列表(List)\"></a>列表(List)</h2><h2 id=\"集合-Set\"><a href=\"#集合-Set\" class=\"headerlink\" title=\"集合(Set)\"></a>集合(Set)</h2><h2 id=\"有序集合-Zset\"><a href=\"#有序集合-Zset\" class=\"headerlink\" title=\"有序集合(Zset)\"></a>有序集合(Zset)</h2>"},{"title":"Redis中数据结构","date":"2022-03-01T01:35:21.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n\n\n\n\n","source":"_posts/Redis中数据结构.md","raw":"---\ntitle: Redis中数据结构\ndate: 2022-03-01 09:35:21\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - Redis\ntags:\n    - Redis\n    - Redis数据结构\n---\n\n\n\n\n\n","slug":"Redis中数据结构","published":1,"updated":"2022-03-02T01:34:23.026Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8x001e9op79mbncqfi","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"gRPC","date":"2022-02-23T03:20:47.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：`gRPC`是`Google`开发的`远程过程调用`开源框架\n\n## 引言（Introduction）\n\n![](landing-2.svg)\n\n## 概述（Overview）\n### 服务定义（Service definition）\n`gRPC`一般使用`protocol buffers`来作为`接口定义语言`(`IDL`), 如下：\n```Protobuf\nservice HelloService {\n  rpc SayHello (HelloRequest) returns (HelloResponse);\n}\n\nmessage HelloRequest {\n  string greeting = 1;\n}\n\nmessage HelloResponse {\n  string reply = 1;\n}\n```\n\n> `gRPC`允许您定义`四种`服务方法：\n#### 一元RPC（Unary RPCs）\n客户端向服务器发送单个请求并获得单个响应，就像正常的函数调用一样\n```Protobuf\nrpc SayHello(HelloRequest) returns (HelloResponse);\n```\n\n#### 服务器流式RPC（Server streaming RPCs）\n客户端向服务器发送请求并获取流以读回一系列消息。客户端从返回的流中读取，直到没有更多消息为止。`gRPC` 保证单个 `RPC` 调用中的消息顺序\n```Protobuf\nrpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);\n```\n\n#### 客户端流式RPC（Client streaming RPCs）\n客户端写入一系列消息并将它们发送到服务器，再次使用提供的流。一旦客户端完成了消息的写入，它就会等待服务器读取它们并返回它的响应。`gRPC` 再次保证了单个 `RPC` 调用中的消息顺序。\n```Protobuf\nrpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);\n```\n\n#### 双向流式RPC（Bidirectional streaming RPCs）\n双方使用读写流发送一系列消息。这两个流独立运行，因此客户端和服务器可以按照他们喜欢的任何顺序读取和写入.\n\n例如：服务器可以在写入响应之前等待接收所有客户端消息，或者它可以交替读取消息然后写入消息，或其他一些读取和写入的组合。保留每个流中消息的顺序\n\n```Protobuf\nrpc BidiHello(stream HelloRequest) returns (stream HelloResponse);\n```\n\n\n### API使用（Using the API ）\n从.proto文件中的服务定义开始，gRPC 提供了生成客户端和服务器端代码的协议缓冲区编译器插件。gRPC 用户通常在客户端调用这些 API，并在服务器端实现相应的 API。\n- 在服务端，服务端实现服务声明的方法，并运行一个 gRPC 服务端来处理客户端调用。gRPC 基础架构解码传入请求、执行服务方法并编码服务响应。\n- 在客户端，客户端有一个称为存根的本地对象（对于某些语言，首选术语是客户端），它实现与服务相同的方法。然后客户端可以在本地对象上调用这些方法，将调用的参数包装在适当的协议缓冲区消息类型中 - gRPC 会在将请求发送到服务器并返回服务器的协议缓冲区响应之后进行处理。\n\n### 同步与异步\n在服务器收到响应之前阻塞的同步 RPC 调用是最接近 RPC 所追求的过程调用抽象的近似值。另一方面，网络本质上是异步的，在许多情况下，能够在不阻塞当前线程的情况下启动 RPC 是很有用的。\n\n大多数语言中的 gRPC 编程 API 有同步和异步两种风格。您可以在每种语言的教程和参考文档中找到更多信息（完整的参考文档即将推出）。\n\n## 架构\n\n## 生命周期\n#### 一元RPC（Unary RPCs）\n\n#### 服务器流式RPC（Server streaming RPCs）\n\n\n#### 客户端流式RPC（Client streaming RPCs）\n\n\n#### 双向流式RPC（Bidirectional streaming RPCs）\n\n## 使用\n### Java\n### Go\n\n---\n\n**参考**\n- [gRPC文档](https://grpc.io/docs)\n\n\n\n","source":"_posts/gRPC.md","raw":"---\ntitle: gRPC\ndate: 2022-02-23 11:20:47\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary:\ncategories:\n    - gRPC\ntags:\n    - gRPC\n    - RPC\n---\n\n> 摘要：`gRPC`是`Google`开发的`远程过程调用`开源框架\n\n## 引言（Introduction）\n\n![](landing-2.svg)\n\n## 概述（Overview）\n### 服务定义（Service definition）\n`gRPC`一般使用`protocol buffers`来作为`接口定义语言`(`IDL`), 如下：\n```Protobuf\nservice HelloService {\n  rpc SayHello (HelloRequest) returns (HelloResponse);\n}\n\nmessage HelloRequest {\n  string greeting = 1;\n}\n\nmessage HelloResponse {\n  string reply = 1;\n}\n```\n\n> `gRPC`允许您定义`四种`服务方法：\n#### 一元RPC（Unary RPCs）\n客户端向服务器发送单个请求并获得单个响应，就像正常的函数调用一样\n```Protobuf\nrpc SayHello(HelloRequest) returns (HelloResponse);\n```\n\n#### 服务器流式RPC（Server streaming RPCs）\n客户端向服务器发送请求并获取流以读回一系列消息。客户端从返回的流中读取，直到没有更多消息为止。`gRPC` 保证单个 `RPC` 调用中的消息顺序\n```Protobuf\nrpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);\n```\n\n#### 客户端流式RPC（Client streaming RPCs）\n客户端写入一系列消息并将它们发送到服务器，再次使用提供的流。一旦客户端完成了消息的写入，它就会等待服务器读取它们并返回它的响应。`gRPC` 再次保证了单个 `RPC` 调用中的消息顺序。\n```Protobuf\nrpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);\n```\n\n#### 双向流式RPC（Bidirectional streaming RPCs）\n双方使用读写流发送一系列消息。这两个流独立运行，因此客户端和服务器可以按照他们喜欢的任何顺序读取和写入.\n\n例如：服务器可以在写入响应之前等待接收所有客户端消息，或者它可以交替读取消息然后写入消息，或其他一些读取和写入的组合。保留每个流中消息的顺序\n\n```Protobuf\nrpc BidiHello(stream HelloRequest) returns (stream HelloResponse);\n```\n\n\n### API使用（Using the API ）\n从.proto文件中的服务定义开始，gRPC 提供了生成客户端和服务器端代码的协议缓冲区编译器插件。gRPC 用户通常在客户端调用这些 API，并在服务器端实现相应的 API。\n- 在服务端，服务端实现服务声明的方法，并运行一个 gRPC 服务端来处理客户端调用。gRPC 基础架构解码传入请求、执行服务方法并编码服务响应。\n- 在客户端，客户端有一个称为存根的本地对象（对于某些语言，首选术语是客户端），它实现与服务相同的方法。然后客户端可以在本地对象上调用这些方法，将调用的参数包装在适当的协议缓冲区消息类型中 - gRPC 会在将请求发送到服务器并返回服务器的协议缓冲区响应之后进行处理。\n\n### 同步与异步\n在服务器收到响应之前阻塞的同步 RPC 调用是最接近 RPC 所追求的过程调用抽象的近似值。另一方面，网络本质上是异步的，在许多情况下，能够在不阻塞当前线程的情况下启动 RPC 是很有用的。\n\n大多数语言中的 gRPC 编程 API 有同步和异步两种风格。您可以在每种语言的教程和参考文档中找到更多信息（完整的参考文档即将推出）。\n\n## 架构\n\n## 生命周期\n#### 一元RPC（Unary RPCs）\n\n#### 服务器流式RPC（Server streaming RPCs）\n\n\n#### 客户端流式RPC（Client streaming RPCs）\n\n\n#### 双向流式RPC（Bidirectional streaming RPCs）\n\n## 使用\n### Java\n### Go\n\n---\n\n**参考**\n- [gRPC文档](https://grpc.io/docs)\n\n\n\n","slug":"gRPC","published":1,"updated":"2022-02-23T04:07:23.457Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw8y001g9op782gm72m6","content":"<blockquote>\n<p>摘要：<code>gRPC</code>是<code>Google</code>开发的<code>远程过程调用</code>开源框架</p>\n</blockquote>\n<h2 id=\"引言（Introduction）\"><a href=\"#引言（Introduction）\" class=\"headerlink\" title=\"引言（Introduction）\"></a>引言（Introduction）</h2><p><img src=\"landing-2.svg\"></p>\n<h2 id=\"概述（Overview）\"><a href=\"#概述（Overview）\" class=\"headerlink\" title=\"概述（Overview）\"></a>概述（Overview）</h2><h3 id=\"服务定义（Service-definition）\"><a href=\"#服务定义（Service-definition）\" class=\"headerlink\" title=\"服务定义（Service definition）\"></a>服务定义（Service definition）</h3><p><code>gRPC</code>一般使用<code>protocol buffers</code>来作为<code>接口定义语言</code>(<code>IDL</code>), 如下：</p>\n<pre class=\" language-Protobuf\"><code class=\"language-Protobuf\">service HelloService {\n  rpc SayHello (HelloRequest) returns (HelloResponse);\n}\n\nmessage HelloRequest {\n  string greeting = 1;\n}\n\nmessage HelloResponse {\n  string reply = 1;\n}\n</code></pre>\n<blockquote>\n<p><code>gRPC</code>允许您定义<code>四种</code>服务方法：</p>\n</blockquote>\n<h4 id=\"一元RPC（Unary-RPCs）\"><a href=\"#一元RPC（Unary-RPCs）\" class=\"headerlink\" title=\"一元RPC（Unary RPCs）\"></a>一元RPC（Unary RPCs）</h4><p>客户端向服务器发送单个请求并获得单个响应，就像正常的函数调用一样</p>\n<pre class=\" language-Protobuf\"><code class=\"language-Protobuf\">rpc SayHello(HelloRequest) returns (HelloResponse);\n</code></pre>\n<h4 id=\"服务器流式RPC（Server-streaming-RPCs）\"><a href=\"#服务器流式RPC（Server-streaming-RPCs）\" class=\"headerlink\" title=\"服务器流式RPC（Server streaming RPCs）\"></a>服务器流式RPC（Server streaming RPCs）</h4><p>客户端向服务器发送请求并获取流以读回一系列消息。客户端从返回的流中读取，直到没有更多消息为止。<code>gRPC</code> 保证单个 <code>RPC</code> 调用中的消息顺序</p>\n<pre class=\" language-Protobuf\"><code class=\"language-Protobuf\">rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);\n</code></pre>\n<h4 id=\"客户端流式RPC（Client-streaming-RPCs）\"><a href=\"#客户端流式RPC（Client-streaming-RPCs）\" class=\"headerlink\" title=\"客户端流式RPC（Client streaming RPCs）\"></a>客户端流式RPC（Client streaming RPCs）</h4><p>客户端写入一系列消息并将它们发送到服务器，再次使用提供的流。一旦客户端完成了消息的写入，它就会等待服务器读取它们并返回它的响应。<code>gRPC</code> 再次保证了单个 <code>RPC</code> 调用中的消息顺序。</p>\n<pre class=\" language-Protobuf\"><code class=\"language-Protobuf\">rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);\n</code></pre>\n<h4 id=\"双向流式RPC（Bidirectional-streaming-RPCs）\"><a href=\"#双向流式RPC（Bidirectional-streaming-RPCs）\" class=\"headerlink\" title=\"双向流式RPC（Bidirectional streaming RPCs）\"></a>双向流式RPC（Bidirectional streaming RPCs）</h4><p>双方使用读写流发送一系列消息。这两个流独立运行，因此客户端和服务器可以按照他们喜欢的任何顺序读取和写入.</p>\n<p>例如：服务器可以在写入响应之前等待接收所有客户端消息，或者它可以交替读取消息然后写入消息，或其他一些读取和写入的组合。保留每个流中消息的顺序</p>\n<pre class=\" language-Protobuf\"><code class=\"language-Protobuf\">rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);\n</code></pre>\n<h3 id=\"API使用（Using-the-API-）\"><a href=\"#API使用（Using-the-API-）\" class=\"headerlink\" title=\"API使用（Using the API ）\"></a>API使用（Using the API ）</h3><p>从.proto文件中的服务定义开始，gRPC 提供了生成客户端和服务器端代码的协议缓冲区编译器插件。gRPC 用户通常在客户端调用这些 API，并在服务器端实现相应的 API。</p>\n<ul>\n<li>在服务端，服务端实现服务声明的方法，并运行一个 gRPC 服务端来处理客户端调用。gRPC 基础架构解码传入请求、执行服务方法并编码服务响应。</li>\n<li>在客户端，客户端有一个称为存根的本地对象（对于某些语言，首选术语是客户端），它实现与服务相同的方法。然后客户端可以在本地对象上调用这些方法，将调用的参数包装在适当的协议缓冲区消息类型中 - gRPC 会在将请求发送到服务器并返回服务器的协议缓冲区响应之后进行处理。</li>\n</ul>\n<h3 id=\"同步与异步\"><a href=\"#同步与异步\" class=\"headerlink\" title=\"同步与异步\"></a>同步与异步</h3><p>在服务器收到响应之前阻塞的同步 RPC 调用是最接近 RPC 所追求的过程调用抽象的近似值。另一方面，网络本质上是异步的，在许多情况下，能够在不阻塞当前线程的情况下启动 RPC 是很有用的。</p>\n<p>大多数语言中的 gRPC 编程 API 有同步和异步两种风格。您可以在每种语言的教程和参考文档中找到更多信息（完整的参考文档即将推出）。</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><h2 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a>生命周期</h2><h4 id=\"一元RPC（Unary-RPCs）-1\"><a href=\"#一元RPC（Unary-RPCs）-1\" class=\"headerlink\" title=\"一元RPC（Unary RPCs）\"></a>一元RPC（Unary RPCs）</h4><h4 id=\"服务器流式RPC（Server-streaming-RPCs）-1\"><a href=\"#服务器流式RPC（Server-streaming-RPCs）-1\" class=\"headerlink\" title=\"服务器流式RPC（Server streaming RPCs）\"></a>服务器流式RPC（Server streaming RPCs）</h4><h4 id=\"客户端流式RPC（Client-streaming-RPCs）-1\"><a href=\"#客户端流式RPC（Client-streaming-RPCs）-1\" class=\"headerlink\" title=\"客户端流式RPC（Client streaming RPCs）\"></a>客户端流式RPC（Client streaming RPCs）</h4><h4 id=\"双向流式RPC（Bidirectional-streaming-RPCs）-1\"><a href=\"#双向流式RPC（Bidirectional-streaming-RPCs）-1\" class=\"headerlink\" title=\"双向流式RPC（Bidirectional streaming RPCs）\"></a>双向流式RPC（Bidirectional streaming RPCs）</h4><h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><h3 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h3><h3 id=\"Go\"><a href=\"#Go\" class=\"headerlink\" title=\"Go\"></a>Go</h3><hr>\n<p><strong>参考</strong></p>\n<ul>\n<li><a href=\"https://grpc.io/docs\">gRPC文档</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：<code>gRPC</code>是<code>Google</code>开发的<code>远程过程调用</code>开源框架</p>\n</blockquote>\n<h2 id=\"引言（Introduction）\"><a href=\"#引言（Introduction）\" class=\"headerlink\" title=\"引言（Introduction）\"></a>引言（Introduction）</h2><p><img src=\"landing-2.svg\"></p>\n<h2 id=\"概述（Overview）\"><a href=\"#概述（Overview）\" class=\"headerlink\" title=\"概述（Overview）\"></a>概述（Overview）</h2><h3 id=\"服务定义（Service-definition）\"><a href=\"#服务定义（Service-definition）\" class=\"headerlink\" title=\"服务定义（Service definition）\"></a>服务定义（Service definition）</h3><p><code>gRPC</code>一般使用<code>protocol buffers</code>来作为<code>接口定义语言</code>(<code>IDL</code>), 如下：</p>\n<pre><code class=\"Protobuf\">service HelloService &#123;\n  rpc SayHello (HelloRequest) returns (HelloResponse);\n&#125;\n\nmessage HelloRequest &#123;\n  string greeting = 1;\n&#125;\n\nmessage HelloResponse &#123;\n  string reply = 1;\n&#125;\n</code></pre>\n<blockquote>\n<p><code>gRPC</code>允许您定义<code>四种</code>服务方法：</p>\n</blockquote>\n<h4 id=\"一元RPC（Unary-RPCs）\"><a href=\"#一元RPC（Unary-RPCs）\" class=\"headerlink\" title=\"一元RPC（Unary RPCs）\"></a>一元RPC（Unary RPCs）</h4><p>客户端向服务器发送单个请求并获得单个响应，就像正常的函数调用一样</p>\n<pre><code class=\"Protobuf\">rpc SayHello(HelloRequest) returns (HelloResponse);\n</code></pre>\n<h4 id=\"服务器流式RPC（Server-streaming-RPCs）\"><a href=\"#服务器流式RPC（Server-streaming-RPCs）\" class=\"headerlink\" title=\"服务器流式RPC（Server streaming RPCs）\"></a>服务器流式RPC（Server streaming RPCs）</h4><p>客户端向服务器发送请求并获取流以读回一系列消息。客户端从返回的流中读取，直到没有更多消息为止。<code>gRPC</code> 保证单个 <code>RPC</code> 调用中的消息顺序</p>\n<pre><code class=\"Protobuf\">rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);\n</code></pre>\n<h4 id=\"客户端流式RPC（Client-streaming-RPCs）\"><a href=\"#客户端流式RPC（Client-streaming-RPCs）\" class=\"headerlink\" title=\"客户端流式RPC（Client streaming RPCs）\"></a>客户端流式RPC（Client streaming RPCs）</h4><p>客户端写入一系列消息并将它们发送到服务器，再次使用提供的流。一旦客户端完成了消息的写入，它就会等待服务器读取它们并返回它的响应。<code>gRPC</code> 再次保证了单个 <code>RPC</code> 调用中的消息顺序。</p>\n<pre><code class=\"Protobuf\">rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);\n</code></pre>\n<h4 id=\"双向流式RPC（Bidirectional-streaming-RPCs）\"><a href=\"#双向流式RPC（Bidirectional-streaming-RPCs）\" class=\"headerlink\" title=\"双向流式RPC（Bidirectional streaming RPCs）\"></a>双向流式RPC（Bidirectional streaming RPCs）</h4><p>双方使用读写流发送一系列消息。这两个流独立运行，因此客户端和服务器可以按照他们喜欢的任何顺序读取和写入.</p>\n<p>例如：服务器可以在写入响应之前等待接收所有客户端消息，或者它可以交替读取消息然后写入消息，或其他一些读取和写入的组合。保留每个流中消息的顺序</p>\n<pre><code class=\"Protobuf\">rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);\n</code></pre>\n<h3 id=\"API使用（Using-the-API-）\"><a href=\"#API使用（Using-the-API-）\" class=\"headerlink\" title=\"API使用（Using the API ）\"></a>API使用（Using the API ）</h3><p>从.proto文件中的服务定义开始，gRPC 提供了生成客户端和服务器端代码的协议缓冲区编译器插件。gRPC 用户通常在客户端调用这些 API，并在服务器端实现相应的 API。</p>\n<ul>\n<li>在服务端，服务端实现服务声明的方法，并运行一个 gRPC 服务端来处理客户端调用。gRPC 基础架构解码传入请求、执行服务方法并编码服务响应。</li>\n<li>在客户端，客户端有一个称为存根的本地对象（对于某些语言，首选术语是客户端），它实现与服务相同的方法。然后客户端可以在本地对象上调用这些方法，将调用的参数包装在适当的协议缓冲区消息类型中 - gRPC 会在将请求发送到服务器并返回服务器的协议缓冲区响应之后进行处理。</li>\n</ul>\n<h3 id=\"同步与异步\"><a href=\"#同步与异步\" class=\"headerlink\" title=\"同步与异步\"></a>同步与异步</h3><p>在服务器收到响应之前阻塞的同步 RPC 调用是最接近 RPC 所追求的过程调用抽象的近似值。另一方面，网络本质上是异步的，在许多情况下，能够在不阻塞当前线程的情况下启动 RPC 是很有用的。</p>\n<p>大多数语言中的 gRPC 编程 API 有同步和异步两种风格。您可以在每种语言的教程和参考文档中找到更多信息（完整的参考文档即将推出）。</p>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><h2 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a>生命周期</h2><h4 id=\"一元RPC（Unary-RPCs）-1\"><a href=\"#一元RPC（Unary-RPCs）-1\" class=\"headerlink\" title=\"一元RPC（Unary RPCs）\"></a>一元RPC（Unary RPCs）</h4><h4 id=\"服务器流式RPC（Server-streaming-RPCs）-1\"><a href=\"#服务器流式RPC（Server-streaming-RPCs）-1\" class=\"headerlink\" title=\"服务器流式RPC（Server streaming RPCs）\"></a>服务器流式RPC（Server streaming RPCs）</h4><h4 id=\"客户端流式RPC（Client-streaming-RPCs）-1\"><a href=\"#客户端流式RPC（Client-streaming-RPCs）-1\" class=\"headerlink\" title=\"客户端流式RPC（Client streaming RPCs）\"></a>客户端流式RPC（Client streaming RPCs）</h4><h4 id=\"双向流式RPC（Bidirectional-streaming-RPCs）-1\"><a href=\"#双向流式RPC（Bidirectional-streaming-RPCs）-1\" class=\"headerlink\" title=\"双向流式RPC（Bidirectional streaming RPCs）\"></a>双向流式RPC（Bidirectional streaming RPCs）</h4><h2 id=\"使用\"><a href=\"#使用\" class=\"headerlink\" title=\"使用\"></a>使用</h2><h3 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h3><h3 id=\"Go\"><a href=\"#Go\" class=\"headerlink\" title=\"Go\"></a>Go</h3><hr>\n<p><strong>参考</strong></p>\n<ul>\n<li><a href=\"https://grpc.io/docs\">gRPC文档</a></li>\n</ul>\n"},{"title":"分布式系统模式","date":"2022-03-08T06:50:46.000Z","_content":"\n## 一致性内核\n## 固定分区\n## \n\n---\n参考\n- [分布式系统模式](https://martinfowler.com/articles/patterns-of-distributed-systems/)","source":"_posts/分布式系统模式.md","raw":"---\ntitle: 分布式系统模式\ndate: 2022-03-08 14:50:46\ntags:\n---\n\n## 一致性内核\n## 固定分区\n## \n\n---\n参考\n- [分布式系统模式](https://martinfowler.com/articles/patterns-of-distributed-systems/)","slug":"分布式系统模式","published":1,"updated":"2022-03-08T06:53:50.314Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw91001m9op7ajm600us","content":"<h2 id=\"一致性内核\"><a href=\"#一致性内核\" class=\"headerlink\" title=\"一致性内核\"></a>一致性内核</h2><h2 id=\"固定分区\"><a href=\"#固定分区\" class=\"headerlink\" title=\"固定分区\"></a>固定分区</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://martinfowler.com/articles/patterns-of-distributed-systems/\">分布式系统模式</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一致性内核\"><a href=\"#一致性内核\" class=\"headerlink\" title=\"一致性内核\"></a>一致性内核</h2><h2 id=\"固定分区\"><a href=\"#固定分区\" class=\"headerlink\" title=\"固定分区\"></a>固定分区</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://martinfowler.com/articles/patterns-of-distributed-systems/\">分布式系统模式</a></li>\n</ul>\n"},{"title":"计算机科学 | 字符、字符集、字符编码详解","date":"2021-10-24T14:54:18.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n> 摘要：学习`计算机科学`数据存储，记录笔记，方便后续温故\n\n在`计算机`中存储文本数据，文本数据就是`字符`组成的数据，但是计算机只能存储数字，代表`字符`的数字就是字符集，`字符`转`数字`的过程叫`字符编码`\n\n# 字符\n是一个`信息单位`。字母系统或音节文字等自然语言, 如：一个汉字、英文、假名、韩文等\n\n# 字符集\n\n# 字符编码\n\n---------\n\n参考\n- [字符——维基百科](https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6)","source":"_posts/计算机科学-字符、字符集、字符编码详解.md","raw":"---\ntitle: 计算机科学 | 字符、字符集、字符编码详解\ndate: 2021-10-24 22:54:18\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java8新特性\ncategories:\n    - [计算机科学]\ntags:\n    - 计算机科学\n---\n\n> 摘要：学习`计算机科学`数据存储，记录笔记，方便后续温故\n\n在`计算机`中存储文本数据，文本数据就是`字符`组成的数据，但是计算机只能存储数字，代表`字符`的数字就是字符集，`字符`转`数字`的过程叫`字符编码`\n\n# 字符\n是一个`信息单位`。字母系统或音节文字等自然语言, 如：一个汉字、英文、假名、韩文等\n\n# 字符集\n\n# 字符编码\n\n---------\n\n参考\n- [字符——维基百科](https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6)","slug":"计算机科学-字符、字符集、字符编码详解","published":1,"updated":"2021-10-25T12:21:20.519Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw93001p9op73fos02qn","content":"<blockquote>\n<p>摘要：学习<code>计算机科学</code>数据存储，记录笔记，方便后续温故</p>\n</blockquote>\n<p>在<code>计算机</code>中存储文本数据，文本数据就是<code>字符</code>组成的数据，但是计算机只能存储数字，代表<code>字符</code>的数字就是字符集，<code>字符</code>转<code>数字</code>的过程叫<code>字符编码</code></p>\n<h1 id=\"字符\"><a href=\"#字符\" class=\"headerlink\" title=\"字符\"></a>字符</h1><p>是一个<code>信息单位</code>。字母系统或音节文字等自然语言, 如：一个汉字、英文、假名、韩文等</p>\n<h1 id=\"字符集\"><a href=\"#字符集\" class=\"headerlink\" title=\"字符集\"></a>字符集</h1><h1 id=\"字符编码\"><a href=\"#字符编码\" class=\"headerlink\" title=\"字符编码\"></a>字符编码</h1><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6\">字符——维基百科</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>摘要：学习<code>计算机科学</code>数据存储，记录笔记，方便后续温故</p>\n</blockquote>\n<p>在<code>计算机</code>中存储文本数据，文本数据就是<code>字符</code>组成的数据，但是计算机只能存储数字，代表<code>字符</code>的数字就是字符集，<code>字符</code>转<code>数字</code>的过程叫<code>字符编码</code></p>\n<h1 id=\"字符\"><a href=\"#字符\" class=\"headerlink\" title=\"字符\"></a>字符</h1><p>是一个<code>信息单位</code>。字母系统或音节文字等自然语言, 如：一个汉字、英文、假名、韩文等</p>\n<h1 id=\"字符集\"><a href=\"#字符集\" class=\"headerlink\" title=\"字符集\"></a>字符集</h1><h1 id=\"字符编码\"><a href=\"#字符编码\" class=\"headerlink\" title=\"字符编码\"></a>字符编码</h1><hr>\n<p>参考</p>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6\">字符——维基百科</a></li>\n</ul>\n"},{"title":"算法:SHA-1","date":"2022-03-08T02:58:34.000Z","_content":"","source":"_posts/算法-SHA-1.md","raw":"---\ntitle: '算法:SHA-1'\ndate: 2022-03-08 10:58:34\ntags:\n---\n","slug":"算法-SHA-1","published":1,"updated":"2022-03-08T02:58:34.124Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw94001r9op71b093zu9","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"设计模式","date":"2015-07-31T16:00:00.000Z","top":false,"hide":false,"cover":false,"toc":true,"mathjax":false,"_content":"\n`设计模式`：是`经验复用`。谁多前辈遭遇过相同问题, 顺利解决这些问题的方法。把这些方法抽象总结就成了`设计模式`\n\n设计原则：\n    - 把`变化`与`不变化`的功能代码分开，让`不变化`功能代码不受`变化`功能代码影响\n    - 针对`接口编程`，而不是实现编程\n\n## 设计模式六大原则\n\n### 单一职责原则\n定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 \n\n问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。\n\n解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。\n\n### 里氏替换原则\n定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。\n\n定义2：所有引用基类的地方必须能透明地使用其子类的对象。\n\n问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。\n\n解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。\n\n### 依赖倒置原则\n\n### 接口隔离原则\n\n### 迪米特法则\n\n### 开闭原则\n\n\n<br/>\n\n\n## 创建模式\n\n## 创建模式\n\n---\n\n参考\n\n","source":"_posts/设计模式.md","raw":"---\ntitle: 设计模式\ndate: 2015-08-01 00:00:00\n# img: /source/images/xxx.jpg\ntop: false\nhide: false\ncover: false\n# coverImg: /images/1.jpg\n# password: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92\ntoc: true\nmathjax: false\n# summary: 记录Java在Mac系统中的开发环境配置\ncategories: \n    - 设计模式\ntags:\n    - 设计模式\n---\n\n`设计模式`：是`经验复用`。谁多前辈遭遇过相同问题, 顺利解决这些问题的方法。把这些方法抽象总结就成了`设计模式`\n\n设计原则：\n    - 把`变化`与`不变化`的功能代码分开，让`不变化`功能代码不受`变化`功能代码影响\n    - 针对`接口编程`，而不是实现编程\n\n## 设计模式六大原则\n\n### 单一职责原则\n定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 \n\n问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。\n\n解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。\n\n### 里氏替换原则\n定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。\n\n定义2：所有引用基类的地方必须能透明地使用其子类的对象。\n\n问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。\n\n解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。\n\n### 依赖倒置原则\n\n### 接口隔离原则\n\n### 迪米特法则\n\n### 开闭原则\n\n\n<br/>\n\n\n## 创建模式\n\n## 创建模式\n\n---\n\n参考\n\n","slug":"设计模式","published":1,"updated":"2022-01-19T13:45:45.267Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1t9uw95001u9op7et7q5cqd","content":"<p><code>设计模式</code>：是<code>经验复用</code>。谁多前辈遭遇过相同问题, 顺利解决这些问题的方法。把这些方法抽象总结就成了<code>设计模式</code></p>\n<p>设计原则：\n    - 把<code>变化</code>与<code>不变化</code>的功能代码分开，让<code>不变化</code>功能代码不受<code>变化</code>功能代码影响\n    - 针对<code>接口编程</code>，而不是实现编程</p>\n<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><h3 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h3><p>定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 </p>\n<p>问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。</p>\n<p>解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。</p>\n<h3 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h3><p>定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。</p>\n<p>定义2：所有引用基类的地方必须能透明地使用其子类的对象。</p>\n<p>问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。</p>\n<p>解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。</p>\n<h3 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h3><h3 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h3><h3 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h3><h3 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h3><br>\n\n\n<h2 id=\"创建模式\"><a href=\"#创建模式\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h2><h2 id=\"创建模式-1\"><a href=\"#创建模式-1\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h2><hr>\n<p>参考</p>\n","site":{"data":{}},"excerpt":"","more":"<p><code>设计模式</code>：是<code>经验复用</code>。谁多前辈遭遇过相同问题, 顺利解决这些问题的方法。把这些方法抽象总结就成了<code>设计模式</code></p>\n<p>设计原则：\n    - 把<code>变化</code>与<code>不变化</code>的功能代码分开，让<code>不变化</code>功能代码不受<code>变化</code>功能代码影响\n    - 针对<code>接口编程</code>，而不是实现编程</p>\n<h2 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h2><h3 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h3><p>定义：不要存在多于一个导致类变更的原因。通俗的说，即一个类只负责一项职责。 </p>\n<p>问题由来：类T负责两个不同的职责：职责P1，职责P2。当由于职责P1需求发生改变而需要修改类T时，有可能会导致原本运行正常的职责P2功能发生故障。</p>\n<p>解决方案：遵循单一职责原则。分别建立两个类T1、T2，使T1完成职责P1功能，T2完成职责P2功能。这样，当修改类T1时，不会使职责P2发生故障风险；同理，当修改T2时，也不会使职责P1发生故障风险。</p>\n<h3 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h3><p>定义1：如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。</p>\n<p>定义2：所有引用基类的地方必须能透明地使用其子类的对象。</p>\n<p>问题由来：有一功能P1，由类A完成。现需要将功能P1进行扩展，扩展后的功能为P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。</p>\n<p>解决方案：当使用继承时，遵循里氏替换原则。类B继承类A时，除添加新的方法完成新增功能P2外，尽量不要重写父类A的方法，也尽量不要重载父类A的方法。</p>\n<h3 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h3><h3 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h3><h3 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h3><h3 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h3><br/>\n\n\n<h2 id=\"创建模式\"><a href=\"#创建模式\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h2><h2 id=\"创建模式-1\"><a href=\"#创建模式-1\" class=\"headerlink\" title=\"创建模式\"></a>创建模式</h2><hr>\n<p>参考</p>\n"}],"PostAsset":[{"_id":"source/_posts/01-MySQL实战45讲-基础架构：一条SQL查询语句是如何执行的/1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg","slug":"1568963177160-f355b449-96c8-4ed8-a280-598febedb881.jpg","post":"ckr8tjsur0001r5p7a2vo974p","modified":0,"renderable":0},{"_id":"source/_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的/0d2070e8f84c4801adbfa03bda1f98d9.png","slug":"0d2070e8f84c4801adbfa03bda1f98d9.png","post":"ckr8tjsuv0003r5p762oi8jkr","modified":0,"renderable":0},{"_id":"source/_posts/02-MySQL实战45讲-日志系统：一条SQL更新语句是如何执行的/16a7950217b3f0f4ed02db5db59562a7.png","slug":"16a7950217b3f0f4ed02db5db59562a7.png","post":"ckr8tjsuv0003r5p762oi8jkr","modified":0,"renderable":0},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","slug":"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","post":"ckr8tjsuz0009r5p7bjyrhve3","modified":0,"renderable":0},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg","slug":"1569149358407-d63ddc13-2047-4460-b20a-d3ac886758e4.jpg","post":"ckr8tjsuz0009r5p7bjyrhve3","modified":0,"renderable":0},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg","slug":"1569149358442-aa863587-7ebf-4e00-9956-c8d326a55b7c.jpg","post":"ckr8tjsuz0009r5p7bjyrhve3","modified":0,"renderable":0},{"_id":"source/_posts/05-MySQL实战45讲-深入浅出索引（下）/1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg","slug":"1569149358557-78017d09-f35c-487d-bd57-6ff946ce747a.jpg","post":"ckr8tjsuz0009r5p7bjyrhve3","modified":0,"renderable":0},{"_id":"source/_posts/06-MySQL实战45讲-全局锁和表锁：给表加个字段怎么有这么多阻碍/1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg","slug":"1569382154657-6fef5930-ab96-45c6-ae36-cfe33b021189.jpg","post":"ckr8tjsv2000dr5p73txwd8e9","modified":0,"renderable":0},{"_id":"source/_posts/03-MySQL实战45讲-事务隔离：为什么你改了我还看不见/1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg","slug":"1569213942008-c0e161c4-b6ee-4a40-a5e9-e6f22d52bee7.jpg","post":"ckr8tjsuy0007r5p7c7s4d9kg","modified":0,"renderable":0},{"_id":"source/_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响/1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg","slug":"1568952598708-f0bb75aa-8319-4517-ab34-5b7e8d1c6b77.jpg","post":"ckr8tjsv3000er5p7gubh7mbr","modified":0,"renderable":0},{"_id":"source/_posts/07-MySQL实战45讲-行锁功过：怎么减少行锁对性能的影响/1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg","slug":"1568952598739-1a1fecae-52ed-4931-8207-f142b367a5cc.jpg","post":"ckr8tjsv3000er5p7gubh7mbr","modified":0,"renderable":0},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg","slug":"1568953304397-c2c0d64d-1d3a-4d94-ae08-786421f1a9b9.jpg","post":"ckr8tjsv0000ar5p7dqrkbrss","modified":0,"renderable":0},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg","slug":"1568953304427-83dfa291-dca7-43d4-ac7c-2abfbbf1b3ee.jpg","post":"ckr8tjsv0000ar5p7dqrkbrss","modified":0,"renderable":0},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","slug":"1568953304433-bbbf58ba-bb93-4152-9572-dc8616aadf57.jpg","post":"ckr8tjsv0000ar5p7dqrkbrss","modified":0,"renderable":0},{"_id":"source/_posts/04-MySQL实战45讲-深入浅出索引（上）/1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg","slug":"1568953304441-959631b0-f145-4924-ba8d-e1eb8034754c.jpg","post":"ckr8tjsv0000ar5p7dqrkbrss","modified":0,"renderable":0},{"_id":"source/_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的/1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg","slug":"1569748050059-bd55fc29-e4f6-44be-b3b1-5faba6f6bb74.jpg","post":"ckr8tjsv4000jr5p7c41e91pu","modified":0,"renderable":0},{"_id":"source/_posts/08-MySQL实战45讲-事务到底是隔离的还是不隔离的/1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg","slug":"1569748050205-95cf583a-451d-4f53-8d84-cef62ff2b926.jpg","post":"ckr8tjsv4000jr5p7c41e91pu","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg","slug":"1569155459504-8aad0b91-4d74-49bd-a77b-d40f8d4520d8.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg","slug":"1569155459505-69d48d0d-752d-431b-bd21-a1143bd11029.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg","slug":"1569155459509-b884de06-1e6d-4614-9997-a9f4ebb69c0c.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg","slug":"1569155459514-c58a9786-fb78-4ac0-a895-f05ac3686404.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg","slug":"1569155459524-c178149b-eeaa-49e3-8642-e5086decca9f.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg","slug":"1569155459528-4d82361e-e063-4e8e-b9b6-a7305bcbca56.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg","slug":"1569155459541-53897d4c-c379-4311-a3a7-6ee6670855d5.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg","slug":"1569155459547-bf77ed64-909a-438f-af79-790e783dfa74.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg","slug":"1569155459554-46a65268-ebdc-4a08-bf67-ea1b25ccbd62.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg","slug":"1569155459556-9a88dfd7-dcb9-43cc-8713-743299b239d4.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/10-MySQL为什么有时候会选错索引/1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg","slug":"1569155459642-2046af04-8679-4440-bd25-0dd6b45ef1bd.jpg","post":"ckr8tjsv5000mr5p7b8icclkm","modified":0,"renderable":0},{"_id":"source/_posts/11-怎么给字符串字段加索引/1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg","slug":"1569223778013-4084d6a1-03aa-46de-a69c-c85be31d071e.jpg","post":"ckr8tjsv8000tr5p7ap4l6r2t","modified":0,"renderable":0},{"_id":"source/_posts/11-怎么给字符串字段加索引/1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg","slug":"1569223778021-a386caf4-cb89-4c33-ad94-0d77bdc5ebbb.jpg","post":"ckr8tjsv8000tr5p7ap4l6r2t","modified":0,"renderable":0},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg","slug":"1569233914755-6524a051-c78f-4f9d-ba18-251561548ad2.jpg","post":"ckr8tjsvb000xr5p79rwi2mo6","modified":0,"renderable":0},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg","slug":"1569233914781-02374899-ab80-4101-8a6a-4cbd3ee34cf6.jpg","post":"ckr8tjsvb000xr5p79rwi2mo6","modified":0,"renderable":0},{"_id":"source/_posts/13-为什么表数据删掉一半，表文件大小不变/1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg","slug":"1569233914793-a25a1f16-f674-4b5a-88e2-c13421e78725.jpg","post":"ckr8tjsvb000xr5p79rwi2mo6","modified":0,"renderable":0},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg","slug":"1569241121302-11844cb2-9695-48e3-b54f-4238c46e603d.jpg","post":"ckr8tjsvc0010r5p76ctfb8o2","modified":0,"renderable":0},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg","slug":"1569241121309-be960491-3b01-43b6-83c6-89beba87d41f.jpg","post":"ckr8tjsvc0010r5p76ctfb8o2","modified":0,"renderable":0},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg","slug":"1569241121312-c0d12d47-a7e2-4914-9ef4-2032a271a58c.jpg","post":"ckr8tjsvc0010r5p76ctfb8o2","modified":0,"renderable":0},{"_id":"source/_posts/14-count-这么慢，我该怎么办/1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg","slug":"1569241121358-b2c3f313-be99-4f14-8555-9b12c31c1d3b.jpg","post":"ckr8tjsvc0010r5p76ctfb8o2","modified":0,"renderable":0},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png","slug":"1544620888346-1b3f4245-e4a5-4bbb-9966-73856c038f9f.png","post":"ckr8tjsvd0014r5p7fvd92d00","modified":0,"renderable":0},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg","slug":"1569233917227-802817be-61ca-4573-b260-e84157098f16.jpg","post":"ckr8tjsvd0014r5p7fvd92d00","modified":0,"renderable":0},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg","slug":"1569233917227-9d4081f3-4c5f-40d8-89c9-77dff9db4f31.jpg","post":"ckr8tjsvd0014r5p7fvd92d00","modified":0,"renderable":0},{"_id":"source/_posts/12-为什么我的MySQL会“抖”一下/1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg","slug":"1569233917230-43e80ab7-b678-402e-b30c-6675d01823ef.jpg","post":"ckr8tjsvd0014r5p7fvd92d00","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg","slug":"1568993087598-70c22401-6211-4a07-98f5-63ab8acb7dd2.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg","slug":"1568993087605-8e8ea93a-963d-4e97-b53b-2a01373fc125.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg","slug":"1568993087620-57e1b53e-7863-4e97-90a4-e1728903d77e.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg","slug":"1568993087625-a8fd3929-5fb1-4861-a921-3a9a6c8db110.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg","slug":"1568993087650-11f243a7-0baa-41cc-874c-db63dabfa62f.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/17-如何正确地显示随机消息/1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg","slug":"1568993087942-101a36d6-8d85-4ed9-a3e0-7fb3556b17a9.jpg","post":"ckr8tjsvg001er5p7h0t74j4e","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg","slug":"1568953318740-38e607d6-be0c-4447-a803-4de1d13bd45c.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg","slug":"1568953318743-9f9abdce-4820-4f1c-8047-5fbdb531572b.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg","slug":"1568953318750-bed69a95-b80f-4dde-8a89-e4cab20bdaaa.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg","slug":"1568953318765-da9e50f4-c79f-489b-b031-8b67acedd387.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg","slug":"1568953318788-1bd3f77e-9f50-488d-b225-72a5cc05720a.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg","slug":"1568953318916-1fdbbcf2-32e3-4397-9622-ad0ef7472d42.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/15-答疑文章（一）：日志和索引相关问题/1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg","slug":"1568953318970-d8a438f5-0bc8-4d89-97f9-9cc02bc0cf89.jpg","post":"ckr8tjsve0017r5p7b1fh223f","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg","slug":"1568959646688-1a9af5c0-82af-4371-ba80-cf917a46a5c7.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg","slug":"1568959646698-25748ead-47ae-4b59-af7e-0796737a5bf3.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg","slug":"1568959646704-f257520f-52d3-484a-aea0-fe22c3df2783.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg","slug":"1568959646707-2aaaa1aa-3189-4d6c-b6d2-32f3bc18a975.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg","slug":"1568959646709-61cf5ca2-2c38-4049-8025-2d7ee463f828.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg","slug":"1568959646720-d5987c2e-433d-4b90-939d-79eb05c04ba2.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg","slug":"1568959646720-ea85c83c-c9a7-4976-b16a-c37d50e15fa7.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg","slug":"1568959646727-bfe83267-5061-4859-ad5b-f72e80f7fae9.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg","slug":"1568959646739-fe3a6f13-e8eb-47c6-8dc6-2915ab534b8b.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg","slug":"1568959646745-0e47db60-83b6-4d0f-bf75-03b4de743dac.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/16-“order-by”是怎么工作的/1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg","slug":"1568959646787-e5a2b53c-60c0-4244-bb85-ad3041b1ba93.jpg","post":"ckr8tjsvf001br5p753ap9jig","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg","slug":"1569243871331-022ddca9-83c6-48ec-b160-0ad5395dcddd.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg","slug":"1569243871334-45a37eaf-4ddb-4bf5-b658-64c584d32bf5.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg","slug":"1569243871342-7a1857f3-1719-4eb3-9f39-a6438129c4b1.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg","slug":"1569243871349-c206682a-17d7-44c2-bdaa-2a9e2299bc83.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg","slug":"1569243871377-bb887b38-5423-43c4-ac60-af0b530d17cd.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg","slug":"1569243871396-d59360f0-39e4-46fc-987c-aea2b4419e8f.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/18-为什么这些SQL语句逻辑相同，性能却差异巨大/1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg","slug":"1569243871404-261369c4-4204-4fb6-93c8-ec699d6085c0.jpg","post":"ckr8tjsvh001ir5p772qt3n1o","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg","slug":"1569229744979-4c49e3b4-f88d-4e43-8878-f81dfc1ade55.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg","slug":"1569229744984-4de5d039-83e3-432e-ad71-9db0906d0f29.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg","slug":"1569229744990-e871c1bb-06d6-46c8-934c-b57b0d00a24d.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg","slug":"1569229744991-b046d45c-dee2-4b31-a383-0df3d87b6ee9.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg","slug":"1569229744992-67149568-12f0-4b9a-aa9e-63f94c888009.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg","slug":"1569229744994-d99eb119-756f-484d-bb76-dcbbb35b867d.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg","slug":"1569229744996-1219760a-c232-41a1-a443-34a209c846f1.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg","slug":"1569229744998-2f703278-0ea4-4747-af83-7a56ebd0e412.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg","slug":"1569229745002-251b75ba-87e9-4c57-8812-da52fe2def32.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg","slug":"1569229745005-b6a4c9cf-d241-4b6e-aa8a-6337b468e9c7.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg","slug":"1569229745006-c0b56e58-0fa2-4e84-b7bb-884260da9fa8.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg","slug":"1569229745015-e7c4f4d3-2819-4ec8-b84e-8b89b49bce23.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg","slug":"1569229745016-d17920f5-c976-4a5c-98ec-f2a38aab8687.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg","slug":"1569229745037-5790b499-f2ba-4f5e-8bcf-a5d608f2c308.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg","slug":"1569229745059-7bb8a71d-338f-453c-9124-3dbe003eefb2.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/19-为什么我只查一行的语句，也执行这么慢/1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg","slug":"1569229745133-7105772e-5c7e-49e2-b43e-057ac68accbf.jpg","post":"ckr8tjsvi001lr5p74qow6dpr","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg","slug":"1569229734334-0898c1cf-864f-4d45-aded-56b662490616.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg","slug":"1569229734336-f9e83cf7-4935-42f5-8370-fed21918ae4b.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg","slug":"1569229734344-1a7742d7-7399-4c46-a0af-6e5bdef29657.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg","slug":"1569229734350-0784d553-48da-4aac-8cb9-1829b0407799.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg","slug":"1569229734355-ae07f8f9-8457-44a5-9986-6692f38934ca.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg","slug":"1569229734358-6e027ab6-6cd4-42f4-a0b2-d0434fde47eb.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg","slug":"1569229734377-a93754bb-5210-40f7-b177-24809968a16a.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg","slug":"1569229734395-5e64deb0-9922-4385-bae2-acb9fd1fc6a8.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/20-幻读是什么，幻读有什么问题/1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg","slug":"1569229734401-ccc07104-5150-4b52-a0f4-e0ca3fc2223e.jpg","post":"ckr8tjsvi001or5p7hu986o59","modified":0,"renderable":0},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg","slug":"1569241555863-60e92ede-2277-410b-bf8b-42603c3434a6.jpg","post":"ckr8tjsvj001rr5p78vne2uml","modified":0,"renderable":0},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg","slug":"1569241555874-c9651937-9718-43b9-a03a-b89d2bbaa075.jpg","post":"ckr8tjsvj001rr5p78vne2uml","modified":0,"renderable":0},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg","slug":"1569241555906-18ddf80b-4e97-4fd2-8805-b0135f94d0cf.jpg","post":"ckr8tjsvj001rr5p78vne2uml","modified":0,"renderable":0},{"_id":"source/_posts/22-MySQL有哪些“饮鸩止渴”提高性能的方法/1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg","slug":"1569241555969-b48df94b-bbe3-4dad-9f01-943a9f6d0c7f.jpg","post":"ckr8tjsvj001rr5p78vne2uml","modified":0,"renderable":0},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.png","slug":"1546827952613-25f75d53-dc10-45aa-b730-1dc85df2c286.png","post":"ckr8tjsvl001xr5p72yyf3ze4","modified":0,"renderable":0},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg","slug":"1568993828269-00043949-d752-46c7-a179-6c868b004387.jpg","post":"ckr8tjsvl001xr5p72yyf3ze4","modified":0,"renderable":0},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg","slug":"1568993828412-332e973e-f96d-4806-8562-a72424b6dd42.jpg","post":"ckr8tjsvl001xr5p72yyf3ze4","modified":0,"renderable":0},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg","slug":"1568993828446-4a6231cd-be32-4b5d-a4cb-596f4b04ab37.jpg","post":"ckr8tjsvl001xr5p72yyf3ze4","modified":0,"renderable":0},{"_id":"source/_posts/23-MySQL是怎么保证数据不丢的/1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg","slug":"1568993828535-a6742049-7a5f-461c-bcc4-f8e3120837f8.jpg","post":"ckr8tjsvl001xr5p72yyf3ze4","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg","slug":"1569240878793-1464412e-f116-405e-9884-2ef01ade4dba.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg","slug":"1569240878798-c975e65e-e7b5-4ffe-bdb8-d566f4148700.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg","slug":"1569240878807-c5bc240a-d02c-484e-960b-28c36c498f4c.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg","slug":"1569240878808-3b5f0a01-6ace-4e30-bdc2-449772b2f522.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg","slug":"1569240878811-2833e4e6-028e-47e0-acdb-e187c34b1d3f.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg","slug":"1569240878815-44f005c6-39de-4f7d-b65d-9327e9e89fac.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg","slug":"1569240878820-bc96be63-c9e4-4962-945e-1060a369baa5.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg","slug":"1569240878821-53a60a0f-561b-4393-b010-e8446375106e.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg","slug":"1569240878822-abd77190-e6e9-445a-b0eb-4f9204082e23.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg","slug":"1569240878831-24eefbd9-6a4f-4308-903a-9b810ddf682a.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/21-为什么我只改一行的语句，锁这么多/1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg","slug":"1569240878874-2068a32e-7bb9-4e6c-bc97-9ca7ca768973.jpg","post":"ckr8tjsvk001ur5p73urk5fxe","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpeg","slug":"1547087111097-320c5e99-54a0-41b6-9bec-00dbea00a22c.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpeg","slug":"1547087144644-3c03a5d3-9f03-4ca7-8fd9-f5826e2ed376.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpeg","slug":"1547087279990-5d481429-5f03-4511-b0d1-726dd5968b45.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpeg","slug":"1547087301388-59a283bb-bea4-443e-b0d0-10d15dc2084f.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpeg","slug":"1547087347792-ed937e8a-007c-4831-a233-20e30f3c9d36.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/25-MySQL是怎么保证高可用的/1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpeg","slug":"1547087367383-0c9fa77f-13d9-4bf4-a60f-bde92786f673.jpeg","post":"ckr8tjsvm0023r5p7825ddr59","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpeg","slug":"1547087397255-5d8975df-f95d-45cd-9b8e-cd88b14e0fcb.jpeg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg","slug":"1569158622762-b58a14d8-a5da-4f59-8690-fceac19368c9.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg","slug":"1569158622770-7d25470c-1a4f-42c8-baf8-58124f33ebd5.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg","slug":"1569158622775-796fa91e-e9ba-4fcb-99d0-176a32cd57b7.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg","slug":"1569158622776-34328582-4194-44e4-9857-e26d7bf933bb.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg","slug":"1569158622782-d21ccfca-ab86-4601-b1ea-974e49a14e2b.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg","slug":"1569158622783-62547ed7-6c14-4c9e-9bbe-fce159063ee7.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg","slug":"1569158622831-22448866-547a-4634-a9da-ed1e515e9c3f.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg","slug":"1569158622895-5a167c2f-e4b7-4625-9514-59c6099529fd.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/24-MySQL是怎么保证主备一致的/1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg","slug":"1569158622931-d4f264e0-dfec-44cb-8d62-216a2c465bd3.jpg","post":"ckr8tjsvm0020r5p75jmk1cvw","modified":0,"renderable":0},{"_id":"source/_posts/Github搭建Hexo/1542037823098.jpg","slug":"1542037823098.jpg","post":"ckr8tjswd004tr5p7anegal9r","modified":0,"renderable":0},{"_id":"source/_posts/Github搭建Hexo/1542073066701.jpg","slug":"1542073066701.jpg","post":"ckr8tjswd004tr5p7anegal9r","modified":0,"renderable":0},{"_id":"source/_posts/Github搭建Hexo/1542074055382.jpg","slug":"1542074055382.jpg","post":"ckr8tjswd004tr5p7anegal9r","modified":0,"renderable":0},{"_id":"source/_posts/Java-Agent详解/1565784207465.jpg","slug":"1565784207465.jpg","post":"ckr8tjswh0055r5p7346o5ppb","modified":0,"renderable":0},{"_id":"source/_posts/Java-Agent详解/1565786297241.jpg","slug":"1565786297241.jpg","post":"ckr8tjswh0055r5p7346o5ppb","modified":0,"renderable":0},{"_id":"source/_posts/MongoDB安装/adminMongo_connections.png","slug":"adminMongo_connections.png","post":"ckr8tjswr006ar5p7fch2dzj0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png","slug":"graphviz-167adfc2e52e078d4c0e3c8a9eddec54551602fb.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png","slug":"graphviz-5f4d8b6177061ac52d0ae05ef357fceb52e9cb90.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png","slug":"graphviz-72760f6945c3742eca0df91a91cc379168eda82d.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png","slug":"graphviz-8fc5de396a5b52c3d0b1991a1e09558ad055dd86.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f.png","slug":"graphviz-acf7fe010d7b09c5d2500c72eb555863e67ad74f.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png","slug":"graphviz-bd3eecd927a4d8fc33b4a1c7f5957c52d67c5021.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/Redis设计与实现/lru_comparison.png","slug":"lru_comparison.png","post":"ckr8tjsx3007pr5p786ki9ze0","modified":0,"renderable":0},{"_id":"source/_posts/lrzsz/122150034707951.png","slug":"122150034707951.png","post":"ckr8tjsx9008gr5p7ebje7rg5","modified":0,"renderable":0},{"_id":"source/_posts/lrzsz/x_engine_paper.pdf","slug":"x_engine_paper.pdf","post":"ckr8tjsx9008gr5p7ebje7rg5","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/1543202719106.jpg","slug":"1543202719106.jpg","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/1543213263217.jpg","slug":"1543213263217.jpg","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/Appearance.jpg","slug":"Appearance.jpg","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/Setting_Default_Term.png","slug":"Setting_Default_Term.png","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/Status_bar.jpg","slug":"Status_bar.jpg","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/iTerm2/logo2x.jpg","slug":"logo2x.jpg","post":"ckr8tjsx8008cr5p7285l76as","modified":0,"renderable":0},{"_id":"source/_posts/tensorflow教程/tensors_flowing.gif","slug":"tensors_flowing.gif","post":"ckr8tjsxb008or5p7c9g737hs","modified":0,"renderable":0},{"_id":"source/_posts/thrift教程/thrift-layers.png","slug":"thrift-layers.png","post":"ckr8tjsxc008sr5p7a5w8erud","modified":0,"renderable":0},{"_id":"source/_posts/人工神经网络/1543648111947.jpg","slug":"1543648111947.jpg","post":"ckr8tjsxf0093r5p7993h9ekq","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/55821626-8701-4F00-879A-93B7D5039B06.png","slug":"55821626-8701-4F00-879A-93B7D5039B06.png","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/55821626-8701-4F00-879A-93B7D5039B06.svg","slug":"55821626-8701-4F00-879A-93B7D5039B06.svg","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/carbon.svg","slug":"carbon.svg","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/test.drawio.svg","slug":"test.drawio.svg","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/test1.drawio.png","slug":"test1.drawio.png","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/语法分析器的设计和实现/转换示例.svg","slug":"转换示例.svg","post":"ckr8tjsy300bhr5p7cnyidc6z","modified":0,"renderable":0},{"_id":"source/_posts/Git/areas.png","post":"cl1t9uw7o00009op7356id00e","slug":"areas.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/basic-merging-2.png","post":"cl1t9uw7o00009op7356id00e","slug":"basic-merging-2.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/basic-rebase-3.png","post":"cl1t9uw7o00009op7356id00e","slug":"basic-rebase-3.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/benevolent-dictator.png","post":"cl1t9uw7o00009op7356id00e","slug":"benevolent-dictator.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/centralized_workflow.png","post":"cl1t9uw7o00009op7356id00e","slug":"centralized_workflow.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/commit-and-tree.png","post":"cl1t9uw7o00009op7356id00e","slug":"commit-and-tree.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/commits-and-parents.png","post":"cl1t9uw7o00009op7356id00e","slug":"commits-and-parents.png","modified":1,"renderable":1},{"_id":"source/_posts/Git/integration-manager.png","post":"cl1t9uw7o00009op7356id00e","slug":"integration-manager.png","modified":1,"renderable":1},{"_id":"source/_posts/IntelliJ-IDEA破解/1645412947773.jpg","post":"cl1t9uw8h000h9op7h8k1dkp6","slug":"1645412947773.jpg","modified":1,"renderable":1},{"_id":"source/_posts/IntelliJ-IDEA破解/1645497394807.jpg","post":"cl1t9uw8h000h9op7h8k1dkp6","slug":"1645497394807.jpg","modified":1,"renderable":1},{"_id":"source/_posts/IntelliJ-IDEA破解/1645497851808.jpg","post":"cl1t9uw8h000h9op7h8k1dkp6","slug":"1645497851808.jpg","modified":1,"renderable":1},{"_id":"source/_posts/Java程序设计/变量-内存.jpg","post":"cl1t9uw8r00109op75fu7912q","slug":"变量-内存.jpg","modified":1,"renderable":1},{"_id":"source/_posts/gRPC/landing-2.svg","post":"cl1t9uw8y001g9op782gm72m6","slug":"landing-2.svg","modified":1,"renderable":1}],"PostCategory":[{"post_id":"ckr8tjsuz0009r5p7bjyrhve3","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsv4000fr5p78y5h3otv"},{"post_id":"ckr8tjsur0001r5p7a2vo974p","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsv5000kr5p75n1c7yai"},{"post_id":"ckr8tjsv0000ar5p7dqrkbrss","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsv6000nr5p7hwu0dem8"},{"post_id":"ckr8tjsv2000dr5p73txwd8e9","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsv7000rr5p72ro2hsez"},{"post_id":"ckr8tjsuv0003r5p762oi8jkr","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsva000ur5p734twewwa"},{"post_id":"ckr8tjsv3000er5p7gubh7mbr","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvc000yr5p7bpd11ln8"},{"post_id":"ckr8tjsv4000jr5p7c41e91pu","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvc0011r5p73noggqv7"},{"post_id":"ckr8tjsuy0007r5p7c7s4d9kg","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvd0015r5p76use4j02"},{"post_id":"ckr8tjsv5000mr5p7b8icclkm","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsve0018r5p7g0zicxng"},{"post_id":"ckr8tjsv7000qr5p709jiah95","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvg001cr5p70xar9h64"},{"post_id":"ckr8tjsv8000tr5p7ap4l6r2t","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvg001fr5p749uyd4tx"},{"post_id":"ckr8tjsvb000xr5p79rwi2mo6","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvh001jr5p759pd2qis"},{"post_id":"ckr8tjsvc0010r5p76ctfb8o2","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvi001mr5p797342vws"},{"post_id":"ckr8tjsvd0014r5p7fvd92d00","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvj001pr5p75oin92fg"},{"post_id":"ckr8tjsve0017r5p7b1fh223f","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvk001sr5p7fiws0viq"},{"post_id":"ckr8tjsvf001br5p753ap9jig","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvl001vr5p7b9m58b4c"},{"post_id":"ckr8tjsvg001er5p7h0t74j4e","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvl001yr5p7a6db4t7k"},{"post_id":"ckr8tjsvh001ir5p772qt3n1o","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvm0021r5p7fkwvcowa"},{"post_id":"ckr8tjsvi001lr5p74qow6dpr","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvn0024r5p70smrewmr"},{"post_id":"ckr8tjsvi001or5p7hu986o59","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvn0027r5p7dc6bg4fn"},{"post_id":"ckr8tjsvj001rr5p78vne2uml","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvo002ar5p737npg8f2"},{"post_id":"ckr8tjsvk001ur5p73urk5fxe","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvp002dr5p74szh736l"},{"post_id":"ckr8tjsvl001xr5p72yyf3ze4","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvq002gr5p75iqj1a0v"},{"post_id":"ckr8tjsvm0020r5p75jmk1cvw","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvr002jr5p73v1p7qss"},{"post_id":"ckr8tjsvm0023r5p7825ddr59","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvr002mr5p7gpnfbads"},{"post_id":"ckr8tjsvn0026r5p73e8eexpo","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvs002pr5p7dbdxa89r"},{"post_id":"ckr8tjsvo0029r5p78w5cd450","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvt002sr5p78zjl08vj"},{"post_id":"ckr8tjsvo002cr5p75rva2n21","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvt002vr5p75bqe23en"},{"post_id":"ckr8tjsvp002fr5p7d51iazoo","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvu002yr5p7gvbo6qp0"},{"post_id":"ckr8tjsvq002ir5p771g568tg","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvv0031r5p7heiw17hb"},{"post_id":"ckr8tjsvs002or5p7bj8efrg4","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvw0034r5p7cy7b49u9"},{"post_id":"ckr8tjsvs002rr5p7ap0lhudo","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvw0037r5p75yzpdtw9"},{"post_id":"ckr8tjsvt002ur5p75fa8aey8","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvx003ar5p73rd67ywl"},{"post_id":"ckr8tjsvu002xr5p74lqw8k3i","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvy003dr5p7gv1hctwf"},{"post_id":"ckr8tjsvu0030r5p764q45jf6","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsvz003gr5p7954618mi"},{"post_id":"ckr8tjsvv0033r5p76l94cq3i","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw0003jr5p74qm6fdw9"},{"post_id":"ckr8tjsvw0036r5p7fcyf20mz","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw1003mr5p77xc10ah6"},{"post_id":"ckr8tjsvx0039r5p7714b0tj5","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw1003pr5p7boip3sdq"},{"post_id":"ckr8tjsvx003cr5p77rn63fo7","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw2003sr5p75v225td5"},{"post_id":"ckr8tjsvy003fr5p7da5gh57h","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw3003vr5p78a3a08jj"},{"post_id":"ckr8tjsvz003ir5p7he0kerkq","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw4003yr5p7dumhg1sd"},{"post_id":"ckr8tjsw0003lr5p75q48eq3t","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw50041r5p76m1p2nbg"},{"post_id":"ckr8tjsw1003or5p7f5yp4ogj","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw60044r5p72chk6epk"},{"post_id":"ckr8tjsw2003rr5p7fyat6ksl","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw60047r5p794ov71bh"},{"post_id":"ckr8tjsw3003ur5p7gvgc7o3e","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw7004ar5p74abt5fah"},{"post_id":"ckr8tjsw4003xr5p7hb7g19jr","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw8004dr5p70zwrhdnx"},{"post_id":"ckr8tjsw40040r5p71k6530a9","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsw9004gr5p775iqhj1j"},{"post_id":"ckr8tjsw50043r5p7aq4w5hh1","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswa004jr5p72md8c15r"},{"post_id":"ckr8tjsw60046r5p734tr885a","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswc004or5p70ymh5vzv"},{"post_id":"ckr8tjsw70049r5p7doda01nb","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswd004rr5p7bgn11dyd"},{"post_id":"ckr8tjsw7004cr5p706jbbqw7","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswe004wr5p7hfy98d9f"},{"post_id":"ckr8tjsw9004fr5p7hytz1spx","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjswh0052r5p718vt6zd5"},{"post_id":"ckr8tjswa004ir5p73mq49yit","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjswj0059r5p78ggf183p"},{"post_id":"ckr8tjswf0050r5p7hqtr45w2","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjswj005dr5p72lr1gj7m"},{"post_id":"ckr8tjswc004nr5p77232ehq8","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjswk005gr5p7c7qf6uoz"},{"post_id":"ckr8tjswc004qr5p7fhlrenml","category_id":"ckr8tjswi0058r5p78pw234ru","_id":"ckr8tjswm005nr5p74svocpfz"},{"post_id":"ckr8tjswd004tr5p7anegal9r","category_id":"ckr8tjswk005hr5p7fno38tp3","_id":"ckr8tjswo005ur5p77m3mb2ks"},{"post_id":"ckr8tjswm005mr5p7eswp9yoe","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjswp005zr5p75bki1fp6"},{"post_id":"ckr8tjswp0061r5p7gamd7u9h","category_id":"ckr8tjswm005or5p78ous5s06","_id":"ckr8tjswt006er5p7e68f89sd"},{"post_id":"ckr8tjswi0057r5p72kfjdcte","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"ckr8tjswu006jr5p7e4pdhdem"},{"post_id":"ckr8tjswj005cr5p7gnipfc7l","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsww006pr5p728pv9mfg"},{"post_id":"ckr8tjswt006hr5p7an4r0gvu","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjsww006tr5p7gdiz3drq"},{"post_id":"ckr8tjswu006lr5p7b9lu9pqj","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswx006wr5p75j2851iu"},{"post_id":"ckr8tjswk005fr5p7evsy0vnr","category_id":"ckr8tjswu006ir5p7ernm2wp2","_id":"ckr8tjswy0071r5p75syj0s2b"},{"post_id":"ckr8tjsww006sr5p728t62h09","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"ckr8tjswz0074r5p75vx3771z"},{"post_id":"ckr8tjswn005rr5p79bip2adw","category_id":"ckr8tjsww006qr5p76g6c2j44","_id":"ckr8tjsx00079r5p7a7jw5ufi"},{"post_id":"ckr8tjswn005tr5p7f1qua03j","category_id":"ckr8tjswx006yr5p7dqu692c1","_id":"ckr8tjsx1007fr5p76pes0mct"},{"post_id":"ckr8tjsx0007br5p70y8aey5q","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"ckr8tjsx3007mr5p7gwwkeaj0"},{"post_id":"ckr8tjsx1007er5p72tcnf6sr","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"ckr8tjsx4007qr5p72j2v7900"},{"post_id":"ckr8tjswe004yr5p7bs70703a","category_id":"ckr8tjswm005or5p78ous5s06","_id":"ckr8tjsx4007tr5p7apkc26wd"},{"post_id":"ckr8tjswe004yr5p7bs70703a","category_id":"ckr8tjswz0078r5p74mle2jl2","_id":"ckr8tjsx5007yr5p7cxth39fk"},{"post_id":"ckr8tjsx2007lr5p7ah6900gb","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"ckr8tjsx60081r5p7co1qbr4e"},{"post_id":"ckr8tjswo005yr5p722n44n4j","category_id":"ckr8tjsx1007gr5p7dxavet9n","_id":"ckr8tjsx70085r5p7b2ol2vrk"},{"post_id":"ckr8tjsx3007pr5p786ki9ze0","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"ckr8tjsx80089r5p76r84dsmv"},{"post_id":"ckr8tjswh0055r5p7346o5ppb","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsx9008dr5p72zzvft0a"},{"post_id":"ckr8tjswh0055r5p7346o5ppb","category_id":"ckr8tjsx3007nr5p77y8x2nrq","_id":"ckr8tjsx9008hr5p7efsj07fe"},{"post_id":"ckr8tjsx50080r5p7hlxw8x8g","category_id":"ckr8tjswi0058r5p78pw234ru","_id":"ckr8tjsxa008lr5p7cqo1ah79"},{"post_id":"ckr8tjswr0067r5p71pqg2p5y","category_id":"ckr8tjsx70086r5p71j2gfe73","_id":"ckr8tjsxc008tr5p766ta1vko"},{"post_id":"ckr8tjswy0070r5p7979ggwup","category_id":"ckr8tjsxb008mr5p717wafpwd","_id":"ckr8tjsxf0091r5p746lk6pcx"},{"post_id":"ckr8tjswy0073r5p7chmifdr2","category_id":"ckr8tjsxb008mr5p717wafpwd","_id":"ckr8tjsxg0097r5p73pe4fbio"},{"post_id":"ckr8tjswz0077r5p73sxb46tp","category_id":"ckr8tjsxe0090r5p7dlk884vk","_id":"ckr8tjsxl009hr5p7ccfc2dkc"},{"post_id":"ckr8tjsx1007ir5p7clh4dp4s","category_id":"ckr8tjsxb008mr5p717wafpwd","_id":"ckr8tjsxn009or5p73mopd98o"},{"post_id":"ckr8tjsxl009fr5p7csg49kfd","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsxp009rr5p79v43ceey"},{"post_id":"ckr8tjsx4007sr5p71vphdbcw","category_id":"ckr8tjsx9008er5p7dqfk3mbk","_id":"ckr8tjsxq009vr5p7baq8bwvt"},{"post_id":"ckr8tjsx5007xr5p7eukkctak","category_id":"ckr8tjsxn009nr5p743am74ue","_id":"ckr8tjsxs00a2r5p72bt58xrj"},{"post_id":"ckr8tjsxq009ur5p76lpe9g8j","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsxt00a6r5p7el9x73nl"},{"post_id":"ckr8tjsx60084r5p75fej1rp9","category_id":"ckr8tjsxq009wr5p78guhdfu1","_id":"ckr8tjsxu00aar5p7dt5re6ry"},{"post_id":"ckr8tjsxs00a5r5p7byoig8fx","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsxv00agr5p7cfg2brq3"},{"post_id":"ckr8tjsx70088r5p75ys04q1e","category_id":"ckr8tjsxs00a3r5p7b0yz5goj","_id":"ckr8tjsxw00akr5p7hzsafkjz"},{"post_id":"ckr8tjsxv00afr5p7hu22di4c","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsxy00arr5p7gg6i4ed4"},{"post_id":"ckr8tjsx8008cr5p7285l76as","category_id":"ckr8tjswm005or5p78ous5s06","_id":"ckr8tjsxy00avr5p71oudbaq8"},{"post_id":"ckr8tjsx8008cr5p7285l76as","category_id":"ckr8tjsxu00abr5p7dj7l7r8l","_id":"ckr8tjsxz00azr5p74grz7v9n"},{"post_id":"ckr8tjsxw00ajr5p779c8fo4t","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsy000b3r5p78htu17zs"},{"post_id":"ckr8tjswx006vr5p7087xefv6","category_id":"ckr8tjsx9008er5p7dqfk3mbk","_id":"ckr8tjsy100b7r5p7b9pie03y"},{"post_id":"ckr8tjswx006vr5p7087xefv6","category_id":"ckr8tjsxw00alr5p7528j72f9","_id":"ckr8tjsy200bbr5p7dh343qzp"},{"post_id":"ckr8tjsxx00aqr5p7frs98jzh","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsy300ber5p7125dhjvw"},{"post_id":"ckr8tjsxa008kr5p70rz4hve7","category_id":"ckr8tjsxy00asr5p7c5ij1pxt","_id":"ckr8tjsy400bir5p7hw0y2gsk"},{"post_id":"ckr8tjsxb008or5p7c9g737hs","category_id":"ckr8tjsy100b8r5p7d9cm211c","_id":"ckr8tjsy600bpr5p7f6o99jwr"},{"post_id":"ckr8tjsy500blr5p776azd4f2","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsy700bwr5p7hbphdopw"},{"post_id":"ckr8tjsxc008sr5p7a5w8erud","category_id":"ckr8tjsy400bjr5p73418bvei","_id":"ckr8tjsy800bzr5p71ket7b5e"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","category_id":"ckr8tjswb004kr5p729fz3ao9","_id":"ckr8tjsy800c2r5p79ie96uia"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","category_id":"ckr8tjsy600bqr5p799lf9o2t","_id":"ckr8tjsy800c5r5p7epzrdsgg"},{"post_id":"ckr8tjsxe008zr5p79so8em2y","category_id":"ckr8tjsy800bxr5p79kiegev5","_id":"ckr8tjsy900c8r5p7g4e1exp7"},{"post_id":"ckr8tjsxf0093r5p7993h9ekq","category_id":"ckr8tjsy800c3r5p74sb0922c","_id":"ckr8tjsy900cfr5p7fchj7tuy"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","category_id":"ckr8tjsy800bxr5p79kiegev5","_id":"ckr8tjsya00cjr5p7feg7012v"},{"post_id":"ckr8tjsxh0099r5p7b48f4t14","category_id":"ckr8tjsy900cer5p7awlec400","_id":"ckr8tjsyb00cpr5p7bp7hcoue"},{"post_id":"ckr8tjsxi009cr5p731p24zc6","category_id":"ckr8tjsy800c3r5p74sb0922c","_id":"ckr8tjsyb00ctr5p774u4b1fb"},{"post_id":"ckr8tjsxm009jr5p740eedl12","category_id":"ckr8tjsya00cor5p7age53ds8","_id":"ckr8tjsyc00czr5p7en2xfl2k"},{"post_id":"ckr8tjsxn009mr5p758j64jdt","category_id":"ckr8tjsy800c3r5p74sb0922c","_id":"ckr8tjsyd00d3r5p7g836b1eb"},{"post_id":"ckr8tjsxo009qr5p79xw43yj0","category_id":"ckr8tjsyc00cyr5p7h7b31cc5","_id":"ckr8tjsyd00d8r5p74c3jbwjn"},{"post_id":"ckr8tjsxr009yr5p7f5ycdc3d","category_id":"ckr8tjsyd00d4r5p7ckek2xfg","_id":"ckr8tjsye00der5p731xsdzfd"},{"post_id":"ckr8tjsxs00a1r5p76p0ed87d","category_id":"ckr8tjsyd00dar5p7eoe1aw9o","_id":"ckr8tjsyf00dkr5p7765ydigj"},{"post_id":"ckr8tjsxt00a8r5p7b96c7c8l","category_id":"ckr8tjsyd00d4r5p7ckek2xfg","_id":"ckr8tjsyf00dpr5p787nug1bb"},{"post_id":"ckr8tjsxu00adr5p7d42u6202","category_id":"ckr8tjsyd00d4r5p7ckek2xfg","_id":"ckr8tjsyg00dur5p7gr48cute"},{"post_id":"ckr8tjsxw00anr5p7h9wr6kqo","category_id":"ckr8tjsy800bxr5p79kiegev5","_id":"ckr8tjsyg00dzr5p7frrhd2wu"},{"post_id":"ckr8tjsxy00aur5p7hi144gq5","category_id":"ckr8tjsyc00cyr5p7h7b31cc5","_id":"ckr8tjsyh00e4r5p72d8o7zwh"},{"post_id":"ckr8tjsxz00ayr5p726p44p9k","category_id":"ckr8tjsyd00d4r5p7ckek2xfg","_id":"ckr8tjsyj00e8r5p7364b31x6"},{"post_id":"ckr8tjsy000b2r5p7giiy9zw1","category_id":"ckr8tjsyh00e3r5p7541g6d86","_id":"ckr8tjsyk00eer5p7cd74048e"},{"post_id":"ckr8tjsy000b6r5p70wfd33cw","category_id":"ckr8tjsyh00e3r5p7541g6d86","_id":"ckr8tjsyk00eir5p7aynzf289"},{"post_id":"ckr8tjsy200bar5p76ar92kh0","category_id":"ckr8tjsyj00edr5p7axid26wd","_id":"ckr8tjsyl00enr5p79c4jeq7c"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","category_id":"ckr8tjswm005or5p78ous5s06","_id":"ckr8tjsym00eur5p7b0q8hvr7"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","category_id":"ckr8tjsxz00b0r5p75h3h0i8k","_id":"ckr8tjsym00exr5p71ydifvl7"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","category_id":"ckr8tjsyk00ejr5p77mgwb3rr","_id":"ckr8tjsym00f0r5p75wlx6i5v"},{"post_id":"ckr8tjsy200bdr5p76ludg8dr","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"ckr8tjsyn00f3r5p7515lhv9v"},{"post_id":"ckr8tjsy200bdr5p76ludg8dr","category_id":"ckr8tjsyl00epr5p72ixzdgir","_id":"ckr8tjsyn00f6r5p78h9tdzmh"},{"post_id":"ckr8tjsy300bhr5p7cnyidc6z","category_id":"ckr8tjsxq009wr5p78guhdfu1","_id":"ckr8tjsyn00f9r5p71ju42gai"},{"post_id":"ckr8tjsy300bhr5p7cnyidc6z","category_id":"ckr8tjsyl00etr5p7agh3dyid","_id":"ckr8tjsyn00fcr5p74hp736m4"},{"post_id":"ckr8tjsy500bor5p772iw4089","category_id":"ckr8tjsy800c3r5p74sb0922c","_id":"ckr8tjsyo00ffr5p75l257i7n"},{"post_id":"ckr8tjsy600bsr5p70e27hhgf","category_id":"ckr8tjsyn00f5r5p71nvl2zkb","_id":"ckr8tjsyo00fhr5p79hjsf9vt"},{"post_id":"ckr8tjsy700bvr5p75zgbbm5q","category_id":"ckr8tjsyn00fbr5p79xaacpg8","_id":"ckr8tjsyo00fmr5p7hjwldjyz"},{"post_id":"cl1t9uw7o00009op7356id00e","category_id":"cl1t9uw7s00029op73qm3he2c","_id":"cl1t9uw8d000d9op79t2d95yr"},{"post_id":"cl1t9uw8b000a9op7g1pc4oqp","category_id":"cl1t9uw8900079op7gl1g102q","_id":"cl1t9uw8i000i9op70scuazka"},{"post_id":"cl1t9uw7q00019op7bqi66d56","category_id":"cl1t9uw8900079op7gl1g102q","_id":"cl1t9uw8k000m9op7075ta5jd"},{"post_id":"cl1t9uw8600049op78e3f5zr8","category_id":"cl1t9uw8900079op7gl1g102q","_id":"cl1t9uw8m000p9op7c8x8h4dm"},{"post_id":"cl1t9uw8700059op7ge6p6duu","category_id":"cl1t9uw8900079op7gl1g102q","_id":"cl1t9uw8p000v9op7flur1b38"},{"post_id":"cl1t9uw8m000r9op7484o95wd","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"cl1t9uw8s00119op71h9c43xz"},{"post_id":"cl1t9uw8800069op75b8ke8qf","category_id":"cl1t9uw8900079op7gl1g102q","_id":"cl1t9uw8t00169op74en116be"},{"post_id":"cl1t9uw8o000t9op75nbe6zuf","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"cl1t9uw8v00189op791jagemy"},{"post_id":"cl1t9uw8c000c9op7dkio9hyh","category_id":"cl1t9uw8p000u9op79i582r2x","_id":"cl1t9uw8x001c9op76qqcdot4"},{"post_id":"cl1t9uw8u00179op70ie56308","category_id":"ckr8tjsuw0004r5p74d0y8bli","_id":"cl1t9uw8z001h9op76nhfczvu"},{"post_id":"cl1t9uw8h000h9op7h8k1dkp6","category_id":"cl1t9uw8s00129op71bux99f9","_id":"cl1t9uw91001l9op78h0phc5j"},{"post_id":"cl1t9uw8w001b9op79ja8bqr1","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"cl1t9uw92001n9op7bnhv57np"},{"post_id":"cl1t9uw8x001e9op79mbncqfi","category_id":"ckr8tjswq0065r5p70oupdgqt","_id":"cl1t9uw93001q9op721bd9h4u"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","category_id":"ckr8tjswo005wr5p7663l8xyi","_id":"cl1t9uw94001s9op7hg7j61kh"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","category_id":"cl1t9uw8v00199op70sdjce73","_id":"cl1t9uw96001w9op7avi8ef8p"},{"post_id":"cl1t9uw8y001g9op782gm72m6","category_id":"cl1t9uw8p000u9op79i582r2x","_id":"cl1t9uw96001y9op730vj8pil"},{"post_id":"cl1t9uw8r00109op75fu7912q","category_id":"cl1t9uw8z001i9op79aqd6rov","_id":"cl1t9uw9700219op7e4oshe2e"},{"post_id":"cl1t9uw95001u9op7et7q5cqd","category_id":"ckr8tjsyj00edr5p7axid26wd","_id":"cl1t9uw9700239op77saj6im8"},{"post_id":"cl1t9uw93001p9op73fos02qn","category_id":"cl1t9uw96001v9op7ehko42it","_id":"cl1t9uw9800269op7eg004loy"}],"PostTag":[{"post_id":"ckr8tjsv2000dr5p73txwd8e9","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsv4000ir5p7hsw274b9"},{"post_id":"ckr8tjsv2000dr5p73txwd8e9","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsv5000lr5p7fi2wdpsz"},{"post_id":"ckr8tjsur0001r5p7a2vo974p","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsv7000pr5p715xmcax2"},{"post_id":"ckr8tjsur0001r5p7a2vo974p","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsv7000sr5p7336h030c"},{"post_id":"ckr8tjsv3000er5p7gubh7mbr","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvb000wr5p7184r226c"},{"post_id":"ckr8tjsv3000er5p7gubh7mbr","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvc000zr5p7craa0aiw"},{"post_id":"ckr8tjsv4000jr5p7c41e91pu","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvd0013r5p745f123f5"},{"post_id":"ckr8tjsv4000jr5p7c41e91pu","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsve0016r5p7ebcnelst"},{"post_id":"ckr8tjsv5000mr5p7b8icclkm","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvf001ar5p77u0oak9b"},{"post_id":"ckr8tjsv5000mr5p7b8icclkm","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvg001dr5p7c6jp6kgq"},{"post_id":"ckr8tjsv7000qr5p709jiah95","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvh001hr5p73gq0bukk"},{"post_id":"ckr8tjsv7000qr5p709jiah95","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvi001kr5p74jm75ewl"},{"post_id":"ckr8tjsuv0003r5p762oi8jkr","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvi001nr5p79oh5hklp"},{"post_id":"ckr8tjsuv0003r5p762oi8jkr","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvj001qr5p75ef7goax"},{"post_id":"ckr8tjsv8000tr5p7ap4l6r2t","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvk001tr5p75c6s6v29"},{"post_id":"ckr8tjsv8000tr5p7ap4l6r2t","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvl001wr5p7fixb8orm"},{"post_id":"ckr8tjsvb000xr5p79rwi2mo6","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvl001zr5p72miyaiii"},{"post_id":"ckr8tjsvb000xr5p79rwi2mo6","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvm0022r5p78ihz8oql"},{"post_id":"ckr8tjsvc0010r5p76ctfb8o2","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvn0025r5p78wxp50l4"},{"post_id":"ckr8tjsvc0010r5p76ctfb8o2","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvo0028r5p7gj7tb8m2"},{"post_id":"ckr8tjsvd0014r5p7fvd92d00","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvo002br5p76bhqfmdz"},{"post_id":"ckr8tjsvd0014r5p7fvd92d00","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvp002er5p75ltoasgm"},{"post_id":"ckr8tjsuy0007r5p7c7s4d9kg","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvq002hr5p7g8m56n7l"},{"post_id":"ckr8tjsuy0007r5p7c7s4d9kg","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvr002kr5p78y0c7tdb"},{"post_id":"ckr8tjsve0017r5p7b1fh223f","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvs002nr5p7e6wz8ue0"},{"post_id":"ckr8tjsve0017r5p7b1fh223f","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvs002qr5p7cx4of96y"},{"post_id":"ckr8tjsvf001br5p753ap9jig","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvt002tr5p73q0ld14o"},{"post_id":"ckr8tjsvf001br5p753ap9jig","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvu002wr5p7ehhs57ya"},{"post_id":"ckr8tjsuz0009r5p7bjyrhve3","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvu002zr5p75mpf3nei"},{"post_id":"ckr8tjsuz0009r5p7bjyrhve3","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvv0032r5p7658k1vwx"},{"post_id":"ckr8tjsvg001er5p7h0t74j4e","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvw0035r5p7g1ergiw4"},{"post_id":"ckr8tjsvg001er5p7h0t74j4e","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvx0038r5p7bagge4lw"},{"post_id":"ckr8tjsvh001ir5p772qt3n1o","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvx003br5p7hncx0xkt"},{"post_id":"ckr8tjsvh001ir5p772qt3n1o","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsvy003er5p702z26rh0"},{"post_id":"ckr8tjsv0000ar5p7dqrkbrss","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsvz003hr5p7d5a779bt"},{"post_id":"ckr8tjsv0000ar5p7dqrkbrss","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw0003kr5p76slhei37"},{"post_id":"ckr8tjsvi001lr5p74qow6dpr","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw1003nr5p70cv9e1wf"},{"post_id":"ckr8tjsvi001lr5p74qow6dpr","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw1003qr5p7hkgaeyx1"},{"post_id":"ckr8tjsvi001or5p7hu986o59","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw3003tr5p70u1bhuhu"},{"post_id":"ckr8tjsvi001or5p7hu986o59","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw3003wr5p72jv44a23"},{"post_id":"ckr8tjsvj001rr5p78vne2uml","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw4003zr5p76pg8e51t"},{"post_id":"ckr8tjsvj001rr5p78vne2uml","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw50042r5p7gkog3xcx"},{"post_id":"ckr8tjsvk001ur5p73urk5fxe","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw60045r5p7eeq36ttq"},{"post_id":"ckr8tjsvk001ur5p73urk5fxe","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw70048r5p7aqavatym"},{"post_id":"ckr8tjsvl001xr5p72yyf3ze4","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw7004br5p7b2jwa3h3"},{"post_id":"ckr8tjsvl001xr5p72yyf3ze4","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsw9004er5p70gjhdds0"},{"post_id":"ckr8tjsvm0020r5p75jmk1cvw","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsw9004hr5p7a0ey4sui"},{"post_id":"ckr8tjsvm0020r5p75jmk1cvw","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswc004mr5p71ae6hvhl"},{"post_id":"ckr8tjsvm0023r5p7825ddr59","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswc004pr5p7dun5fhqj"},{"post_id":"ckr8tjsvm0023r5p7825ddr59","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswd004sr5p7bmap3elz"},{"post_id":"ckr8tjsvn0026r5p73e8eexpo","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswe004xr5p795p9ecw3"},{"post_id":"ckr8tjsvn0026r5p73e8eexpo","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswf004zr5p7htk44wpx"},{"post_id":"ckr8tjsvo0029r5p78w5cd450","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswh0054r5p7esu8gsol"},{"post_id":"ckr8tjsvo0029r5p78w5cd450","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswi0056r5p7ex052fre"},{"post_id":"ckr8tjsvo002cr5p75rva2n21","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswj005br5p7evsh6typ"},{"post_id":"ckr8tjsvo002cr5p75rva2n21","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswk005er5p79c3i4iiv"},{"post_id":"ckr8tjsvp002fr5p7d51iazoo","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswl005jr5p7b5h6givu"},{"post_id":"ckr8tjsvp002fr5p7d51iazoo","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswm005lr5p75tqzds4d"},{"post_id":"ckr8tjsvq002ir5p771g568tg","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswn005qr5p72vdv90c5"},{"post_id":"ckr8tjsvq002ir5p771g568tg","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswn005sr5p76h891pjm"},{"post_id":"ckr8tjsvs002or5p7bj8efrg4","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswo005xr5p7gedjds8w"},{"post_id":"ckr8tjsvs002or5p7bj8efrg4","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswp0060r5p77fstd65o"},{"post_id":"ckr8tjsvs002rr5p7ap0lhudo","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswq0063r5p760tx69lv"},{"post_id":"ckr8tjsvs002rr5p7ap0lhudo","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswr0066r5p7441u8r4p"},{"post_id":"ckr8tjsvt002ur5p75fa8aey8","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswr0069r5p7f17qblwj"},{"post_id":"ckr8tjsvt002ur5p75fa8aey8","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswt006cr5p7bp438neb"},{"post_id":"ckr8tjsvu002xr5p74lqw8k3i","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswt006gr5p70sjtgq5u"},{"post_id":"ckr8tjsvu002xr5p74lqw8k3i","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswu006kr5p75g1gbknu"},{"post_id":"ckr8tjsvu0030r5p764q45jf6","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswv006mr5p7ha2c4qb9"},{"post_id":"ckr8tjsvu0030r5p764q45jf6","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsww006rr5p773x2eoi5"},{"post_id":"ckr8tjsvv0033r5p76l94cq3i","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswx006ur5p7a9k50h8f"},{"post_id":"ckr8tjsvv0033r5p76l94cq3i","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswy006zr5p739y53m55"},{"post_id":"ckr8tjsvw0036r5p7fcyf20mz","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjswy0072r5p7f5va8wsl"},{"post_id":"ckr8tjsvw0036r5p7fcyf20mz","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjswz0076r5p7c4st2x7v"},{"post_id":"ckr8tjsvx0039r5p7714b0tj5","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx0007ar5p7cpr5e6nf"},{"post_id":"ckr8tjsvx0039r5p7714b0tj5","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx0007dr5p79ns33rex"},{"post_id":"ckr8tjsvx003cr5p77rn63fo7","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx1007hr5p74s7l9yi1"},{"post_id":"ckr8tjsvx003cr5p77rn63fo7","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx2007kr5p7a1g470m7"},{"post_id":"ckr8tjsvy003fr5p7da5gh57h","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx3007or5p71zxi8s6g"},{"post_id":"ckr8tjsvy003fr5p7da5gh57h","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx4007rr5p7dcpsa2wl"},{"post_id":"ckr8tjsvz003ir5p7he0kerkq","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx5007wr5p76ygb1ypf"},{"post_id":"ckr8tjsvz003ir5p7he0kerkq","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx5007zr5p78m51bfw3"},{"post_id":"ckr8tjsw0003lr5p75q48eq3t","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx60083r5p7h49nclhd"},{"post_id":"ckr8tjsw0003lr5p75q48eq3t","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx70087r5p7d4hveyog"},{"post_id":"ckr8tjsw1003or5p7f5yp4ogj","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsx8008br5p7g6awcuh6"},{"post_id":"ckr8tjsw1003or5p7f5yp4ogj","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsx9008fr5p75cx540ce"},{"post_id":"ckr8tjsw2003rr5p7fyat6ksl","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxa008jr5p757fm1c4b"},{"post_id":"ckr8tjsw2003rr5p7fyat6ksl","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxb008nr5p7bbyyg94s"},{"post_id":"ckr8tjsw3003ur5p7gvgc7o3e","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxc008rr5p7aitif6du"},{"post_id":"ckr8tjsw3003ur5p7gvgc7o3e","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxd008vr5p77r1rerd0"},{"post_id":"ckr8tjsw4003xr5p7hb7g19jr","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxd008yr5p73e7b80ik"},{"post_id":"ckr8tjsw4003xr5p7hb7g19jr","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxf0092r5p785swgeax"},{"post_id":"ckr8tjsw40040r5p71k6530a9","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxg0095r5p70h2i0gfd"},{"post_id":"ckr8tjsw40040r5p71k6530a9","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxg0098r5p7gnwia0td"},{"post_id":"ckr8tjsw50043r5p7aq4w5hh1","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxi009br5p772qvcu94"},{"post_id":"ckr8tjsw50043r5p7aq4w5hh1","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxl009er5p78zdp4mtu"},{"post_id":"ckr8tjsw60046r5p734tr885a","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxm009ir5p7es4bdzui"},{"post_id":"ckr8tjsw60046r5p734tr885a","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxn009lr5p7b0un3mjq"},{"post_id":"ckr8tjsw70049r5p7doda01nb","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxo009pr5p72w1z4ced"},{"post_id":"ckr8tjsw70049r5p7doda01nb","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxq009tr5p70jgih8d9"},{"post_id":"ckr8tjsw7004cr5p706jbbqw7","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxr009xr5p7egyr7pv0"},{"post_id":"ckr8tjsw7004cr5p706jbbqw7","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsxs00a0r5p7a0sbh12d"},{"post_id":"ckr8tjsw9004fr5p7hytz1spx","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsxs00a4r5p79r8b4rup"},{"post_id":"ckr8tjsw9004fr5p7hytz1spx","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsxt00a7r5p75fw05s8o"},{"post_id":"ckr8tjsw9004fr5p7hytz1spx","tag_id":"ckr8tjswh0053r5p7140k283j","_id":"ckr8tjsxu00acr5p7akz98qcx"},{"post_id":"ckr8tjswa004ir5p73mq49yit","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsxv00aer5p7fbm66j2j"},{"post_id":"ckr8tjswa004ir5p73mq49yit","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsxv00air5p7g3u06z0a"},{"post_id":"ckr8tjswa004ir5p73mq49yit","tag_id":"ckr8tjswh0053r5p7140k283j","_id":"ckr8tjsxw00amr5p76nhyhxzd"},{"post_id":"ckr8tjswc004nr5p77232ehq8","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsxx00apr5p75oiq7b79"},{"post_id":"ckr8tjswc004nr5p77232ehq8","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsxy00atr5p796prfbt7"},{"post_id":"ckr8tjswt006hr5p7an4r0gvu","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsxz00axr5p7eym02zg0"},{"post_id":"ckr8tjswt006hr5p7an4r0gvu","tag_id":"ckr8tjsv1000cr5p7cs25fruw","_id":"ckr8tjsy000b1r5p7bcui9v3x"},{"post_id":"ckr8tjswu006lr5p7b9lu9pqj","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsy000b5r5p7dkj9dyf3"},{"post_id":"ckr8tjswc004qr5p7fhlrenml","tag_id":"ckr8tjswr0068r5p79dlxa3ij","_id":"ckr8tjsy200b9r5p7040gdpvn"},{"post_id":"ckr8tjswc004qr5p7fhlrenml","tag_id":"ckr8tjswt006fr5p73t6q8vfw","_id":"ckr8tjsy200bcr5p757ip02w4"},{"post_id":"ckr8tjsww006sr5p728t62h09","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsy300bgr5p7751w7ivg"},{"post_id":"ckr8tjswd004tr5p7anegal9r","tag_id":"ckr8tjswv006or5p70f5zf3m1","_id":"ckr8tjsy400bkr5p78nof6jug"},{"post_id":"ckr8tjswe004yr5p7bs70703a","tag_id":"ckr8tjswx006xr5p7e4vxds87","_id":"ckr8tjsy500bnr5p75vi8debm"},{"post_id":"ckr8tjswe004yr5p7bs70703a","tag_id":"ckr8tjswz0075r5p7c96s2j1l","_id":"ckr8tjsy600brr5p76fob9jnd"},{"post_id":"ckr8tjswf0050r5p7hqtr45w2","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsy700bur5p72eit9r46"},{"post_id":"ckr8tjswf0050r5p7hqtr45w2","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsy800byr5p76t4rfbao"},{"post_id":"ckr8tjswf0050r5p7hqtr45w2","tag_id":"ckr8tjswh0053r5p7140k283j","_id":"ckr8tjsy800c1r5p78fu0dt9i"},{"post_id":"ckr8tjswh0055r5p7346o5ppb","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsy800c4r5p7bwh81rws"},{"post_id":"ckr8tjswh0055r5p7346o5ppb","tag_id":"ckr8tjsx4007ur5p77csu27nw","_id":"ckr8tjsy900c7r5p7afp88g8m"},{"post_id":"ckr8tjswi0057r5p72kfjdcte","tag_id":"ckr8tjsx60082r5p73zflbt3k","_id":"ckr8tjsy900c9r5p77kd8ccph"},{"post_id":"ckr8tjswi0057r5p72kfjdcte","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"ckr8tjsy900cbr5p75esz9a98"},{"post_id":"ckr8tjswj005cr5p7gnipfc7l","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsy900cdr5p7hv923cc1"},{"post_id":"ckr8tjswk005fr5p7evsy0vnr","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsya00cgr5p7c55we6uf"},{"post_id":"ckr8tjswk005fr5p7evsy0vnr","tag_id":"ckr8tjswx006xr5p7e4vxds87","_id":"ckr8tjsya00cir5p7g3kge3q2"},{"post_id":"ckr8tjswm005mr5p7eswp9yoe","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsya00clr5p70x92gz36"},{"post_id":"ckr8tjswm005mr5p7eswp9yoe","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsya00cnr5p7cfjsdevh"},{"post_id":"ckr8tjswm005mr5p7eswp9yoe","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsyb00cqr5p7dbsyfb0i"},{"post_id":"ckr8tjswm005mr5p7eswp9yoe","tag_id":"ckr8tjsxl009dr5p77fbxbn27","_id":"ckr8tjsyb00csr5p75e5zff5t"},{"post_id":"ckr8tjsxq009ur5p76lpe9g8j","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsyb00cvr5p71ibm6zy1"},{"post_id":"ckr8tjsxq009ur5p76lpe9g8j","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyc00cxr5p7hpd86ab5"},{"post_id":"ckr8tjsxq009ur5p76lpe9g8j","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsyc00d0r5p70jo76koc"},{"post_id":"ckr8tjswn005rr5p79bip2adw","tag_id":"ckr8tjsxm009kr5p7fywi3rvt","_id":"ckr8tjsyd00d2r5p7dj9qff64"},{"post_id":"ckr8tjswn005rr5p79bip2adw","tag_id":"ckr8tjsxq009sr5p73eo7hy8v","_id":"ckr8tjsyd00d5r5p70s2k1dnz"},{"post_id":"ckr8tjswn005tr5p7f1qua03j","tag_id":"ckr8tjsxr009zr5p7ccsy1gr4","_id":"ckr8tjsyd00d7r5p76sh71k42"},{"post_id":"ckr8tjswn005tr5p7f1qua03j","tag_id":"ckr8tjsxu00a9r5p7fuyae6dn","_id":"ckr8tjsyd00d9r5p79iooge2s"},{"post_id":"ckr8tjswo005yr5p722n44n4j","tag_id":"ckr8tjsxv00ahr5p7eoekfxvv","_id":"ckr8tjsye00dcr5p714jv6dmg"},{"post_id":"ckr8tjsxx00aqr5p7frs98jzh","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsye00ddr5p7d0n22wvc"},{"post_id":"ckr8tjswp0061r5p7gamd7u9h","tag_id":"ckr8tjswx006xr5p7e4vxds87","_id":"ckr8tjsyf00dhr5p71ygy1tc6"},{"post_id":"ckr8tjswr0067r5p71pqg2p5y","tag_id":"ckr8tjsy000b4r5p7gxgf61p9","_id":"ckr8tjsyf00dmr5p78f2602rf"},{"post_id":"ckr8tjswx006vr5p7087xefv6","tag_id":"ckr8tjsy300bfr5p7hufkcl61","_id":"ckr8tjsyf00dnr5p7g2ac0c95"},{"post_id":"ckr8tjswx006vr5p7087xefv6","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"ckr8tjsyg00drr5p780if2yha"},{"post_id":"ckr8tjswy0070r5p7979ggwup","tag_id":"ckr8tjsy500bmr5p7g53a5tdw","_id":"ckr8tjsyg00dsr5p7biqy6spa"},{"post_id":"ckr8tjswy0073r5p7chmifdr2","tag_id":"ckr8tjsy500bmr5p7g53a5tdw","_id":"ckr8tjsyg00dwr5p7frad8pgu"},{"post_id":"ckr8tjswz0077r5p73sxb46tp","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyg00dxr5p7e1dz1351"},{"post_id":"ckr8tjswz0077r5p73sxb46tp","tag_id":"ckr8tjsy800c0r5p7119t8roj","_id":"ckr8tjsyh00e1r5p7g05zd0r0"},{"post_id":"ckr8tjswz0077r5p73sxb46tp","tag_id":"ckr8tjsy900c6r5p7enr4gw03","_id":"ckr8tjsyh00e2r5p7bnmi9h6n"},{"post_id":"ckr8tjswz0077r5p73sxb46tp","tag_id":"ckr8tjsy900ccr5p745oq3pgs","_id":"ckr8tjsyj00e6r5p7bcpufglc"},{"post_id":"ckr8tjsx0007br5p70y8aey5q","tag_id":"ckr8tjsx60082r5p73zflbt3k","_id":"ckr8tjsyj00e7r5p708tdgit1"},{"post_id":"ckr8tjsx0007br5p70y8aey5q","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"ckr8tjsyj00ebr5p72gyh1k0e"},{"post_id":"ckr8tjsx1007er5p72tcnf6sr","tag_id":"ckr8tjsx60082r5p73zflbt3k","_id":"ckr8tjsyj00ecr5p75lspf4ia"},{"post_id":"ckr8tjsx1007er5p72tcnf6sr","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"ckr8tjsyk00efr5p749ky1bid"},{"post_id":"ckr8tjsx1007ir5p7clh4dp4s","tag_id":"ckr8tjsy500bmr5p7g53a5tdw","_id":"ckr8tjsyk00ehr5p79m0dftw9"},{"post_id":"ckr8tjsx2007lr5p7ah6900gb","tag_id":"ckr8tjsx60082r5p73zflbt3k","_id":"ckr8tjsyk00ekr5p7ghol1gdf"},{"post_id":"ckr8tjsx2007lr5p7ah6900gb","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"ckr8tjsyl00emr5p77yys9cpr"},{"post_id":"ckr8tjsx3007pr5p786ki9ze0","tag_id":"ckr8tjsx60082r5p73zflbt3k","_id":"ckr8tjsyl00eor5p74twsbmj4"},{"post_id":"ckr8tjsx3007pr5p786ki9ze0","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"ckr8tjsyl00err5p716rs48ew"},{"post_id":"ckr8tjsx4007sr5p71vphdbcw","tag_id":"ckr8tjsy300bfr5p7hufkcl61","_id":"ckr8tjsyl00esr5p79hl9guwx"},{"post_id":"ckr8tjsx5007xr5p7eukkctak","tag_id":"ckr8tjsyg00dvr5p7bvtjhh5i","_id":"ckr8tjsym00ewr5p7au926kia"},{"post_id":"ckr8tjsx50080r5p7hlxw8x8g","tag_id":"ckr8tjswr0068r5p79dlxa3ij","_id":"ckr8tjsym00eyr5p73p9pc5ni"},{"post_id":"ckr8tjsx50080r5p7hlxw8x8g","tag_id":"ckr8tjsyg00dvr5p7bvtjhh5i","_id":"ckr8tjsym00f1r5p7ge6z9si2"},{"post_id":"ckr8tjsx50080r5p7hlxw8x8g","tag_id":"ckr8tjswt006fr5p73t6q8vfw","_id":"ckr8tjsyn00f4r5p7ghhf7yzo"},{"post_id":"ckr8tjsx60084r5p75fej1rp9","tag_id":"ckr8tjsyh00e5r5p74uxh5obg","_id":"ckr8tjsyn00f7r5p786x47l7i"},{"post_id":"ckr8tjsx70088r5p75ys04q1e","tag_id":"ckr8tjsyj00ear5p7192te2a6","_id":"ckr8tjsyn00far5p72yac0uk0"},{"post_id":"ckr8tjsx8008cr5p7285l76as","tag_id":"ckr8tjswx006xr5p7e4vxds87","_id":"ckr8tjsyo00fdr5p77gx034rs"},{"post_id":"ckr8tjsx8008cr5p7285l76as","tag_id":"ckr8tjsyk00egr5p75s1ke13y","_id":"ckr8tjsyo00fgr5p75eywffr0"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","tag_id":"ckr8tjswx006xr5p7e4vxds87","_id":"ckr8tjsyo00fir5p7b8l2e0ka"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","tag_id":"ckr8tjsyl00elr5p70unaeslt","_id":"ckr8tjsyo00fkr5p7a9chfuqr"},{"post_id":"ckr8tjsx9008gr5p7ebje7rg5","tag_id":"ckr8tjsyl00eqr5p7gjr1726v","_id":"ckr8tjsyo00flr5p76zkkfdae"},{"post_id":"ckr8tjsxa008kr5p70rz4hve7","tag_id":"ckr8tjsym00evr5p71jug383w","_id":"ckr8tjsyp00for5p7habh10re"},{"post_id":"ckr8tjsxb008or5p7c9g737hs","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyp00fpr5p7056m00nb"},{"post_id":"ckr8tjsxb008or5p7c9g737hs","tag_id":"ckr8tjsy800c0r5p7119t8roj","_id":"ckr8tjsyp00frr5p7anez8b06"},{"post_id":"ckr8tjsxb008or5p7c9g737hs","tag_id":"ckr8tjsy900c6r5p7enr4gw03","_id":"ckr8tjsyp00fsr5p79jaz7csh"},{"post_id":"ckr8tjsxb008or5p7c9g737hs","tag_id":"ckr8tjsyo00fer5p767yp7i56","_id":"ckr8tjsyp00ftr5p75vs46qcs"},{"post_id":"ckr8tjsxc008sr5p7a5w8erud","tag_id":"ckr8tjsyo00fjr5p7b2qye4i0","_id":"ckr8tjsyp00fvr5p768qhgmym"},{"post_id":"ckr8tjsxc008sr5p7a5w8erud","tag_id":"ckr8tjsyo00fnr5p74v1bce1y","_id":"ckr8tjsyp00fwr5p7agk535h8"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyq00fzr5p77f4fgjl6"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","tag_id":"ckr8tjsyp00fqr5p78ajs4yc7","_id":"ckr8tjsyq00g0r5p7976rhfto"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","tag_id":"ckr8tjsyp00fur5p764656o2e","_id":"ckr8tjsyq00g2r5p74si0ho2q"},{"post_id":"ckr8tjsxd008wr5p7eal03hao","tag_id":"ckr8tjsy800c0r5p7119t8roj","_id":"ckr8tjsyq00g3r5p733ig84ia"},{"post_id":"ckr8tjsxe008zr5p79so8em2y","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsyr00g5r5p74xez3o13"},{"post_id":"ckr8tjsxe008zr5p79so8em2y","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyr00g6r5p71sdyf2nx"},{"post_id":"ckr8tjsxe008zr5p79so8em2y","tag_id":"ckr8tjsyq00fyr5p70y2o801t","_id":"ckr8tjsyr00g8r5p73l7r1xeg"},{"post_id":"ckr8tjsxe008zr5p79so8em2y","tag_id":"ckr8tjsyq00g1r5p72n7d7mmz","_id":"ckr8tjsyr00g9r5p75thkgsoy"},{"post_id":"ckr8tjsxf0093r5p7993h9ekq","tag_id":"ckr8tjsyq00g4r5p738t4dve6","_id":"ckr8tjsyr00gbr5p7cm820jr7"},{"post_id":"ckr8tjsxf0093r5p7993h9ekq","tag_id":"ckr8tjsyr00g7r5p7c8jrbwce","_id":"ckr8tjsyr00gcr5p7f9u9fcfl"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsys00ggr5p7006r6n0f"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsys00ghr5p76sdpb53y"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsys00gjr5p76ow917w3"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","tag_id":"ckr8tjsyq00fyr5p70y2o801t","_id":"ckr8tjsyt00gkr5p75sz5gnk0"},{"post_id":"ckr8tjsxg0096r5p772p9a6tl","tag_id":"ckr8tjsyq00g1r5p72n7d7mmz","_id":"ckr8tjsyt00gmr5p796pd5c3n"},{"post_id":"ckr8tjsxh0099r5p7b48f4t14","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsyt00gnr5p7d18lg13z"},{"post_id":"ckr8tjsxh0099r5p7b48f4t14","tag_id":"ckr8tjsys00gfr5p797sjcl3m","_id":"ckr8tjsyt00gpr5p7grsrevzd"},{"post_id":"ckr8tjsxh0099r5p7b48f4t14","tag_id":"ckr8tjsys00gir5p7cjc93x89","_id":"ckr8tjsyt00gqr5p782tn2mhy"},{"post_id":"ckr8tjsxi009cr5p731p24zc6","tag_id":"ckr8tjsyq00g4r5p738t4dve6","_id":"ckr8tjsyu00gsr5p774kz1k84"},{"post_id":"ckr8tjsxi009cr5p731p24zc6","tag_id":"ckr8tjsyr00g7r5p7c8jrbwce","_id":"ckr8tjsyu00gtr5p7605xh66h"},{"post_id":"ckr8tjsxl009fr5p7csg49kfd","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsyu00gvr5p7d57j385q"},{"post_id":"ckr8tjsxl009fr5p7csg49kfd","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyu00gwr5p7cyzodbre"},{"post_id":"ckr8tjsxl009fr5p7csg49kfd","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsyu00gyr5p7bk6k3ql7"},{"post_id":"ckr8tjsxl009fr5p7csg49kfd","tag_id":"ckr8tjsyt00grr5p7fphihfyy","_id":"ckr8tjsyu00gzr5p76fh39p6m"},{"post_id":"ckr8tjsxm009jr5p740eedl12","tag_id":"ckr8tjsyu00gur5p7bcx1g7k3","_id":"ckr8tjsyu00h1r5p7789ybx73"},{"post_id":"ckr8tjsxm009jr5p740eedl12","tag_id":"ckr8tjsyu00gxr5p72auwf3tb","_id":"ckr8tjsyu00h2r5p7cba4ha41"},{"post_id":"ckr8tjsxn009mr5p758j64jdt","tag_id":"ckr8tjsyq00g4r5p738t4dve6","_id":"ckr8tjsyv00h7r5p7cc1n3zlw"},{"post_id":"ckr8tjsxn009mr5p758j64jdt","tag_id":"ckr8tjsyr00g7r5p7c8jrbwce","_id":"ckr8tjsyv00h8r5p72kbgcvup"},{"post_id":"ckr8tjsxn009mr5p758j64jdt","tag_id":"ckr8tjsyv00h4r5p7g3uabpt1","_id":"ckr8tjsyw00har5p7750tdo5l"},{"post_id":"ckr8tjsxn009mr5p758j64jdt","tag_id":"ckr8tjsyv00h5r5p7127n4ycj","_id":"ckr8tjsyw00hbr5p7azlo6jj8"},{"post_id":"ckr8tjsxo009qr5p79xw43yj0","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsyw00hfr5p7dqsce4va"},{"post_id":"ckr8tjsxo009qr5p79xw43yj0","tag_id":"ckr8tjsyv00h9r5p7fe4033pd","_id":"ckr8tjsyw00hgr5p709pm22uv"},{"post_id":"ckr8tjsxo009qr5p79xw43yj0","tag_id":"ckr8tjsyw00hcr5p789w3ffp5","_id":"ckr8tjsyx00hir5p7bchi9jtv"},{"post_id":"ckr8tjsxo009qr5p79xw43yj0","tag_id":"ckr8tjsyw00hdr5p72nm8e6wa","_id":"ckr8tjsyx00hjr5p77k3z2g9c"},{"post_id":"ckr8tjsxr009yr5p7f5ycdc3d","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsyx00hmr5p707j34cvf"},{"post_id":"ckr8tjsxr009yr5p7f5ycdc3d","tag_id":"ckr8tjsyw00hhr5p70xxu8rbn","_id":"ckr8tjsyx00hnr5p76zjm4lxo"},{"post_id":"ckr8tjsxr009yr5p7f5ycdc3d","tag_id":"ckr8tjsyx00hkr5p758db82no","_id":"ckr8tjsyx00hpr5p70hrg86dp"},{"post_id":"ckr8tjsxs00a1r5p76p0ed87d","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsyx00hqr5p76359h6e3"},{"post_id":"ckr8tjsxs00a1r5p76p0ed87d","tag_id":"ckr8tjsyx00hlr5p7gmc35n5y","_id":"ckr8tjsyy00hsr5p7gop13dhz"},{"post_id":"ckr8tjsxs00a5r5p7byoig8fx","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsyy00htr5p72ksddtu8"},{"post_id":"ckr8tjsxs00a5r5p7byoig8fx","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsyy00hvr5p7ato22ju1"},{"post_id":"ckr8tjsxs00a5r5p7byoig8fx","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsyy00hwr5p77yjma3cn"},{"post_id":"ckr8tjsxs00a5r5p7byoig8fx","tag_id":"ckr8tjsyx00hor5p7guqmaayh","_id":"ckr8tjsyy00hyr5p719jw61lr"},{"post_id":"ckr8tjsxt00a8r5p7b96c7c8l","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsyz00i0r5p7a6cd8qu5"},{"post_id":"ckr8tjsxt00a8r5p7b96c7c8l","tag_id":"ckr8tjsyw00hhr5p70xxu8rbn","_id":"ckr8tjsyz00i1r5p735jqalmj"},{"post_id":"ckr8tjsxt00a8r5p7b96c7c8l","tag_id":"ckr8tjsyy00hxr5p71ugtap5v","_id":"ckr8tjsyz00i3r5p7f00g0uf6"},{"post_id":"ckr8tjsxu00adr5p7d42u6202","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsz000i6r5p72lwuevt0"},{"post_id":"ckr8tjsxu00adr5p7d42u6202","tag_id":"ckr8tjsyw00hhr5p70xxu8rbn","_id":"ckr8tjsz000i7r5p7h79db44x"},{"post_id":"ckr8tjsxu00adr5p7d42u6202","tag_id":"ckr8tjsyx00hkr5p758db82no","_id":"ckr8tjsz000i9r5p7249s5fpf"},{"post_id":"ckr8tjsxv00afr5p7hu22di4c","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsz000iar5p71rf27kuy"},{"post_id":"ckr8tjsxv00afr5p7hu22di4c","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsz000icr5p738hka2k7"},{"post_id":"ckr8tjsxv00afr5p7hu22di4c","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsz000idr5p7ahjqag0r"},{"post_id":"ckr8tjsxv00afr5p7hu22di4c","tag_id":"ckr8tjsyt00grr5p7fphihfyy","_id":"ckr8tjsz100ifr5p7hznd9t1y"},{"post_id":"ckr8tjsxw00ajr5p779c8fo4t","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsz100igr5p7463xc7ez"},{"post_id":"ckr8tjsxw00ajr5p779c8fo4t","tag_id":"ckr8tjsyq00g4r5p738t4dve6","_id":"ckr8tjsz100iir5p73wfxci2d"},{"post_id":"ckr8tjsxw00ajr5p779c8fo4t","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsz100ijr5p71622aeob"},{"post_id":"ckr8tjsxw00anr5p7h9wr6kqo","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsz100ilr5p7f4vu00bf"},{"post_id":"ckr8tjsxw00anr5p7h9wr6kqo","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsz100imr5p7gf3ab9ff"},{"post_id":"ckr8tjsxw00anr5p7h9wr6kqo","tag_id":"ckr8tjsyq00fyr5p70y2o801t","_id":"ckr8tjsz200ior5p79hw64o39"},{"post_id":"ckr8tjsxw00anr5p7h9wr6kqo","tag_id":"ckr8tjsyq00g1r5p72n7d7mmz","_id":"ckr8tjsz200ipr5p756rz5p3h"},{"post_id":"ckr8tjsxy00aur5p7hi144gq5","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsz200isr5p7e23s7jtx"},{"post_id":"ckr8tjsxy00aur5p7hi144gq5","tag_id":"ckr8tjsyv00h9r5p7fe4033pd","_id":"ckr8tjsz200itr5p7dwymalpi"},{"post_id":"ckr8tjsxy00aur5p7hi144gq5","tag_id":"ckr8tjsyw00hcr5p789w3ffp5","_id":"ckr8tjsz300ivr5p7etipcn1t"},{"post_id":"ckr8tjsxy00aur5p7hi144gq5","tag_id":"ckr8tjsyw00hdr5p72nm8e6wa","_id":"ckr8tjsz300iwr5p777d66djl"},{"post_id":"ckr8tjsxz00ayr5p726p44p9k","tag_id":"ckr8tjsyr00gar5p71jyicxwr","_id":"ckr8tjsz300izr5p7hmdx4rek"},{"post_id":"ckr8tjsxz00ayr5p726p44p9k","tag_id":"ckr8tjsyw00hhr5p70xxu8rbn","_id":"ckr8tjsz300j0r5p7gcmrdyfm"},{"post_id":"ckr8tjsxz00ayr5p726p44p9k","tag_id":"ckr8tjsyx00hkr5p758db82no","_id":"ckr8tjsz400j2r5p7cpx5gpnd"},{"post_id":"ckr8tjsy000b2r5p7giiy9zw1","tag_id":"ckr8tjsz300iyr5p7dsdtee2t","_id":"ckr8tjsz400j4r5p7ca3q2442"},{"post_id":"ckr8tjsy000b2r5p7giiy9zw1","tag_id":"ckr8tjsz300j1r5p72b337wy9","_id":"ckr8tjsz400j5r5p7gnmvblqi"},{"post_id":"ckr8tjsy000b6r5p70wfd33cw","tag_id":"ckr8tjsz300iyr5p7dsdtee2t","_id":"ckr8tjsz500j9r5p73t9430u2"},{"post_id":"ckr8tjsy000b6r5p70wfd33cw","tag_id":"ckr8tjsz400j6r5p7aq3xecu8","_id":"ckr8tjsz600jar5p7cx9vhwm2"},{"post_id":"ckr8tjsy000b6r5p70wfd33cw","tag_id":"ckr8tjsz400j7r5p73bwh7y6w","_id":"ckr8tjsz600jcr5p7etnd2ww0"},{"post_id":"ckr8tjsy200bar5p76ar92kh0","tag_id":"ckr8tjsz400j8r5p78zty94ur","_id":"ckr8tjsz600jdr5p7cdhc4avh"},{"post_id":"ckr8tjsy200bdr5p76ludg8dr","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"ckr8tjsz600jfr5p78ho48eq3"},{"post_id":"ckr8tjsy200bdr5p76ludg8dr","tag_id":"ckr8tjsz600jbr5p7c1ps8dyc","_id":"ckr8tjsz600jgr5p7hu845oz2"},{"post_id":"ckr8tjsy300bhr5p7cnyidc6z","tag_id":"ckr8tjsyh00e5r5p74uxh5obg","_id":"ckr8tjsz700jjr5p73s9p5jc1"},{"post_id":"ckr8tjsy300bhr5p7cnyidc6z","tag_id":"ckr8tjsz600jhr5p7h876992x","_id":"ckr8tjsz700jkr5p73hsl5qzq"},{"post_id":"ckr8tjsy500blr5p776azd4f2","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsz700jmr5p7eoh53p5z"},{"post_id":"ckr8tjsy500blr5p776azd4f2","tag_id":"ckr8tjswe004vr5p75ur57sac","_id":"ckr8tjsz700jnr5p7cahkaxp4"},{"post_id":"ckr8tjsy500blr5p776azd4f2","tag_id":"ckr8tjsxf0094r5p71b5sh8g0","_id":"ckr8tjsz800jpr5p7f9qn6ga9"},{"post_id":"ckr8tjsy500blr5p776azd4f2","tag_id":"ckr8tjsyt00grr5p7fphihfyy","_id":"ckr8tjsz800jqr5p7gey6ej0g"},{"post_id":"ckr8tjsy500bor5p772iw4089","tag_id":"ckr8tjsyq00g4r5p738t4dve6","_id":"ckr8tjsz800jsr5p71fet97wf"},{"post_id":"ckr8tjsy500bor5p772iw4089","tag_id":"ckr8tjsyr00g7r5p7c8jrbwce","_id":"ckr8tjsz800jtr5p76ods7l9d"},{"post_id":"ckr8tjsy600bsr5p70e27hhgf","tag_id":"ckr8tjsz800jrr5p76lakhkw0","_id":"ckr8tjsz800jvr5p7606g39gz"},{"post_id":"ckr8tjsy700bvr5p75zgbbm5q","tag_id":"ckr8tjswb004lr5p71u225fg9","_id":"ckr8tjsz800jwr5p70vmp18es"},{"post_id":"ckr8tjsy700bvr5p75zgbbm5q","tag_id":"ckr8tjsz800jur5p7humt4ryf","_id":"ckr8tjsz800jxr5p7g8jeg155"},{"post_id":"cl1t9uw7o00009op7356id00e","tag_id":"cl1t9uw8500039op7c867f2z1","_id":"cl1t9uw8b00099op7cke386y4"},{"post_id":"cl1t9uw7o00009op7356id00e","tag_id":"ckr8tjsxy00awr5p7fnr21qml","_id":"cl1t9uw8c000b9op748rm7ns5"},{"post_id":"cl1t9uw7q00019op7bqi66d56","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw8o000s9op7c81tgbi4"},{"post_id":"cl1t9uw7q00019op7bqi66d56","tag_id":"cl1t9uw8e000f9op7gysw74nz","_id":"cl1t9uw8p000w9op7gpkv0zii"},{"post_id":"cl1t9uw7q00019op7bqi66d56","tag_id":"cl1t9uw8j000k9op7ad5og7oc","_id":"cl1t9uw8r000z9op7a08q7njs"},{"post_id":"cl1t9uw8m000r9op7484o95wd","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"cl1t9uw8s00139op723f56bcy"},{"post_id":"cl1t9uw8600049op78e3f5zr8","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw8x001d9op7h2tjfbt6"},{"post_id":"cl1t9uw8600049op78e3f5zr8","tag_id":"cl1t9uw8e000f9op7gysw74nz","_id":"cl1t9uw8y001f9op77sandg0k"},{"post_id":"cl1t9uw8600049op78e3f5zr8","tag_id":"cl1t9uw8j000k9op7ad5og7oc","_id":"cl1t9uw90001k9op7ah5255aw"},{"post_id":"cl1t9uw8700059op7ge6p6duu","tag_id":"cl1t9uw8w001a9op786vkcy5y","_id":"cl1t9uw96001x9op7bu5r44fp"},{"post_id":"cl1t9uw8700059op7ge6p6duu","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw96001z9op723qh3p3a"},{"post_id":"cl1t9uw8700059op7ge6p6duu","tag_id":"cl1t9uw92001o9op74qnqb8pt","_id":"cl1t9uw9700229op7014jd3ct"},{"post_id":"cl1t9uw95001u9op7et7q5cqd","tag_id":"ckr8tjsz400j8r5p78zty94ur","_id":"cl1t9uw9700249op72bat0ub9"},{"post_id":"cl1t9uw8800069op75b8ke8qf","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw9900289op7gop2d7m8"},{"post_id":"cl1t9uw8800069op75b8ke8qf","tag_id":"cl1t9uw8w001a9op786vkcy5y","_id":"cl1t9uw9900299op7fsjwcfkn"},{"post_id":"cl1t9uw8800069op75b8ke8qf","tag_id":"cl1t9uw9700259op76mb8f88r","_id":"cl1t9uw99002b9op77ais93yn"},{"post_id":"cl1t9uw8b000a9op7g1pc4oqp","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw9a002d9op7gmaxdc4n"},{"post_id":"cl1t9uw8b000a9op7g1pc4oqp","tag_id":"cl1t9uw8e000f9op7gysw74nz","_id":"cl1t9uw9a002e9op7dh5bdxpd"},{"post_id":"cl1t9uw8b000a9op7g1pc4oqp","tag_id":"cl1t9uw99002a9op7gtdrflsq","_id":"cl1t9uw9b002g9op7c0ty8v8d"},{"post_id":"cl1t9uw8c000c9op7dkio9hyh","tag_id":"cl1t9uw8900089op79iez9q74","_id":"cl1t9uw9b002i9op7etku2mpt"},{"post_id":"cl1t9uw8c000c9op7dkio9hyh","tag_id":"cl1t9uw8e000f9op7gysw74nz","_id":"cl1t9uw9b002j9op7h0wu6d06"},{"post_id":"cl1t9uw8c000c9op7dkio9hyh","tag_id":"cl1t9uw8j000k9op7ad5og7oc","_id":"cl1t9uw9c002l9op7gc9l9hqb"},{"post_id":"cl1t9uw8h000h9op7h8k1dkp6","tag_id":"cl1t9uw9b002h9op77dh7cdwp","_id":"cl1t9uw9c002n9op7hhb9ga9b"},{"post_id":"cl1t9uw8h000h9op7h8k1dkp6","tag_id":"cl1t9uw9b002k9op79ltgfcdh","_id":"cl1t9uw9c002o9op7011fa39q"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"cl1t9uw9e002s9op76bpkdbxp"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","tag_id":"cl1t9uw9c002m9op71ot296wu","_id":"cl1t9uw9e002t9op73t2ohsgq"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","tag_id":"cl1t9uw9c002p9op7166h0fdg","_id":"cl1t9uw9e002v9op74ib79qsi"},{"post_id":"cl1t9uw8l000n9op7gzwt5dky","tag_id":"cl1t9uw9d002q9op75m1479xi","_id":"cl1t9uw9e002w9op725kj8zzt"},{"post_id":"cl1t9uw8o000t9op75nbe6zuf","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"cl1t9uw9e002y9op70dzeh9nq"},{"post_id":"cl1t9uw8o000t9op75nbe6zuf","tag_id":"cl1t9uw9d002r9op7ejqyfct8","_id":"cl1t9uw9f002z9op76immclu1"},{"post_id":"cl1t9uw8o000t9op75nbe6zuf","tag_id":"cl1t9uw9e002u9op7aspyamsw","_id":"cl1t9uw9f00319op74hzc3g4d"},{"post_id":"cl1t9uw8r00109op75fu7912q","tag_id":"ckr8tjsx2007jr5p7a6jub7mv","_id":"cl1t9uw9f00329op7a8yi4kz5"},{"post_id":"cl1t9uw8r00109op75fu7912q","tag_id":"cl1t9uw9e002x9op792ru6ec6","_id":"cl1t9uw9f00349op722bm1q7r"},{"post_id":"cl1t9uw8u00179op70ie56308","tag_id":"cl1t9uw9f00309op7br8p1gbe","_id":"cl1t9uw9g00369op7dugg6lpz"},{"post_id":"cl1t9uw8u00179op70ie56308","tag_id":"ckr8tjsux0005r5p76rdhgltb","_id":"cl1t9uw9g00379op79rpi48jw"},{"post_id":"cl1t9uw8u00179op70ie56308","tag_id":"cl1t9uw9f00339op7bs6x5mgc","_id":"cl1t9uw9g00399op7fjvh5zmx"},{"post_id":"cl1t9uw8w001b9op79ja8bqr1","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"cl1t9uw9g003a9op7cm7me0b9"},{"post_id":"cl1t9uw8w001b9op79ja8bqr1","tag_id":"cl1t9uw9f00359op75qsra9d2","_id":"cl1t9uw9h003c9op75v59enpx"},{"post_id":"cl1t9uw8x001e9op79mbncqfi","tag_id":"ckr8tjsx8008ar5p74qiz6vsd","_id":"cl1t9uw9h003d9op719x46zbe"},{"post_id":"cl1t9uw8x001e9op79mbncqfi","tag_id":"cl1t9uw9g00389op7f233aloj","_id":"cl1t9uw9h003f9op72jrvhtyh"},{"post_id":"cl1t9uw8y001g9op782gm72m6","tag_id":"cl1t9uw9g003b9op7emkq2tvy","_id":"cl1t9uw9h003g9op7alk6h1o8"},{"post_id":"cl1t9uw8y001g9op782gm72m6","tag_id":"ckr8tjsyo00fjr5p7b2qye4i0","_id":"cl1t9uw9h003h9op7053t4hc7"},{"post_id":"cl1t9uw93001p9op73fos02qn","tag_id":"cl1t9uw9h003e9op77he3dq72","_id":"cl1t9uw9i003i9op7hk2xglet"}],"Tag":[{"name":"MySQL","_id":"ckr8tjsux0005r5p76rdhgltb"},{"name":"MySQL实战45讲","_id":"ckr8tjsv1000cr5p7cs25fruw"},{"name":"算法","_id":"ckr8tjswb004lr5p71u225fg9"},{"name":"机器学习","_id":"ckr8tjswe004vr5p75ur57sac"},{"name":"决策树","_id":"ckr8tjswh0053r5p7140k283j"},{"name":"全文搜索","_id":"ckr8tjswr0068r5p79dlxa3ij"},{"name":"Elasticsearch","_id":"ckr8tjswt006fr5p73t6q8vfw"},{"name":"Hexo","_id":"ckr8tjswv006or5p70f5zf3m1"},{"name":"Mac","_id":"ckr8tjswx006xr5p7e4vxds87"},{"name":"Homebrew","_id":"ckr8tjswz0075r5p7c96s2j1l"},{"name":"Java","_id":"ckr8tjsx2007jr5p7a6jub7mv"},{"name":"JavaAgent","_id":"ckr8tjsx4007ur5p77csu27nw"},{"name":"NoSQL","_id":"ckr8tjsx60082r5p73zflbt3k"},{"name":"Redis","_id":"ckr8tjsx8008ar5p74qiz6vsd"},{"name":"监督学习","_id":"ckr8tjsxf0094r5p71b5sh8g0"},{"name":"KNN","_id":"ckr8tjsxl009dr5p77fbxbn27"},{"name":"消息队列","_id":"ckr8tjsxm009kr5p7fywi3rvt"},{"name":"Kafka","_id":"ckr8tjsxq009sr5p73eo7hy8v"},{"name":"LaTeX","_id":"ckr8tjsxr009zr5p7ccsy1gr4"},{"name":"公式","_id":"ckr8tjsxu00a9r5p7fuyae6dn"},{"name":"Linux","_id":"ckr8tjsxv00ahr5p7eoekfxvv"},{"name":"Git","_id":"ckr8tjsxy00awr5p7fnr21qml"},{"name":"Markdown","_id":"ckr8tjsy000b4r5p7gxgf61p9"},{"name":"SQL","_id":"ckr8tjsy300bfr5p7hufkcl61"},{"name":"SQL转换","_id":"ckr8tjsy500bmr5p7g53a5tdw"},{"name":"深度学习","_id":"ckr8tjsy800c0r5p7119t8roj"},{"name":"深度学习框架","_id":"ckr8tjsy900c6r5p7enr4gw03"},{"name":"PyTorch","_id":"ckr8tjsy900ccr5p745oq3pgs"},{"name":"SpringBoot","_id":"ckr8tjsyg00dvr5p7bvtjhh5i"},{"name":"词法分析","_id":"ckr8tjsyh00e5r5p74uxh5obg"},{"name":"ZooKeeper","_id":"ckr8tjsyj00ear5p7192te2a6"},{"name":"Iterm2","_id":"ckr8tjsyk00egr5p75s1ke13y"},{"name":"rz","_id":"ckr8tjsyl00elr5p70unaeslt"},{"name":"sz","_id":"ckr8tjsyl00eqr5p7gjr1726v"},{"name":"Python","_id":"ckr8tjsym00evr5p71jug383w"},{"name":"Tensorflow","_id":"ckr8tjsyo00fer5p767yp7i56"},{"name":"RPC","_id":"ckr8tjsyo00fjr5p7b2qye4i0"},{"name":"Thrift","_id":"ckr8tjsyo00fnr5p74v1bce1y"},{"name":"自然语言处理","_id":"ckr8tjsyp00fqr5p78ajs4yc7"},{"name":"中文分词","_id":"ckr8tjsyp00fur5p764656o2e"},{"name":"信息论","_id":"ckr8tjsyq00fyr5p70y2o801t"},{"name":"信息熵","_id":"ckr8tjsyq00g1r5p72n7d7mmz"},{"name":"人工智能","_id":"ckr8tjsyq00g4r5p738t4dve6"},{"name":"神经网络","_id":"ckr8tjsyr00g7r5p7c8jrbwce"},{"name":"数学","_id":"ckr8tjsyr00gar5p71jyicxwr"},{"name":"Tomcat","_id":"ckr8tjsys00gfr5p797sjcl3m"},{"name":"Slow","_id":"ckr8tjsys00gir5p7cjc93x89"},{"name":"贝叶斯","_id":"ckr8tjsyt00grr5p7fphihfyy"},{"name":"Algorithm","_id":"ckr8tjsyu00gur5p7bcx1g7k3"},{"name":"Hash","_id":"ckr8tjsyu00gxr5p72auwf3tb"},{"name":"前馈神经网络","_id":"ckr8tjsyv00h4r5p7g3uabpt1"},{"name":"卷积神经网络","_id":"ckr8tjsyv00h5r5p7127n4ycj"},{"name":"高等数学","_id":"ckr8tjsyv00h9r5p7fe4033pd"},{"name":"极限","_id":"ckr8tjsyw00hcr5p789w3ffp5"},{"name":"微积分","_id":"ckr8tjsyw00hdr5p72nm8e6wa"},{"name":"概率与统计","_id":"ckr8tjsyw00hhr5p70xxu8rbn"},{"name":"方差","_id":"ckr8tjsyx00hkr5p758db82no"},{"name":"排序","_id":"ckr8tjsyx00hlr5p7gmc35n5y"},{"name":"SVM","_id":"ckr8tjsyx00hor5p7guqmaayh"},{"name":"期望","_id":"ckr8tjsyy00hxr5p71ugtap5v"},{"name":"编译原理","_id":"ckr8tjsz300iyr5p7dsdtee2t"},{"name":"Compilers Principles","_id":"ckr8tjsz300j1r5p72b337wy9"},{"name":"编译器","_id":"ckr8tjsz400j6r5p7aq3xecu8"},{"name":"解释器","_id":"ckr8tjsz400j7r5p73bwh7y6w"},{"name":"设计模式","_id":"ckr8tjsz400j8r5p78zty94ur"},{"name":"Trace","_id":"ckr8tjsz600jbr5p7c1ps8dyc"},{"name":"语法分析","_id":"ckr8tjsz600jhr5p7h876992x"},{"name":"面试","_id":"ckr8tjsz800jrr5p76lakhkw0"},{"name":"负载均衡","_id":"ckr8tjsz800jur5p7humt4ryf"},{"name":"版本控制系统","_id":"cl1t9uw8500039op7c867f2z1"},{"name":"分布式系统","_id":"cl1t9uw8900089op79iez9q74"},{"name":"Google分布式系统","_id":"cl1t9uw8e000f9op7gysw74nz"},{"name":"大数据","_id":"cl1t9uw8j000k9op7ad5og7oc"},{"name":"Google","_id":"cl1t9uw8w001a9op786vkcy5y"},{"name":"分布式系统的跟踪系统","_id":"cl1t9uw92001o9op74qnqb8pt"},{"name":"分布式文件系统","_id":"cl1t9uw9700259op76mb8f88r"},{"name":"MapReduce","_id":"cl1t9uw99002a9op7gtdrflsq"},{"name":"IntelliJ IDEA破解","_id":"cl1t9uw9b002h9op77dh7cdwp"},{"name":"破解","_id":"cl1t9uw9b002k9op79ltgfcdh"},{"name":"多态性","_id":"cl1t9uw9c002m9op71ot296wu"},{"name":"重写","_id":"cl1t9uw9c002p9op7166h0fdg"},{"name":"重载","_id":"cl1t9uw9d002q9op75m1479xi"},{"name":"静态绑定","_id":"cl1t9uw9d002r9op7ejqyfct8"},{"name":"动态绑定","_id":"cl1t9uw9e002u9op7aspyamsw"},{"name":"程序设计","_id":"cl1t9uw9e002x9op792ru6ec6"},{"name":"数据库","_id":"cl1t9uw9f00309op7br8p1gbe"},{"name":"Innodb","_id":"cl1t9uw9f00339op7bs6x5mgc"},{"name":"Redis对象类型","_id":"cl1t9uw9f00359op75qsra9d2"},{"name":"Redis数据结构","_id":"cl1t9uw9g00389op7f233aloj"},{"name":"gRPC","_id":"cl1t9uw9g003b9op7emkq2tvy"},{"name":"计算机科学","_id":"cl1t9uw9h003e9op77he3dq72"}]}}